[
  "",
  "ID: '1004'\nName: Sensitive Cookie Without 'HttpOnly' Flag\nDescription: The product uses a cookie to store sensitive information, but the cookie\n  is not marked with the HttpOnly flag.\nExtended_Description: The HttpOnly flag directs compatible browsers to prevent client-side\n  script from accessing cookies. Including the HttpOnly flag in the Set-Cookie HTTP\n  response header helps mitigate the risk associated with Cross-Site Scripting (XSS)\n  where an attacker's script code might attempt to read the contents of a cookie and\n  exfiltrate information obtained. When set, browsers that support the flag will not\n  reveal the contents of the cookie to a third party via client-side script executed\n  via XSS.\nApplicable_Platforms:\n  Technology: Web Based\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Leverage the HttpOnly flag when setting a\n  sensitive cookie in a response.'\nObserved_Examples: 'CVE-2014-3852: CMS written in Python does not include the HTTPOnly\n  flag in a Set-Cookie header, allowing remote attackers to obtain potentially sensitive\n  information via script access to this cookie.\n\n\n  CVE-2015-4138: Appliance for managing encrypted communications does not use HttpOnly\n  flag.'\n",
  "ID: '1007'\nName: Insufficient Visual Distinction of Homoglyphs Presented to User\nDescription: The product displays information or identifiers to a user, but the display\n  mechanism does not make it easy for the user to distinguish between visually similar\n  or identical glyphs (homoglyphs), which may cause the user to misinterpret a glyph\n  and perform an unintended, insecure action.\nExtended_Description: \"Some glyphs, pictures, or icons can be semantically distinct\\\n  \\ to a program, while appearing very similar or identical to a human user. These\\\n  \\ are referred to as homoglyphs. For example, the lowercase \\\"l\\\" (ell) and uppercase\\\n  \\ \\\"I\\\" (eye) have different character codes, but these characters can be displayed\\\n  \\ in exactly the same way to a user, depending on the font. This can also occur\\\n  \\ between different character sets. For example, the Latin capital letter \\\"A\\\"\\\n  \\ and the Greek capital letter \\\"\\u0391\\\" (Alpha) are treated as distinct by programs,\\\n  \\ but may be displayed in exactly the same way to a user. Accent marks may also\\\n  \\ cause letters to appear very similar, such as the Latin capital letter grave mark\\\n  \\ \\\"\\xC0\\\" and its equivalent \\\"\\xC1\\\" with the acute accent.\\nAdversaries can exploit\\\n  \\ this visual similarity for attacks such as phishing, e.g. by providing a link\\\n  \\ to an attacker-controlled hostname that looks like a hostname that the victim\\\n  \\ trusts. In a different use of homoglyphs, an adversary may create a back door\\\n  \\ username that is visually similar to the username of a regular user, which then\\\n  \\ makes it more difficult for a system administrator to detect the malicious username\\\n  \\ while reviewing logs.\"\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: 'Homograph Attack: \"Homograph\" is often used as a synonym of \"homoglyph\"\n  by researchers, but according to Wikipedia, a homograph is a word that has multiple,\n  distinct meanings.'\nModes_Of_Introduction: 'Architecture and Design: This weakness may occur when characters\n  from various character sets are allowed to be interchanged within a URL, username,\n  email address, etc. without any notification to the user or underlying system being\n  used.\n\n\n  Implementation: '\nDetection_Methods: 'Manual Dynamic Analysis: If utilizing user accounts, attempt to\n  submit a username that contains homoglyphs. Similarly, check to see if links containing\n  homoglyphs can be sent via email, web browsers, or other mechanisms.'\nPotential_Mitigations: 'Implementation: Use a browser that displays Punycode for IDNs\n  in the URL and status bars, or which color code various scripts in URLs.\n\n  Due to the prominence of homoglyph attacks, several browsers now help safeguard\n  against this attack via the use of Punycode. For example, Mozilla Firefox and Google\n  Chrome will display IDNs as Punycode if top-level domains do not restrict which\n  characters can be used in domain names or if labels mix scripts for different languages.\n\n\n  Implementation: Use an email client that has strict filters and prevents messages\n  that mix character sets to end up in a user''s inbox.\n\n  Certain email clients such as Google''s GMail prevent the use of non-Latin characters\n  in email addresses or in links contained within emails. This helps prevent homoglyph\n  attacks by flagging these emails and redirecting them to a user''s spam folder.'\nObserved_Examples: 'CVE-2013-7236: web forum allows impersonation of users with homoglyphs\n  in account names\n\n\n  CVE-2012-0584: Improper character restriction in URLs in web browser\n\n\n  CVE-2009-0652: Incomplete denylist does not include homoglyphs of \"/\" and \"?\" characters\n  in URLs\n\n\n  CVE-2017-5015: web browser does not convert hyphens to punycode, allowing IDN spoofing\n  in URLs\n\n\n  CVE-2005-0233: homoglyph spoofing using punycode in URLs and certificates\n\n\n  CVE-2005-0234: homoglyph spoofing using punycode in URLs and certificates\n\n\n  CVE-2005-0235: homoglyph spoofing using punycode in URLs and certificates'\nRelated_Attack_Patterns: '632: '\n",
  "ID: '102'\nName: 'Struts: Duplicate Validation Forms'\nDescription: The product uses multiple validation forms with the same name, which\n  might cause the Struts Validator to validate a form that the programmer does not\n  expect.\nExtended_Description: If two validation forms have the same name, the Struts Validator\n  arbitrarily chooses one of the forms to use for input validation and discards the\n  other. This decision might not correspond to the programmer's expectations, possibly\n  leading to resultant weaknesses. Moreover, it indicates that the validation logic\n  is not up-to-date, and can indicate that other, more subtle validation errors are\n  present.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: The DTD or schema validation will not catch\n  the duplicate occurrence of the same form name. To find the issue in the implementation,\n  manual checks or automated static analysis could be applied to the xml configuration\n  files.'\n",
  "ID: '1021'\nName: Improper Restriction of Rendered UI Layers or Frames\nDescription: The web application does not restrict or incorrectly restricts frame\n  objects or UI layers that belong to another application or domain, which can lead\n  to user confusion about which interface the user is interacting with.\nExtended_Description: A web application is expected to place restrictions on whether\n  it is allowed to be rendered within frames, iframes, objects, embed or applet elements.\n  Without the restrictions, users can be tricked into interacting with the application\n  when they were not intending to.\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: \"Clickjacking: \\n\\nUI Redress Attack: \\n\\nTapjacking: \\\"Tapjacking\\\"\\\n  \\ is similar to clickjacking, except it is used for mobile applications in which\\\n  \\ the user \\\"taps\\\" the application instead of performing a mouse click.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: The use of X-Frame-Options allows developers\n  of web content to restrict the usage of their application within the form of overlays,\n  frames, or iFrames. The developer can indicate from which domains can frame the\n  content.\n\n  The concept of X-Frame-Options is well documented, but implementation of this protection\n  mechanism is in development to cover gaps. There is a need for allowing frames from\n  multiple domains.\n\n\n  Implementation: A developer can use a \"frame-breaker\" script in each page that should\n  not be framed. This is very helpful for legacy browsers that do not support X-Frame-Options\n  security feature previously mentioned.\n\n  It is also important to note that this tactic has been circumvented or bypassed.\n  Improper usage of frames can persist in the web application through nested frames.\n  The \"frame-breaking\" script does not intuitively account for multiple nested frames\n  that can be presented to the user.\n\n\n  Implementation: This defense-in-depth technique can be used to prevent the improper\n  usage of frames in web applications. It prioritizes the valid sources of data to\n  be loaded into the application through the usage of declarative policies. Based\n  on which implementation of Content Security Policy is in use, the developer should\n  use the \"frame-ancestors\" directive or the \"frame-src\" directive to mitigate this\n  weakness. Both directives allow for the placement of restrictions when it comes\n  to allowing embedded content.'\nObserved_Examples: 'CVE-2017-7440: E-mail preview feature in a desktop application\n  allows clickjacking attacks via a crafted e-mail message\n\n\n  CVE-2017-5697: Hardware/firmware product has insufficient clickjacking protection\n  in its web user interface\n\n\n  CVE-2017-4015: Clickjacking in data-loss prevention product via HTTP response header.\n\n\n  CVE-2016-2496: Tapjacking in permission dialog for mobile OS allows access of private\n  storage using a partially-overlapping window.\n\n\n  CVE-2015-1241: Tapjacking in web browser related to page navigation and touch/gesture\n  events.\n\n\n  CVE-2017-0492: System UI in mobile OS allows a malicious application to create a\n  UI overlay of the entire screen to gain privileges.'\nRelated_Attack_Patterns: \"103: \\n\\n181: \\n\\n222: \\n\\n504: \\n\\n506: \\n\\n587: \\n\\n654: \"\n",
  "ID: '1022'\nName: Use of Web Link to Untrusted Target with window.opener Access\nDescription: The web application produces links to untrusted external sites outside\n  of its sphere of control, but it does not properly prevent the external site from\n  modifying  security-critical properties of the window.opener object, such as the\n  location property.\nExtended_Description: When a user clicks a link to an external site (\"target\"), the\n  target=\"_blank\" attribute causes the target site's contents to be opened in a new\n  window or tab, which runs in the same process as the original page. The window.opener\n  object records information about the original page that offered the link.  If an\n  attacker can run script on the target page, then they could read or modify certain\n  properties of the window.opener object, including the location property - even if\n  the original and target site are not the same origin.  An attacker can modify the\n  location property to automatically redirect the user to a malicious site, e.g. as\n  part of a phishing attack. Since this redirect happens in the original window/tab\n  - which is not necessarily visible, since the browser is focusing the display on\n  the new target page - the user might not notice any suspicious redirection.\nApplicable_Platforms:\n  Language: JavaScript\n  Technology: Web Based\nModes_Of_Introduction: 'Architecture and Design: This weakness is introduced during\n  the design of an application when the architect does not specify that a linked external\n  document should not be able to alter the location of the calling page.\n\n\n  Implementation: This weakness is introduced during the coding of an application\n  when the developer does not include the noopener and/or noreferrer value for the\n  rel attribute.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Specify in the design that any linked\n  external document must not be granted access to the location object of the calling\n  page.\n\n\n  Implementation: When creating a link to an external document using the <a> tag with\n  a defined target, for example \"_blank\" or a named frame, provide the rel attribute\n  with a value \"noopener noreferrer\".\n\n  If opening the external document in a new window via javascript, then reset the\n  opener by setting it equal to null.\n\n\n  Implementation: Do not use \"_blank\" targets. However, this can affect the usability\n  of the application.'\n",
  "ID: '1023'\nName: Incomplete Comparison with Missing Factors\nDescription: The product performs a comparison between entities that must consider\n  multiple factors or characteristics of each entity, but the comparison does not\n  include one or more of these factors.\nExtended_Description: An incomplete comparison can lead to resultant weaknesses, e.g.,\n  by operating on the wrong object or making a security decision without considering\n  a required factor.\nPotential_Mitigations: 'Testing: Thoroughly test the comparison scheme before deploying\n  code into production. Perform positive testing as well as negative testing.'\n",
  "ID: '1024'\nName: Comparison of Incompatible Types\nDescription: The product performs a comparison between two entities, but the entities\n  are of different, incompatible types that cannot be guaranteed to provide correct\n  results when they are directly compared.\nExtended_Description: In languages that are strictly typed but support casting/conversion,\n  such as C or C++, the programmer might assume that casting one entity to the same\n  type as another entity will ensure that the comparison will be performed correctly,\n  but this cannot be guaranteed.  In languages that are not strictly typed, such as\n  PHP or JavaScript, there may be implicit casting/conversion to a type that the programmer\n  is unaware of, causing unexpected results; for example, the string \"123\" might be\n  converted to a number type.  See examples.\nApplicable_Platforms:\n  Language: JavaScript, PHP\nPotential_Mitigations: 'Testing: Thoroughly test the comparison scheme before deploying\n  code into production. Perform positive testing as well as negative testing.'\n",
  "ID: '1025'\nName: Comparison Using Wrong Factors\nDescription: The code performs a comparison between two entities, but the comparison\n  examines the wrong factors or characteristics of the entities, which can lead to\n  incorrect results and resultant weaknesses.\nExtended_Description: This can lead to incorrect results and resultant weaknesses.  For\n  example, the code might inadvertently compare references to objects, instead of\n  the relevant contents of those objects, causing two \"equal\" objects to be considered\n  unequal.\nPotential_Mitigations: 'Testing: Thoroughly test the comparison scheme before deploying\n  code into production. Perform positive testing as well as negative testing.'\n",
  "ID: '103'\nName: 'Struts: Incomplete validate() Method Definition'\nDescription: The product has a validator form that either does not define a validate()\n  method, or defines a validate() method but does not call super.validate().\nExtended_Description: If the code does not call super.validate(), the Validation Framework\n  cannot check the contents of the form against a validation form. In other words,\n  the validation framework will be disabled for the given form.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Implement the validate() method and call super.validate()\n  within that method.'\n",
  "ID: '1037'\nName: Processor Optimization Removal or Modification of Security-critical Code\nDescription: The developer builds a security-critical protection mechanism into the\n  software, but the processor optimizes the execution of the program such that the\n  mechanism is removed or modified.\nApplicable_Platforms:\n  Technology: Processor Hardware\nModes_Of_Introduction: 'Architecture and Design: Optimizations built into the design\n  of the processor can have unintended consequences during the execution of an application.'\nDetection_Methods: 'White Box: In theory this weakness can be detected through the\n  use of white box testing techniques where specifically crafted test cases are used\n  in conjunction with debuggers to verify the order of statements being executed.\n\n  Although the mentioned detection method is theoretically possible, the use of speculative\n  execution is a preferred way of increasing processor performance. The reality is\n  that a large number of statements are executed out of order, and determining if\n  any of them break an access control property would be extremely opportunistic.'\nObserved_Examples: 'CVE-2017-5715: Intel, ARM, and AMD processor optimizations related\n  to speculative execution and branch prediction cause access control checks to be\n  bypassed when placing data into the cache. Often known as \"Spectre\".\n\n\n  CVE-2017-5753: Intel, ARM, and AMD processor optimizations related to speculative\n  execution and branch prediction cause access control checks to be bypassed when\n  placing data into the cache. Often known as \"Spectre\".\n\n\n  CVE-2017-5754: Intel processor optimizations related to speculative execution cause\n  access control checks to be bypassed when placing data into the cache. Often known\n  as \"Meltdown\".'\nRelated_Attack_Patterns: '663: '\n",
  "ID: '1038'\nName: Insecure Automated Optimizations\nDescription: The product uses a mechanism that automatically optimizes code, e.g.\n  to improve a characteristic such as performance, but the optimizations can have\n  an unintended side effect that might violate an intended security assumption.\nModes_Of_Introduction: 'Architecture and Design: Optimizations built into the design\n  of a product can have unintended consequences during execution.'\n",
  "ID: '1039'\nName: Automated Recognition Mechanism with Inadequate Detection or Handling of Adversarial\n  Input Perturbations\nDescription: The product uses an automated mechanism such as machine learning to recognize\n  complex data inputs (e.g. image or audio) as a particular concept or category, but\n  it does not properly detect or handle inputs that have been modified or constructed\n  in a way that causes the mechanism to detect a different, incorrect concept.\nExtended_Description: 'When techniques such as machine learning are used to automatically\n  classify input streams, and those classifications are used for security-critical\n  decisions, then any mistake in classification can introduce a vulnerability that\n  allows attackers to cause the product to make the wrong security decision.  If the\n  automated mechanism is not developed or \"trained\" with enough input data, then attackers\n  may be able to craft malicious input that intentionally triggers the incorrect classification.\n\n  Targeted technologies include, but are not necessarily limited to:\n\n  For example, an attacker might modify road signs or road surface markings to trick\n  autonomous vehicles into misreading the sign/marking and performing a dangerous\n  action.'\nModes_Of_Introduction: 'Architecture and Design: This issue can be introduced into\n  the automated algorithm itself.'\n",
  "ID: '104'\nName: 'Struts: Form Bean Does Not Extend Validation Class'\nDescription: If a form bean does not extend an ActionForm subclass of the Validator\n  framework, it can expose the application to other weaknesses related to insufficient\n  input validation.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Ensure that all forms extend one of the Validation\n  Classes.'\n",
  "ID: '1041'\nName: Use of Redundant Code\nDescription: \"The product has multiple functions, methods, procedures, macros, etc.\\\n  \\ that\\n\\t\\t\\t\\t\\tcontain the same code.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  For example, if there are two copies of the\n  same code, the programmer might fix a weakness in one copy while forgetting to fix\n  the same weakness in another copy.\nPotential_Mitigations: 'Implementation: Merge common functionality into a single function\n  and then call that function from across the entire code base.'\n",
  "ID: '1042'\nName: Static Member Data Element outside of a Singleton Class Element\nDescription: \"The code contains a member element that is declared as static (but not\\\n  \\ final), in which\\n\\t\\t\\t\\t\\tits parent class element \\n\\t\\t\\t\\t\\tis not a singleton\\\n  \\ class - that is, a class element that can be used only once in\\n\\t\\t\\t\\t\\tthe\\\n  \\ 'to' association of a Create action.\"\nExtended_Description: This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n",
  "ID: '1043'\nName: Data Element Aggregating an Excessively Large Number of Non-Primitive Elements\nDescription: \"The product uses a data element that has an excessively large\\n\\t\\t\\t\\\n  \\t\\tnumber of sub-elements with non-primitive data types such as structures or aggregated\\\n  \\ objects.\"\nExtended_Description: 'This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n\n  While the interpretation of \"excessively large\" may vary for each product or developer,\n  CISQ recommends a default of 5 sub-elements.'\n",
  "ID: '1044'\nName: Architecture with Number of Horizontal Layers Outside of Expected Range\nDescription: \"The product's architecture contains too many - or too few -\\n\\t\\t\\t\\t\\\n  \\thorizontal layers.\"\nExtended_Description: 'This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"expected range\" may vary for each product or developer,\n  CISQ recommends a default minimum of 4 layers and maximum of 8 layers.'\n",
  "ID: '1045'\nName: Parent Class with a Virtual Destructor and a Child Class without a Virtual Destructor\nDescription: A parent class has a virtual destructor method, but the parent has a\n  child class that does not have a virtual destructor.\nExtended_Description: This issue can prevent the product from running reliably, since\n  the child might not perform essential destruction operations.  If the relevant code\n  is reachable by an attacker, then this reliability problem might introduce a vulnerability,\n  such as a memory leak (CWE-401).\n",
  "ID: '1046'\nName: Creation of Immutable Text Using String Concatenation\nDescription: The product creates an immutable text string using string concatenation\n  operations.\nExtended_Description: When building a string via a looping feature (e.g., a FOR or\n  WHILE loop), the use of += to append to the existing string will result in the creation\n  of a new object with each iteration. This programming pattern can be inefficient\n  in comparison with use of text buffer data elements. This issue can make the product\n  perform more slowly. If the relevant code is reachable by an attacker, then this\n  could be influenced to create performance problem.\n",
  "ID: '1047'\nName: Modules with Circular Dependencies\nDescription: The product contains modules in which one module has references that\n  cycle back to itself, i.e., there are circular dependencies.\nExtended_Description: 'As an example, with Java, this weakness might indicate cycles\n  between packages.\n\n  This issue makes it more difficult to maintain the product due to insufficient modularity,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  This issue can prevent the product from running reliably.  If the relevant code\n  is reachable by an attacker, then this reliability problem might introduce a vulnerability.'\n",
  "ID: '1048'\nName: Invokable Control Element with Large Number of Outward Calls\nDescription: \"The code contains callable control elements that\\n         contain an\\\n  \\ excessively large number of references to other\\n         application objects\\\n  \\ external to the context of the callable,\\n         i.e. a Fan-Out value that is\\\n  \\ excessively large.\"\nExtended_Description: 'While the interpretation of \"excessively large Fan-Out value\"\n  may vary for each product or developer, CISQ recommends a default of 5 referenced\n  objects.\n\n  This issue makes it more difficult to maintain the product, which indirectly affects\n  security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It\n  also might make it easier to introduce vulnerabilities.'\n",
  "ID: '1049'\nName: Excessive Data Query Operations in a Large Data Table\nDescription: \"The product performs a data query with a large number of joins\\n\\t\\t\\\n  \\t\\t\\tand sub-queries on a large data table.\"\nExtended_Description: 'This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n\n  While the interpretation of \"large data table\" and \"large number of joins or sub-queries\"\n  may vary for each product or developer, CISQ recommends a default of 1 million rows\n  for a \"large\" data table, a default minimum of 5 joins, and a default minimum of\n  3 sub-queries.'\n",
  "ID: '105'\nName: 'Struts: Form Field Without Validator'\nDescription: The product has a form field that is not validated by a corresponding\n  validation form, which can introduce other weaknesses related to insufficient input\n  validation.\nExtended_Description: Omitting validation for even a single input field may give attackers\n  the leeway they need to compromise the product. Although J2EE applications are not\n  generally susceptible to memory corruption attacks, if a J2EE application interfaces\n  with native code that does not perform array bounds checking, an attacker may be\n  able to use an input validation mistake in the J2EE application to launch a buffer\n  overflow attack.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: 'Implementation: Some products use the same ActionForm for\n  more than one purpose. In situations like this, some fields may go unused under\n  some action mappings.'\nPotential_Mitigations: 'Implementation: Validate all form fields. If a field is unused,\n  it is still important to constrain it so that it is empty or undefined.'\n",
  "ID: '1050'\nName: Excessive Platform Resource Consumption within a Loop\nDescription: \"The product has a loop body or loop condition that contains a control\\\n  \\ element that directly or\\n\\t\\t\\t\\t\\tindirectly consumes platform resources, e.g.\\\n  \\ messaging, sessions, locks, or file\\n\\t\\t\\t\\t\\tdescriptors.\"\nExtended_Description: This issue can make the product perform more slowly.  If an\n  attacker can influence the number of iterations in the loop, then this performance\n  problem might allow a denial of service by consuming more platform resources than\n  intended.\n",
  "ID: '1051'\nName: Initialization with Hard-Coded Network Resource Configuration Data\nDescription: The product initializes data using hard-coded values that act as network\n  resource identifiers.\nExtended_Description: This issue can prevent the product from running reliably, e.g.\n  if it runs in an environment does not use the hard-coded network resource identifiers.\n  If the relevant code is reachable by an attacker, then this reliability problem\n  might introduce a vulnerability.\n",
  "ID: '1052'\nName: Excessive Use of Hard-Coded Literals in Initialization\nDescription: \"The product initializes a data element using a hard-coded\\n\\t\\t\\t\\t\\t\\\n  literal that is not a simple integer or static constant element.\"\nExtended_Description: This issue makes it more difficult to modify or maintain the\n  product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1053'\nName: Missing Documentation for Design\nDescription: The product does not have documentation that represents how it is designed.\nExtended_Description: This issue can make it more difficult to understand and maintain\n  the product. It can make it more difficult and time-consuming to detect and/or fix\n  vulnerabilities.\n",
  "ID: '1054'\nName: Invocation of a Control Element at an Unnecessarily Deep Horizontal Layer\nDescription: \"The code at one architectural layer invokes code that resides\\n\\t\\t\\t\\\n  \\t\\tat a deeper layer than the adjacent layer, i.e., the invocation skips at least\\\n  \\ one\\n\\t\\t\\t\\t\\tlayer, and the invoked code is not part of a vertical utility layer\\\n  \\ that can be referenced from any horizontal layer.\"\nExtended_Description: This issue makes it more difficult to understand and maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1055'\nName: Multiple Inheritance from Concrete Classes\nDescription: \"The product contains a class with inheritance from more than\\n\\t\\t\\t\\\n  \\t\\tone concrete class.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1056'\nName: Invokable Control Element with Variadic Parameters\nDescription: \"A named-callable or method control element has a signature that\\n\\t\\t\\\n  \\t\\t\\tsupports a variable (variadic) number of parameters or arguments.\"\nExtended_Description: 'This issue can prevent the product from running reliably.  If\n  the relevant code is reachable by an attacker, then this reliability problem might\n  introduce a vulnerability.\n\n  With variadic arguments, it can be difficult or inefficient for manual analysis\n  to be certain of which function/method is being invoked.'\n",
  "ID: '1057'\nName: Data Access Operations Outside of Expected Data Manager Component\nDescription: The product uses a dedicated, central data manager component as required\n  by design, but it contains code that performs data-access operations that do not\n  use this data manager.\nExtended_Description: This issue can make the product perform more slowly than intended,\n  since the intended central data manager may have been explicitly optimized for performance\n  or other quality characteristics.  If the relevant code is reachable by an attacker,\n  then this performance problem might introduce a vulnerability.\n",
  "ID: '1058'\nName: Invokable Control Element in Multi-Thread Context with non-Final Static Storable\n  or Member Element\nDescription: \"The code contains a function or method that\\n\\t\\t operates in a multi-threaded\\\n  \\ environment but owns an unsafe non-final\\n\\t\\t                     static storable\\\n  \\ or member data element.\"\nExtended_Description: This issue can prevent the product from running reliably.  If\n  the relevant code is reachable by an attacker, then this reliability problem might\n  introduce a vulnerability.\n",
  "ID: '1059'\nName: Insufficient Technical Documentation\nDescription: \"The product does not contain sufficient\\n         technical or engineering\\\n  \\ documentation (whether on paper or\\n         in electronic form) that contains\\\n  \\ descriptions of all the\\n         relevant software/hardware elements of the product,\\\n  \\ such as\\n         its usage, structure, architectural components, interfaces,\\\n  \\ design, implementation,\\n         configuration, operation, etc.\"\nExtended_Description: 'When technical documentation is limited or lacking, products\n  are more difficult to maintain.  This indirectly affects security by making it more\n  difficult or time-consuming to find and/or fix vulnerabilities.\n\n  When using time-limited or labor-limited third-party/in-house security consulting\n  services (such as threat modeling, vulnerability discovery, or pentesting), insufficient\n  documentation can force those consultants to invest unnecessary time in learning\n  how the product is organized, instead of focusing their expertise on finding the\n  flaws or suggesting effective mitigations.\n\n  With respect to hardware design, the lack of a formal, final manufacturer reference\n  can make it difficult or impossible to evaluate the final product, including post-manufacture\n  verification. One cannot ensure that design functionality or operation is within\n  acceptable tolerances, conforms to specifications, and is free from unexpected behavior.\n  Hardware-related documentation may include engineering artifacts such as hardware\n  description language (HDLs), netlists, Gerber files, Bills of Materials, EDA (Electronic\n  Design Automation) tool files, etc.'\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nDocumentation: \"\nPotential_Mitigations: 'Documentation\n\n  Architecture and Design: Ensure that design documentation is detailed enough to\n  allow for post-manufacturing verification.'\n",
  "ID: '106'\nName: 'Struts: Plug-in Framework not in Use'\nDescription: When an application does not use an input validation framework such as\n  the Struts Validator, there is a greater risk of introducing weaknesses related\n  to insufficient input validation.\nExtended_Description: 'Unchecked input is the leading cause of vulnerabilities in\n  J2EE applications. Unchecked input leads to cross-site scripting, process control,\n  and SQL injection vulnerabilities, among others.\n\n  Although J2EE applications are not generally susceptible to memory corruption attacks,\n  if a J2EE application interfaces with native code that does not perform array bounds\n  checking, an attacker may be able to use an input validation mistake in the J2EE\n  application to launch a buffer overflow attack.'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Architecture and Design: Use an input validation framework\n  such as Struts.\n\n\n  Architecture and Design: Use an input validation framework such as Struts.\n\n\n  Implementation: Use the Struts Validator to validate all program input before it\n  is processed by the application. Ensure that there are no holes in the configuration\n  of the Struts Validator. Example uses of the validator include checking to ensure\n  that:\n\n\n  Implementation: Use the Struts Validator to validate all program input before it\n  is processed by the application. Ensure that there are no holes in the configuration\n  of the Struts Validator. Example uses of the validator include checking to ensure\n  that:'\n",
  "ID: '1060'\nName: Excessive Number of Inefficient Server-Side Data Accesses\nDescription: The product performs too many data queries without using efficient data\n  processing functionality such as stored procedures.\nExtended_Description: 'This issue can make the product perform more slowly due to\n  computational expense.  If the relevant code is reachable by an attacker, then this\n  performance problem might introduce a vulnerability.\n\n  While the interpretation of \"too many data queries\" may vary for each product or\n  developer, CISQ recommends a default maximum of 5 data queries for an inefficient\n  function/procedure.'\n",
  "ID: '1061'\nName: Insufficient Encapsulation\nDescription: The product does not sufficiently hide the internal representation and\n  implementation details of data or methods, which might allow external components\n  or modules to modify data unexpectedly, invoke unexpected functionality, or introduce\n  dependencies that the programmer did not intend.\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1062'\nName: Parent Class with References to Child Class\nDescription: The code has a parent class that contains references to a child class,\n  its methods, or its members.\nExtended_Description: This issue can prevent the product from running reliably.  If\n  the relevant code is reachable by an attacker, then this reliability problem might\n  introduce a vulnerability.\n",
  "ID: '1063'\nName: Creation of Class Instance within a Static Code Block\nDescription: A static code block creates an instance of a class.\nExtended_Description: 'This pattern identifies situations where a storable data element\n  or member data element is initialized with a value in a block of code which is declared\n  as static.\n\n  This issue can make the product perform more slowly by performing initialization\n  before it is needed.  If the relevant code is reachable by an attacker, then this\n  performance problem might introduce a vulnerability.'\n",
  "ID: '1064'\nName: Invokable Control Element with Signature Containing an Excessive Number of Parameters\nDescription: \"The product contains a function, subroutine, or method whose signature\\\n  \\ has an unnecessarily large number of\\n\\t\\t\\t\\t\\tparameters/arguments.\"\nExtended_Description: 'This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"large number of parameters.\" may vary for each product\n  or developer, CISQ recommends a default maximum of 7 parameters/arguments.'\n",
  "ID: '1065'\nName: Runtime Resource Management Control Element in a Component Built to Run on Application\n  Servers\nDescription: The product uses deployed components from application servers, but it\n  also uses low-level functions/methods for management of resources, instead of the\n  API provided by the application server.\nExtended_Description: This issue can prevent the product from running reliably.  If\n  the relevant code is reachable by an attacker, then this reliability problem might\n  introduce a vulnerability.\n",
  "ID: '1066'\nName: Missing Serialization Control Element\nDescription: \"The product contains a serializable data element that does not\\n\\t\\t\\\n  \\t\\t\\thave an associated serialization method.\"\nExtended_Description: 'This issue can prevent the product from running reliably, e.g.\n  by triggering an exception.  If the relevant code is reachable by an attacker, then\n  this reliability problem might introduce a vulnerability.\n\n  As examples, the serializable nature of a data element comes from a serializable\n  SerializableAttribute attribute in .NET and the inheritance from the java.io.Serializable\n  interface in Java.'\n",
  "ID: '1067'\nName: Excessive Execution of Sequential Searches of Data Resource\nDescription: \"The product contains a data query against an SQL table or view\\n\\t\\t\\\n  \\t\\t\\tthat is configured in a way that does not utilize an index and may cause\\n\\\n  \\t\\t\\t\\t\\tsequential searches to be performed.\"\nExtended_Description: This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n",
  "ID: '1068'\nName: Inconsistency Between Implementation and Documented Design\nDescription: \"The implementation of the product is not consistent with the\\n\\t\\t\\t\\\n  \\t\\tdesign as described within the relevant documentation.\"\nExtended_Description: This issue makes it more difficult to maintain the product due\n  to inconsistencies, which indirectly affects security by making it more difficult\n  or time-consuming to find and/or fix vulnerabilities.  It also might make it easier\n  to introduce vulnerabilities.\nApplicable_Platforms:\n  Technology: ICS/OT\n",
  "ID: '1069'\nName: Empty Exception Block\nDescription: An invokable code block contains an exception handling block that does\n  not contain any code, i.e. is empty.\nExtended_Description: When an exception handling block (such as a Catch and Finally\n  block) is used, but that block is empty, this can prevent the product from running\n  reliably.  If the relevant code is reachable by an attacker, then this reliability\n  problem might introduce a vulnerability.\nPotential_Mitigations: 'Implementation: For every exception block add code that handles\n  the specific exception in the way intended by the application.'\n",
  "ID: '107'\nName: 'Struts: Unused Validation Form'\nDescription: An unused validation form indicates that validation logic is not up-to-date.\nExtended_Description: It is easy for developers to forget to update validation logic\n  when they remove or rename action form mappings. One indication that validation\n  logic is not being properly maintained is the presence of an unused validation form.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Implementation: Remove the unused Validation Form from the\n  validation.xml file.'\n",
  "ID: '1070'\nName: Serializable Data Element Containing non-Serializable Item Elements\nDescription: \"The product contains a serializable, storable data element such as a\\\n  \\ field or member,\\n\\t\\t\\t\\t\\tbut the data element contains member elements that\\\n  \\ are not\\n\\t\\t\\t\\t\\tserializable.\"\nExtended_Description: 'This issue can prevent the product from running reliably.  If\n  the relevant code is reachable by an attacker, then this reliability problem might\n  introduce a vulnerability.\n\n  As examples, the serializable nature of a data element comes from a serializable\n  SerializableAttribute attribute in .NET and the inheritance from the java.io.Serializable\n  interface in Java.'\n",
  "ID: '1071'\nName: Empty Code Block\nDescription: The source code contains a block that does not contain any code, i.e.,\n  the block is empty.\nExtended_Description: Empty code blocks can occur in the bodies of conditionals, function\n  or method definitions, exception handlers, etc.  While an empty code block might\n  be intentional, it might also indicate incomplete implementation, accidental code\n  deletion, unexpected macro expansion, etc.  For some programming languages and constructs,\n  an empty block might be allowed by the syntax, but the lack of any behavior within\n  the block might violate a convention or API in such a way that it is an error.\n",
  "ID: '1072'\nName: Data Resource Access without Use of Connection Pooling\nDescription: \"The product accesses a data resource through a database without using\\\n  \\ a\\n\\t\\t\\t\\t\\tconnection pooling capability.\"\nExtended_Description: This issue can make the product perform more slowly, as connection\n  pools allow connections to be reused without the overhead and time consumption of\n  opening and closing a new connection.  If the relevant code is reachable by an attacker,\n  then this performance problem might introduce a vulnerability.\n",
  "ID: '1073'\nName: Non-SQL Invokable Control Element with Excessive Number of Data Resource Accesses\nDescription: The product contains a client with a function or method that contains\n  a large number of data accesses/queries that are sent through a data manager, i.e.,\n  does not use efficient database capabilities.\nExtended_Description: 'This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n\n  While the interpretation of \"large number of data accesses/queries\" may vary for\n  each product or developer, CISQ recommends a default maximum of 2 data accesses\n  per function/method.'\n",
  "ID: '1074'\nName: Class with Excessively Deep Inheritance\nDescription: \"A class has an inheritance level that is too high, i.e., it\\n\\t\\t\\t\\t\\\n  \\thas a large number of parent classes.\"\nExtended_Description: 'This issue makes it more difficult to understand and maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"large number of parent classes\" may vary for each product\n  or developer, CISQ recommends a default maximum of 7 parent classes.'\n",
  "ID: '1075'\nName: Unconditional Control Flow Transfer outside of Switch Block\nDescription: \"The product performs unconditional control transfer (such as a\\n\\t\\t\\\n  \\t\\t\\t\\\"goto\\\") in code outside of a branching structure such as a switch\\n\\t\\t\\t\\\n  \\t\\tblock.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1076'\nName: Insufficient Adherence to Expected Conventions\nDescription: \"The product's architecture, source code, design, documentation,\\n\\t\\t\\\n  \\t\\t\\tor other artifact does not follow required conventions.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1077'\nName: Floating Point Comparison with Incorrect Operator\nDescription: \"The code performs a comparison such as an\\n        equality test between\\\n  \\ two float (floating point) values, but\\n        it uses comparison operators that\\\n  \\ do not account for the\\n        possibility of loss of precision.\"\nExtended_Description: \"Numeric calculation using floating point values\\n\\t   can generate\\\n  \\ imprecise results because of rounding errors.\\n\\t   As a result, two different\\\n  \\ calculations might generate\\n\\t   numbers that are mathematically equal, but have\\\n  \\ slightly\\n\\t   different bit representations that do not translate to the\\n\\t\\\n  \\   same mathematically-equal values.  As a result, an equality\\n\\t   test or other\\\n  \\ comparison might produce unexpected\\n\\t   results.\\nThis issue can prevent the\\\n  \\ product from running reliably.  If the relevant code is reachable by an attacker,\\\n  \\ then this reliability problem might introduce a vulnerability.\"\n",
  "ID: '1078'\nName: Inappropriate Source Code Style or Formatting\nDescription: \"The source code does not follow\\n\\t\\t\\t\\tdesired style or formatting\\\n  \\ for indentation, white\\n\\t\\t\\t\\tspace, comments, etc.\"\n",
  "ID: '1079'\nName: Parent Class without Virtual Destructor Method\nDescription: A parent class contains one or more child classes, but the parent class\n  does not have a virtual destructor method.\nExtended_Description: This issue can prevent the product from running reliably due\n  to undefined or unexpected behaviors.  If the relevant code is reachable by an attacker,\n  then this reliability problem might introduce a vulnerability.\n",
  "ID: '108'\nName: 'Struts: Unvalidated Action Form'\nDescription: Every Action Form must have a corresponding validation form.\nExtended_Description: If a Struts Action Form Mapping specifies a form, it must have\n  a validation form defined under the Struts Validator.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Map every Action Form to a corresponding validation\n  form.\n\n  An action or a form may perform validation in other ways, but the Struts Validator\n  provides an excellent way to verify that all input receives at least a basic level\n  of validation. Without this approach, it is difficult, and often impossible, to\n  establish with a high level of confidence that all input is validated.'\n",
  "ID: '1080'\nName: Source Code File with Excessive Number of Lines of Code\nDescription: \"A source code file has too many lines of\\n\\t\\t\\t\\t\\tcode.\"\nExtended_Description: 'This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"too many lines of code\" may vary for each product or\n  developer, CISQ recommends a default threshold value of 1000.'\n",
  "ID: '1082'\nName: Class Instance Self Destruction Control Element\nDescription: The code contains a class instance that calls the method or function\n  to delete or destroy itself.\nExtended_Description: 'For example, in C++, \"delete this\" will cause the object to\n  delete itself.\n\n  This issue can prevent the product from running reliably.  If the relevant code\n  is reachable by an attacker, then this reliability problem might introduce a vulnerability.'\n",
  "ID: '1083'\nName: Data Access from Outside Expected Data Manager Component\nDescription: The product is intended to manage data access through a particular data\n  manager component such as a relational or non-SQL database, but it contains code\n  that performs data access operations without using that component.\nExtended_Description: 'When the product has a data access component, the design may\n  be intended to handle all data access operations through that component.  If a data\n  access operation is performed outside of that component, then this may indicate\n  a violation of the intended design.\n\n  This issue can prevent the product from running reliably.  If the relevant code\n  is reachable by an attacker, then this reliability problem might introduce a vulnerability.'\n",
  "ID: '1084'\nName: Invokable Control Element with Excessive File or Data Access Operations\nDescription: \"A function or method contains too many\\n\\t\\t\\t\\t\\toperations that utilize\\\n  \\ a data manager or file resource.\"\nExtended_Description: 'This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"too many operations\" may vary for each product or developer,\n  CISQ recommends a default maximum of 7 operations for the same data manager or file.'\n",
  "ID: '1085'\nName: Invokable Control Element with Excessive Volume of Commented-out Code\nDescription: \"A function, method, procedure, etc. contains an excessive amount of\\\n  \\ code that has been\\n\\t\\t\\t\\t\\tcommented out within its body.\"\nExtended_Description: 'This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"excessive volume\" may vary for each product or developer,\n  CISQ recommends a default threshold of 2% of commented code.'\n",
  "ID: '1086'\nName: Class with Excessive Number of Child Classes\nDescription: \"A class contains an unnecessarily large number of\\n\\t\\t\\t\\t\\tchildren.\"\nExtended_Description: 'This issue makes it more difficult to understand and maintain\n  the software, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  While the interpretation of \"large number of children\" may vary for each product\n  or developer, CISQ recommends a default maximum of 10 child classes.'\n",
  "ID: '1087'\nName: Class with Virtual Method without a Virtual Destructor\nDescription: A class contains a virtual method, but the method does not have an associated\n  virtual destructor.\nExtended_Description: This issue can prevent the product from running reliably, e.g.\n  due to undefined behavior.  If the relevant code is reachable by an attacker, then\n  this reliability problem might introduce a vulnerability.\n",
  "ID: '1088'\nName: Synchronous Access of Remote Resource without Timeout\nDescription: The code has a synchronous call to a remote resource, but there is no\n  timeout for the call, or the timeout is set to infinite.\nExtended_Description: This issue can prevent the product from running reliably, since\n  an outage for the remote resource can cause the product to hang.  If the relevant\n  code is reachable by an attacker, then this reliability problem might introduce\n  a vulnerability.\n",
  "ID: '1089'\nName: Large Data Table with Excessive Number of Indices\nDescription: \"The product uses a large data table that contains an excessively large\\\n  \\ number of\\n\\t\\t\\t\\t\\tindices.\"\nExtended_Description: 'This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n\n  While the interpretation of \"large data table\" and \"excessively large number of\n  indices\" may vary for each product or developer, CISQ recommends a default threshold\n  of 1000000 rows for a \"large\" table and a default threshold of 3 indices.'\n",
  "ID: '109'\nName: 'Struts: Validator Turned Off'\nDescription: Automatic filtering via a Struts bean has been turned off, which disables\n  the Struts Validator and custom validation logic. This exposes the application to\n  other weaknesses related to insufficient input validation.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Ensure that an action form mapping enables\n  validation. Set the validate field to true.'\n",
  "ID: '1090'\nName: Method Containing Access of a Member Element from Another Class\nDescription: \"A method for a class performs an operation that directly\\n\\t\\t\\t\\t\\t\\\n  accesses a member element from another class.\"\nExtended_Description: This issue suggests poor encapsulation and makes it more difficult\n  to understand and maintain the product, which indirectly affects security by making\n  it more difficult or time-consuming to find and/or fix vulnerabilities.  It also\n  might make it easier to introduce vulnerabilities.\n",
  "ID: '1091'\nName: Use of Object without Invoking Destructor Method\nDescription: \"The product contains a method that accesses an object but does not later\\\n  \\ invoke\\n\\t\\t\\t\\t\\tthe element's associated finalize/destructor method.\"\nExtended_Description: This issue can make the product perform more slowly by retaining\n  memory and/or other resources longer than necessary.  If the relevant code is reachable\n  by an attacker, then this performance problem might introduce a vulnerability.\n",
  "ID: '1092'\nName: Use of Same Invokable Control Element in Multiple Architectural Layers\nDescription: \"The product uses the same control element across multiple\\n\\t\\t\\t\\t\\t\\\n  architectural layers.\"\nExtended_Description: This issue makes it more difficult to understand and maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1093'\nName: Excessively Complex Data Representation\nDescription: The product uses an unnecessarily complex internal representation for\n  its data structures or interrelationships between those structures.\nExtended_Description: This issue makes it more difficult to understand or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1094'\nName: Excessive Index Range Scan for a Data Resource\nDescription: \"The product contains an index range scan for a large data table,\\n\\t\\\n  \\t\\t\\t\\tbut the scan can cover a large number of rows.\"\nExtended_Description: 'This issue can make the product perform more slowly.  If the\n  relevant code is reachable by an attacker, then this performance problem might introduce\n  a vulnerability.\n\n  While the interpretation of \"large data table\" and \"excessive index range\" may vary\n  for each product or developer, CISQ recommends a threshold of 1000000 table rows\n  and a threshold of 10 for the index range.'\n",
  "ID: '1095'\nName: Loop Condition Value Update within the Loop\nDescription: \"The product uses a loop with a control flow condition based on\\n\\t\\t\\\n  \\t\\t\\ta value that is updated within the body of the loop.\"\nExtended_Description: This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1096'\nName: Singleton Class Instance Creation without Proper Locking or Synchronization\nDescription: The product implements a Singleton design pattern but does not use appropriate\n  locking or other synchronization mechanism to ensure that the singleton class is\n  only instantiated once.\nExtended_Description: This issue can prevent the product from running reliably, e.g.\n  by making the instantiation process non-thread-safe and introducing deadlock (CWE-833)\n  or livelock conditions.  If the relevant code is reachable by an attacker, then\n  this reliability problem might introduce a vulnerability.\n",
  "ID: '1097'\nName: Persistent Storable Data Element without Associated Comparison Control Element\nDescription: \"The product uses a storable data element that does not have\\n\\t\\t\\t\\t\\\n  \\tall of the associated functions or methods that are necessary to support\\n\\t\\t\\\n  \\t\\t\\tcomparison.\"\nExtended_Description: 'For example, with Java, a class that is made persistent requires\n  both hashCode() and equals() methods to be defined.\n\n  This issue can prevent the product from running reliably, due to incorrect or unexpected\n  comparison results.  If the relevant code is reachable by an attacker, then this\n  reliability problem might introduce a vulnerability.'\n",
  "ID: '1098'\nName: Data Element containing Pointer Item without Proper Copy Control Element\nDescription: The code contains a data element with a pointer that does not have an\n  associated copy or constructor method.\nExtended_Description: This issue can prevent the product from running reliably.  If\n  the relevant code is reachable by an attacker, then this reliability problem might\n  introduce a vulnerability.\n",
  "ID: '1099'\nName: Inconsistent Naming Conventions for Identifiers\nDescription: \"The product's code, documentation, or other artifacts do not\\n\\t\\t\\t\\\n  \\t\\tconsistently use the same naming conventions for variables, callables, groups\\\n  \\ of\\n\\t\\t\\t\\t\\trelated callables, I/O capabilities, data types, file names, or\\\n  \\ similar types of\\n\\t\\t\\t\\t\\telements.\"\nExtended_Description: This issue makes it more difficult to understand and/or maintain\n  the product due to inconsistencies, which indirectly affects security by making\n  it more difficult or time-consuming to find and/or fix vulnerabilities.  It also\n  might make it easier to introduce vulnerabilities.\n",
  "ID: '11'\nName: 'ASP.NET Misconfiguration: Creating Debug Binary'\nDescription: Debugging messages help attackers learn about the system and plan a form\n  of attack.\nExtended_Description: ASP .NET applications can be configured to produce debug binaries.\n  These binaries give detailed debugging messages and should not be used in production\n  environments. Debug binaries are meant to be used in a development or testing environment\n  and can pose a security risk if they are deployed to production.\nApplicable_Platforms:\n  Language: ASP.NET\nModes_Of_Introduction: \"Implementation: \\n\\nBuild and Compilation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'System Configuration: Avoid releasing debug binaries into\n  the production environment. Change the debug mode to false when the application\n  is deployed into production.'\n",
  "ID: '110'\nName: 'Struts: Validator Without Form Field'\nDescription: Validation fields that do not appear in forms they are associated with\n  indicate that the validation logic is out of date.\nExtended_Description: 'It is easy for developers to forget to update validation logic\n  when they make changes to an ActionForm class. One indication that validation logic\n  is not being properly maintained is inconsistencies between the action form and\n  the validation form.\n\n  Although J2EE applications are not generally susceptible to memory corruption attacks,\n  if a J2EE application interfaces with native code that does not perform array bounds\n  checking, an attacker may be able to use an input validation mistake in the J2EE\n  application to launch a buffer overflow attack.'\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: To find the issue in the implementation,\n  manual checks or automated static analysis could be applied to the XML configuration\n  files.\n\n\n  Manual Static Analysis: To find the issue in the implementation, manual checks or\n  automated static analysis could be applied to the XML configuration files.'\n",
  "ID: '1100'\nName: Insufficient Isolation of System-Dependent Functions\nDescription: \"The product or code does not isolate system-dependent\\n\\t\\t\\t\\t\\tfunctionality\\\n  \\ into separate standalone modules.\"\nExtended_Description: This issue makes it more difficult to maintain and/or port the\n  product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1101'\nName: Reliance on Runtime Component in Generated Code\nDescription: \"The product uses automatically-generated code that cannot be\\n\\t\\t\\t\\\n  \\t\\texecuted without a specific runtime support component.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1102'\nName: Reliance on Machine-Dependent Data Representation\nDescription: \"The code uses a data representation that relies on low-level\\n\\t\\t\\t\\\n  \\t\\tdata representation or constructs that may vary across different processors,\\n\\\n  \\t\\t\\t\\t\\tphysical machines, OSes, or other physical components.\"\nExtended_Description: This issue makes it more difficult to maintain and/or port the\n  product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1103'\nName: Use of Platform-Dependent Third Party Components\nDescription: \"The product relies on third-party components that do\\n\\t\\t\\t\\t\\tnot\\\n  \\ provide equivalent functionality across all desirable\\n\\t\\t\\t\\t\\tplatforms.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1104'\nName: Use of Unmaintained Third Party Components\nDescription: \"The product relies on third-party components that are not\\n\\t\\t\\t\\t\\t\\\n  actively supported or maintained by the original developer or a trusted proxy\\n\\t\\\n  \\t\\t\\t\\tfor the original developer.\"\nExtended_Description: 'Reliance on components that are no longer maintained can make\n  it difficult or impossible to fix significant bugs, vulnerabilities, or quality\n  issues. In effect, unmaintained code can become obsolete.\n\n  This issue makes it more difficult to maintain the product, which indirectly affects\n  security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It\n  also might make it easier to introduce vulnerabilities.'\nApplicable_Platforms:\n  Technology: ICS/OT\n",
  "ID: '1105'\nName: Insufficient Encapsulation of Machine-Dependent Functionality\nDescription: \"The product or code uses machine-dependent functionality, but\\n\\t\\t\\t\\\n  \\t\\tit does not sufficiently encapsulate or isolate this functionality from\\n\\t\\t\\\n  \\t\\t\\tthe rest of the code.\"\nExtended_Description: This issue makes it more difficult to port or maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1106'\nName: Insufficient Use of Symbolic Constants\nDescription: \"The source code uses literal constants that may need to change\\n\\t\\t\\\n  \\t\\t\\tor evolve over time, instead of using symbolic constants.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1107'\nName: Insufficient Isolation of Symbolic Constant Definitions\nDescription: \"The source code uses symbolic constants, but it does not\\n\\t\\t\\t\\t\\t\\\n  sufficiently place the definitions of these constants into a more centralized or\\n\\\n  \\t\\t\\t\\t\\tisolated location.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1108'\nName: Excessive Reliance on Global Variables\nDescription: \"The code is structured in a way that relies too much on using\\n\\t\\t\\t\\\n  \\t\\tor setting global variables throughout various points in the code, instead of\\n\\\n  \\t\\t\\t\\t\\tpreserving the associated information in a narrower, more local\\n\\t\\t\\t\\\n  \\t\\tcontext.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '1109'\nName: Use of Same Variable for Multiple Purposes\nDescription: \"The code contains a callable, block, or other code element in\\n\\t\\t\\t\\\n  \\t\\twhich the same variable is used to control more than one unique task or store\\n\\\n  \\t\\t\\t\\t\\tmore than one instance of data.\"\nExtended_Description: 'Use of the same variable for multiple purposes can make it\n  more difficult for a person to read or understand the code, potentially hiding other\n  quality issues.\n\n  This issue makes it more difficult to maintain the product, which indirectly affects\n  security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It\n  also might make it easier to introduce vulnerabilities.'\n",
  "ID: '111'\nName: Direct Use of Unsafe JNI\nDescription: When a Java application uses the Java Native Interface (JNI) to call\n  code written in another programming language, it can expose the application to weaknesses\n  in that code, even if those weaknesses cannot occur in Java.\nExtended_Description: Many safety features that programmers may take for granted do\n  not apply for native code, so you must carefully review all such code for potential\n  problems. The languages used to implement native code may be more susceptible to\n  buffer overflows and other attacks. Native code is unprotected by the security features\n  enforced by the runtime environment, such as strong typing and array bounds checking.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Implement error handling around the JNI call.\n\n\n  Implementation: Do not use JNI calls if you don''t trust the native library.\n\n\n  Implementation: Be reluctant to use JNI calls. A Java API equivalent may exist.'\n",
  "ID: '1110'\nName: Incomplete Design Documentation\nDescription: \"The product's design documentation does not adequately describe\\n\\t\\t\\\n  \\t\\t\\tcontrol flow, data flow, system initialization, relationships between tasks,\\n\\\n  \\t\\t\\t\\t\\tcomponents, rationales, or other important aspects of the\\n\\t\\t\\t\\t\\t\\\n  design.\"\nApplicable_Platforms:\n  Technology: ICS/OT\n",
  "ID: '1111'\nName: Incomplete I/O Documentation\nDescription: \"The product's documentation does not adequately define inputs,\\n\\t\\t\\\n  \\t\\t\\toutputs, or system/software interfaces.\"\n",
  "ID: '1112'\nName: Incomplete Documentation of Program Execution\nDescription: \"The document does not fully define all mechanisms that are used\\n\\t\\t\\\n  \\t\\t\\tto control or influence how product-specific programs are\\n\\t\\t\\t\\t\\texecuted.\"\nExtended_Description: This includes environmental variables, configuration files,\n  registry keys, command-line switches or options, or system settings.\n",
  "ID: '1113'\nName: Inappropriate Comment Style\nDescription: \"The source code uses comment styles or formats that are\\n\\t\\t\\t\\t\\t\\\n  inconsistent or do not follow expected standards for the\\n\\t\\t\\t\\t\\tproduct.\"\nExtended_Description: This issue makes it more difficult to maintain the product due\n  to insufficient legibility, which indirectly affects security by making it more\n  difficult or time-consuming to find and/or fix vulnerabilities.  It also might make\n  it easier to introduce vulnerabilities.\n",
  "ID: '1114'\nName: Inappropriate Whitespace Style\nDescription: \"The source code contains whitespace that is inconsistent across\\n\\t\\t\\\n  \\t\\t\\tthe code or does not follow expected standards for the\\n\\t\\t\\t\\t\\tproduct.\"\nExtended_Description: This issue makes it more difficult to understand and maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1115'\nName: Source Code Element without Standard Prologue\nDescription: \"The source code contains elements such as source files \\n\\t\\t\\t\\t\\t\\\n  that do not consistently provide a prologue or header that has been\\n\\t\\t\\t\\t\\t\\\n  standardized for the project.\"\nExtended_Description: 'The lack of a prologue can make it more difficult to accurately\n  and quickly understand the associated code. Standard prologues or headers may contain\n  information such as module name, version number, author, date, purpose, function,\n  assumptions, limitations, accuracy considerations, etc.\n\n  This issue makes it more difficult to maintain the product due to insufficient analyzability,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.'\n",
  "ID: '1116'\nName: Inaccurate Comments\nDescription: \"The source code contains comments that do not accurately\\n\\t\\t\\t\\t\\t\\\n  describe or explain aspects of the portion of the code with which the comment is\\n\\\n  \\t\\t\\t\\t\\tassociated.\"\nExtended_Description: 'When a comment does not accurately reflect the associated code\n  elements, this can introduce confusion to a reviewer (due to inconsistencies) or\n  make it more difficult and less efficient to validate that the code is implementing\n  the intended behavior correctly.\n\n  This issue makes it more difficult to maintain the product, which indirectly affects\n  security by making it more difficult or time-consuming to find and/or fix vulnerabilities.  It\n  also might make it easier to introduce vulnerabilities.'\nPotential_Mitigations: 'Implementation: Verify that each comment accurately reflects\n  what is intended to happen during execution of the code.'\n",
  "ID: '1117'\nName: Callable with Insufficient Behavioral Summary\nDescription: \"The code contains a function or method whose signature and/or associated\\n\\\n  \\t\\t\\t\\t\\tinline documentation does not sufficiently describe the callable's inputs,\\\n  \\ outputs,\\n\\t\\t\\t\\t\\tside effects, assumptions, or return codes.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1118'\nName: Insufficient Documentation of Error Handling Techniques\nDescription: \"The documentation does not sufficiently describe the techniques\\n\\t\\t\\\n  \\t\\t\\tthat are used for error handling, exception processing, or similar\\n\\t\\t\\t\\\n  \\t\\tmechanisms.\"\nExtended_Description: Documentation may need to cover error handling techniques at\n  multiple layers, such as module, executable, compilable code unit, or callable.\n",
  "ID: '1119'\nName: Excessive Use of Unconditional Branching\nDescription: \"The code uses too many unconditional branches (such as\\n\\t\\t\\t\\t\\t\\\"\\\n  goto\\\").\"\nExtended_Description: This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '112'\nName: Missing XML Validation\nDescription: The product accepts XML from an untrusted source but does not validate\n  the XML against the proper schema.\nExtended_Description: Most successful attacks begin with a violation of the programmer's\n  assumptions. By accepting an XML document without validating it against a DTD or\n  XML schema, the programmer leaves a door open for attackers to provide unexpected,\n  unreasonable, or malicious input.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Always validate XML input against\n  a known XML Schema or DTD.\n\n  It is not possible for an XML parser to validate all aspects of a document''s content\n  because a parser cannot understand the complete semantics of the data. However,\n  a parser can do a complete and thorough job of checking the document''s structure\n  and therefore guarantee to the code that processes the document that the content\n  is well-formed.'\nRelated_Attack_Patterns: \"230: \\n\\n231: \"\n",
  "ID: '1120'\nName: Excessive Code Complexity\nDescription: \"The code is too complex, as calculated using a well-defined,\\n\\t\\t\\t\\\n  \\t\\tquantitative measure.\"\nExtended_Description: 'This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n\n  This issue can make the product perform more slowly.  If the relevant code is reachable\n  by an attacker, then this performance problem might introduce a vulnerability.'\n",
  "ID: '1121'\nName: Excessive McCabe Cyclomatic Complexity\nDescription: \"The code contains McCabe cyclomatic complexity that exceeds a\\n\\tdesirable\\\n  \\ maximum.\"\nExtended_Description: This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1122'\nName: Excessive Halstead Complexity\nDescription: \"The code is structured in a way that a Halstead complexity\\n\\t\\t\\t\\t\\\n  \\tmeasure exceeds a desirable maximum.\"\nExtended_Description: 'A variety of Halstead complexity measures exist, such as program\n  vocabulary size or volume.\n\n  This issue makes it more difficult to understand and/or maintain the product, which\n  indirectly affects security by making it more difficult or time-consuming to find\n  and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.'\n",
  "ID: '1123'\nName: Excessive Use of Self-Modifying Code\nDescription: \"The product uses too much self-modifying\\n\\t\\t\\t\\t\\tcode.\"\nExtended_Description: This issue makes it more difficult to understand or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1124'\nName: Excessively Deep Nesting\nDescription: \"The code contains a callable or other code grouping in which\\n\\t\\t\\t\\\n  \\t\\tthe nesting / branching is too deep.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1125'\nName: Excessive Attack Surface\nDescription: \"The product has an attack surface whose quantitative\\n\\t\\t\\t\\t\\tmeasurement\\\n  \\ exceeds a desirable maximum.\"\nExtended_Description: Originating from software security, an \"attack surface\" measure\n  typically reflects the number of input points and output points that can be utilized\n  by an untrusted party, i.e. a potential attacker. A larger attack surface provides\n  more places to attack, and more opportunities for developers to introduce weaknesses.  In\n  some cases, this measure may reflect other aspects of quality besides security;\n  e.g., a product with many inputs and outputs may require a large number of tests\n  in order to improve code coverage.\n",
  "ID: '1126'\nName: Declaration of Variable with Unnecessarily Wide Scope\nDescription: \"The source code declares a variable in one scope, but the\\n\\t\\t\\t\\t\\t\\\n  variable is only used within a narrower scope.\"\nExtended_Description: This issue makes it more difficult to understand and/or maintain\n  the product, which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '1127'\nName: Compilation with Insufficient Warnings or Errors\nDescription: \"The code is compiled without sufficient warnings enabled, which\\n\\t\\t\\\n  \\t\\t\\tmay prevent the detection of subtle bugs or quality\\n\\t\\t\\t\\t\\tissues.\"\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\n",
  "ID: '113'\nName: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Request/Response\n  Splitting')\nDescription: The product receives data from an HTTP agent/component (e.g., web server,\n  proxy, browser, etc.), but it does not neutralize or incorrectly neutralizes CR\n  and LF characters before the data is included in outgoing HTTP headers.\nExtended_Description: 'HTTP agents or components may include a web server, load balancer,\n  reverse proxy, web caching proxy, application firewall, web browser, etc. Regardless\n  of the role, they are expected to maintain coherent, consistent HTTP communication\n  state across all components. However, including unexpected data in an HTTP header\n  allows an attacker to specify the entirety of the HTTP message that is rendered\n  by the client HTTP agent (e.g., web browser) or back-end HTTP agent (e.g., web server),\n  whether the message is part of a request or a response.\n\n  When an HTTP request contains unexpected CR and LF characters, the server may respond\n  with an output stream that is interpreted as \"splitting\" the stream into two different\n  HTTP messages instead of one. CR is carriage return, also given by %0d or \\r, and\n  LF is line feed, also given by %0a or \\n.\n\n  In addition to CR and LF characters, other valid/RFC compliant special characters\n  and unique character encodings can be utilized, such as HT (horizontal tab, also\n  given by %09 or \\t) and SP (space, also given as + sign or %20).\n\n  These types of unvalidated and unexpected data in HTTP message headers allow an\n  attacker to control the second \"split\" message to mount attacks such as server-side\n  request forgery, cross-site scripting, and cache poisoning attacks.\n\n  HTTP response splitting weaknesses may be present when:'\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: \"HTTP Request Splitting: \\n\\nHTTP Response Splitting: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Construct HTTP headers very carefully, avoiding\n  the use of non-validated input data.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. If an input does not strictly conform to specifications, reject\n  it or transform it into something that conforms.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2020-15811: Chain: Proxy uses a substring search instead of\n  parsing the Transfer-Encoding header (CWE-697), allowing request splitting (CWE-113)\n  and cache poisoning\n\n\n  CVE-2021-41084: Scala-based HTTP interface allows request splitting and response\n  splitting through header names, header values, status reasons, and URIs\n\n\n  CVE-2018-12116: Javascript-based framework allows request splitting through a path\n  option of an HTTP request\n\n\n  CVE-2004-2146: Application accepts CRLF in an object ID, allowing HTTP response\n  splitting.\n\n\n  CVE-2004-1656: Shopping cart allows HTTP response splitting to perform HTML injection\n  via CRLF in a parameter for a url\n\n\n  CVE-2005-2060: Bulletin board allows response splitting via CRLF in parameter.\n\n\n  CVE-2004-2512: Response splitting via CRLF in PHPSESSID.\n\n\n  CVE-2005-1951: e-commerce app allows HTTP response splitting using CRLF in object\n  id parameters'\nRelated_Attack_Patterns: \"105: \\n\\n31: \\n\\n34: \\n\\n85: \"\n",
  "ID: '114'\nName: Process Control\nDescription: Executing commands or loading libraries from an untrusted source or in\n  an untrusted environment can cause an application to execute malicious commands\n  (and payloads) on behalf of an attacker.\nExtended_Description: Process control vulnerabilities of the first type occur when\n  either data enters the application from an untrusted source and the data is used\n  as part of a string representing a command that is executed by the application.\n  By executing the command, the application gives an attacker a privilege or capability\n  that the attacker would not otherwise have.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Libraries that are loaded should\n  be well understood and come from a trusted source. The application can execute code\n  contained in the native libraries, which often contain calls that are susceptible\n  to other security problems, such as buffer overflows or command injection. All native\n  libraries should be validated to determine if the application requires the use of\n  the library. It is very difficult to determine what these native libraries actually\n  do, and the potential for malicious code is high. In addition, the potential for\n  an inadvertent mistake in these native libraries is also high, as many are written\n  in C or C++ and may be susceptible to buffer overflow or race condition problems.\n  To help prevent buffer overflow attacks, validate all input to native calls for\n  content and length. If the native library does not come from a trusted source, review\n  the source code of the library. The library should be built from the reviewed source\n  before using it.'\nRelated_Attack_Patterns: \"108: \\n\\n640: \"\n",
  "ID: '115'\nName: Misinterpretation of Input\nDescription: The product misinterprets an input, whether from an attacker or another\n  product, in a security-relevant fashion.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nObserved_Examples: 'CVE-2005-2225: Product sees dangerous file extension in free text\n  of a group discussion, disconnects all users.\n\n\n  CVE-2001-0003: Product does not correctly import and process security settings from\n  another product.'\n",
  "ID: '116'\nName: Improper Encoding or Escaping of Output\nDescription: The product prepares a structured message for communication with another\n  component, but encoding or escaping of the data is either missing or done incorrectly.\n  As a result, the intended structure of the message is not preserved.\nExtended_Description: 'Improper encoding or escaping can allow attackers to change\n  the commands that are sent to another component, inserting malicious commands instead.\n\n  Most products follow a certain protocol that uses structured messages for communication\n  between components, such as queries or commands. These structured messages can contain\n  raw data interspersed with metadata or control information. For example, \"GET /index.html\n  HTTP/1.1\" is a structured message containing a command (\"GET\") with a single argument\n  (\"/index.html\") and metadata about which protocol version is being used (\"HTTP/1.1\").\n\n  If an application uses attacker-supplied inputs to construct a structured message\n  without properly encoding or escaping, then the attacker could insert special characters\n  that will cause the data to be interpreted as control information or metadata. Consequently,\n  the component that receives the output will perform the wrong operations, or otherwise\n  interpret the data incorrectly.'\nApplicable_Platforms:\n  Technology: Database Server, Web Server\nAlternate_Terms: \"Output Sanitization: \\n\\nOutput Validation: \\n\\nOutput Encoding: \"\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.'\nPotential_Mitigations: 'Architecture and Design: Use a vetted library or framework\n  that does not allow this weakness to occur or provides constructs that make this\n  weakness easier to avoid.\n\n  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool,\n  library, or framework. These will help the programmer encode outputs in a manner\n  less prone to error.\n\n  Alternately, use built-in functions, but consider using wrappers in case those functions\n  are discovered to have a vulnerability.\n\n\n  Architecture and Design: If available, use structured mechanisms that automatically\n  enforce the separation between data and code. These mechanisms may be able to provide\n  the relevant quoting, encoding, and validation automatically, instead of relying\n  on the developer to provide this capability at every point where output is generated.\n\n  For example, stored procedures can enforce database query structure and reduce the\n  likelihood of SQL injection.\n\n\n  Architecture and Design\n\n  Implementation: Understand the context in which your data will be used and the encoding\n  that will be expected. This is especially important when transmitting data between\n  different components, or when generating outputs that can contain multiple encodings\n  at the same time, such as web pages or multi-part mail messages. Study all expected\n  communication protocols and data representations to determine the required encoding\n  strategies.\n\n\n  Architecture and Design: In some cases, input validation may be an important strategy\n  when output encoding is not a complete solution. For example, you may be providing\n  the same output that will be processed by multiple consumers that use different\n  encodings or representations. In other cases, you may be required to allow user-supplied\n  input to contain control information, such as limited HTML tags that support formatting\n  in a wiki or bulletin board. When this type of requirement must be met, use an extremely\n  strict allowlist to limit which control sequences can be used. Verify that the resulting\n  syntactic structure is what you expect. Use your normal encoding methods for the\n  remainder of the input.\n\n\n  Architecture and Design: Use input validation as a defense-in-depth measure to reduce\n  the likelihood of output encoding errors (see CWE-20).\n\n\n  Requirements: Fully specify which encodings are required by components that will\n  be communicating with each other.\n\n\n  Implementation: When exchanging data between components, ensure that both components\n  are using the same character encoding. Ensure that the proper encoding is applied\n  at each interface. Explicitly set the encoding you are using whenever the protocol\n  allows you to do so.'\nObserved_Examples: 'CVE-2021-41232: Chain: authentication routine in Go-based agile\n  development product does not escape user name (CWE-116), allowing LDAP injection\n  (CWE-90)\n\n\n  CVE-2008-4636: OS command injection in backup software using shell metacharacters\n  in a filename; correct behavior would require that this filename could not be changed.\n\n\n  CVE-2008-0769: Web application does not set the charset when sending a page to a\n  browser, allowing for XSS exploitation when a browser chooses an unexpected encoding.\n\n\n  CVE-2008-0005: Program does not set the charset when sending a page to a browser,\n  allowing for XSS exploitation when a browser chooses an unexpected encoding.\n\n\n  CVE-2008-5573: SQL injection via password parameter; a strong password might contain\n  \"&\"\n\n\n  CVE-2008-3773: Cross-site scripting in chat application via a message subject, which\n  normally might contain \"&\" and other XSS-related characters.\n\n\n  CVE-2008-0757: Cross-site scripting in chat application via a message, which normally\n  might be allowed to contain arbitrary content.'\nRelated_Attack_Patterns: \"104: \\n\\n73: \\n\\n81: \\n\\n85: \"\n",
  "ID: '1164'\nName: Irrelevant Code\nDescription: \"The product contains code that is not essential for execution,\\n\\t \\\n  \\    i.e. makes no state changes and has no side effects that alter\\n\\t     data\\\n  \\ or control flow, such that removal of the code would have no impact\\n\\t     to\\\n  \\ functionality or correctness.\"\nExtended_Description: \"Irrelevant code could include dead code,\\n\\t     initialization\\\n  \\ that is not used, empty blocks, code that could be entirely\\n\\t     removed due\\\n  \\ to optimization, etc.\"\n",
  "ID: '117'\nName: Improper Output Neutralization for Logs\nDescription: The product does not neutralize or incorrectly neutralizes output that\n  is written to logs.\nExtended_Description: 'This can allow an attacker to forge log entries or inject malicious\n  content into logs.\n\n  Log forging vulnerabilities occur when:'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2006-4624: Chain: inject fake log entries with fake timestamps\n  using CRLF injection'\nRelated_Attack_Patterns: \"268: \\n\\n81: \\n\\n93: \"\n",
  "ID: '1173'\nName: Improper Use of Validation Framework\nDescription: The product does not use, or incorrectly uses, an input validation framework\n  that is provided by the source language or an independent library.\nExtended_Description: Many modern coding languages provide developers with input validation\n  frameworks to make the task of input validation easier and less error-prone. These\n  frameworks will automatically check all input against specified criteria and direct\n  execution to error handlers when invalid input is received. The improper use (i.e.,\n  an incorrect implementation or missing altogether) of these frameworks is not directly\n  exploitable, but can lead to an exploitable condition if proper input validation\n  is not performed later in the product. Not using provided input validation frameworks\n  can also hurt the maintainability of code as future developers may not recognize\n  the downstream input validation being used in the place of the validation framework.\nModes_Of_Introduction: 'Architecture and Design: This weakness may occur when software\n  designers choose to not leverage input validation frameworks provided by the source\n  language.\n\n\n  Implementation: This weakness may occur when developers do not correctly use a provided\n  input validation framework.'\nDetection_Methods: 'Automated Static Analysis: Some instances of improper input validation\n  can be detected using automated static analysis.\n\n  A static analysis tool might allow the user to specify which application-specific\n  methods or functions perform input validation; the tool might also have built-in\n  knowledge of validation frameworks such as Struts. The tool may then suppress or\n  de-prioritize any associated warnings. This allows the analyst to focus on areas\n  of the software in which input validation does not appear to be present.\n\n  Except in the cases described in the previous paragraph, automated static analysis\n  might not be able to recognize when proper input validation is being performed,\n  leading to false positives - i.e., warnings that do not have any security consequences\n  or require any code changes.'\nPotential_Mitigations: 'Implementation: Properly use provided input validation frameworks.'\n",
  "ID: '1174'\nName: 'ASP.NET Misconfiguration: Improper Model Validation'\nDescription: The ASP.NET application does not use, or incorrectly uses, the model\n  validation framework.\nApplicable_Platforms:\n  Language: ASP.NET\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '1176'\nName: Inefficient CPU Computation\nDescription: \"The product performs CPU computations using\\n         algorithms that\\\n  \\ are not as efficient as they could be for the\\n         needs of the developer,\\\n  \\ i.e., the computations can be\\n         optimized further.\"\nExtended_Description: This issue can make the product perform more slowly, possibly\n  in ways that are noticeable to the users.  If an attacker can influence the amount\n  of computation that must be performed, e.g. by triggering worst-case complexity,\n  then this performance problem might introduce a vulnerability.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '1177'\nName: Use of Prohibited Code\nDescription: \"The product uses a function, library, or third party component\\n\\t \\\n  \\    that has been explicitly prohibited, whether by the developer or\\n\\t     the\\\n  \\ customer.\"\nExtended_Description: 'The developer - or customers - may wish to restrict or eliminate\n  use of a function, library, or third party component for any number of reasons,\n  including real or suspected vulnerabilities; difficulty to use securely; export\n  controls or license requirements; obsolete or poorly-maintained code; internal code\n  being scheduled for deprecation; etc.\n\n  To reduce risk of vulnerabilities, the developer might maintain a list of \"banned\"\n  functions that programmers must avoid using because the functions are difficult\n  or impossible to use securely.  This issue can also make the product more costly\n  and difficult to maintain.'\n",
  "ID: '118'\nName: Incorrect Access of Indexable Resource ('Range Error')\nDescription: The product does not restrict or incorrectly restricts operations within\n  the boundaries of a resource that is accessed using an index or pointer, such as\n  memory or files.\nRelated_Attack_Patterns: \"10: \\n\\n14: \\n\\n24: \\n\\n45: \\n\\n46: \\n\\n47: \\n\\n8: \\n\\n\\\n  9: \"\n",
  "ID: '1187'\nName: 'DEPRECATED: Use of Uninitialized Resource'\nDescription: This entry has been deprecated because it was a duplicate of CWE-908.\n  All content has been transferred to CWE-908.\n",
  "ID: '1188'\nName: Insecure Default Initialization of Resource\nDescription: The product initializes or sets a resource with a default that is intended\n  to be changed by the administrator, but the default is not secure.\nExtended_Description: Developers often choose default values that leave the product\n  as open and easy to use as possible out-of-the-box, under the assumption that the\n  administrator can (or should) change the default value.  However, this ease-of-use\n  comes at a cost when the default is insecure and the administrator does not change\n  it.\nRelated_Attack_Patterns: '665: '\n",
  "ID: '1189'\nName: Improper Isolation of Shared Resources on System-on-a-Chip (SoC)\nDescription: The System-On-a-Chip (SoC) does not properly isolate shared resources\n  between trusted and untrusted agents.\nExtended_Description: A System-On-a-Chip (SoC) has a lot of functionality, but it\n  may have a limited number of pins or pads. A pin can only perform one function at\n  a time. However, it can be configured to perform multiple different functions. This\n  technique is called pin multiplexing. Similarly, several resources on the chip may\n  be shared to multiplex and support different features or functions. When such resources\n  are shared between trusted and untrusted agents, untrusted agents may be able to\n  access the assets intended to be accessed only by the trusted agents.\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Dynamic Analysis: Pre-silicon / post-silicon: Test access\n  to shared systems resources (memory ranges, control registers, etc.) from untrusted\n  software to verify that the assets are not incorrectly exposed to untrusted agents.\n  Note that access to shared resources can be dynamically allowed or revoked based\n  on system flows. Security testing should cover such dynamic shared resource allocation\n  and access control modification flows.'\nPotential_Mitigations: 'Architecture and Design: When sharing resources, avoid mixing\n  agents of varying trust levels.\n\n  Untrusted agents should not share resources with trusted agents.'\nObserved_Examples: 'CVE-2020-8698: Processor has improper isolation of shared resources\n  allowing for information disclosure.\n\n\n  CVE-2019-6260: Baseboard Management Controller (BMC) device implements Advanced\n  High-performance Bus (AHB) bridges that do not require authentication for arbitrary\n  read and write access to the BMC''s physical address space from the host, and possibly\n  the network [REF-1138].'\nRelated_Attack_Patterns: '124: '\n",
  "ID: '119'\nName: Improper Restriction of Operations within the Bounds of a Memory Buffer\nDescription: The product performs operations on a memory buffer, but it can read from\n  or write to a memory location that is outside of the intended boundary of the buffer.\nExtended_Description: 'Certain languages allow direct addressing of memory locations\n  and do not automatically ensure that these locations are valid for the memory buffer\n  that is being referenced. This can cause read or write operations to be performed\n  on memory locations that may be associated with other variables, data structures,\n  or internal program data.\n\n  As a result, an attacker may be able to execute arbitrary code, alter the intended\n  control flow, read sensitive information, or cause the system to crash.'\nApplicable_Platforms:\n  Language: C, C++, Assembly\nAlternate_Terms: 'Buffer Overflow: This term has many different meanings to different\n  audiences.  From a CWE mapping perspective, this term should be avoided where possible.\n  Some researchers, developers, and tools intend for it to mean \"write past the end\n  of a buffer,\" whereas others use the same term to mean \"any read or write outside\n  the boundaries of a buffer, whether before the beginning of the buffer or after\n  the end of the buffer.\"  Still others using the same term could mean \"any action\n  after the end of a buffer, whether it is a read or write.\" Since the term is commonly\n  used for exploitation and for vulnerabilities, it further confuses things.\n\n\n  buffer overrun: Some prominent vendors and researchers use the term \"buffer overrun,\"\n  but most people use \"buffer overflow.\" See the alternate term for \"buffer overflow\"\n  for context.\n\n\n  memory safety: Generally used for techniques that avoid weaknesses related to memory\n  access, such as those identified by CWE-119 and its descendants. However, the term\n  is not formal, and there is likely disagreement between practitioners as to which\n  weaknesses are implicitly covered by the \"memory safety\" term.'\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis generally does not account for environmental considerations\n  when reporting out-of-bounds memory operations. This can make it difficult for users\n  to determine which warnings should be investigated first. For example, an analysis\n  tool might report buffer overflows that originate from command line arguments in\n  a program that is not expected to run with setuid or other special privileges.\n\n  Detection techniques for buffer-related errors are more mature than for most other\n  weakness types.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, many languages that perform their own memory management, such as Java\n  and Perl, are not subject to buffer overflows. Other languages, such as Ada and\n  C#, typically provide overflow protection, but the protection can be disabled by\n  the programmer.\n\n  Be wary that a language''s interface to native code may still be subject to overflows,\n  even if the language itself is theoretically safe.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57],\n  and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer\n  versions of overflow-prone string-handling functions.\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Implementation: Consider adhering to the following rules when allocating and managing\n  an application''s memory:\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Implementation: Replace unbounded copy functions with analogous functions that support\n  length arguments, such as strcpy with strncpy. Create these if they are not available.'\nObserved_Examples: \"CVE-2021-22991: Incorrect URI normalization in application traffic\\\n  \\ product leads to buffer overflow, as exploited in the wild per CISA KEV.\\n\\nCVE-2020-29557:\\\n  \\ Buffer overflow in Wi-Fi router web interface, as exploited in the wild per CISA\\\n  \\ KEV.\\n\\nCVE-2009-2550: Classic stack-based buffer overflow in media player using\\\n  \\ a long entry in a playlist\\n\\nCVE-2009-2403: Heap-based buffer overflow in media\\\n  \\ player using a long entry in a playlist\\n\\nCVE-2009-0689: large precision value\\\n  \\ in a format string triggers overflow\\n\\nCVE-2009-0690: negative offset value leads\\\n  \\ to out-of-bounds read\\n\\nCVE-2009-1532: malformed inputs cause accesses of uninitialized\\\n  \\ or previously-deleted objects, leading to memory corruption\\n\\nCVE-2009-1528:\\\n  \\ chain: lack of synchronization leads to memory corruption\\n\\nCVE-2021-29529: Chain:\\\n  \\ machine-learning product can have a heap-based\\n\\t      buffer overflow (CWE-122)\\\n  \\ when some integer-oriented bounds are\\n\\t      calculated by using ceiling() and\\\n  \\ floor() on floating point values\\n\\t      (CWE-1339)\\n\\nCVE-2009-0558: attacker-controlled\\\n  \\ array index leads to code execution\\n\\nCVE-2009-0269: chain: -1 value from a function\\\n  \\ call was intended to indicate an error, but is used as an array index instead.\\n\\\n  \\nCVE-2009-0566: chain: incorrect calculations lead to incorrect pointer dereference\\\n  \\ and memory corruption\\n\\nCVE-2009-1350: product accepts crafted messages that\\\n  \\ lead to a dereference of an arbitrary pointer\\n\\nCVE-2009-0191: chain: malformed\\\n  \\ input causes dereference of uninitialized memory\\n\\nCVE-2008-4113: OS kernel trusts\\\n  \\ userland-supplied length value, allowing reading of sensitive information\\n\\n\\\n  CVE-2005-1513: Chain: integer overflow in securely-coded mail program leads to buffer\\\n  \\ overflow. In 2005, this was regarded as unrealistic to exploit, but in 2020, it\\\n  \\ was rediscovered to be easier to exploit due to evolutions of the technology.\\n\\\n  \\nCVE-2003-0542: buffer overflow involving a regular expression with a large number\\\n  \\ of captures\\n\\nCVE-2017-1000121: chain: unchecked message size metadata allows\\\n  \\ integer overflow (CWE-190) leading to buffer overflow (CWE-119).\"\nRelated_Attack_Patterns: \"10: \\n\\n100: \\n\\n123: \\n\\n14: \\n\\n24: \\n\\n42: \\n\\n44: \\n\\\n  \\n45: \\n\\n46: \\n\\n47: \\n\\n8: \\n\\n9: \"\n",
  "ID: '1190'\nName: DMA Device Enabled Too Early in Boot Phase\nDescription: The product enables a Direct Memory Access (DMA) capable device before\n  the security configuration settings are established, which allows an attacker to\n  extract data from or gain privileges on the product.\nExtended_Description: \"DMA is included in a number of devices because it allows\\n\\\n  \\              data transfer between the computer and the connected device, using\\n\\\n  \\              direct hardware access to read or write directly to main memory\\n\\\n  \\              without any OS interaction. An attacker could exploit this to\\n \\\n  \\             access secrets. Several virtualization-based mitigations have been\\\n  \\ introduced to thwart DMA attacks. These are usually\\n              configured/setup\\\n  \\ during boot time. However, certain IPs that are\\n              powered up before\\\n  \\ boot is complete (known as early boot IPs) may\\n              be DMA capable.\\\n  \\ Such IPs, if not trusted, could launch DMA\\n              attacks and gain access\\\n  \\ to assets that should otherwise be\\n              protected.\"\nApplicable_Platforms:\n  Technology: System on Chip\nPotential_Mitigations: \"Architecture and Design: Utilize an IOMMU to orchestrate IO\\\n  \\ access from\\n                 the start of the boot process.\"\nRelated_Attack_Patterns: '180: '\n",
  "ID: '1191'\nName: On-Chip Debug and Test Interface With Improper Access Control\nDescription: The chip does not implement or does not correctly perform access control\n  to check whether users are authorized to access internal registers and test modes\n  through the physical debug/test interface.\nExtended_Description: 'A device''s internal information may be accessed through a\n  scan chain of interconnected internal registers, usually through a JTAG interface.\n  The JTAG interface provides access to these registers in a serial fashion in the\n  form of a scan chain for the purposes of debugging programs running on a device.\n  Since almost all information contained within a device may be accessed over this\n  interface, device manufacturers typically insert some form of authentication and\n  authorization to prevent unintended use of this sensitive information. This mechanism\n  is implemented in addition to on-chip protections that are already present.\n\n  If authorization, authentication, or some other form of access control is not implemented\n  or not implemented correctly, a user may be able to bypass on-chip protection mechanisms\n  through the debug interface.\n\n  Sometimes, designers choose not to expose the debug pins on the motherboard. Instead,\n  they choose to hide these pins in the intermediate layers of the board. This is\n  primarily done to work around the lack of debug authorization inside the chip. In\n  such a scenario (without debug authorization), when the debug interface is exposed,\n  chip internals are accessible to an attacker.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Dynamic Analysis with Manual Results Interpretation: Authentication\n  and authorization of debug and test interfaces should be part of the architecture\n  and design review process. Withholding of private register documentation from the\n  debug and test interface public specification (\"Security by obscurity\") should not\n  be considered as sufficient security.\n\n\n  Dynamic Analysis with Manual Results Interpretation: Dynamic tests should be done\n  in the pre-silicon and post-silicon stages to verify that the debug and test interfaces\n  are not open by default.\n\n\n  Fuzzing: Tests that fuzz Debug and Test Interfaces should ensure that no access\n  without appropriate authentication and authorization is possible.'\nPotential_Mitigations: 'Architecture and Design: If feasible, the manufacturer should\n  disable the JTAG interface or implement authentication and authorization for the\n  JTAG interface. If authentication logic is added, it should be resistant to timing\n  attacks. Security-sensitive data stored in registers, such as keys, etc. should\n  be cleared when entering debug mode.'\nObserved_Examples: 'CVE-2019-18827: chain: JTAG interface is not disabled (CWE-1191)\n  during ROM code execution, introducing a race condition (CWE-362) to extract encryption\n  keys'\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '1192'\nName: System-on-Chip (SoC) Using Components without Unique, Immutable Identifiers\nDescription: The System-on-Chip (SoC) does not have unique, immutable identifiers\n  for each of its components.\nExtended_Description: \"A System-on-Chip (SoC) comprises several components (IP) with\\\n  \\ varied\\n           trust requirements. It is required that each IP is identified\\n\\\n  \\           uniquely and should distinguish itself from other entities in\\n    \\\n  \\       the SoC without any ambiguity. The unique secured identity is\\n        \\\n  \\   required for various purposes. Most of the time the identity is used\\n     \\\n  \\      to route a transaction or perform certain actions, including \\n         \\\n  \\  resetting, retrieving a sensitive information, and acting upon or on\\n      \\\n  \\     behalf of something else.\\nThere are several variants of this weakness:\"\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: \"Architecture and Design: Every identity generated in the SoC\\\n  \\ should be unique and\\n                    immutable in hardware. The actions that\\\n  \\ an IP is trusted or\\n                    not trusted should be clearly defined,\\\n  \\ implemented,\\n                    configured, and tested. If the definition is\\\n  \\ implemented via a\\n                    policy, then the policy should be immutable\\\n  \\ or protected with\\n                    clear authentication and authorization.\"\nRelated_Attack_Patterns: '113: '\n",
  "ID: '1193'\nName: Power-On of Untrusted Execution Core Before Enabling Fabric Access Control\nDescription: The product enables components that contain untrusted firmware before\n  memory and fabric access controls have been enabled.\nExtended_Description: \"After initial reset, System-on-Chip (SoC) fabric access controls\\\n  \\ and other\\n           security features need to be programmed by trusted firmware\\\n  \\ as part\\n           of the boot sequence. If untrusted IPs or peripheral microcontrollers\\n\\\n  \\t   are enabled first, then the untrusted component can master\\n           transactions\\\n  \\ on the hardware bus and target memory or other assets to\\n           compromise\\\n  \\ the SoC boot firmware.\"\nPotential_Mitigations: 'Architecture and Design: The boot sequence should enable fabric\n  access controls and memory protections before enabling third-party hardware IPs\n  and peripheral microcontrollers that use untrusted firmware.'\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '12'\nName: 'ASP.NET Misconfiguration: Missing Custom Error Page'\nDescription: An ASP .NET application must enable custom error pages in order to prevent\n  attackers from mining information from the framework's built-in responses.\nApplicable_Platforms:\n  Language: ASP.NET\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'System Configuration: Handle exceptions appropriately in source\n  code. ASP .NET applications should be configured to use custom error pages instead\n  of the framework default page.\n\n\n  Architecture and Design: Do not attempt to process an error or attempt to mask it.\n\n\n  Implementation: Verify return values are correct and do not supply sensitive information\n  about the system.'\n",
  "ID: '120'\nName: Buffer Copy without Checking Size of Input ('Classic Buffer Overflow')\nDescription: The product copies an input buffer to an output buffer without verifying\n  that the size of the input buffer is less than the size of the output buffer, leading\n  to a buffer overflow.\nExtended_Description: A buffer overflow condition exists when a product attempts to\n  put more data in a buffer than it can hold, or when it attempts to put data in a\n  memory area outside of the boundaries of a buffer. The simplest type of error, and\n  the most common cause of buffer overflows, is the \"classic\" case in which the product\n  copies the buffer without restricting how much is copied. Other variants exist,\n  but the existence of a classic overflow strongly suggests that the programmer is\n  not considering even the most basic of security protections.\nApplicable_Platforms:\n  Language: C, C++, Assembly\nAlternate_Terms: 'Classic Buffer Overflow: This term was frequently used by vulnerability\n  researchers during approximately 1995 to 2005 to differentiate buffer copies without\n  length checks (which had been known about for decades) from other emerging weaknesses\n  that still involved invalid accesses of buffers, as vulnerability researchers began\n  to develop advanced exploitation techniques.\n\n\n  Unbounded Transfer: '\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis generally does not account for environmental considerations\n  when reporting out-of-bounds memory operations. This can make it difficult for users\n  to determine which warnings should be investigated first. For example, an analysis\n  tool might report buffer overflows that originate from command line arguments in\n  a program that is not expected to run with setuid or other special privileges.\n\n  Detection techniques for buffer-related errors are more mature than for most other\n  weakness types.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n\n  Manual Analysis: Manual analysis can be useful for finding this weakness, but it\n  might not achieve desired code coverage within limited time constraints. This becomes\n  difficult for weaknesses that must be considered for all inputs, since the attack\n  surface can be too large.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, many languages that perform their own memory management, such as Java\n  and Perl, are not subject to buffer overflows. Other languages, such as Ada and\n  C#, typically provide overflow protection, but the protection can be disabled by\n  the programmer.\n\n  Be wary that a language''s interface to native code may still be subject to overflows,\n  even if the language itself is theoretically safe.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57],\n  and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer\n  versions of overflow-prone string-handling functions.\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Implementation: Consider adhering to the following rules when allocating and managing\n  an application''s memory:\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Build and Compilation\n\n  Operation: Most mitigating technologies at the compiler or OS level to date address\n  only a subset of buffer overflow problems and rarely provide complete protection\n  against even that subset. It is good practice to implement strategies to increase\n  the workload of an attacker, such as leaving the attacker to guess an unknown value\n  that changes every program execution.\n\n\n  Implementation: Replace unbounded copy functions with analogous functions that support\n  length arguments, such as strcpy with strncpy. Create these if they are not available.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.'\nObserved_Examples: 'CVE-2000-1094: buffer overflow using command with long argument\n\n\n  CVE-1999-0046: buffer overflow in local program using long environment variable\n\n\n  CVE-2002-1337: buffer overflow in comment characters, when product increments a\n  counter for a \">\" but does not decrement for \"<\"\n\n\n  CVE-2003-0595: By replacing a valid cookie value with an extremely long string of\n  characters, an attacker may overflow the application''s buffers.\n\n\n  CVE-2001-0191: By replacing a valid cookie value with an extremely long string of\n  characters, an attacker may overflow the application''s buffers.'\nRelated_Attack_Patterns: \"10: \\n\\n100: \\n\\n14: \\n\\n24: \\n\\n42: \\n\\n44: \\n\\n45: \\n\\n\\\n  46: \\n\\n47: \\n\\n67: \\n\\n8: \\n\\n9: \\n\\n92: \"\n",
  "ID: '1204'\nName: Generation of Weak Initialization Vector (IV)\nDescription: \"The product uses a cryptographic primitive that uses an Initialization\\n\\\n  \\t\\t\\tVector (IV), but the product does not generate IVs that are\\n\\t\\t\\tsufficiently\\\n  \\ unpredictable or unique according to the expected\\n\\t\\t\\tcryptographic requirements\\\n  \\ for that primitive.\"\nExtended_Description: \"By design, some cryptographic primitives\\n\\t\\t\\t  (such as\\\n  \\ block ciphers) require that IVs\\n\\t\\t\\t  must have certain properties for the\\n\\\n  \\t\\t\\t  uniqueness and/or unpredictability of an\\n\\t\\t\\t  IV. Primitives may vary\\\n  \\ in how important\\n\\t\\t\\t  these properties are. If these properties\\n\\t\\t\\t  are\\\n  \\ not maintained, e.g. by a bug in the\\n\\t\\t\\t  code, then the cryptography may\\\n  \\ be weakened\\n\\t\\t\\t  or broken by attacking the IVs themselves.\"\nPotential_Mitigations: \"Implementation: Different cipher\\n\\t\\t\\t    modes have different\\\n  \\ requirements for\\n\\t\\t\\t    their IVs. When choosing and implementing\\n\\t\\t\\t\\\n  \\    a mode, it is important to understand\\n\\t\\t\\t    those requirements in order\\\n  \\ to keep\\n\\t\\t\\t    security guarantees intact. Generally, it\\n\\t\\t\\t    is safest\\\n  \\ to generate a random IV, since\\n\\t\\t\\t    it will be both unpredictable and have\\\n  \\ a\\n\\t\\t\\t    very low chance of being non-unique. IVs\\n\\t\\t\\t    do not have to\\\n  \\ be kept secret, so if\\n\\t\\t\\t    generating duplicate IVs is a concern, a\\n\\t\\t\\\n  \\t    list of already-used IVs can be kept and\\n\\t\\t\\t    checked against.\\nNIST\\\n  \\ offers recommendations on generation of IVs for modes of which they have approved.\\\n  \\ These include options for when random IVs are not practical. For CBC, CFB, and\\\n  \\ OFB, see [REF-1175]; for GCM, see [REF-1178].\"\nObserved_Examples: 'CVE-2020-1472: ZeroLogon vulnerability - use of a static IV of\n  all zeroes in AES-CFB8 mode\n\n\n  CVE-2011-3389: BEAST attack in SSL 3.0 / TLS 1.0. In CBC mode, chained initialization\n  vectors are non-random, allowing decryption of HTTPS traffic using a chosen plaintext\n  attack.\n\n\n  CVE-2001-0161: wireless router does not use 6 of the 24 bits for WEP encryption,\n  making it easier for attackers to decrypt traffic\n\n\n  CVE-2001-0160: WEP card generates predictable IV values, making it easier for attackers\n  to decrypt traffic\n\n\n  CVE-2017-3225: device bootloader uses a zero initialization vector during AES-CBC\n\n\n  CVE-2016-6485: crypto framework uses PHP rand function - which is not cryptographically\n  secure - for an initialization vector\n\n\n  CVE-2014-5386: encryption routine does not seed the random number generator, causing\n  the same initialization vector to be generated repeatedly\n\n\n  CVE-2020-5408: encryption functionality in an authentication framework uses a fixed\n  null IV with CBC mode, allowing attackers to decrypt traffic in applications that\n  use this functionality\n\n\n  CVE-2017-17704: messages for a door-unlocking product use a fixed IV in CBC mode,\n  which is the same after each restart\n\n\n  CVE-2017-11133: application uses AES in CBC mode, but the pseudo-random secret and\n  IV are generated using math.random, which is not cryptographically strong.\n\n\n  CVE-2007-3528: Blowfish-CBC implementation constructs an IV where each byte is calculated\n  modulo 8 instead of modulo 256, resulting in less than 12 bits for the effective\n  IV length, and less than 4096 possible IV values.'\nRelated_Attack_Patterns: \"20: \\n\\n97: \"\n",
  "ID: '1209'\nName: Failure to Disable Reserved Bits\nDescription: The reserved bits in a hardware design are not disabled prior to production.\n  Typically, reserved bits are used for future capabilities and should not support\n  any functional logic in the design.   However, designers might covertly use these\n  bits to debug or further develop new capabilities in production hardware. Adversaries\n  with access to these bits will write to them in hopes of compromising hardware state.\nExtended_Description: Reserved bits are labeled as such so they can be allocated for\n  a later purpose. They are not to do anything in the current design.  However, designers\n  might want to use these bits to debug or control/configure a future capability to\n  help minimize time to market (TTM). If the logic being controlled by these bits\n  is still enabled in production, an adversary could use the logic to induce unwanted/unsupported\n  behavior in the hardware.\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: The Designer and Implementer have\n  to make a conscious choice to do this\n\n\n  Implementation: The Designer and Implementer have to make a conscious choice to\n  do this\n\n\n  Documentation: If documentation labels anything \"for future use\", \"reserved\", or\n  the like, such labeling could indicate to an attacker a potential attack point'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Include a feature to disable reserved bits.\n\n\n  Integration: Any writes to these reserve bits are blocked (e.g., ignored, access-protected,\n  etc.), or an exception can be asserted.'\nRelated_Attack_Patterns: '121: '\n",
  "ID: '121'\nName: Stack-based Buffer Overflow\nDescription: A stack-based buffer overflow condition is a condition where the buffer\n  being overwritten is allocated on the stack (i.e., is a local variable or, rarely,\n  a parameter to a function).\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: 'Stack Overflow: \"Stack Overflow\" is often used to mean the same\n  thing as stack-based buffer overflow, however it is also used on occasion to mean\n  stack exhaustion, usually a result from an excessively recursive function call.\n  Due to the ambiguity of the term, use of stack overflow to describe either circumstance\n  is discouraged.'\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Architecture and Design: Use an abstraction library to abstract away risky APIs.\n  Not a complete solution.\n\n\n  Implementation: Implement and perform bounds checking on input.\n\n\n  Implementation: Do not use dangerous functions such as gets. Use safer, equivalent\n  functions which check for boundary errors.\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].'\nObserved_Examples: 'CVE-2021-35395: Stack-based buffer overflows in SFK for wifi chipset\n  used for IoT/embedded devices, as exploited in the wild per CISA KEV.'\n",
  "ID: '122'\nName: Heap-based Buffer Overflow\nDescription: A heap overflow condition is a buffer overflow, where the buffer that\n  can be overwritten is allocated in the heap portion of memory, generally meaning\n  that the buffer was allocated using a routine such as malloc().\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nPotential_Mitigations: 'Pre-design: Use a language or compiler that performs automatic\n  bounds checking.\n\n\n  Architecture and Design: Use an abstraction library to abstract away risky APIs.\n  Not a complete solution.\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Implementation: Implement and perform bounds checking on input.\n\n\n  Implementation: Do not use dangerous functions such as gets. Look for their safe\n  equivalent, which checks for the boundary.\n\n\n  Operation: Use OS-level preventative functionality. This is not a complete solution,\n  but it provides some defense in depth.'\nObserved_Examples: \"CVE-2007-4268: Chain: integer signedness error (CWE-195) passes\\\n  \\ signed comparison, leading to heap overflow (CWE-122)\\n\\nCVE-2009-2523: Chain:\\\n  \\ product does not handle when an input string is not NULL terminated (CWE-170),\\\n  \\ leading to buffer over-read (CWE-125) or heap-based buffer overflow (CWE-122).\\n\\\n  \\nCVE-2021-29529: Chain: machine-learning product can have a heap-based\\n\\t    \\\n  \\  buffer overflow (CWE-122) when some integer-oriented bounds are\\n\\t      calculated\\\n  \\ by using ceiling() and floor() on floating point values\\n\\t      (CWE-1339)\"\nRelated_Attack_Patterns: '92: '\n",
  "ID: '1220'\nName: Insufficient Granularity of Access Control\nDescription: The product implements access controls via a policy or other feature\n  with the intention to disable or restrict accesses (reads and/or writes) to assets\n  in a system from untrusted agents. However, implemented access controls lack required\n  granularity, which renders the control policy too broad because it allows accesses\n  from unauthorized agents to the security-sensitive assets.\nExtended_Description: 'Integrated circuits and hardware engines can expose accesses\n  to assets (device configuration, keys, etc.) to trusted firmware or a software module\n  (commonly set by BIOS/bootloader). This access is typically access-controlled. Upon\n  a power reset, the hardware or system usually starts with default values in registers,\n  and the trusted firmware (Boot firmware) configures the necessary access-control\n  protection.\n\n  A common weakness that can exist in such protection schemes is that access controls\n  or policies are not granular enough. This condition allows agents beyond trusted\n  agents to access assets and could lead to a loss of functionality or the ability\n  to set up the device securely. This further results in security risks from leaked,\n  sensitive, key material to modification of device configuration.'\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during hardware implementation and\n  identified later during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation\n\n  Testing: '\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '1221'\nName: Incorrect Register Defaults or Module Parameters\nDescription: Hardware description language code incorrectly defines register defaults\n  or hardware IP parameters to insecure values.\nExtended_Description: 'Integrated circuits and hardware IP software programmable controls\n  and settings are commonly stored in register circuits. These register contents have\n  to be initialized at hardware reset to defined default values that are hard coded\n  in the hardware description language (HDL) code of the hardware unit. Hardware descriptive\n  languages also support definition of parameter variables, which can be defined in\n  code during instantiation of the hardware IP module. Such parameters are generally\n  used to configure a specific instance of a hardware IP in the design.\n\n  The system security settings of a hardware design can be affected by incorrectly\n  defined default values or IP parameters. The hardware IP would be in an insecure\n  state at power reset, and this can be exposed or exploited by untrusted software\n  running on the system. Both register defaults and parameters are hardcoded values,\n  which cannot be changed using software or firmware patches but must be changed in\n  hardware silicon. Thus, such security issues are considerably more difficult to\n  address later in the lifecycle. Hardware designs can have a large number of such\n  parameters and register defaults settings, and it is important to have design tool\n  support to check these settings in an automated way and be able to identify which\n  settings are security sensitive.'\nApplicable_Platforms:\n  Language: Verilog, VHDL\nModes_Of_Introduction: 'Implementation: Such issues could be introduced during implementation\n  of hardware design, since IP parameters and defaults are defined in HDL code and\n  identified later during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design: During hardware design, all the system\n  parameters and register defaults must be reviewed to identify security sensitive\n  settings.\n\n\n  Implementation: The default values of these security sensitive settings need to\n  be defined as part of the design review phase.\n\n\n  Testing: Testing phase should use automated tools to test that values are configured\n  per design specifications.'\nRelated_Attack_Patterns: '166: '\n",
  "ID: '1222'\nName: Insufficient Granularity of Address Regions Protected by Register Locks\nDescription: The product defines a large address region protected from modification\n  by the same register lock control bit. This results in a conflict between the functional\n  requirement that some addresses need to be writable by software during operation\n  and the security requirement that the system configuration lock bit must be set\n  during the boot process.\nExtended_Description: 'Integrated circuits and hardware IPs can expose the device\n  configuration controls that need to be programmed after device power reset by a\n  trusted firmware or software module (commonly set by BIOS/bootloader) and then locked\n  from any further modification. In hardware design, this is commonly implemented\n  using a programmable lock bit which enables/disables writing to a protected set\n  of registers or address regions. When the programmable lock bit is set, the relevant\n  address region can be implemented as a hardcoded value in hardware logic that cannot\n  be changed later.\n\n  A problem can arise wherein the protected region definition is not granular enough.\n  After the programmable lock bit has been set, then this new functionality cannot\n  be implemented without change to the hardware design.'\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: Such issues are introduced during\n  hardware architecture and design since software controls and configuration are defined\n  during these phases and identified later during Testing or System Configuration\n  phases.'\nPotential_Mitigations: 'Architecture and Design: The defining of protected locked\n  registers should be reviewed or tested early in the design phase with software teams\n  to ensure software flows are not blocked by the security locks.\n\n  As an alternative to using register lock control bits and fixed access control regions,\n  the hardware design could use programmable security access control configuration\n  so that device trusted firmware can configure and change the protected regions based\n  on software usage and security models.'\nRelated_Attack_Patterns: '679: '\n",
  "ID: '1223'\nName: Race Condition for Write-Once Attributes\nDescription: A write-once register in hardware design is programmable by an untrusted\n  software component earlier than the trusted software component, resulting in a race\n  condition issue.\nExtended_Description: 'Integrated circuits and hardware IP software programmable controls\n  and settings are commonly stored in register circuits. These register contents have\n  to be initialized at hardware reset to defined default values that are hard coded\n  in the hardware description language (HDL) code of the hardware unit. A common security\n  protection method used to protect register settings from modification by software\n  is to make them write-once. This means the hardware implementation only allows writing\n  to such registers once, and they become read-only after having been written once\n  by software. This is useful to allow initial boot software to configure systems\n  settings to secure values while blocking runtime software from modifying such hardware\n  settings.\n\n  Implementation issues in hardware design of such controls can expose such registers\n  to a race condition security flaw. For example, consider a hardware design that\n  has two different software/firmware modules executing in parallel. One module is\n  trusted (module A) and another is untrusted (module B). In this design it could\n  be possible for Module B to send write cycles to the write-once register before\n  Module A. Since the field is write-once the programmed value from Module A will\n  be ignored and the pre-empted value programmed by Module B will be used by hardware.'\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: This weakness can appear in designs\n  that use register write-once attributes with two or more software/firmware modules\n  with varying levels of trust executing in parallel.'\nPotential_Mitigations: 'Architecture and Design: During hardware design all register\n  write-once or sticky fields must be evaluated for proper configuration.\n\n\n  Testing: The testing phase should use automated tools to test that values are not\n  reprogrammable and that write-once fields lock on writing zeros.'\nRelated_Attack_Patterns: '26: '\n",
  "ID: '1224'\nName: Improper Restriction of Write-Once Bit Fields\nDescription: The hardware design control register \"sticky bits\" or write-once bit\n  fields are improperly implemented, such that they can be reprogrammed by software.\nExtended_Description: 'Integrated circuits and hardware IP software programmable controls\n  and settings are commonly stored in register circuits. These register contents have\n  to be initialized at hardware reset to define default values that are hard coded\n  in the hardware description language (HDL) code of the hardware unit. A common security\n  protection method used to protect register settings from modification by software\n  is to make the settings write-once or \"sticky.\" This allows writing to such registers\n  only once, whereupon they become read-only. This is useful to allow initial boot\n  software to configure systems settings to secure values while blocking runtime software\n  from modifying such hardware settings.\n\n  Failure to implement write-once restrictions in hardware design can expose such\n  registers to being re-programmed by software and written multiple times. For example,\n  write-once fields could be implemented to only be write-protected if they have been\n  set to value \"1\", wherein they would work as \"write-1-once\" and not \"write-once\".'\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: Such issues could\\\n  \\ be introduced during implementation of hardware design, since IP parameters and\\\n  \\ defaults are defined in HDL code and identified later during Testing or System\\\n  \\ Configuration phases.\"\nPotential_Mitigations: 'Architecture and Design: During hardware design all register\n  write-once or sticky fields must be evaluated for proper configuration.\n\n\n  Testing: The testing phase should use automated tools to test that values are not\n  reprogrammable and that write-once fields lock on writing zeros.'\nRelated_Attack_Patterns: '680: '\n",
  "ID: '1229'\nName: Creation of Emergent Resource\nDescription: The product manages resources or behaves in a way that indirectly creates\n  a new, distinct resource that can be used by attackers in violation of the intended\n  policy.\nExtended_Description: A product is only expected to behave in a way that was specifically\n  intended by the developer.  Resource allocation and management is expected to be\n  performed explicitly by the associated code.  However, in systems with complex behavior,\n  the product might indirectly produce new kinds of resources that were never intended\n  in the original design.  For example, a covert channel is a resource that was never\n  explicitly intended by the developer, but it is useful to attackers.  \"Parasitic\n  computing,\" while not necessarily malicious in nature, effectively tricks a product\n  into performing unintended computations on behalf of another party.\n",
  "ID: '123'\nName: Write-what-where Condition\nDescription: Any condition where the attacker has the ability to write an arbitrary\n  value to an arbitrary location, often as the result of a buffer overflow.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Architecture and Design: Use a language that provides appropriate\n  memory abstractions.\n\n\n  Operation: Use OS-level preventative functionality integrated after the fact. Not\n  a complete solution.'\n",
  "ID: '1230'\nName: Exposure of Sensitive Information Through Metadata\nDescription: The product prevents direct access to a resource containing sensitive\n  information, but it does not sufficiently limit access to metadata that is derived\n  from the original, sensitive information.\nExtended_Description: Developers might correctly prevent unauthorized access to a\n  database or other resource containing sensitive information, but they might not\n  consider that portions of the original information might also be recorded in metadata,\n  search indices, statistical reports, or other resources.  If these resources are\n  not also restricted, then attackers might be able to extract some or all of the\n  original information, or otherwise infer some details.  For example, an attacker\n  could specify search terms that are known to be unique to a particular person, or\n  view metadata such as activity or creation dates in order to identify usage patterns.\n",
  "ID: '1231'\nName: Improper Prevention of Lock Bit Modification\nDescription: The product uses a trusted lock bit for restricting access to registers,\n  address regions, or other resources, but the product does not prevent the value\n  of the lock bit from being modified after it has been set.\nExtended_Description: \"In integrated circuits and hardware\\n\\t\\t\\t  intellectual property\\\n  \\ (IP) cores, device configuration\\n\\t\\t\\t  controls are commonly programmed after\\\n  \\ a device power\\n\\t\\t\\t  reset by a trusted firmware or software module (e.g.,\\n\\\n  \\t\\t\\t  BIOS/bootloader) and then locked from any further\\n\\t\\t\\t  modification.\\n\\\n  This behavior is commonly implemented using a trusted lock bit. \\n\\t\\t\\t  When set,\\\n  \\ the lock bit disables writes to a protected set of\\n\\t\\t\\t  registers or address\\\n  \\ regions. Design or coding errors in\\n\\t\\t\\t  the implementation of the lock bit\\\n  \\ protection feature\\n\\t\\t\\t  may allow the lock bit to be modified or cleared by\\n\\\n  \\t\\t\\t  software after it has been set. Attackers might be able to unlock the system\\\n  \\ and\\n\\t\\t\\t  features that the bit is intended to protect.\"\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during implementation and identified\n  later during Testing or System Configuration phases.'\nDetection_Methods: \"Manual Analysis: Set the lock bit. Power cycle the\\n\\t     device.\\\n  \\ Attempt to clear the lock bit.  If the\\n\\t     information is changed, implement\\\n  \\ a design\\n\\t     fix. Retest. Also, attempt to indirectly clear the lock\\n\\t \\\n  \\    bit or bypass it.\"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation\n\n  Testing: '\nObserved_Examples: 'CVE-2017-6283: chip reset clears critical read/write lock permissions\n  for RSA function'\nRelated_Attack_Patterns: '680: '\n",
  "ID: '1232'\nName: Improper Lock Behavior After Power State Transition\nDescription: Register lock bit protection disables changes to system configuration\n  once the bit is set. Some of the protected registers or lock bits become programmable\n  after power state transitions (e.g., Entry and wake from low power sleep modes)\n  causing the system configuration to be changeable.\nExtended_Description: 'Devices may allow device configuration controls which need\n  to be programmed after device power reset via a trusted firmware or software module\n  (commonly set by BIOS/bootloader) and then locked from any further modification.\n  This action is commonly implemented using a programmable lock bit, which, when set,\n  disables writes to a protected set of registers or address regions.\n\n  After a power state transition, the lock bit is set to unlocked. Some common weaknesses\n  that can exist in such a protection scheme are that the lock gets cleared, the values\n  of the protected registers get reset, or the lock become programmable.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation\n\n  Testing: '\nRelated_Attack_Patterns: '166: '\n",
  "ID: '1233'\nName: Security-Sensitive Hardware Controls with Missing Lock Bit Protection\nDescription: The product uses a register lock bit protection mechanism, but it does\n  not ensure that the lock bit prevents modification of system registers or controls\n  that perform changes to important hardware system configuration.\nExtended_Description: 'Integrated circuits and hardware intellectual properties (IPs)\n  might provide device configuration controls that need to be programmed after device\n  power reset by a trusted firmware or software module, commonly set by BIOS/bootloader.\n  After reset, there can be an expectation that the controls cannot be used to perform\n  any further modification. This behavior is commonly implemented using a trusted\n  lock bit, which can be set to disable writes to a protected set of registers or\n  address regions. The lock protection is intended to prevent modification of certain\n  system configuration (e.g., memory/memory protection unit configuration).\n\n  However, if the lock bit does not effectively write-protect all system registers\n  or controls that could modify the protected system configuration, then an adversary\n  may be able to use software to access the registers/controls and modify the protected\n  hardware configuration.'\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during implementation and identified\n  later during Testing or System Configuration phases.'\nDetection_Methods: \"Manual Analysis: Set the lock bit. Attempt to modify the\\n\\t \\\n  \\    information protected by the lock bit. If the information\\n\\t     is changed,\\\n  \\ implement a design fix. Retest. Also, attempt\\n\\t     to indirectly clear the\\\n  \\ lock bit or bypass\\n\\t     it.\"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation\n\n  Testing: '\nObserved_Examples: \"CVE-2018-9085: Certain servers leave a write protection lock bit\\n\\\n  \\t\\tunset after boot, potentially allowing modification of\\n\\t\\tparts of flash memory.\\n\\\n  \\nCVE-2014-8273: Chain: chipset has a race condition (CWE-362) between when an interrupt\\\n  \\ handler detects an attempt to write-enable the BIOS (in violation of the lock\\\n  \\ bit), and when the handler resets the write-enable bit back to 0, allowing attackers\\\n  \\ to issue BIOS writes during the timing window [REF-1237].\"\nRelated_Attack_Patterns: \"176: \\n\\n680: \"\n",
  "ID: '1234'\nName: Hardware Internal or Debug Modes Allow Override of Locks\nDescription: System configuration protection may be bypassed during debug mode.\nExtended_Description: Device configuration controls are commonly programmed after\n  a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader)\n  and then locked from any further modification. This is commonly implemented using\n  a trusted lock bit, which when set, disables writes to a protected set of registers\n  or address regions. The lock protection is intended to prevent modification of certain\n  system configuration (e.g., memory/memory protection unit configuration). If debug\n  features supported by hardware or internal modes/system states are supported in\n  the hardware design, modification of the lock protection may be allowed allowing\n  access and modification of configuration information.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation\n\n  Testing: '\nRelated_Attack_Patterns: '176: '\n",
  "ID: '1235'\nName: Incorrect Use of Autoboxing and Unboxing for Performance Critical Operations\nDescription: The code uses boxed primitives, which may introduce inefficiencies into\n  performance-critical operations.\nExtended_Description: 'Languages such as Java and C# support automatic conversion\n  through their respective compilers from primitive types into objects of the corresponding\n  wrapper classes, and vice versa. For example, a compiler might convert an int to\n  Integer (called autoboxing) or an Integer to int (called unboxing). This eliminates\n  forcing the programmer to perform these conversions manually, which makes the code\n  cleaner.\n\n  However, this feature comes at a cost of performance and can lead to resource exhaustion\n  and impact availability when used with generic collections. Therefore, they should\n  not be used for scientific computing or other performance critical operations. They\n  are only suited to support \"impedance mismatch\" between reference types and primitives.'\nApplicable_Platforms:\n  Language: Java, C#\nModes_Of_Introduction: 'Implementation: The programmer may use boxed primitives when\n  not strictly necessary.'\nPotential_Mitigations: 'Implementation: Use of boxed primitives should be limited\n  to certain situations such as when calling methods with typed parameters.  Examine\n  the use of boxed primitives prior to use. Use SparseArrays or ArrayMap instead of\n  HashMap to avoid performance overhead.'\n",
  "ID: '1236'\nName: Improper Neutralization of Formula Elements in a CSV File\nDescription: The product saves user-provided information into a Comma-Separated Value\n  (CSV) file, but it does not neutralize or incorrectly neutralizes special elements\n  that could be interpreted as a command when the file is opened by a spreadsheet\n  product.\nExtended_Description: User-provided data is often saved to traditional databases.  This\n  data can be exported to a CSV file, which allows users to read the data using spreadsheet\n  software such as Excel, Numbers, or Calc.  This software interprets entries beginning\n  with '=' as formulas, which are then executed by the spreadsheet software.  The\n  software's formula language often allows methods to access hyperlinks or the local\n  command line, and frequently allows enough characters to invoke an entire script.\n  Attackers can populate data fields which, when saved to a CSV file, may attempt\n  information exfiltration or other malicious activity when automatically executed\n  by the spreadsheet software.\nApplicable_Platforms:\n  Technology: Other\nAlternate_Terms: \"CSV Injection: \\n\\nFormula Injection: \\n\\nExcel Macro Injection: \"\nModes_Of_Introduction: 'Implementation: The weakness is in the implementation of a\n  software''s CSV export feature, in particular how it formats formula entries as\n  the output gets flattened into a text file.'\nPotential_Mitigations: 'Implementation: When generating CSV output, ensure that formula-sensitive\n  metacharacters are effectively escaped or removed from all data before storage in\n  the resultant CSV.  Risky characters include ''='' (equal), ''+'' (plus), ''-''\n  (minus), and ''@'' (at).\n\n\n  Implementation: If a field starts with a formula character, prepend it with a ''\n  (single apostrophe), which prevents Excel from executing the formula.\n\n\n  Architecture and Design: Certain implementations of spreadsheet software might disallow\n  formulas from executing if the file is untrusted, or if the file is not authored\n  by the current user.'\nObserved_Examples: 'CVE-2019-12134: Low privileged user can trigger CSV injection\n  through a contact form field value\n\n\n  CVE-2019-4521: Cloud management product allows arbitrary command execution via CSV\n  injection\n\n\n  CVE-2019-17661: CSV injection in content management system via formula code in a\n  first or last name'\n",
  "ID: '1239'\nName: Improper Zeroization of Hardware Register\nDescription: The hardware product does not properly clear sensitive information from\n  built-in registers when the user of the hardware block changes.\nExtended_Description: Hardware logic operates on data stored in registers local to\n  the hardware block. Most hardware IPs, including cryptographic accelerators, rely\n  on registers to buffer I/O, store intermediate values, and interface with software.\n  The result of this is that sensitive information, such as passwords or encryption\n  keys, can exist in locations not transparent to the user of the hardware logic.\n  When a different entity obtains access to the IP due to a change in operating mode\n  or conditions, the new entity can extract information belonging to the previous\n  user if no mechanisms are in place to clear register contents. It is important to\n  clear information stored in the hardware if a physical attack on the product is\n  detected, or if the user of the hardware block changes. The process of clearing\n  register contents in a hardware IP is referred to as zeroization in standards for\n  cryptographic hardware modules such as FIPS-140-2 [REF-267].\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: Lack of hardware mechanisms to zeroize\n  or clear registers in the design or specification.\n\n\n  Implementation: Mechanisms to zeroize and clear registers are in the design but\n  implemented incorrectly.\n\n\n  Operation: Hardware-provided zeroization mechanisms are not used appropriately by\n  the IP user (ex. firmware), or data remanence issues are not taken into account.'\nPotential_Mitigations: 'Architecture and Design: Every register potentially containing\n  sensitive information must have a policy specifying how and when information is\n  cleared, in addition to clarifying if it is the responsibility of the hardware logic\n  or IP user to initiate the zeroization procedure at the appropriate time.'\nRelated_Attack_Patterns: \"150: \\n\\n204: \\n\\n37: \\n\\n545: \"\n",
  "ID: '124'\nName: Buffer Underwrite ('Buffer Underflow')\nDescription: The product writes to a buffer using an index or pointer that references\n  a memory location prior to the beginning of the buffer.\nExtended_Description: This typically occurs when a pointer or its index is decremented\n  to a position before the buffer, when pointer arithmetic results in a position before\n  the beginning of the valid memory location, or when a negative index is used.\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: 'buffer underrun: Some prominent vendors and researchers use the\n  term \"buffer underrun\". \"Buffer underflow\" is more commonly used, although both\n  terms are also sometimes used to describe a buffer under-read (CWE-127).'\nPotential_Mitigations: 'Requirements: Choose a language that is not susceptible to\n  these issues.\n\n\n  Implementation: All calculated values that are used as index or for pointer arithmetic\n  should be validated to ensure that they are within an expected range.'\nObserved_Examples: 'CVE-2021-24018: buffer underwrite in firmware verification routine\n  allows code execution via a crafted firmware image\n\n\n  CVE-2002-2227: Unchecked length of SSLv2 challenge value leads to buffer underflow.\n\n\n  CVE-2007-4580: Buffer underflow from a small size value with a large buffer (length\n  parameter inconsistency, CWE-130)\n\n\n  CVE-2007-1584: Buffer underflow from an all-whitespace string, which causes a counter\n  to be decremented before the buffer while looking for a non-whitespace character.\n\n\n  CVE-2007-0886: Buffer underflow resultant from encoded data that triggers an integer\n  overflow.\n\n\n  CVE-2006-6171: Product sets an incorrect buffer size limit, leading to \"off-by-two\"\n  buffer underflow.\n\n\n  CVE-2006-4024: Negative value is used in a memcpy() operation, leading to buffer\n  underflow.\n\n\n  CVE-2004-2620: Buffer underflow due to mishandled special characters'\n",
  "ID: '1240'\nName: Use of a Cryptographic Primitive with a Risky Implementation\nDescription: To fulfill the need for a cryptographic primitive, the product implements\n  a cryptographic algorithm using a non-standard, unproven, or disallowed/non-compliant\n  cryptographic implementation.\nExtended_Description: 'Cryptographic protocols and systems depend on cryptographic\n  primitives (and associated algorithms) as their basic building blocks. Some common\n  examples of primitives are digital signatures, one-way hash functions, ciphers,\n  and public key cryptography; however, the notion of \"primitive\" can vary depending\n  on point of view. See \"Terminology Notes\" for further explanation of some concepts.\n\n  Cryptographic primitives are defined to accomplish one very specific task in a precisely\n  defined and mathematically reliable fashion. For example, suppose that for a specific\n  cryptographic primitive (such as an encryption routine), the consensus is that the\n  primitive can only be broken after trying out N different inputs (where the larger\n  the value of N, the stronger the cryptography). For an encryption scheme like AES-256,\n  one would expect N to be so large as to be infeasible to execute in a reasonable\n  amount of time.\n\n  If a vulnerability is ever found that shows that one can break a cryptographic primitive\n  in significantly less than the expected number of attempts, then that primitive\n  is considered weakened (or sometimes in extreme cases, colloquially it is \"broken\").\n  As a result, anything using this cryptographic primitive would now be considered\n  insecure or risky. Thus, even breaking or weakening a seemingly small cryptographic\n  primitive has the potential to render the whole system vulnerable, due to its reliance\n  on the primitive. A historical example can be found in TLS when using DES. One would\n  colloquially call DES the cryptographic primitive for transport encryption in this\n  version of TLS. In the past, DES was considered strong, because no weaknesses were\n  found in it; importantly, DES has a key length of 56 bits. Trying N=2^56 keys was\n  considered impractical for most actors. Unfortunately, attacking a system with 56-bit\n  keys is now practical via brute force, which makes defeating DES encryption practical.\n  It is now practical for an adversary to read any information sent under this version\n  of TLS and use this information to attack the system. As a result, it can be claimed\n  that this use of TLS is weak, and that any system depending on TLS with DES could\n  potentially render the entire system vulnerable to attack.\n\n  Cryptographic primitives and associated algorithms are only considered safe after\n  extensive research and review from experienced cryptographers from academia, industry,\n  and government entities looking for any possible flaws. Furthermore, cryptographic\n  primitives and associated algorithms are frequently reevaluated for safety when\n  new mathematical and attack techniques are discovered.  As a result and over time,\n  even well-known cryptographic primitives can lose their compliance status with the\n  discovery of novel attacks that might either defeat the algorithm or reduce its\n  robustness significantly.\n\n  If ad-hoc cryptographic primitives are implemented, it is almost certain that the\n  implementation will be vulnerable to attacks that are well understood by cryptographers,\n  resulting in the exposure of sensitive information and other consequences.\n\n  This weakness is even more difficult to manage for hardware-implemented deployment\n  of cryptographic algorithms. First, because hardware is not patchable as easily\n  as software, any flaw discovered after release and production typically cannot be\n  fixed without a recall of the product. Secondly, the hardware product is often expected\n  to work for years, during which time computation power available to the attacker\n  only increases. Therefore, for hardware implementations of cryptographic primitives,\n  it is absolutely essential that only strong, proven cryptographic primitives are\n  used.'\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: This weakness is primarily introduced\n  during the architecture and design phase as risky primitives are included.\n\n\n  Implementation: Even in cases where the Architectural phase properly specifies a\n  cryptographically secure design, the design may be changed during implementation\n  due to unforeseen constraints.'\nDetection_Methods: 'Architecture or Design Review: Review requirements, documentation,\n  and product design to ensure that primitives are consistent with the strongest-available\n  recommendations from trusted parties. If the product appears to be using custom\n  or proprietary implementations that have not had sufficient public review and approval,\n  then this is a significant concern.\n\n\n  Manual Analysis: Analyze the product to ensure that implementations for each primitive\n  do not contain any known vulnerabilities and are not using any known-weak algorithms,\n  including MD4, MD5, SHA1, DES, etc.\n\n\n  Dynamic Analysis with Manual Results Interpretation: For hardware, during the implementation\n  (pre-Silicon / post-Silicon) phase, dynamic tests should be done to ensure that\n  outputs from cryptographic routines are indeed working properly, such as test vectors\n  provided by NIST [REF-1236].\n\n\n  Dynamic Analysis with Manual Results Interpretation: It needs to be determined if\n  the output of a cryptographic primitive is lacking entropy, which is one clear sign\n  that something went wrong with the crypto implementation. There exist many methods\n  of measuring the entropy of a bytestream, from sophisticated ones (like calculating\n  Shannon''s entropy of a sequence of characters) to crude ones (by compressing it\n  and comparing the size of the original bytestream vs. the compressed - a truly random\n  byte stream should not be compressible and hence the uncompressed and compressed\n  bytestreams should be nearly identical in size).'\nPotential_Mitigations: 'Requirements: Require compliance with the strongest-available\n  recommendations from trusted parties, and require that compliance must be kept up-to-date,\n  since recommendations evolve over time. For example, US government systems require\n  FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].\n\n\n  Architecture and Design: Ensure that the architecture/design uses the strongest-available\n  primitives and algorithms from trusted parties. For example, US government systems\n  require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].\n\n\n  Architecture and Design: Do not develop custom or private cryptographic algorithms.\n  They will likely be exposed to attacks that are well-understood by cryptographers.\n  As with all cryptographic mechanisms, the source code should be available for analysis.\n  If the algorithm may be compromised when attackers find out how it works, then it\n  is especially weak.\n\n\n  Architecture and Design: Try not to use cryptographic algorithms in novel ways or\n  with new modes of operation even when you \"know\" it is secure. For example, using\n  SHA-2 chaining to create a 1-time pad for encryption might sound like a good idea,\n  but one should not do this.\n\n\n  Architecture and Design: Ensure that the design can replace one cryptographic primitive\n  or algorithm with another in the next generation (\"cryptographic agility\"). Where\n  possible, use wrappers to make the interfaces uniform. This will make it easier\n  to upgrade to stronger algorithms. This is especially important for hardware, which\n  can be more difficult to upgrade quickly than software; design the hardware at a\n  replaceable block level.\n\n\n  Architecture and Design: Do not use outdated or non-compliant cryptography algorithms.\n  Some older algorithms, once thought to require a billion years of computing time,\n  can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other\n  algorithms that were once regarded as strong [REF-267].\n\n\n  Architecture and Design\n\n  Implementation: Do not use a linear-feedback shift register (LFSR) or other legacy\n  methods as a substitute for an accepted and standard Random Number Generator.\n\n\n  Architecture and Design\n\n  Implementation: Do not use a checksum as a substitute for a cryptographically generated\n  hash.\n\n\n  Architecture and Design: Use a vetted cryptographic library or framework. Industry-standard\n  implementations will save development time and are more likely to avoid errors that\n  can occur during implementation of cryptographic algorithms. However, the library/framework\n  could be used incorrectly during implementation.\n\n\n  Architecture and Design\n\n  Implementation: When using industry-approved techniques, use them correctly. Don''t\n  cut corners by skipping resource-intensive steps (CWE-325). These steps are often\n  essential for the prevention of common attacks.\n\n\n  Architecture and Design\n\n  Implementation: Do not store keys in areas accessible to untrusted agents. Carefully\n  manage and protect the cryptographic keys (see CWE-320). If the keys can be guessed\n  or stolen, then the strength of the cryptography algorithm is irrelevant.'\nObserved_Examples: 'CVE-2020-4778: software uses MD5, which is less safe than the\n  default SHA-256 used by related products\n\n\n  CVE-2005-2946: Default configuration of product uses MD5 instead of stronger algorithms\n  that are available, simplifying forgery of certificates.\n\n\n  CVE-2019-3907: identity card uses MD5 hash of a salt and password\n\n\n  CVE-2021-34687: personal key is transmitted over the network using a substitution\n  cipher\n\n\n  CVE-2020-14254: product does not disable TLS-RSA cipher suites, allowing decryption\n  of traffic if TLS 2.0 and secure ciphers are not enabled.\n\n\n  CVE-2019-1543: SSL/TLS library generates 16-byte nonces but reduces them to 12 byte\n  nonces for the ChaCha20-Poly1305 cipher, converting them in a way that violates\n  the cipher''s requirements for unique nonces.\n\n\n  CVE-2017-9267: LDAP interface allows use of weak ciphers\n\n\n  CVE-2017-7971: SCADA product allows \"use of outdated cipher suites\"\n\n\n  CVE-2020-6616: Chip implementing Bluetooth uses a low-entropy PRNG instead of a\n  hardware RNG, allowing spoofing.\n\n\n  CVE-2019-1715: security product has insufficient entropy in the DRBG, allowing collisions\n  and private key discovery\n\n\n  CVE-2014-4192: Dual_EC_DRBG implementation in RSA toolkit does not correctly handle\n  certain byte requests, simplifying plaintext recovery\n\n\n  CVE-2007-6755: Recommendation for Dual_EC_DRBG algorithm contains point Q constants\n  that could simplify decryption'\nRelated_Attack_Patterns: '97: '\n",
  "ID: '1241'\nName: Use of Predictable Algorithm in Random Number Generator\nDescription: The device uses an algorithm that is predictable and generates a pseudo-random\n  number.\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: In many cases,\\\n  \\ the design originally defines a cryptographically secure random number generator,\\\n  \\ but is then changed during implementation due to unforeseen constraints.\"\nPotential_Mitigations: 'Architecture and Design: A true random number generator should\n  be specified for cryptographic algorithms.\n\n\n  Implementation: A true random number generator should be implemented for cryptographic\n  algorithms.'\nRelated_Attack_Patterns: '97: '\n",
  "ID: '1242'\nName: Inclusion of Undocumented Features or Chicken Bits\nDescription: The device includes chicken bits or undocumented features that can create\n  entry points for unauthorized actors.\nExtended_Description: A common design practice is to use undocumented bits on a device\n  that can be used to disable certain functional security features. These bits are\n  commonly referred to as \"chicken bits\". They can facilitate quick identification\n  and isolation of faulty components, features that negatively affect performance,\n  or features that do not provide the required controllability for debug and test.\n  Another way to achieve this is through implementation of undocumented features.\n  An attacker might exploit these interfaces for unauthorized access.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nDocumentation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: The implementation of chicken bits in a released product is highly\n  discouraged. If implemented at all, ensure that they are disabled in production\n  devices. All interfaces to a device should be documented.'\nRelated_Attack_Patterns: \"212: \\n\\n36: \"\n",
  "ID: '1243'\nName: Sensitive Non-Volatile Information Not Protected During Debug\nDescription: Access to security-sensitive information stored in fuses is not limited\n  during debug.\nExtended_Description: Several security-sensitive values are programmed into fuses\n  to be used during early-boot flows or later at runtime. Examples of these security-sensitive\n  values include root keys, encryption keys, manufacturing-specific information, chip-manufacturer-specific\n  information, and original-equipment-manufacturer (OEM) data. After the chip is powered\n  on, these values are sensed from fuses and stored in temporary locations such as\n  registers and local memories. These locations are typically access-control protected\n  from untrusted agents capable of accessing them. Even to trusted agents, only read-access\n  is provided. However, these locations are not blocked during debug operations, allowing\n  a user to access this sensitive information.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Disable access to security-sensitive information stored in fuses\n  directly and also reflected from  temporary storage locations when in debug mode.'\nRelated_Attack_Patterns: \"116: \\n\\n545: \"\n",
  "ID: '1244'\nName: Internal Asset Exposed to Unsafe Debug Access Level or State\nDescription: \"The product uses physical debug or test\\n        interfaces with support\\\n  \\ for multiple access levels, but it\\n        assigns the wrong debug access level\\\n  \\ to an internal asset,\\n        providing unintended access to the asset from untrusted\\\n  \\ debug\\n        agents.\"\nExtended_Description: \"Debug authorization can have multiple levels of\\n\\t  access,\\\n  \\ defined such that different system internal assets\\n\\t  are accessible based on\\\n  \\ the current authorized debug\\n\\t  level. Other than debugger authentication (e.g.,\\\n  \\ using\\n\\t  passwords or challenges), the authorization can also be\\n\\t  based\\\n  \\ on the system state or boot stage. For example, full\\n\\t  system debug access\\\n  \\ might only be allowed early in boot\\n\\t  after a system reset to ensure that previous\\\n  \\ session data is\\n\\t  not accessible to the authenticated debugger.\\nIf this protection\\\n  \\ mechanism does not ensure that\\n          internal assets have the correct debug\\\n  \\ access level during\\n          each boot stage or change in system state, an attacker\\\n  \\ could\\n          obtain sensitive information from the internal asset using a\\n\\\n  \\          debugger.\"\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Manual Analysis: Check 2 devices for their passcode to authenticate\n  access to JTAG/debugging ports. If the passcodes are missing or the same, update\n  the design to fix and retest. Check communications over JTAG/debugging ports for\n  encryption. If the communications are not encrypted, fix the design and retest.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: For security-sensitive assets accessible over debug/test interfaces,\n  only allow trusted agents.\n\n\n  Architecture and Design: Apply blinding [REF-1219] or masking techniques in strategic\n  areas.\n\n\n  Implementation: Add shielding or tamper-resistant protections to the device, which\n  increases the difficulty and cost for accessing debug/test interfaces.'\nObserved_Examples: 'CVE-2019-18827: After ROM code execution, JTAG access is disabled.\n  But before the ROM code is executed, JTAG access is possible, allowing a user full\n  system access.  This allows a user to modify the boot flow and successfully bypass\n  the secure-boot process.'\nRelated_Attack_Patterns: '114: '\n",
  "ID: '1245'\nName: Improper Finite State Machines (FSMs) in Hardware Logic\nDescription: Faulty finite state machines (FSMs) in the hardware logic allow an attacker\n  to put the system in an undefined state, to cause a denial of service (DoS) or gain\n  privileges on the victim's system.\nExtended_Description: The functionality and security of the system heavily depend\n  on the implementation of FSMs. FSMs can be used to indicate the current security\n  state of the system. Lots of secure data operations and data transfers rely on the\n  state reported by the FSM. Faulty FSM designs that do not account for all states,\n  either through undefined states (left as don't cares) or through incorrect implementation,\n  might lead an attacker to drive the system into an unstable state from which the\n  system cannot recover without a reset, thus causing a DoS. Depending on what the\n  FSM is used for, an attacker might also gain additional privileges to launch further\n  attacks and compromise the security guarantees.\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Define all possible states and handle all unused states through\n  default statements. Ensure that system defaults to a secure state.'\nRelated_Attack_Patterns: '74: '\n",
  "ID: '1246'\nName: Improper Write Handling in Limited-write Non-Volatile Memories\nDescription: The product does not implement or incorrectly implements wear leveling\n  operations in limited-write non-volatile memories.\nExtended_Description: Non-volatile memories such as NAND Flash, EEPROM, etc. have\n  individually erasable segments, each of which can be put through a limited number\n  of program/erase or write cycles. For example, the device can only endure a limited\n  number of writes, after which the device becomes unreliable. In order to wear out\n  the cells in a uniform manner, non-volatile memory and storage products based on\n  the above-mentioned technologies implement a technique called wear leveling. Once\n  a set threshold is reached, wear leveling maps writes of a logical block to a different\n  physical block. This prevents a single physical block from prematurely failing due\n  to a high concentration of writes. If wear leveling is improperly implemented, attackers\n  may be able to programmatically cause the storage to become unreliable within a\n  much shorter time than would normally be expected.\nApplicable_Platforms:\n  Technology: System on Chip, Memory Hardware, Storage Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation\n\n  Testing: Include secure wear leveling algorithms and ensure they may not be bypassed.'\nRelated_Attack_Patterns: '212: '\n",
  "ID: '1247'\nName: Improper Protection Against Voltage and Clock Glitches\nDescription: The device does not contain or contains incorrectly implemented circuitry\n  or sensors to detect and mitigate voltage and clock glitches and protect sensitive\n  information or software contained on the device.\nExtended_Description: A device might support features such as secure boot which are\n  supplemented with hardware and firmware support. This involves establishing a chain\n  of trust, starting with an immutable root of trust by checking the signature of\n  the next stage (culminating with the OS and runtime software) against a golden value\n  before transferring control. The intermediate stages typically set up the system\n  in a secure state by configuring several access control settings. Similarly, security\n  logic for exercising a debug or testing interface may be implemented in hardware,\n  firmware, or both. A device needs to guard against fault attacks such as voltage\n  glitches and clock glitches that an attacker may employ in an attempt to compromise\n  the system.\nApplicable_Platforms:\n  Technology: ICS/OT, System on Chip, Power Management Hardware, Clock/Counter Hardware,\n    Sensor Hardware\nDetection_Methods: \"Manual Analysis: Put the processor in an infinite\\n\\t\\t\\tloop,\\\n  \\ which is then followed by instructions\\n\\t\\t\\tthat should not ever be executed,\\\n  \\ since the\\n\\t\\t\\tloop is not expected to exit.  After the loop,\\n\\t\\t\\ttoggle\\\n  \\ an I/O bit (for oscilloscope monitoring\\n\\t\\t\\tpurposes), print a console message,\\\n  \\ and\\n\\t\\t\\treenter the loop.  Note that to ensure that\\n\\t\\t\\tthe loop exit is\\\n  \\ actually captured, many NOP\\n\\t\\t\\tinstructions should be coded after the loop\\n\\\n  \\t\\t\\tbranch instruction and before the I/O bit\\n\\t\\t\\ttoggle and the print statement.\\n\\\n  Margining the clock consists of varying the clock\\n\\t\\t\\tfrequency until an anomaly\\\n  \\ occurs. This could be a\\n\\t\\t\\tcontinuous frequency change or it could be a single\\n\\\n  \\t\\t\\tcycle. The single cycle method is described here. For\\n\\t\\t\\tevery 1000th\\\n  \\ clock pulse, the clock cycle is shortened by\\n\\t\\t\\t10 percent. If no effect is\\\n  \\ observed, the width is\\n\\t\\t\\tshortened by 20%. This process is continued in 10%\\n\\\n  \\t\\t\\tincrements up to and including 50%. Note that the cycle\\n\\t\\t\\ttime may be\\\n  \\ increased as well, down to seconds per\\n\\t\\t\\tcycle.\\nSeparately, the voltage\\\n  \\ is margined. Note that\\n\\t\\t\\tthe voltage could be increased or decreased. Increasing\\n\\\n  \\t\\t\\tthe voltage has limits, as the circuitry may not be able\\n\\t\\t\\tto withstand\\\n  \\ a drastically increased voltage. This process\\n\\t\\t\\tstarts with a 5% reduction\\\n  \\ of the DC supply to the CPU\\n\\t\\t\\tchip for 5 millisecond repeated at 1KHz. If\\\n  \\ this has no\\n\\t\\t\\teffect, the process is repeated, but a 10% reduction is\\n\\t\\\n  \\t\\tused. This process is repeated at 10% increments down to a\\n\\t\\t\\t50% reduction.\\\n  \\ If no effects are observed at 5\\n\\t\\t\\tmillisecond, the whole process is repeated\\\n  \\ using a 10\\n\\t\\t\\tmillisecond pulse. If no effects are observed, the process\\n\\\n  \\t\\t\\tis repeated in 10 millisecond increments out to 100\\n\\t\\t\\tmillisecond pulses.\\n\\\n  While these are suggested starting points for\\n\\t\\t\\ttesting circuitry for weaknesses,\\\n  \\ the limits may need to\\n\\t\\t\\tbe pushed further at the risk of device damage.\\\n  \\ See\\n\\t\\t\\t[REF-1217] for descriptions of Smart Card attacks against\\n\\t\\t\\ta\\\n  \\ clock (section 14.6.2) and using a voltage glitch\\n\\t\\t\\t(section 15.5.3).\\n\\n\\\n  Dynamic Analysis with Manual Results Interpretation: During the implementation phase\\\n  \\ where actual hardware is available, specialized hardware tools and apparatus such\\\n  \\ as ChipWhisperer may be used to check if the platform is indeed susceptible to\\\n  \\ voltage and clock glitching attacks.\\n\\nArchitecture or Design Review: Review\\\n  \\ if the protections against glitching merely transfer the attack target. For example,\\\n  \\ suppose a critical authentication routine that an attacker would want to bypass\\\n  \\ is given the protection of modifying certain artifacts from within that specific\\\n  \\ routine (so that if the routine is bypassed, one can examine the artifacts and\\\n  \\ figure out that an attack must have happened). However, if the attacker has the\\\n  \\ ability to bypass the critical authentication routine, they might also have the\\\n  \\ ability to bypass the other protection routine that checks the artifacts. Basically,\\\n  \\ depending on these kind of protections is akin to resorting to \\\"Security by Obscurity\\\"\\\n  .\\n\\nArchitecture or Design Review: Many SoCs come equipped with a built-in Dynamic\\\n  \\ Voltage and Frequency Scaling (DVFS) that can control the voltage and clocks via\\\n  \\ software alone. However, there have been demonstrated attacks (like Plundervolt\\\n  \\ and CLKSCREW) that target this DVFS [REF-1081] [REF-1082]. During the design and\\\n  \\ implementation phases, one needs to check if the interface to this power management\\\n  \\ feature is available from unprivileged SW (CWE-1256), which would make the attack\\\n  \\ very easy.\"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: At the circuit-level, using Tunable Replica Circuits (TRCs) or special\n  flip-flops such as Razor flip-flops helps mitigate glitch attacks. Working at the\n  SoC or platform base, level sensors may be implemented to detect glitches. Implementing\n  redundancy in security-sensitive code (e.g., where checks are performed)also can\n  help with mitigation of glitch attacks.'\nObserved_Examples: 'CVE-2019-17391: Lack of anti-glitch protections allows an attacker\n  to launch a physical attack to bypass the secure boot and read protected eFuses.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1248'\nName: Semiconductor Defects in Hardware Logic with Security-Sensitive Implications\nDescription: The security-sensitive hardware module contains semiconductor defects.\nExtended_Description: A semiconductor device can fail for various reasons. While some\n  are manufacturing and packaging defects, the rest are due to prolonged use or usage\n  under extreme conditions. Some mechanisms that lead to semiconductor defects include\n  encapsulation failure, die-attach failure, wire-bond failure, bulk-silicon defects,\n  oxide-layer faults, aluminum-metal faults (including electromigration, corrosion\n  of aluminum, etc.), and thermal/electrical stress. These defects manifest as faults\n  on chip-internal signals or registers, have the effect of inputs, outputs, or intermediate\n  signals being always 0 or always 1, and do not switch as expected. If such faults\n  occur in security-sensitive hardware modules, the security objectives of the hardware\n  module may be compromised.\nModes_Of_Introduction: 'Manufacturing: May be introduced due to issues in the manufacturing\n  environment or improper handling of components, for example.\n\n\n  Operation: May be introduced by improper handling or usage outside of rated operating\n  environments (temperature, humidity, etc.)'\nPotential_Mitigations: 'Testing: While semiconductor-manufacturing companies implement\n  several mechanisms to continuously improve the semiconductor manufacturing process\n  to ensure reduction of defects, some defects can only be fixed after manufacturing.\n  Post-manufacturing testing of silicon die is critical. Fault models such as stuck-at-0\n  or stuck-at-1 must be used to develop post-manufacturing test cases and achieve\n  good coverage. Once the silicon packaging is done, extensive post-silicon testing\n  must be performed to ensure that hardware logic implementing security functionalities\n  is defect-free.\n\n\n  Operation: Operating the hardware outside device specification, such as at extremely\n  high temperatures, voltage, etc., accelerates semiconductor degradation and results\n  in defects.  When these defects manifest as faults in security-critical, hardware\n  modules, it results in compromise of security guarantees. Thus, operating the device\n  within the specification is important.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1249'\nName: Application-Level Admin Tool with Inconsistent View of Underlying Operating\n  System\nDescription: The product provides an application for administrators to manage parts\n  of the underlying operating system, but the application does not accurately identify\n  all of the relevant entities or resources that exist in the OS; that is, the application's\n  model of the OS's state is inconsistent with the OS's actual state.\nExtended_Description: \"Many products provide web-based applications or other interfaces\\\n  \\ for managing the underlying operating system. This is common with cloud, network\\\n  \\ access devices, home networking, and other systems.  When the management tool\\\n  \\ does not accurately represent what is in the OS - such as user accounts - then\\\n  \\ the administrator might not see suspicious activities that would be noticed otherwise.\\n\\\n  For example, numerous systems utilize a web\\n\\t\\t\\t\\tfront-end for administrative\\\n  \\ control. They also offer\\n\\t\\t\\t\\tthe ability to add, alter, and drop users with\\\n  \\ various\\n\\t\\t\\t\\tprivileges as it relates to the functionality of the\\n\\t\\t\\t\\t\\\n  system.  A potential architectural weakness may exist\\n\\t\\t\\t\\twhere the user information\\\n  \\ reflected in the web\\n\\t\\t\\t\\tinterface does not mirror the users in the underlying\\n\\\n  \\t\\t\\t\\toperating system.  Many web UI or REST APIs use the\\n\\t\\t\\t\\tunderlying\\\n  \\ operating system for authentication; the\\n\\t\\t\\t\\tsystem's logic may also track\\\n  \\ an additional set of\\n\\t\\t\\t\\tuser capabilities within configuration files\\n\\t\\\n  \\t\\t\\tand datasets for authorization capabilities. When\\n\\t\\t\\t\\tthere is a discrepancy\\\n  \\ between the user information in\\n\\t\\t\\t\\tthe UI or REST API's interface system\\\n  \\ and the\\n\\t\\t\\t\\tunderlying operating system's user listing, this may\\n\\t\\t\\t\\t\\\n  introduce a weakness into the system.  For example, if an\\n\\t\\t\\t\\tattacker compromises\\\n  \\ the OS and adds a new user\\n\\t\\t\\t\\taccount - a \\\"ghost\\\" account - then the attacker\\\n  \\ could escape detection if\\n\\t\\t\\t\\tthe management tool does not list the newly-added\\n\\\n  \\t\\t\\t\\taccount.\\nThis discrepancy could be exploited in several ways:\\nMany of\\\n  \\ these attacker scenarios can be\\n\\t\\t\\t\\trealized by leveraging separate vulnerabilities\\n\\\n  \\t\\t\\t\\trelated to XSS, command injection, authentication\\n\\t\\t\\t\\tbypass, or logic\\\n  \\ flaws on the various systems.\"\nApplicable_Platforms:\n  Technology: Web Based\nModes_Of_Introduction: 'Architecture and Design: The design might assume that the\n  underlying OS does not change.\n\n\n  Implementation: Assumptions about the underlying OS might be hard-coded into the\n  application or otherwise in external data stores in a way that is not updated when\n  the OS''s state changes.'\nPotential_Mitigations: 'Architecture and Design: Ensure that the admin tool refreshes\n  its model of the underlying OS on a regular basis, and note any inconsistencies\n  with configuration files or other data sources that are expected to have the same\n  data.'\n",
  "ID: '125'\nName: Out-of-bounds Read\nDescription: The product reads data past the end, or before the beginning, of the\n  intended buffer.\nExtended_Description: Typically, this can allow attackers to read sensitive information\n  from other memory locations or cause a crash.  A crash can occur when the code reads\n  a variable amount of data and assumes that a sentinel exists to stop the read operation,\n  such as a NUL in a string.  The expected sentinel might not be located in the out-of-bounds\n  memory, causing excessive data to be read, leading to a segmentation fault or a\n  buffer overflow.  The product may modify an index or perform pointer arithmetic\n  that references a memory location that is outside of the boundaries of the buffer.  A\n  subsequent read operation then produces undefined or unexpected results.\nApplicable_Platforms:\n  Language: C, C++\n  Technology: ICS/OT\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  To reduce the likelihood of introducing an out-of-bounds read, ensure that you validate\n  and ensure correct calculations for any length argument, buffer size calculation,\n  or offset. Be especially careful of relying on a sentinel (i.e. special character\n  such as NUL) in untrusted inputs.\n\n\n  Architecture and Design: Use a language that provides appropriate memory abstractions.'\nObserved_Examples: \"CVE-2020-11899: Out-of-bounds read in IP stack used in embedded\\\n  \\ systems, as exploited in the wild per CISA KEV.\\n\\nCVE-2014-0160: Chain: \\\"Heartbleed\\\"\\\n  \\ bug receives an inconsistent length parameter (CWE-130) enabling an out-of-bounds\\\n  \\ read (CWE-126), returning memory that could include private cryptographic keys\\\n  \\ and other sensitive data.\\n\\nCVE-2018-10887: Chain: unexpected sign extension\\\n  \\ (CWE-194) leads to integer overflow (CWE-190), causing an out-of-bounds read (CWE-125)\\n\\\n  \\nCVE-2009-2523: Chain: product does not handle when an input string is not NULL\\\n  \\ terminated (CWE-170), leading to buffer over-read (CWE-125) or heap-based buffer\\\n  \\ overflow (CWE-122).\\n\\nCVE-2018-16069: Chain: series of floating-point precision\\\n  \\ errors\\n\\t      (CWE-1339) in a web browser rendering engine causes out-of-bounds\\\n  \\ read\\n\\t      (CWE-125), giving access to cross-origin data\\n\\nCVE-2004-0112:\\\n  \\ out-of-bounds read due to improper length check\\n\\nCVE-2004-0183: packet with\\\n  \\ large number of specified elements cause out-of-bounds read.\\n\\nCVE-2004-0221:\\\n  \\ packet with large number of specified elements cause out-of-bounds read.\\n\\nCVE-2004-0184:\\\n  \\ out-of-bounds read, resultant from integer underflow\\n\\nCVE-2004-1940: large length\\\n  \\ value causes out-of-bounds read\\n\\nCVE-2004-0421: malformed image causes out-of-bounds\\\n  \\ read\\n\\nCVE-2008-4113: OS kernel trusts userland-supplied length value, allowing\\\n  \\ reading of sensitive information\"\nRelated_Attack_Patterns: '540: '\n",
  "ID: '1250'\nName: Improper Preservation of Consistency Between Independent Representations of\n  Shared State\nDescription: The product has or supports multiple distributed components or sub-systems\n  that are each required to keep their own local copy of shared data - such as state\n  or cache - but the product does not ensure that all local copies remain consistent\n  with each other.\nExtended_Description: \"In highly distributed environments, or on systems with distinct\\\n  \\ physical components that operate independently, there is often a need for each\\\n  \\ component to store and update its own local copy of key data such as state or\\\n  \\ cache, so that all components have the same \\\"view\\\" of the overall system and\\\n  \\ operate in a coordinated fashion.  For example, users of a social media service\\\n  \\ or a massively multiplayer online game might be using their own personal computers\\\n  \\ while also interacting with different physical hosts in a globally distributed\\\n  \\ service, but all participants must be able to have the same \\\"view\\\" of the world.\\\n  \\  Alternately, a processor's Memory Management Unit (MMU) might have \\\"shadow\\\"\\\n  \\ MMUs to distribute its workload, and all shadow MMUs are expected to have the\\\n  \\ same accessible ranges of memory.\\nIn such environments, it becomes critical for\\n\\\n  \\t\\tthe product to ensure that this \\\"shared state\\\" is\\n\\t\\tconsistently modified\\\n  \\ across all distributed systems.\\n\\t\\tIf state is not consistently maintained across\\\n  \\ all\\n\\t\\tsystems, then critical transactions might take place\\n\\t\\tout of order,\\\n  \\ or some users might not get the same\\n\\t\\tdata as other users.  When this inconsistency\\\n  \\ affects\\n\\t\\tcorrectness of operations, it can introduce\\n\\t\\tvulnerabilities\\\n  \\ in mechanisms that depend on\\n\\t\\tconsistent state.\"\nApplicable_Platforms:\n  Technology: Cloud Computing, Security Hardware\n",
  "ID: '1251'\nName: Mirrored Regions with Different Values\nDescription: The product's architecture mirrors regions without ensuring that their\n  contents always stay in sync.\nExtended_Description: 'Having mirrored regions with different values might result\n  in the exposure of sensitive information or possibly system compromise.\n\n  In the interest of increased performance, one might need to duplicate a resource.\n  A cache memory is a common example of this concept, which keeps a \"local\" copy of\n  a data element in the high speed cache memory. Unfortunately, this speed improvement\n  comes with a downside, since the product needs to ensure that the local copy always\n  mirrors the original copy truthfully. If they get out of sync, the computational\n  result is no longer true.\n\n  During hardware design, memory is not the only item which gets mirrored. There are\n  many other entities that get mirrored, as well: registers, memory regions, and,\n  in some cases, even whole computational units. For example, within a multi-core\n  processor, if all memory accesses for each and every core goes through a single\n  Memory-Management Unit (MMU) then the MMU will become a performance bottleneck.\n  In such cases, duplicating local MMUs that will serve only a subset of the cores\n  rather than all of them may resolve the performance issue. These local copies are\n  also called \"shadow copies\" or \"mirrored copies.\"\n\n  If the original resource never changed, local duplicate copies getting out of sync\n  would never be an issue. However, the values of the original copy will sometimes\n  change. When the original copy changes, the mirrored copies must also change, and\n  change fast.\n\n  This situation of shadow-copy-possibly-out-of-sync-with-original-copy might occur\n  as a result of multiple scenarios, including the following:'\nApplicable_Platforms:\n  Language: VHDL, Verilog\n  Technology: System on Chip\nPotential_Mitigations: 'Architecture and Design: Whenever there are multiple, physically\n  different copies of the same value that might change and the process to update them\n  is not instantaneous and atomic, it is impossible to assert that the original and\n  shadow copies will always be in sync - there will always be a time period when they\n  are out of sync. To mitigate the consequential risk, the recommendations essentially\n  are:'\n",
  "ID: '1252'\nName: CPU Hardware Not Configured to Support Exclusivity of Write and Execute Operations\nDescription: The CPU is not configured to provide hardware support for exclusivity\n  of write and execute operations on memory. This allows an attacker to execute data\n  from all of memory.\nExtended_Description: CPUs provide a special bit that supports exclusivity of write\n  and execute operations. This bit is used to segregate areas of memory to either\n  mark them as code (instructions, which can be executed) or data (which should not\n  be executed). In this way, if a user can write to a region of memory, the user cannot\n  execute from that region and vice versa. This exclusivity provided by special hardware\n  bit is leveraged by the operating system to protect executable space. While this\n  bit is available in most modern processors by default, in some CPUs the exclusivity\n  is implemented via a memory-protection unit (MPU) and memory-management unit (MMU)\n  in which memory regions can be carved out with exact read, write, and execute permissions.\n  However, if the CPU does not have an MMU/MPU, then there is no write exclusivity.\n  Without configuring exclusivity of operations via segregated areas of memory, an\n  attacker may be able to inject malicious code onto memory and later execute it.\nApplicable_Platforms:\n  Technology: Microcontroller Hardware, Processor Hardware\nPotential_Mitigations: 'Architecture and Design: Implement a dedicated bit that can\n  be leveraged by the Operating System to mark data areas as non-executable. If such\n  a bit is not available in the CPU, implement MMU/MPU (memory management unit / memory\n  protection unit).\n\n\n  Integration: If MMU/MPU are not available, then the firewalls need to be implemented\n  in the SoC interconnect to mimic the write-exclusivity operation.'\nRelated_Attack_Patterns: '679: '\n",
  "ID: '1253'\nName: Incorrect Selection of Fuse Values\nDescription: The logic level used to set a system to a secure state relies on a fuse\n  being unblown. An attacker can set the system to an insecure state merely by blowing\n  the fuse.\nExtended_Description: Fuses are often used to store secret data, including security\n  configuration data. When not blown, a fuse is considered to store a logic 0, and,\n  when blown, it indicates a logic 1. Fuses are generally considered to be one-directional,\n  i.e., once blown to logic 1, it cannot be reset to logic 0. However, if the logic\n  used to determine system-security state (by leveraging the values sensed from the\n  fuses) uses negative logic, an attacker might blow the fuse and drive the system\n  to an insecure state.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Logic should be designed in a way\n  that blown fuses do not put the product into an insecure state that can be leveraged\n  by an attacker.'\nRelated_Attack_Patterns: '74: '\n",
  "ID: '1254'\nName: Incorrect Comparison Logic Granularity\nDescription: The product's comparison logic is performed over a series of steps rather\n  than across the entire string in one operation. If there is a comparison logic failure\n  on one of these steps, the operation may be vulnerable to a timing attack that can\n  result in the interception of the process for nefarious purposes.\nExtended_Description: \"Comparison logic is used to compare a variety of objects including\\\n  \\ passwords, Message \\n         Authentication Codes (MACs), and responses to verification\\\n  \\ challenges. When comparison logic is \\n         implemented at a finer granularity\\\n  \\ (e.g., byte-by-byte comparison) and breaks in the case of a \\n         comparison\\\n  \\ failure, an attacker can exploit this implementation to identify when exactly\\\n  \\ \\n         the failure occurred. With multiple attempts, the attacker may be able\\\n  \\ to guesses the correct \\n         password/response to challenge and elevate their\\\n  \\ privileges.\"\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: The hardware designer should ensure that comparison\n  logic is implemented so as to compare in one operation instead in smaller chunks.'\nObserved_Examples: 'CVE-2019-10482: Smartphone OS uses comparison functions that are\n  not in constant time, allowing side channels\n\n\n  CVE-2014-0984: Password-checking function in router terminates validation of a password\n  entry when it encounters the first incorrect character, which allows remote attackers\n  to obtain passwords via a brute-force attack that relies on timing differences in\n  responses to incorrect password guesses, aka a timing side-channel attack.'\nRelated_Attack_Patterns: '26: '\n",
  "ID: '1255'\nName: Comparison Logic is Vulnerable to Power Side-Channel Attacks\nDescription: A device's real time power consumption may be monitored during security\n  token evaluation and the information gleaned may be used to determine the value\n  of the reference token.\nExtended_Description: The power consumed by a device may be instrumented and monitored\n  in real time. If the algorithm for evaluating security tokens is not sufficiently\n  robust, the power consumption may vary by token entry comparison against the reference\n  value. Further, if retries are unlimited, the power difference between a \"good\"\n  entry and a \"bad\" entry may be observed and used to determine whether each entry\n  itself is correct thereby allowing unauthorized parties to calculate the reference\n  value.\nModes_Of_Introduction: 'Architecture and Design: The design of the algorithm itself\n  may intrinsically allow the power side channel attack to be effective\n\n\n  Implementation: This weakness may be introduced during implementation despite a\n  robust design that otherwise prevents exploitation'\nPotential_Mitigations: 'Architecture and Design: The design phase must consider each\n  check of a security token against a standard and the amount of power consumed during\n  the check of a good token versus a bad token. The alternative is an all at once\n  check where a retry counter is incremented PRIOR to the check.\n\n\n  Architecture and Design: Another potential mitigation is to parallelize shifting\n  of secret data (see example 2 below). Note that the wider the bus the more effective\n  the result.\n\n\n  Architecture and Design: An additional potential mitigation is to add random data\n  to each crypto operation then subtract it out afterwards. This is highly effective\n  but costly in performance, area, and power consumption. It also requires a random\n  number generator.\n\n\n  Implementation: If the architecture is unable to prevent the attack, using filtering\n  components may reduce the ability to implement an attack, however, consideration\n  must be given to the physical removal of the filter elements.\n\n\n  Integration: During integration, avoid use of a single secret for an extended period\n  (e.g. frequent key updates). This limits the amount of data compromised but at the\n  cost of complexity of use.'\nObserved_Examples: 'CVE-2020-12788: CMAC verification vulnerable to timing and power\n  attacks.'\nRelated_Attack_Patterns: '189: '\n",
  "ID: '1256'\nName: Improper Restriction of Software Interfaces to Hardware Features\nDescription: \"The product provides software-controllable\\n\\t\\t\\tdevice functionality\\\n  \\ for capabilities such as power and\\n\\t\\t\\tclock management, but it does not properly\\\n  \\ limit\\n\\t\\t\\tfunctionality that can lead to modification of\\n\\t\\t\\thardware memory\\\n  \\ or register bits, or the ability to\\n\\t\\t\\tobserve physical side channels.\"\nExtended_Description: \"It is frequently assumed that physical attacks\\n          \\\n  \\    such as fault injection and side-channel analysis\\n              require an\\\n  \\ attacker to have physical access to the\\n              target device.  This assumption\\\n  \\ may be false if the\\n              device has improperly secured power management\\\n  \\ features,\\n              or similar features.  For mobile devices, minimizing\\n\\\n  \\              power consumption is critical, but these devices run a\\n        \\\n  \\      wide variety of applications with different performance\\n              requirements.\\\n  \\ Software-controllable mechanisms to\\n              dynamically scale device voltage\\\n  \\ and frequency and\\n              monitor power consumption are common features\\\n  \\ in today's\\n              chipsets, but they also enable attackers to mount fault\\n\\\n  \\              injection and side-channel attacks without having\\n             \\\n  \\ physical access to the device.\\nFault injection attacks involve strategic\\n  \\\n  \\            manipulation of bits in a device to achieve a desired\\n           \\\n  \\   effect such as skipping an authentication step,\\n              elevating privileges,\\\n  \\ or altering the output of a\\n              cryptographic operation.  Manipulation\\\n  \\ of the device\\n              clock and voltage supply is a well-known technique\\\n  \\ to\\n              inject faults and is cheap to implement with physical\\n    \\\n  \\          device access.  Poorly protected power management\\n              features\\\n  \\ allow these attacks to be performed from\\n              software.  Other features,\\\n  \\ such as the ability to write\\n              repeatedly to DRAM at a rapid rate\\\n  \\ from unprivileged\\n              software, can result in bit flips in other memory\\n\\\n  \\              locations (Rowhammer, [REF-1083]).\\nSide channel analysis requires\\\n  \\ gathering\\n\\t\\t\\t  measurement traces of physical quantities such as power\\n\\t\\\n  \\t\\t  consumption.  Modern processors often include power\\n\\t\\t\\t  metering capabilities\\\n  \\ in the hardware itself (e.g.,\\n\\t\\t\\t  Intel RAPL) which if not adequately protected\\\n  \\ enable\\n\\t\\t\\t  attackers to gather measurements necessary for\\n\\t\\t\\t  performing\\\n  \\ side-channel attacks from software.\"\nApplicable_Platforms:\n  Technology: Memory Hardware, Power Management Hardware, Clock/Counter Hardware\nModes_Of_Introduction: \"Architecture and Design: An architect may initiate introduction\\\n  \\ of\\n\\t\\t\\t\\t\\tthis weakness via exacting requirements for\\n\\t\\t\\t\\t\\tsoftware\\\n  \\ accessible power/clock management\\n\\t\\t\\t\\t\\trequirements\\n\\nImplementation: An\\\n  \\ implementer may introduce this weakness\\n\\t\\t\\t\\t\\tby assuming there are no consequences\\\n  \\ to unbounded\\n\\t\\t\\t\\t\\tpower and clock management for secure components\\n\\t\\t\\\n  \\t\\t\\tfrom untrusted ones.\"\nDetection_Methods: \"Manual Analysis: Perform a security evaluation of system-level\\n\\\n  \\t\\tarchitecture and design with software-aided physical attacks\\n\\t\\tin scope.\\n\\\n  \\nAutomated Dynamic Analysis: Use custom software to change registers that control\\\n  \\ clock settings or power settings to try to bypass security locks, or repeatedly\\\n  \\ write DRAM to try to change adjacent locations. This can be effective in extracting\\\n  \\ or changing data. The drawback is that it cannot be run before manufacturing,\\\n  \\ and it may require specialized software.\"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Ensure proper access control mechanisms protect software-controllable\n  features altering physical operating conditions such as clock frequency and voltage.'\nObserved_Examples: 'CVE-2019-11157: Plundervolt: Improper conditions check in voltage\n  settings for some Intel(R) Processors may allow a privileged user to potentially\n  enable escalation of privilege and/or information disclosure via local access [REF-1081].\n\n\n  CVE-2020-8694: PLATYPUS Attack: Insufficient access control in the Linux kernel\n  driver for some Intel processors allows information disclosure.\n\n\n  CVE-2020-8695: Observable discrepancy in the RAPL interface for some Intel processors\n  allows information disclosure.\n\n\n  CVE-2020-12912: AMD extension to a Linux service does not require privileged access\n  to the RAPL interface, allowing side-channel attacks.\n\n\n  CVE-2015-0565: NaCl in 2015 allowed the CLFLUSH instruction, making Rowhammer attacks\n  possible.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1257'\nName: Improper Access Control Applied to Mirrored or Aliased Memory Regions\nDescription: Aliased or mirrored memory regions in hardware designs may have inconsistent\n  read/write permissions enforced by the hardware. A possible result is that an untrusted\n  agent is blocked from accessing a memory region but is not blocked from accessing\n  the corresponding aliased memory region.\nExtended_Description: 'Hardware product designs often need to implement memory protection\n  features that enable privileged software to define isolated memory regions and access\n  control (read/write) policies. Isolated memory regions can be defined on different\n  memory spaces in a design (e.g. system physical address, virtual address, memory\n  mapped IO).\n\n  Each memory cell should be mapped and assigned a system address that the core software\n  can use to read/write to that memory. It is possible to map the same memory cell\n  to multiple system addresses such that read/write to any of the aliased system addresses\n  would be decoded to the same memory cell.\n\n  This is commonly done in hardware designs for redundancy and simplifying address\n  decoding logic. If one of the memory regions is corrupted or faulty, then that hardware\n  can switch to using the data in the mirrored memory region. Memory aliases can also\n  be created in the system address map if the address decoder unit ignores higher\n  order address bits when mapping a smaller address region into the full system address.\n\n  A common security weakness that can exist in such memory mapping is that aliased\n  memory regions could have different read/write access protections enforced by the\n  hardware such that an untrusted agent is blocked from accessing a memory address\n  but is not blocked from accessing the corresponding aliased memory address. Such\n  inconsistency can then be used to bypass the access protection of the primary memory\n  block and read or modify the protected memory.\n\n  An untrusted agent could also possibly create memory aliases in the system address\n  map for malicious purposes if it is able to change the mapping of an address region\n  or modify memory region sizes.'\nApplicable_Platforms:\n  Technology: Memory Hardware, Processor Hardware, Microcontroller Hardware, Network\n    on Chip Hardware, System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: The checks should be applied for consistency access rights between\n  primary memory regions and any mirrored or aliased memory regions. If different\n  memory protection units (MPU) are protecting the aliased regions, their protected\n  range definitions and policies should be synchronized.\n\n\n  Architecture and Design\n\n  Implementation: The controls that allow enabling memory aliases or changing the\n  size of mapped memory regions should only be programmable by trusted software components.'\nRelated_Attack_Patterns: \"456: \\n\\n679: \"\n",
  "ID: '1258'\nName: Exposure of Sensitive System Information Due to Uncleared Debug Information\nDescription: The hardware does not fully clear security-sensitive values, such as\n  keys and intermediate values in cryptographic operations, when debug mode is entered.\nExtended_Description: Security sensitive values, keys, intermediate steps of cryptographic\n  operations, etc. are stored in temporary registers in the hardware. If these values\n  are not cleared when debug mode is entered they may be accessed by a debugger allowing\n  sensitive information to be accessible by untrusted parties.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Whenever debug mode is enabled, all\n  registers containing sensitive assets must be cleared.'\nRelated_Attack_Patterns: \"150: \\n\\n204: \\n\\n37: \\n\\n545: \"\n",
  "ID: '1259'\nName: Improper Restriction of Security Token Assignment\nDescription: The System-On-A-Chip (SoC) implements a Security Token mechanism to differentiate\n  what actions are allowed or disallowed when a transaction originates from an entity.\n  However, the Security Tokens are improperly protected.\nExtended_Description: 'Systems-On-A-Chip (Integrated circuits and hardware engines)\n  implement Security Tokens to differentiate and identify which actions originated\n  from which agent. These actions may be one of the directives: ''read'', ''write'',\n  ''program'', ''reset'', ''fetch'', ''compute'', etc. Security Tokens are assigned\n  to every agent in the System that is capable of generating an action or receiving\n  an action from another agent. Multiple Security Tokens may be assigned to an agent\n  and may be unique based on the agent''s trust level or allowed privileges. Since\n  the Security Tokens are integral for the maintenance of security in an SoC, they\n  need to be protected properly. A common weakness afflicting Security Tokens is improperly\n  restricting the assignment to trusted components. Consequently, an improperly protected\n  Security Token may be able to be programmed by a malicious agent (i.e., the Security\n  Token is mutable) to spoof the action as if it originated from a trusted agent.'\nApplicable_Platforms:\n  Technology: Processor Hardware, System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: '\nRelated_Attack_Patterns: \"121: \\n\\n681: \"\n",
  "ID: '126'\nName: Buffer Over-read\nDescription: The product reads from a buffer using buffer access mechanisms such as\n  indexes or pointers that reference memory locations after the targeted buffer.\nExtended_Description: This typically occurs when the pointer or its index is incremented\n  to a position beyond the bounds of the buffer or when pointer arithmetic results\n  in a position outside of the valid memory location to name a few. This may result\n  in exposure of sensitive information or possibly a crash.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2014-0160: Chain: \"Heartbleed\" bug receives an inconsistent\n  length parameter (CWE-130) enabling an out-of-bounds read (CWE-126), returning memory\n  that could include private cryptographic keys and other sensitive data.\n\n\n  CVE-2009-2523: Chain: product does not handle when an input string is not NULL terminated,\n  leading to buffer over-read or heap-based buffer overflow.'\n",
  "ID: '1260'\nName: Improper Handling of Overlap Between Protected Memory Ranges\nDescription: The product allows address regions to overlap, which can result in the\n  bypassing of intended memory protection.\nExtended_Description: 'Isolated memory regions and access control (read/write) policies\n  are used by hardware to protect privileged software. Software components are often\n  allowed to change or remap memory region definitions in order to enable flexible\n  and dynamically changeable memory management by system software.\n\n  If a software component running at lower privilege can program a memory address\n  region to overlap with other memory regions used by software running at higher privilege,\n  privilege escalation may be available to attackers. The memory protection unit (MPU)\n  logic can incorrectly handle such an address overlap and allow the lower-privilege\n  software to read or write into the protected memory region, resulting in privilege\n  escalation attack. An address overlap weakness can also be used to launch a denial\n  of service attack on the higher-privilege software memory regions.'\nApplicable_Platforms:\n  Technology: Memory Hardware, Processor Hardware\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design or implementation and identified later during the\n  Testing phase.\n\n\n  Implementation: '\nDetection_Methods: 'Manual Analysis: Create a high privilege memory block of any arbitrary\n  size. Attempt to create a lower privilege memory block with an overlap of the high\n  privilege memory block. If the creation attempt works, fix the hardware. Repeat\n  the test.'\nPotential_Mitigations: 'Architecture and Design: Ensure that memory regions are isolated\n  as intended and that access control (read/write) policies are used by hardware to\n  protect privileged software.\n\n\n  Implementation: For all of the programmable memory protection regions, the memory\n  protection unit (MPU) design can define a priority scheme.\n\n  For example: if three memory regions can be programmed (Region_0, Region_1, and\n  Region_2), the design can enforce a priority scheme, such that, if a system address\n  is within multiple regions, then the region with the lowest ID takes priority and\n  the access-control policy of that region will be applied.  In some MPU designs,\n  the priority scheme can also be programmed by trusted software.\n\n  Hardware logic or trusted firmware can also check for region definitions and block\n  programming of memory regions with overlapping addresses.\n\n  The memory-access-control-check filter can also be designed to apply a policy filter\n  to all of the overlapping ranges, i.e., if an address is within Region_0 and Region_1,\n  then access to this address is only granted if both Region_0 and Region_1 policies\n  allow the access.'\nObserved_Examples: 'CVE-2008-7096: virtualization product allows compromise of hardware\n  product by accessing certain remapping registers.\n\n\n  [REF-1100]: processor design flaw allows ring 0 code to access more privileged rings\n  by causing a register window to overlap a range of protected system RAM [REF-1100]'\nRelated_Attack_Patterns: \"456: \\n\\n679: \"\n",
  "ID: '1261'\nName: Improper Handling of Single Event Upsets\nDescription: The hardware logic does not effectively handle when single-event upsets\n  (SEUs) occur.\nExtended_Description: \"Technology trends such as CMOS-transistor down-sizing, use\\\n  \\ of \\n            new materials, and system-on-chip architectures continue to increase\\\n  \\ the \\n            sensitivity of systems to soft errors. These errors are random,\\\n  \\ and \\n            their causes might be internal (e.g., interconnect coupling)\\\n  \\ or external \\n            (e.g., cosmic radiation). These soft errors are not\\\n  \\ permanent in nature \\n            and cause temporary bit flips known as single-event\\\n  \\ upsets (SEUs). \\n            SEUs are induced errors in circuits caused when charged\\\n  \\ particles lose \\n            energy by ionizing the medium through which they\\\n  \\ pass, leaving behind a \\n            wake of electron-hole pairs that cause temporary\\\n  \\ failures. If these \\n            failures occur in security-sensitive modules\\\n  \\ in a chip, it might \\n            compromise the security guarantees of the chip.\\\n  \\ For instance, these \\n            temporary failures could be bit flips that change\\\n  \\ the privilege of\\n\\t    a regular user to root.\"\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Implement triple-modular redundancy\n  around security-sensitive modules.\n\n\n  Architecture and Design: SEUs mostly affect SRAMs.  For SRAMs storing security-critical\n  data, implement Error-Correcting-Codes (ECC) and Address Interleaving.'\n",
  "ID: '1262'\nName: Improper Access Control for Register Interface\nDescription: The product uses memory-mapped I/O registers that act as an interface\n  to hardware functionality from software, but there is improper access control to\n  those registers.\nExtended_Description: Software commonly accesses peripherals in a System-on-Chip (SoC)\n  or other device through a memory-mapped register interface. Malicious software could\n  tamper with any security-critical hardware data that is accessible directly or indirectly\n  through the register interface, which could lead to a loss of confidentiality and\n  integrity.\nModes_Of_Introduction: 'Architecture and Design: This weakness may be exploited if\n  the register interface design does not adequately protect hardware assets from software.\n\n\n  Implementation: Mis-implementation of access control policies may inadvertently\n  allow access to hardware assets through the register interface.'\nDetection_Methods: 'Manual Analysis: This is applicable in the Architecture phase\n  before implementation started. Make sure access policy is specified for the entire\n  memory map. Manual analysis may not ensure the implementation is correct.\n\n\n  Manual Analysis: Registers controlling hardware should have access control implemented.\n  This access control may be checked manually for correct implementation. Items to\n  check consist of how are trusted parties set, how are trusted parties verified,\n  how are accesses verified, etc. Effectiveness of a manual analysis will vary depending\n  upon how complicated the interface is constructed.\n\n\n  Simulation / Emulation: Functional simulation is applicable during the Implementation\n  Phase. Testcases must be created and executed for memory mapped registers to verify\n  adherence to the access control policy. This method can be effective, since functional\n  verification needs to be performed on the design, and verification for this weakness\n  will be included. There can be difficulty covering the entire memory space during\n  the test.\n\n\n  Formal Verification: Formal verification is applicable during the Implementation\n  phase. Assertions need to be created in order to capture illegal register access\n  scenarios and prove that they cannot occur. Formal methods are exhaustive and can\n  be very effective, but creating the cases for large designs may be complex and difficult.\n\n\n  Automated Analysis: Information flow tracking can be applicable during the Implementation\n  phase. Security sensitive data (assets) - for example, as stored in registers -\n  is automatically tracked over time through the design to verify the data doesn''t\n  reach illegal destinations that violate the access policies for the memory map.\n  This method can be very effective when used together with simulation and emulation,\n  since detecting violations doesn''t rely on specific scenarios or data values. This\n  method does rely on simulation and emulation, so testcases must exist in order to\n  use this method.\n\n\n  Architecture or Design Review: Manual documentation review of the system memory\n  map, register specification, and permissions associated with accessing security-relevant\n  functionality exposed via memory-mapped registers.\n\n\n  Fuzzing: Perform penetration testing (either manual or semi-automated with fuzzing)\n  to verify that access control mechanisms such as the memory protection units or\n  on-chip bus firewall settings adequately protect critical hardware registers from\n  software access.'\nPotential_Mitigations: 'Architecture and Design: Design proper policies for hardware\n  register access from software.\n\n\n  Implementation: Ensure that access control policies for register access are implemented\n  in accordance with the specified design.'\nObserved_Examples: 'CVE-2014-2915: virtualization product does not restrict access\n  to debug and other processor registers in the hardware, allowing a crash of the\n  host or guest OS\n\n\n  CVE-2021-3011: virtual interrupt controller in a virtualization product allows crash\n  of host by writing a certain invalid value to a register, which triggers a fatal\n  error instead of returning an error code\n\n\n  CVE-2020-12446: Driver exposes access to Model Specific Register (MSR) registers,\n  allowing admin privileges.\n\n\n  CVE-2015-2150: Virtualization product does not restrict access to PCI command registers,\n  allowing host crash from the guest.'\nRelated_Attack_Patterns: '680: '\n",
  "ID: '1263'\nName: Improper Physical Access Control\nDescription: The product is designed with access restricted to certain information,\n  but it does not sufficiently protect against an unauthorized actor with physical\n  access to these areas.\nExtended_Description: Sections of a product intended to have restricted access may\n  be inadvertently or intentionally rendered accessible when the implemented physical\n  protections are insufficient. The specific requirements around how robust the design\n  of the physical protection mechanism needs to be depends on the type of product\n  being protected. Selecting the correct physical protection mechanism and properly\n  enforcing it through implementation and manufacturing are critical to the overall\n  physical security of the product.\nModes_Of_Introduction: 'Architecture and Design: This weakness can arise if design\n  decisions are made that do not align with the intended physical protection of the\n  product\n\n\n  Manufacturing: While the architecture and design phase of the product may have accurately\n  met the intended robustness for product physical protections, this phase may introduce\n  the weakness through errors in physically manufacturing the product.'\nPotential_Mitigations: 'Architecture and Design: Specific protection requirements\n  depend strongly on contextual factors including the level of acceptable risk associated\n  with compromise to the product''s protection mechanism. Designers could incorporate\n  anti-tampering measures that protect against or detect when the product has been\n  tampered with.\n\n\n  Testing: The testing phase of the lifecycle should establish a method for determining\n  whether the protection mechanism is sufficient to prevent unauthorized access.\n\n\n  Manufacturing: Ensure that all protection mechanisms are fully activated at the\n  time of manufacturing and distribution.'\nRelated_Attack_Patterns: '401: '\n",
  "ID: '1264'\nName: Hardware Logic with Insecure De-Synchronization between Control and Data Channels\nDescription: The hardware logic for error handling and security checks can incorrectly\n  forward data before the security check is complete.\nExtended_Description: Many high-performance on-chip bus protocols and processor data-paths\n  employ separate channels for control and data to increase parallelism and maximize\n  throughput. Bugs in the hardware logic that handle errors and security checks can\n  make it possible for data to be forwarded before the completion of the security\n  checks. If the data can propagate to a location in the hardware observable to an\n  attacker, loss of data confidentiality can occur. 'Meltdown' is a concrete example\n  of how de-synchronization between data and permissions checking logic can violate\n  confidentiality requirements. Data loaded from a page marked as privileged was returned\n  to the cpu regardless of current privilege level for performance reasons. The assumption\n  was that the cpu could later remove all traces of this data during the handling\n  of the illegal memory access exception, but this assumption was proven false as\n  traces of the secret data were not removed from the microarchitectural state.\nModes_Of_Introduction: 'Architecture and Design: The weakness can be introduced in\n  the data transfer or bus protocol itself or in the implementation.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Thoroughly verify the data routing\n  logic to ensure that any error handling or security checks effectively block illegal\n  dataflows.'\nObserved_Examples: 'CVE-2017-5754: Systems with microprocessors utilizing speculative\n  execution and indirect branch prediction may allow unauthorized disclosure of information\n  to an attacker with local user access via a side-channel analysis of the data cache.'\nRelated_Attack_Patterns: \"233: \\n\\n663: \"\n",
  "ID: '1265'\nName: Unintended Reentrant Invocation of Non-reentrant Code Via Nested Calls\nDescription: During execution of non-reentrant code, the product performs a call that\n  unintentionally produces a nested invocation of the non-reentrant code.\nExtended_Description: In a complex product, a single function call may lead to many\n  different possible code paths, some of which may involve deeply nested calls. It\n  may be difficult to foresee all possible code paths that could emanate from a given\n  function call. In some systems, an external actor can manipulate inputs to the system\n  and thereby achieve a wide range of possible control flows. This is frequently a\n  concern in products that execute scripts from untrusted sources. Examples of such\n  products are web browsers and PDF readers. A weakness is present when one of the\n  possible code paths resulting from a function call alters program state that the\n  original caller assumes to be unchanged during the call.\nPotential_Mitigations: 'Architecture and Design: When architecting a system that will\n  execute untrusted code in response to events, consider executing the untrusted event\n  handlers asynchronously (asynchronous message passing) as opposed to executing them\n  synchronously at the time each event fires. The untrusted code should execute at\n  the start of the next iteration of the thread''s message loop. In this way, calls\n  into non-reentrant code are strictly serialized, so that each operation completes\n  fully before the next operation begins. Special attention must be paid to all places\n  where type coercion may result in script execution. Performing all needed coercions\n  at the very beginning of an operation can help reduce the chance of operations executing\n  at unexpected junctures.\n\n\n  Implementation: Make sure the code (e.g., function or class) in question is reentrant\n  by not leveraging non-local data, not modifying its own code, and not calling other\n  non-reentrant code.'\nObserved_Examples: 'CVE-2014-1772: In this vulnerability, by registering a malicious\n  onerror handler, an adversary can produce unexpected re-entrance of a CDOMRange\n  object. [REF-1098]\n\n\n  CVE-2018-8174: This CVE covers several vulnerable scenarios enabled by abuse of\n  the Class_Terminate feature in Microsoft VBScript. In one scenario, Class_Terminate\n  is used to produce an undesirable re-entrance of ScriptingDictionary during execution\n  of that object''s destructor. In another scenario, a vulnerable condition results\n  from a recursive entrance of a property setter method. This recursive invocation\n  produces a second, spurious call to the Release method of a reference-counted object,\n  causing a UAF when that object is freed prematurely. This vulnerability pattern\n  has been popularized as \"Double Kill\". [REF-1099]'\nRelated_Attack_Patterns: '74: '\n",
  "ID: '1266'\nName: Improper Scrubbing of Sensitive Data from Decommissioned Device\nDescription: The product does not properly provide a capability for the product administrator\n  to remove sensitive data at the time the product is decommissioned.  A scrubbing\n  capability could be missing, insufficient, or incorrect.\nExtended_Description: When a product is decommissioned - i.e., taken out of service\n  - best practices or regulatory requirements may require the administrator to remove\n  or overwrite sensitive data first, i.e. \"scrubbing.\"  Improper scrubbing of sensitive\n  data from a decommissioned device leaves that data vulnerable to acquisition by\n  a malicious actor. Sensitive data may include, but is not limited to, device/manufacturer\n  proprietary information, user/device credentials, network configurations, and other\n  forms of sensitive data.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nPolicy: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Functionality to completely scrub\n  data from a product at the conclusion of its lifecycle should be part of the design\n  phase. Trying to add this function on top of an existing architecture could lead\n  to incomplete removal of sensitive information/data.\n\n\n  Policy: The manufacturer should describe the location(s) where sensitive data is\n  stored and the policies and procedures for its removal. This information may be\n  conveyed, for example, in an Administrators Guide or a Statement of Volatility.\n\n\n  Implementation: If the capability to wipe sensitive data isn''t built-in, the manufacturer\n  may need to provide a utility to scrub sensitive data from storage if that data\n  is located in a place which is non-accessible by the administrator. One example\n  of this could be when sensitive data is stored on an EEPROM for which there is no\n  user/admin interface provided by the system.'\nRelated_Attack_Patterns: \"150: \\n\\n37: \\n\\n545: \\n\\n546: \\n\\n675: \"\n",
  "ID: '1267'\nName: Policy Uses Obsolete Encoding\nDescription: The product uses an obsolete encoding mechanism to implement access controls.\nExtended_Description: Within a System-On-a-Chip (SoC), various circuits and hardware\n  engines generate transactions for the purpose of accessing (read/write) assets or\n  performing various actions (e.g., reset, fetch, compute, etc.). Among various types\n  of message information, a typical transaction is comprised of source identity (identifying\n  the originator of the transaction) and a destination identity (routing the transaction\n  to the respective entity). Sometimes the transactions are qualified with a Security\n  Token. This Security Token helps the destination agent decide on the set of allowed\n  actions (e.g., access to an asset for reads and writes). A policy encoder is used\n  to map the bus transactions to Security Tokens that in turn are used as access-controls/protection\n  mechanisms. A common weakness involves using an encoding which is no longer trusted,\n  i.e., an obsolete encoding.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Security Token Decoders should be reviewed for design inconsistency\n  and common weaknesses.\n\n  Access and programming flows should be tested in both pre-silicon and post-silicon\n  testing.'\nRelated_Attack_Patterns: \"121: \\n\\n681: \"\n",
  "ID: '1268'\nName: Policy Privileges are not Assigned Consistently Between Control and Data Agents\nDescription: The product's hardware-enforced access control for a particular resource\n  improperly accounts for privilege discrepancies between control and write policies.\nExtended_Description: 'Integrated circuits and hardware engines may provide access\n  to resources (device-configuration, encryption keys, etc.) belonging to trusted\n  firmware or software modules (commonly set by a BIOS or a bootloader). These accesses\n  are typically controlled and limited by the hardware. Hardware design access control\n  is sometimes implemented using a policy. A policy defines which entity or agent\n  may or may not be allowed to perform an action. When a system implements multiple\n  levels of policies, a control policy may allow direct access to a resource as well\n  as changes to the policies themselves.\n\n  Resources that include agents in their control policy but not in their write policy\n  could unintentionally allow an untrusted agent to insert itself in the write policy\n  register. Inclusion in the write policy register could allow a malicious or misbehaving\n  agent write access to resources. This action could result in security compromises\n  including leaked information, leaked encryption keys, or modification of device\n  configuration.'\nModes_Of_Introduction: 'Architecture and Design: This weakness may be introduced during\n  the design of a device when the architect does not comprehensively specify all of\n  the policies required by an agent.\n\n\n  Implementation: This weakness may be introduced during implementation if device\n  policy restrictions do not sufficiently constrain less-privileged clients.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Access-control-policy definition and programming flow must be sufficiently\n  tested in pre-silicon and post-silicon testing.'\nRelated_Attack_Patterns: '180: '\n",
  "ID: '1269'\nName: Product Released in Non-Release Configuration\nDescription: The product released to market is released in pre-production or manufacturing\n  configuration.\nExtended_Description: 'Products in the pre-production or manufacturing stages are\n  configured to have many debug hooks and debug capabilities, including but not limited\n  to:\n\n  The above is by no means an exhaustive list, but it alludes to the greater capability\n  and the greater state of vulnerability of a product during it''s preproduction or\n  manufacturing state.\n\n  Complexity increases when multiple parties are involved in executing the tests before\n  the final production version. For example, a chipmaker might fabricate a chip and\n  run its own preproduction tests, following which the chip would be delivered to\n  the Original Equipment Manufacturer (OEM), who would now run a second set of different\n  preproduction tests on the same chip. Only after both of these sets of activities\n  are complete, can the overall manufacturing phase be called \"complete\" and have\n  the \"Manufacturing Complete\" fuse blown. However, if the OEM forgets to blow the\n  Manufacturing Complete fuse, then the system remains in the manufacturing stage,\n  rendering the system both exposed and vulnerable.'\nApplicable_Platforms:\n  Language: VHDL, Verilog, Compiled\n  Technology: Other\nModes_Of_Introduction: \"Implementation: \\n\\nIntegration: \\n\\nManufacturing: \"\nPotential_Mitigations: 'Implementation: Ensure that there exists a marker for denoting\n  the Manufacturing Complete stage and that the Manufacturing Complete marker gets\n  updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse\n  gets blown).\n\n\n  Integration: Ensure that there exists a marker for denoting the Manufacturing Complete\n  stage and that the Manufacturing Complete marker gets updated at the Manufacturing\n  Complete stage (i.e., the Manufacturing Complete fuse gets blown).\n\n\n  Manufacturing: Ensure that there exists a marker for denoting the Manufacturing\n  Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing\n  Complete stage (i.e., the Manufacturing Complete fuse gets blown).'\nObserved_Examples: 'CVE-2019-13945: Regarding SSA-686531, a hardware based manufacturing\n  access on S7-1200 and\n\n  S7-200 SMART has occurred. A vulnerability has been identified in SIMATIC S7-1200\n  CPU family (incl. SIPLUS variants) (All versions), SIMATIC S7-200 SMART CPU family\n  (All versions). There is an access mode used during manufacturing of S7-1200 CPUs\n  that allows additional diagnostic functionality. The security vulnerability could\n  be exploited by an attacker with physical access to the UART interface during boot\n  process. At the time of advisory publication, no public exploitation of this security\n  vulnerability was known.\n\n\n  CVE-2018-4251: Laptops with Intel chipsets were found to be running in Manufacturing\n  Mode. After this information was reported to the OEM, the vulnerability (CVE-2018-4251)\n  was patched disallowing access to the interface.'\nRelated_Attack_Patterns: '439: '\n",
  "ID: '127'\nName: Buffer Under-read\nDescription: The product reads from a buffer using buffer access mechanisms such as\n  indexes or pointers that reference memory locations prior to the targeted buffer.\nExtended_Description: This typically occurs when the pointer or its index is decremented\n  to a position before the buffer, when pointer arithmetic results in a position before\n  the beginning of the valid memory location, or when a negative index is used. This\n  may result in exposure of sensitive information or possibly a crash.\nApplicable_Platforms:\n  Language: C, C++\n",
  "ID: '1270'\nName: Generation of Incorrect Security Tokens\nDescription: The product implements a Security Token mechanism to differentiate what\n  actions are allowed or disallowed when a transaction originates from an entity.\n  However, the Security Tokens generated in the system are incorrect.\nExtended_Description: Systems-On-a-Chip (SoC) (Integrated circuits and hardware engines)\n  implement Security Tokens to differentiate and identify actions originated from\n  various agents. These actions could be \"read\", \"write\", \"program\", \"reset\", \"fetch\",\n  \"compute\", etc. Security Tokens are generated and assigned to every agent on the\n  SoC that is either capable of generating an action or receiving an action from another\n  agent. Every agent could be assigned a unique, Security Token based on its trust\n  level or privileges. Incorrectly generated Security Tokens could result in the same\n  token used for multiple agents or multiple tokens being used for the same agent.\n  This condition could result in a Denial-of-Service (DoS) or the execution of an\n  action that in turn could result in privilege escalation or unintended access.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: '\nRelated_Attack_Patterns: \"121: \\n\\n633: \\n\\n681: \"\n",
  "ID: '1271'\nName: Uninitialized Value on Reset for Registers Holding Security Settings\nDescription: Security-critical logic is not set to a known value on reset.\nExtended_Description: When the device is first brought out of reset, the state of\n  registers will be indeterminate if they have not been initialized by the logic.\n  Before the registers are initialized, there will be a window during which the device\n  is in an insecure state and may be vulnerable to attack.\nPotential_Mitigations: 'Implementation: Design checks should be performed to identify\n  any uninitialized flip-flops used for security-critical functions.\n\n\n  Architecture and Design: All registers holding security-critical information should\n  be set to a specific value on reset.'\nRelated_Attack_Patterns: '74: '\n",
  "ID: '1272'\nName: Sensitive Information Uncleared Before Debug/Power State Transition\nDescription: The product performs a power or debug state transition, but it does not\n  clear sensitive information that should no longer be accessible due to changes to\n  information access restrictions.\nExtended_Description: A device or system frequently employs many power and sleep states\n  during its normal operation (e.g., normal power, additional power, low power, hibernate,\n  deep sleep, etc.). A device also may be operating within a debug condition. State\n  transitions can happen from one power or debug state to another. If there is information\n  available in the previous state which should not be available in the next state\n  and is not properly removed before the transition into the next state, sensitive\n  information may leak from the system.\nApplicable_Platforms:\n  Language: VHDL, Verilog, Hardware Description Language\nDetection_Methods: 'Manual Analysis: Write a known pattern into each sensitive location.\n  Enter the power/debug state in question. Read data back from the sensitive locations.\n  If the reads are successful, and the data is the same as the pattern that was originally\n  written, the test fails and the device needs to be fixed. Note that this test can\n  likely be automated.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: During state transitions, information not needed in the next state\n  should be removed before the transition to the next state.'\nObserved_Examples: 'CVE-2020-12926: Product software does not set a flag as per TPM\n  specifications, thereby preventing a failed authorization attempt from being recorded\n  after a loss of power.'\nRelated_Attack_Patterns: \"150: \\n\\n37: \\n\\n545: \\n\\n546: \"\n",
  "ID: '1273'\nName: Device Unlock Credential Sharing\nDescription: The credentials necessary for unlocking a device are shared across multiple\n  parties and may expose sensitive information.\nExtended_Description: '\"Unlocking a device\" often means activating certain unadvertised\n  debug and manufacturer-specific capabilities of a device using sensitive credentials.\n  Unlocking a device might be necessary for the purpose of troubleshooting device\n  problems. For example, suppose a device contains the ability to dump the content\n  of the full system memory by disabling the memory-protection mechanisms. Since this\n  is a highly security-sensitive capability, this capability is \"locked\" in the production\n  part. Unless the device gets unlocked by supplying the proper credentials, the debug\n  capabilities are not available. For cases where the chip designer, chip manufacturer\n  (fabricator), and manufacturing and assembly testers are all employed by the same\n  company, the risk of compromise of the credentials is greatly reduced. However,\n  the risk is greater when the chip designer is employed by one company, the chip\n  manufacturer is employed by another company (a foundry), and the assemblers and\n  testers are employed by yet a third company. Since these different companies will\n  need to perform various tests on the device to verify correct device function, they\n  all need to share the unlock key. Unfortunately, the level of secrecy and policy\n  might be quite different at each company, greatly increasing the risk of sensitive\n  credentials being compromised.'\nApplicable_Platforms:\n  Language: VHDL, Verilog, Compiled\n  Technology: Other\nModes_Of_Introduction: \"Integration: \\n\\nManufacturing: \"\nPotential_Mitigations: 'Integration: Ensure the unlock credentials are shared with\n  the minimum number of parties and with utmost secrecy. To limit the risk associated\n  with compromised credentials, where possible, the credentials should be part-specific.\n\n\n  Manufacturing: Ensure the unlock credentials are shared with the minimum number\n  of parties and with utmost secrecy. To limit the risk associated with compromised\n  credentials, where possible, the credentials should be part-specific.'\nRelated_Attack_Patterns: '560: '\n",
  "ID: '1274'\nName: Improper Access Control for Volatile Memory Containing Boot Code\nDescription: The product conducts a secure-boot process that transfers bootloader\n  code from Non-Volatile Memory (NVM) into Volatile Memory (VM), but it does not have\n  sufficient access control or other protections for the Volatile Memory.\nExtended_Description: 'Adversaries could bypass the secure-boot process and execute\n  their own untrusted, malicious boot code.\n\n  As a part of a secure-boot process, the read-only-memory (ROM) code for a System-on-Chip\n  (SoC) or other system fetches bootloader code from Non-Volatile Memory (NVM) and\n  stores the code in Volatile Memory (VM), such as dynamic, random-access memory (DRAM)\n  or static, random-access memory (SRAM). The NVM is usually external to the SoC,\n  while the VM is internal to the SoC. As the code is transferred from NVM to VM,\n  it is authenticated by the SoC''s ROM code.\n\n  If the volatile-memory-region protections or access controls are insufficient to\n  prevent modifications from an adversary or untrusted agent, the secure boot may\n  be bypassed or replaced with the execution of an adversary''s code.'\nModes_Of_Introduction: 'Architecture and Design: This weakness can be introduced during\n  hardware architecture or design but can be identified later during testing.'\nDetection_Methods: 'Manual Analysis: Ensure the volatile memory is lockable or has\n  locks. Ensure the volatile memory is locked for writes from untrusted agents or\n  adversaries. Try modifying the volatile memory from an untrusted agent, and ensure\n  these writes are dropped.\n\n\n  Manual Analysis: Analyze the device using the following steps:\n\n  Only trusted masters should be allowed to write to the memory regions. For example,\n  pluggable device peripherals should not have write access to program load memory\n  regions.'\nPotential_Mitigations: 'Architecture and Design: Ensure that the design of volatile-memory\n  protections is enough to prevent modification from an adversary or untrusted code.\n\n\n  Testing: Test the volatile-memory protections to ensure they are safe from modification\n  or untrusted code.'\nObserved_Examples: 'CVE-2019-2267: Locked memory regions may be modified through other\n  interfaces in a secure-boot-loader image due to improper access control.'\nRelated_Attack_Patterns: \"456: \\n\\n679: \"\n",
  "ID: '1275'\nName: Sensitive Cookie with Improper SameSite Attribute\nDescription: The SameSite attribute for sensitive cookies is not set, or an insecure\n  value is used.\nExtended_Description: 'The SameSite attribute controls how cookies are sent for cross-domain\n  requests. This attribute may have three values: ''Lax'', ''Strict'', or ''None''.\n  If the ''None'' value is used, a website may create a cross-domain POST HTTP request\n  to another website, and the browser automatically adds cookies to this request.\n  This may lead to Cross-Site-Request-Forgery (CSRF) attacks if there are no additional\n  protections in place (such as Anti-CSRF tokens).'\nApplicable_Platforms:\n  Technology: Web Based\nModes_Of_Introduction: 'Implementation: This weakness occurs during implementation\n  when the coder does not properly set the SameSite attribute.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Set the SameSite attribute of a sensitive\n  cookie to ''Lax'' or ''Strict''. This instructs the browser to apply this cookie\n  only to same-domain requests, which provides a good Defense in Depth against CSRF\n  attacks. When the ''Lax'' value is in use, cookies are also sent for top-level cross-domain\n  navigation via HTTP GET, HEAD, OPTIONS, and TRACE methods, but not for other HTTP\n  methods that are more like to cause side-effects of state mutation.'\nRelated_Attack_Patterns: '62: '\n",
  "ID: '1276'\nName: Hardware Child Block Incorrectly Connected to Parent System\nDescription: Signals between a hardware IP and the parent system design are incorrectly\n  connected causing security risks.\nExtended_Description: Individual hardware IP must communicate with the parent system\n  in order for the product to function correctly and as intended. If implemented incorrectly,\n  while not causing any apparent functional issues, may cause security issues. For\n  example, if the IP should only be reset by a system-wide hard reset, but instead\n  the reset input is connected to a software-triggered debug mode reset (which is\n  also asserted during a hard reset), integrity of data inside the IP can be violated.\nModes_Of_Introduction: 'Implementation: This weakness is introduced when integrating\n  IP into a parent design.'\nPotential_Mitigations: 'Testing: System-level verification may be used to ensure that\n  components are correctly connected and that design security requirements are not\n  violated due to interactions between various IP blocks.'\n",
  "ID: '1277'\nName: Firmware Not Updateable\nDescription: \"The product does not provide its\\n\\t\\t\\tusers with the ability to update\\\n  \\ or patch its\\n\\t\\t\\tfirmware to address any vulnerabilities or\\n\\t\\t\\tweaknesses\\\n  \\ that may be present.\"\nExtended_Description: \"Without the ability to\\n\\t\\t\\tpatch or update firmware, consumers\\\n  \\ will be\\n\\t\\t\\tleft vulnerable to exploitation of any known\\n\\t\\t\\tvulnerabilities,\\\n  \\ or any vulnerabilities that\\n\\t\\t\\tare discovered in the future. This can expose\\n\\\n  \\t\\t\\tconsumers to permanent risk throughout the\\n\\t\\t\\tentire lifetime of the device,\\\n  \\ which could be\\n\\t\\t\\tyears or decades. Some external protective\\n\\t\\t\\tmeasures\\\n  \\ and mitigations might be employed to\\n\\t\\t\\taid in preventing or reducing the\\\n  \\ risk of\\n\\t\\t\\tmalicious attack, but the root weakness cannot\\n\\t\\t\\tbe corrected.\"\nModes_Of_Introduction: 'Requirements: Requirements development might not consider\n  the importance of updates over the lifetime of the product, or might not choose\n  the ability due to concerns such as expense or speed to market.\n\n\n  Architecture and Design: Lack of planning during architecture development and design,\n  or external pressures such as speed to market, could ignore the capability to update.\n\n\n  Implementation: The weakness can appear through oversight during implementation.'\nDetection_Methods: 'Manual Analysis: Create a new installable boot image of the current\n  build with a minor version number change. Use the standard installation method to\n  update the boot image. Verify that the minor version number has changed. Create\n  a fake image. Verify that the boot updater will not install the fake image and generates\n  an \"invalid image\" error message or equivalent.\n\n\n  Architecture or Design Review: Check the consumer or maintainer documentation, the\n  architecture/design documentation, or the original requirements to ensure that the\n  documentation includes details for how to update the firmware.\n\n\n  Manual Dynamic Analysis: Determine if there is a lack of a capability to update\n  read-only memory (ROM) structure. This could manifest as a difference between the\n  latest firmware version and the current version within the device.'\nPotential_Mitigations: 'Requirements: Specify requirements to include the ability\n  to update the firmware. Include integrity checks and authentication to ensure that\n  untrusted firmware cannot be installed.\n\n\n  Architecture and Design: Design the device to allow for updating the firmware. Ensure\n  that the design specifies how to distribute the updates and ensure their integrity\n  and authentication.\n\n\n  Implementation: Implement the necessary functionality to allow the firmware to be\n  updated.'\nObserved_Examples: 'CVE-2020-9054: Chain: network-attached storage (NAS) device has\n  a critical OS command injection (CWE-78) vulnerability that is actively exploited\n  to place IoT devices into a botnet, but some products are \"end-of-support\" and cannot\n  be patched (CWE-1277). [REF-1097]\n\n\n  [REF-1095]: A hardware \"smart lock\" has weak key generation that allows attackers\n  to steal the key by BLE sniffing, but the device''s firmware cannot be upgraded\n  and hence remains vulnerable [REF-1095].'\nRelated_Attack_Patterns: '682: '\n",
  "ID: '1278'\nName: Missing Protection Against Hardware Reverse Engineering Using Integrated Circuit\n  (IC) Imaging Techniques\nDescription: Information stored in hardware may be recovered by an attacker with the\n  capability to capture and analyze images of the integrated circuit using techniques\n  such as scanning electron microscopy.\nExtended_Description: 'The physical structure of a device, viewed at high enough magnification,\n  can reveal the information stored inside. Typical steps in IC reverse engineering\n  involve removing the chip packaging (decapsulation) then using various imaging techniques\n  ranging from high resolution x-ray microscopy to invasive techniques involving removing\n  IC layers and imaging each layer using a scanning electron microscope.\n\n  The goal of such activities is to recover secret keys, unique device identifiers,\n  and proprietary code and circuit designs embedded in hardware that the attacker\n  has been unsuccessful at accessing through other means. These secrets may be stored\n  in non-volatile memory or in the circuit netlist. Memory technologies such as masked\n  ROM allow easier to extraction of secrets than One-time Programmable (OTP) memory.'\nPotential_Mitigations: 'Architecture and Design: The cost of secret extraction via\n  IC reverse engineering should outweigh the potential value of the secrets being\n  extracted. Threat model and value of secrets should be used to choose the technology\n  used to safeguard those secrets. Examples include IC camouflaging and obfuscation,\n  tamper-proof packaging, active shielding, and physical tampering detection information\n  erasure.'\nRelated_Attack_Patterns: \"188: \\n\\n37: \\n\\n545: \"\n",
  "ID: '1279'\nName: Cryptographic Operations are run Before Supporting Units are Ready\nDescription: Performing cryptographic operations without ensuring that the supporting\n  inputs are ready to supply valid data may compromise the cryptographic result.\nExtended_Description: Many cryptographic hardware units depend upon other hardware\n  units to supply information to them to produce a securely encrypted result. For\n  example, a cryptographic unit that depends on an external random-number-generator\n  (RNG) unit for entropy must wait until the RNG unit is producing random numbers.\n  If a cryptographic unit retrieves a private encryption key from a fuse unit, the\n  fuse unit must be up and running before a key may be supplied.\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: Processor Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: The decision\\\n  \\ to continue using a cryptographic unit even though the input units to it are not\\\n  \\ producing valid data will compromise the encrypted result.\"\nPotential_Mitigations: 'Architecture and Design: Best practices should be used to\n  design cryptographic systems.\n\n\n  Implementation: Continuously ensuring that cryptographic inputs are supplying valid\n  information is necessary to ensure that the encrypted output is secure.'\nRelated_Attack_Patterns: '97: '\n",
  "ID: '128'\nName: Wrap-around Error\nDescription: Wrap around errors occur whenever a value is incremented past the maximum\n  value for its type and therefore \"wraps around\" to a very small, negative, or undefined\n  value.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Requirements specification: The choice could be made to use\n  a language that is not susceptible to these issues.\n\n\n  Architecture and Design: Provide clear upper and lower bounds on the scale of any\n  protocols designed.\n\n\n  Implementation: Perform validation on all incremented variables to ensure that they\n  remain within reasonable bounds.'\nRelated_Attack_Patterns: '92: '\n",
  "ID: '1280'\nName: Access Control Check Implemented After Asset is Accessed\nDescription: A product's hardware-based access control check occurs after the asset\n  has been accessed.\nExtended_Description: The product implements a hardware-based access control check.\n  The asset should be accessible only after the check is successful. If, however,\n  this operation is not atomic and the asset is accessed before the check is complete,\n  the security of the system may be compromised.\nApplicable_Platforms:\n  Language: Verilog, VHDL\nPotential_Mitigations: 'Implementation: Implement the access control check first.\n  Access should only be given to asset if agent is authorized.'\nRelated_Attack_Patterns: '180: '\n",
  "ID: '1281'\nName: Sequence of Processor Instructions Leads to Unexpected Behavior\nDescription: Specific combinations of processor instructions lead to undesirable behavior\n  such as locking the processor until a hard reset performed.\nExtended_Description: If the instruction set architecture (ISA) and processor logic\n  are not designed carefully and tested thoroughly, certain combinations of instructions\n  may lead to locking the processor or other unexpected and undesirable behavior.  Upon\n  encountering unimplemented instruction opcodes or illegal instruction operands,\n  the processor should throw an exception and carry on without negatively impacting\n  security.  However, specific combinations of legal and illegal instructions may\n  cause unexpected behavior with security implications such as allowing unprivileged\n  programs to completely lock the CPU.\nApplicable_Platforms:\n  Technology: Processor Hardware\nModes_Of_Introduction: 'Architecture and Design: Unexpected behavior from certain\n  instruction combinations can arise from bugs in the ISA\n\n\n  Implementation: Unexpected behavior from certain instruction combinations can arise\n  because of implementation details such as speculative execution, caching etc.'\nPotential_Mitigations: 'Testing: Implement a rigorous testing strategy that incorporates\n  randomization to explore instruction sequences that are unlikely to appear in normal\n  workloads in order to identify halt and catch fire instruction sequences.\n\n\n  Patching and Maintenance: Patch operating system to avoid running Halt and Catch\n  Fire type sequences or to mitigate the damage caused by unexpected behavior.  See\n  [REF-1108].'\nObserved_Examples: 'CVE-1999-1476: A bug in some Intel Pentium processors allow DoS\n  (hang) via an invalid \"CMPXCHG8B\" instruction, causing a deadlock'\nRelated_Attack_Patterns: '212: '\n",
  "ID: '1282'\nName: Assumed-Immutable Data is Stored in Writable Memory\nDescription: Immutable data, such as a first-stage bootloader, device identifiers,\n  and \"write-once\" configuration settings are stored in writable memory that can be\n  re-programmed or updated in the field.\nExtended_Description: Security services such as secure boot, authentication of code\n  and data, and device attestation all require assets such as the first stage bootloader,\n  public keys, golden hash digests, etc. which are implicitly trusted. Storing these\n  assets in read-only memory (ROM), fuses, or one-time programmable (OTP) memory provides\n  strong integrity guarantees and provides a root of trust for securing the rest of\n  the system. Security is lost if assets assumed to be immutable can be modified.\nModes_Of_Introduction: 'Implementation: Keys, code, configuration settings, and other\n  data should be programmed in write-once or read-only memory instead of writable\n  memory.'\nPotential_Mitigations: 'Implementation: All immutable code or data should be programmed\n  into ROM or write-once memory.'\nRelated_Attack_Patterns: \"458: \\n\\n679: \"\n",
  "ID: '1283'\nName: Mutable Attestation or Measurement Reporting Data\nDescription: The register contents used for attestation or measurement reporting data\n  to verify boot flow are modifiable by an adversary.\nExtended_Description: A System-on-Chip (SoC) implements secure boot or verified boot.\n  During this boot flow, the SoC often measures the code that it authenticates. The\n  measurement is usually done by calculating the one-way hash of the code binary and\n  extending it to the previous hash. The hashing algorithm should be a Secure One-Way\n  hash function. The final hash, i.e., the value obtained after the completion of\n  the boot flow, serves as the measurement data used in reporting or in attestation.\n  The calculated hash is often stored in registers that can later be read by the party\n  of interest to determine tampering of the boot flow. A common weakness is that the\n  contents in these registers are modifiable by an adversary, thus spoofing the measurement.\nModes_Of_Introduction: 'Architecture and Design: Such issues can be introduced during\n  hardware architecture or design and can be identified later during Testing or System\n  Configuration phases.\n\n\n  Implementation: If the access-controls which protecting the reporting registers\n  are misconfigured during implementation, this weakness can arise.'\nPotential_Mitigations: 'Architecture and Design: Measurement data should be stored\n  in registers that are read-only or otherwise have access controls that prevent modification\n  by an untrusted agent.'\nRelated_Attack_Patterns: '680: '\n",
  "ID: '1284'\nName: Improper Validation of Specified Quantity in Input\nDescription: The product receives input that is expected to specify a quantity (such\n  as size or length), but it does not validate or incorrectly validates that the quantity\n  has the required properties.\nExtended_Description: Specified quantities include size, length, frequency, price,\n  rate, number of operations, time, and others. Code may rely on specified quantities\n  to allocate resources, perform calculations, control iteration, etc. When the quantity\n  is not properly validated, then attackers can specify malicious quantities to cause\n  excessive resource allocation, trigger unexpected failures, enable buffer overflows,\n  etc.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2022-21668: Chain: Python library does not limit the resources\n  used to process images that specify a very large number of bands (CWE-1284), leading\n  to excessive memory consumption (CWE-789) or an integer overflow (CWE-190).\n\n\n  CVE-2008-1440: lack of validation of length field leads to infinite loop\n\n\n  CVE-2008-2374: lack of validation of string length fields allows memory consumption\n  or buffer over-read'\n",
  "ID: '1285'\nName: Improper Validation of Specified Index, Position, or Offset in Input\nDescription: The product receives input that is expected to specify an index, position,\n  or offset into an indexable resource such as a buffer or file, but it does not validate\n  or incorrectly validates that the specified index/position/offset has the required\n  properties.\nExtended_Description: Often, indexable resources such as memory buffers or files can\n  be accessed using a specific position, index, or offset, such as an index for an\n  array or a position for a file.  When untrusted input is not properly validated\n  before it is used as an index, attackers could access (or attempt to access) unauthorized\n  portions of these resources.  This could be used to cause buffer overflows, excessive\n  resource allocation, or trigger unexpected failures.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2005-0369: large ID in packet used as array index\n\n\n  CVE-2001-1009: negative array index as argument to POP LIST command'\n",
  "ID: '1286'\nName: Improper Validation of Syntactic Correctness of Input\nDescription: The product receives input that is expected to be well-formed - i.e.,\n  to comply with a certain syntax - but it does not validate or incorrectly validates\n  that the input complies with the syntax.\nExtended_Description: Often, complex inputs are expected to follow a particular syntax,\n  which is either assumed by the input itself, or declared within metadata such as\n  headers. The syntax could be for data exchange formats, markup languages, or even\n  programming languages.  When untrusted input is not properly validated for the expected\n  syntax, attackers could cause parsing failures, trigger unexpected errors, or expose\n  latent vulnerabilities that might not be directly exploitable if the input had conformed\n  to the syntax.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2016-4029: Chain: incorrect validation of intended decimal-based\n  IP address format (CWE-1286) enables parsing of octal or hexadecimal formats (CWE-1389),\n  allowing bypass of an SSRF protection mechanism (CWE-918).\n\n\n  CVE-2007-5893: HTTP request with missing protocol version number leads to crash'\nRelated_Attack_Patterns: \"66: \\n\\n676: \"\n",
  "ID: '1287'\nName: Improper Validation of Specified Type of Input\nDescription: The product receives input that is expected to be of a certain type,\n  but it does not validate or incorrectly validates that the input is actually of\n  the expected type.\nExtended_Description: 'When input does not comply with the expected type, attackers\n  could trigger unexpected errors, cause incorrect actions to take place, or exploit\n  latent vulnerabilities that would not be possible if the input conformed with the\n  expected type.\n\n  This weakness can appear in type-unsafe programming languages, or in programming\n  languages that support casting or conversion of an input to another type.'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2008-2223: SQL injection through an ID that was supposed to\n  be numeric.'\n",
  "ID: '1288'\nName: Improper Validation of Consistency within Input\nDescription: The product receives a complex input with multiple elements or fields\n  that must be consistent with each other, but it does not validate or incorrectly\n  validates that the input is actually consistent.\nExtended_Description: Some input data can be structured with multiple elements or\n  fields that must be consistent with each other, e.g. a number-of-items field that\n  is followed by the expected number of elements.  When such complex inputs are inconsistent,\n  attackers could trigger unexpected errors, cause incorrect actions to take place,\n  or exploit latent vulnerabilities.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2018-16733: product does not validate that the start block\n  appears before the end block\n\n\n  CVE-2006-3790: size field that is inconsistent with packet size leads to buffer\n  over-read\n\n\n  CVE-2008-4114: system crash with offset value that is inconsistent with packet size'\n",
  "ID: '1289'\nName: Improper Validation of Unsafe Equivalence in Input\nDescription: The product receives an input value that is used as a resource identifier\n  or other type of reference, but it does not validate or incorrectly validates that\n  the input is equivalent to a potentially-unsafe value.\nExtended_Description: Attackers can sometimes bypass input validation schemes by finding\n  inputs that appear to be safe, but will be dangerous when processed at a lower layer\n  or by a downstream component.  For example, a simple XSS protection mechanism might\n  try to validate that an input has no \"<script>\" tags using case-sensitive matching,\n  but since HTML is case-insensitive when processed by web browsers, an attacker could\n  inject \"<ScrIpT>\" and trigger XSS.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2021-39155: Chain: A microservice integration and management\n  platform compares the hostname in the HTTP Host header in a case-sensitive way (CWE-178,\n  CWE-1289), allowing bypass of the authorization policy (CWE-863) using a hostname\n  with mixed case or other variations.\n\n\n  CVE-2020-11053: Chain: Go-based Oauth2 reverse proxy can send the authenticated\n  user to another site at the end of the authentication flow. A redirect URL with\n  HTML-encoded whitespace characters can bypass the validation (CWE-1289) to redirect\n  to a malicious site (CWE-601)\n\n\n  CVE-2005-0269: File extension check in forum software only verifies extensions that\n  contain all lowercase letters, which allows remote attackers to upload arbitrary\n  files via file extensions that include uppercase letters.\n\n\n  CVE-2001-1238: Task Manager does not allow local users to end processes with uppercase\n  letters named (1) winlogon.exe, (2) csrss.exe, (3) smss.exe and (4) services.exe\n  via the Process tab which could allow local users to install Trojan horses that\n  cannot be stopped.\n\n\n  CVE-2004-2214: HTTP server allows bypass of access restrictions using URIs with\n  mixed case.'\n",
  "ID: '129'\nName: Improper Validation of Array Index\nDescription: The product uses untrusted input when calculating or using an array index,\n  but the product does not validate or incorrectly validates the index to ensure the\n  index references a valid position within the array.\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: \"out-of-bounds array index: \\n\\nindex-out-of-range: \\n\\narray index\\\n  \\ underflow: \"\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis generally does not account for environmental considerations\n  when reporting out-of-bounds memory operations. This can make it difficult for users\n  to determine which warnings should be investigated first. For example, an analysis\n  tool might report array index errors that originate from command line arguments\n  in a program that is not expected to run with setuid or other special privileges.\n\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n\n  Black Box: Black box methods might not get the needed code coverage within limited\n  time constraints, and a dynamic test might not produce any noticeable side effects\n  even if it is successful.'\nPotential_Mitigations: 'Architecture and Design: Use an input validation framework\n  such as Struts or the OWASP ESAPI Validation API. Note that using a framework does\n  not automatically address all input validation problems; be mindful of weaknesses\n  that could arise from misusing the framework itself (CWE-1173).\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n  Even though client-side checks provide minimal benefits with respect to server-side\n  security, they are still useful. First, they can support intrusion detection. If\n  the server receives input that should have been rejected by the client, then it\n  may be an indication of an attack. Second, client-side error-checking can provide\n  helpful feedback to the user about the expectations for valid input. Third, there\n  may be a reduction in server-side processing time for accidental input errors, although\n  this is typically a small savings.\n\n\n  Requirements: Use a language that does not allow this weakness to occur or provides\n  constructs that make this weakness easier to avoid.\n\n  For example, Ada allows the programmer to constrain the values of a variable and\n  languages such as Java and Ruby will allow the programmer to handle exceptions when\n  an out-of-bounds index is accessed.\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When accessing a user-controlled array index, use a stringent range of values that\n  are within the target array. Make sure that you do not allow negative values to\n  be used. That is, verify the minimum as well as the maximum of the range of acceptable\n  values.\n\n\n  Implementation: Be especially careful to validate all input when invoking code that\n  crosses language boundaries, such as from an interpreted language to native code.\n  This could create an unexpected interaction between the language boundaries. Ensure\n  that you are not violating any of the expectations of the language with which you\n  are interfacing. For example, even though Java may not be susceptible to buffer\n  overflows, providing a large argument in a call to native code might trigger an\n  overflow.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.'\nObserved_Examples: 'CVE-2005-0369: large ID in packet used as array index\n\n\n  CVE-2001-1009: negative array index as argument to POP LIST command\n\n\n  CVE-2003-0721: Integer signedness error leads to negative array index\n\n\n  CVE-2004-1189: product does not properly track a count and a maximum number, which\n  can lead to resultant array index overflow.\n\n\n  CVE-2007-5756: Chain: device driver for packet-capturing software allows access\n  to an unintended IOCTL with resultant array index error.\n\n\n  CVE-2005-2456: Chain: array index error (CWE-129) leads to deadlock (CWE-833)'\nRelated_Attack_Patterns: '100: '\n",
  "ID: '1290'\nName: 'Incorrect Decoding of Security Identifiers '\nDescription: The product implements a decoding mechanism to decode certain bus-transaction\n  signals to security identifiers. If the decoding is implemented incorrectly, then\n  untrusted agents can now gain unauthorized access to the asset.\nExtended_Description: 'In a System-On-Chip (SoC), various integrated circuits and\n  hardware engines generate transactions such as to access (reads/writes) assets or\n  perform certain actions (e.g., reset, fetch, compute, etc.). Among various types\n  of message information, a typical transaction is comprised of source identity (to\n  identify the originator of the transaction) and a destination identity (to route\n  the transaction to the respective entity). Sometimes the transactions are qualified\n  with a security identifier. The security identifier helps the destination agent\n  decide on the set of allowed actions (e.g., access an asset for read and writes).\n  A decoder decodes the bus transactions to map security identifiers into necessary\n  access-controls/protections.\n\n  A common weakness that can exist in this scenario is incorrect decoding because\n  an untrusted agent''s security identifier is decoded into a trusted agent''s security\n  identifier. Thus, an untrusted agent previously without access to an asset can now\n  gain access to the asset.'\nApplicable_Platforms:\n  Technology: Bus/Interface Hardware\nModes_Of_Introduction: \"Implementation: \\n\\nArchitecture and Design: \"\nPotential_Mitigations: 'Architecture and Design: Security identifier decoders must\n  be reviewed for design consistency and common weaknesses.\n\n\n  Implementation: Access and programming flows must be tested in pre-silicon and post-silicon\n  testing in order to check for this weakness.'\n",
  "ID: '1291'\nName: Public Key Re-Use for Signing both Debug and Production Code\nDescription: The same public key is used for signing both debug and production code.\nExtended_Description: 'A common usage of public-key cryptography is to verify the\n  integrity and authenticity of another entity (for example a firmware binary). If\n  a company wants to ensure that its firmware runs only on its own hardware, before\n  the firmware runs, an encrypted hash of the firmware image will be decrypted with\n  the public key and then verified against the now-computed hash of the firmware image.\n  This means that the public key forms the root of trust, which necessitates that\n  the public key itself must be protected and used properly.\n\n  During the development phase, debug firmware enables many hardware debug hooks,\n  debug modes, and debug messages for testing. Those debug facilities provide significant,\n  additional views about the firmware''s capability and, in some cases, additional\n  capability into the chip or SoC. If compromised, these capabilities could be exploited\n  by an attacker to take full control of the system.\n\n  Once the product exits the manufacturing stage and enters production, it is good\n  practice to use a different public key. Debug firmware images are known to leak.\n  With the debug key being reused as the production key, the debug image will also\n  work on the production image. Thus, it will open all the internal, debug capabilities\n  to the attacker.\n\n  If a different public key is used for the production image, even if the attacker\n  gains access to the debug firmware image, they will not be able to run it on a production\n  machine. Thus, damage will be limited to the intellectual property leakage resulting\n  from the debug image.'\nDetection_Methods: 'Architecture or Design Review: Compare the debug key with the\n  production key to make sure that they are not the same.\n\n\n  Dynamic Analysis with Manual Results Interpretation: Compare the debug key with\n  the production key to make sure that they are not the same.'\nPotential_Mitigations: 'Implementation: Use different keys for Production and Debug'\n",
  "ID: '1292'\nName: Incorrect Conversion of Security Identifiers\nDescription: The product implements a conversion mechanism to map certain bus-transaction\n  signals to security identifiers. However, if the conversion is incorrectly implemented,\n  untrusted agents can gain unauthorized access to the asset.\nExtended_Description: 'In a System-On-Chip (SoC), various integrated circuits and\n  hardware engines generate transactions such as to access (reads/writes) assets or\n  perform certain actions (e.g., reset, fetch, compute, etc.). Among various types\n  of message information, a typical transaction is comprised of source identity (to\n  identify the originator of the transaction) and a destination identity (to route\n  the transaction to the respective entity). Sometimes the transactions are qualified\n  with a security identifier. This security identifier helps the destination agent\n  decide on the set of allowed actions (e.g., access an asset for read and writes).\n\n  A typical bus connects several leader and follower agents. Some follower agents\n  implement bus protocols differently from leader agents. A protocol conversion happens\n  at a bridge to seamlessly connect different protocols on the bus. One example is\n  a system that implements a leader with the Advanced High-performance Bus (AHB) protocol\n  and a follower with the Open-Core Protocol (OCP). A bridge AHB-to-OCP is needed\n  to translate the transaction from one form to the other.\n\n  A common weakness that can exist in this scenario is that this conversion between\n  protocols is implemented incorrectly, whereupon an untrusted agent may gain unauthorized\n  access to an asset.'\nApplicable_Platforms:\n  Technology: Bus/Interface Hardware\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design, then identified later during Testing or System\n  Configuration phases.\n\n\n  Implementation: Such issues could be introduced during hardware implementation,\n  then identified later during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design: Security identifier decoders must\n  be reviewed for design inconsistency and common weaknesses.\n\n\n  Implementation: Access and programming flows must be tested in pre-silicon and post-silicon\n  testing.'\n",
  "ID: '1293'\nName: Missing Source Correlation of Multiple Independent Data\nDescription: The product relies on one source of data, preventing the ability to detect\n  if an adversary has compromised a data source.\nExtended_Description: To operate successfully, a product sometimes has to implicitly\n  trust the integrity of an information source. When information is implicitly signed,\n  one can ensure that the data was not tampered in transit. This does not ensure that\n  the information source was not compromised when responding to a request. By requesting\n  information from multiple sources, one can check if all of the data is the same.\n  If they are not, the system should report the information sources that respond with\n  a different or minority value as potentially compromised. If there are not enough\n  answers to provide a majority or plurality of responses, the system should report\n  all of the sources as potentially compromised. As the seriousness of the impact\n  of incorrect integrity increases, so should the number of independent information\n  sources that would need to be queried.\nModes_Of_Introduction: 'Architecture and Design: This flaw could be introduced during\n  the design of the application or misconfiguration at run time by only specifying\n  a single point of validation.\n\n\n  Implementation: Such issues could be introduced during hardware implementation,\n  then identified later during Testing or System Configuration phases.\n\n\n  Operation: This weakness could be introduced by intentionally failing all but one\n  of the devices used to retrieve the data or by failing the devices that validate\n  the data.'\nPotential_Mitigations: 'Requirements: Design system to use a Practical Byzantine fault\n  method, to request information from multiple sources to verify the data and report\n  on potentially compromised information sources.\n\n\n  Implementation: Failure to use a Practical Byzantine fault method when requesting\n  data. Lack of place to report potentially compromised information sources. Relying\n  on non-independent information sources for integrity checking. Failure to report\n  information sources that respond in the minority to incident response procedures.'\n",
  "ID: '1294'\nName: Insecure Security Identifier Mechanism\nDescription: The System-on-Chip (SoC) implements a Security Identifier mechanism to\n  differentiate what actions are allowed or disallowed when a transaction originates\n  from an entity. However, the Security Identifiers are not correctly implemented.\nExtended_Description: \"Systems-On-Chip (Integrated circuits and hardware\\n       \\\n  \\             engines) implement Security Identifiers to\\n                    differentiate/identify\\\n  \\ actions originated from various\\n                    agents. These actions could\\\n  \\ be 'read', 'write', 'program',\\n                    'reset', 'fetch', 'compute',\\\n  \\ etc. Security identifiers are\\n                    generated and assigned to every\\\n  \\ agent in the System (SoC)\\n                    that is either capable of generating\\\n  \\ an action or receiving\\n                    an action from another agent. Every\\\n  \\ agent could be assigned\\n                    a unique, Security Identifier based\\\n  \\ on its trust level or\\n                    privileges.\\nA broad class of flaws\\\n  \\ can exist in the Security\\n                    Identifier process, including but\\\n  \\ not limited to missing\\n                    security identifiers, improper conversion\\\n  \\ of security\\n                    identifiers, incorrect generation of security\\\n  \\ identifiers,\\n                    etc.\"\nApplicable_Platforms:\n  Technology: Bus/Interface Hardware\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design, then identified later during Testing or System\n  Configuration phases.\n\n\n  Implementation: Such issues could be introduced during hardware implementation,\n  then identified later during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design: Security Identifier Decoders must\n  be reviewed for design inconsistency and common weaknesses.\n\n\n  Implementation: Access and programming flows must be tested in pre-silicon and post-silicon\n  testing.'\nRelated_Attack_Patterns: \"121: \\n\\n681: \"\n",
  "ID: '1295'\nName: Debug Messages Revealing Unnecessary Information\nDescription: The product fails to adequately prevent the revealing of unnecessary\n  and potentially sensitive system information within debugging messages.\nExtended_Description: Debug messages are messages that help troubleshoot an issue\n  by revealing the internal state of the system. For example, debug data in design\n  can be exposed through internal memory array dumps or boot logs through interfaces\n  like UART via TAP commands, scan chain, etc. Thus, the more information contained\n  in a debug message, the easier it is to debug. However, there is also the risk of\n  revealing information that could help an attacker either decipher a vulnerability,\n  and/or gain a better understanding of the system. Thus, this extra information could\n  lower the \"security by obscurity\" factor. While \"security by obscurity\" alone is\n  insufficient, it can help as a part of \"Defense-in-depth\".\nPotential_Mitigations: 'Implementation: Ensure that a debug message does not reveal\n  any unnecessary information during the debug process for the intended response.'\nObserved_Examples: 'CVE-2020-24491: Processor generates debug message that contains\n  sensitive information (\"addresses of memory transactions\").\n\n\n  CVE-2017-18326: modem debug messages include cryptographic keys'\nRelated_Attack_Patterns: '121: '\n",
  "ID: '1296'\nName: Incorrect Chaining or Granularity of Debug Components\nDescription: The product's debug components contain incorrect chaining or granularity\n  of debug components.\nExtended_Description: 'For debugging and troubleshooting a chip, several hardware\n  design elements are often implemented, including:\n\n  Logic errors during design or synthesis could misconfigure the interconnection of\n  the debug components, which could allow unintended access permissions.'\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: Processor Hardware\nDetection_Methods: 'Architecture or Design Review: Appropriate Post-Si tests should\n  be carried out at various authorization levels to ensure that debug components are\n  properly chained and accessible only to users with appropriate credentials.\n\n\n  Dynamic Analysis with Manual Results Interpretation: Appropriate Post-Si tests should\n  be carried out at various authorization levels to ensure that debug components are\n  properly chained and accessible only to users with appropriate credentials.'\nPotential_Mitigations: 'Implementation: Ensure that debug components are properly\n  chained and their granularity is maintained at different authentication levels.'\nObserved_Examples: 'CVE-2017-18347: Incorrect access control in RDP Level 1 on STMicroelectronics\n  STM32F0 series devices allows physically present attackers to extract the device''s\n  protected firmware via a special sequence of Serial Wire Debug (SWD) commands because\n  there is a race condition between full initialization of the SWD interface and the\n  setup of flash protection.\n\n\n  CVE-2020-1791: There is an improper authorization vulnerability in several smartphones.  The\n  system has a logic-judging error, and, under certain scenarios, a successful exploit\n  could allow the attacker to switch to third desktop after a series of operations\n  in ADB mode. (Vulnerability ID: HWPSIRT-2019-10114).'\nRelated_Attack_Patterns: \"121: \\n\\n702: \"\n",
  "ID: '1297'\nName: Unprotected Confidential Information on Device is Accessible by OSAT Vendors\nDescription: The product does not adequately protect confidential information on the\n  device from being accessed by Outsourced Semiconductor Assembly and Test (OSAT)\n  vendors.\nExtended_Description: 'In contrast to complete vertical integration of architecting,\n  designing, manufacturing, assembling, and testing chips all within a single organization,\n  an organization can choose to simply architect and design a chip before outsourcing\n  the rest of the process to OSAT entities (e.g., external foundries and test houses).\n  In the latter example, the device enters an OSAT facility in a much more vulnerable\n  pre-production stage where many debug and test modes are accessible. Therefore,\n  the chipmaker must place a certain level of trust with the OSAT. To counter this,\n  the chipmaker often requires the OSAT partner to enter into restrictive non-disclosure\n  agreements (NDAs). Nonetheless, OSAT vendors likely have many customers, which increases\n  the risk of accidental sharing of information. There may also be a security vulnerability\n  in the information technology (IT) system of the OSAT facility. Alternatively, a\n  malicious insider at the OSAT facility may carry out an insider attack. Considering\n  these factors, it behooves the chipmaker to minimize any confidential information\n  in the device that may be accessible to the OSAT vendor.\n\n  Logic errors during design or synthesis could misconfigure the interconnection of\n  the debug components, which could provide improper authorization to sensitive information.'\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: Processor Hardware\nDetection_Methods: 'Architecture or Design Review: Appropriate Post-Si tests should\n  be carried out to ensure that residual confidential information is not left on parts\n  leaving one facility for another facility.\n\n\n  Dynamic Analysis with Manual Results Interpretation: Appropriate Post-Si tests should\n  be carried out to ensure that residual confidential information is not left on parts\n  leaving one facility for another facility.'\nPotential_Mitigations: 'Architecture and Design: '\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '1298'\nName: Hardware Logic Contains Race Conditions\nDescription: A race condition in the hardware logic results in undermining security\n  guarantees of the system.\nExtended_Description: A race condition in logic circuits typically occurs when a logic\n  gate gets inputs from signals that have traversed different paths while originating\n  from the same source. Such inputs to the gate can change at slightly different times\n  in response to a change in the source signal. This results in a timing error or\n  a glitch (temporary or permanent) that causes the output to change to an unwanted\n  state before settling back to the desired state. If such timing errors occur in\n  access control logic or finite state machines that are implemented in security sensitive\n  flows, an attacker might exploit them to circumvent existing protections.\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Adopting design practices that encourage\n  designers to recognize and eliminate race conditions, such as Karnaugh maps, could\n  result in the decrease in occurrences of race conditions.\n\n\n  Implementation: Logic redundancy can be implemented along security critical paths\n  to prevent race conditions. To avoid metastability, it is a good practice in general\n  to default to a secure state in which access is not given to untrusted agents.'\nRelated_Attack_Patterns: '26: '\n",
  "ID: '1299'\nName: Missing Protection Mechanism for Alternate Hardware Interface\nDescription: \"The lack of protections on alternate paths to access\\n             \\\n  \\   control-protected assets (such as unprotected shadow registers\\n           \\\n  \\     and other external facing unguarded interfaces) allows an\\n              \\\n  \\  attacker to bypass existing protections to the asset that are\\n\\t\\tonly performed\\\n  \\ against the primary path.\"\nExtended_Description: \"An asset inside a chip might have access-control\\n        \\\n  \\            protections through one interface. However, if all paths to\\n     \\\n  \\               the asset are not protected, an attacker might compromise\\n    \\\n  \\                the asset through alternate paths. These alternate paths\\n    \\\n  \\                could be through shadow or mirror registers inside the IP\\n   \\\n  \\                 core, or could be paths from other external-facing\\n         \\\n  \\           interfaces to the IP core or SoC.\\nConsider an SoC with various interfaces\\\n  \\ such as UART,\\n                    SMBUS, PCIe, USB, etc. If access control is\\\n  \\ implemented for\\n                    SoC internal registers only over the PCIe\\\n  \\ interface, then\\n                    an attacker could still modify the SoC internal\\\n  \\ registers\\n                    through alternate paths by coming through interfaces\\\n  \\ such\\n                    as UART, SMBUS, USB, etc.\\nAlternatively, attackers\\\n  \\ might be able to bypass\\n                    existing protections by exploiting\\\n  \\ unprotected, shadow\\n                    registers. Shadow registers and mirror\\\n  \\ registers typically\\n                    refer to registers that can be accessed\\\n  \\ from multiple\\n                    addresses. Writing to or reading from the aliased/mirrored\\n\\\n  \\                    address has the same effect as writing to the address of\\n\\\n  \\                    the main register. They are typically implemented within an\\n\\\n  \\                    IP core or SoC to temporarily hold certain data. These data\\n\\\n  \\                    will later be updated to the main register, and both\\n    \\\n  \\                registers will be in synch. If the shadow registers are not\\n \\\n  \\                   access-protected, attackers could simply initiate\\n        \\\n  \\            transactions to the shadow registers and compromise system\\n      \\\n  \\              security.\"\nApplicable_Platforms:\n  Technology: Microcontroller Hardware, Processor Hardware, Bus/Interface Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Requirements: Protect assets from accesses against all potential\n  interfaces and alternate paths.\n\n\n  Architecture and Design: Protect assets from accesses against all potential interfaces\n  and alternate paths.\n\n\n  Implementation: Protect assets from accesses against all potential interfaces and\n  alternate paths.'\nObserved_Examples: \"CVE-2017-18293: When GPIO is protected by blocking access\\n  \\\n  \\                      to corresponding GPIO resource registers,\\n             \\\n  \\           protection can be bypassed by writing to the\\n                     \\\n  \\   corresponding banked GPIO registers instead.\\n\\nCVE-2020-15483: monitor device\\\n  \\ allows access to physical UART debug port without authentication\"\nRelated_Attack_Patterns: \"457: \\n\\n554: \"\n",
  "ID: '13'\nName: 'ASP.NET Misconfiguration: Password in Configuration File'\nDescription: Storing a plaintext password in a configuration file allows anyone who\n  can read the file access to the password-protected resource making them an easy\n  target for attackers.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Credentials stored in configuration files\n  should be encrypted, Use standard APIs and industry accepted algorithms to encrypt\n  the credentials stored in configuration files.'\n",
  "ID: '130'\nName: Improper Handling of Length Parameter Inconsistency\nDescription: The product parses a formatted message or structure, but it does not\n  handle or incorrectly handles a length field that is inconsistent with the actual\n  length of the associated data.\nExtended_Description: If an attacker can manipulate the length parameter associated\n  with an input such that it is inconsistent with the actual length of the input,\n  this can be leveraged to cause the target application to behave in unexpected, and\n  possibly, malicious ways. One of the possible motives for doing so is to pass in\n  arbitrarily large input to the application. Another possible motivation is the modification\n  of application state by including invalid data for subsequent properties of the\n  application. Such weaknesses commonly lead to attacks such as buffer overflows and\n  execution of arbitrary code.\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: \"length manipulation: \\n\\nlength tampering: \"\nPotential_Mitigations: 'Implementation: When processing structured incoming data containing\n  a size field followed by raw data, ensure that you identify and resolve any inconsistencies\n  between the size field and the actual size of the data.\n\n\n  Implementation: Do not let the user control the size of the buffer.\n\n\n  Implementation: Validate that the length of the user-supplied data is consistent\n  with the buffer size.'\nObserved_Examples: 'CVE-2014-0160: Chain: \"Heartbleed\" bug receives an inconsistent\n  length parameter (CWE-130) enabling an out-of-bounds read (CWE-126), returning memory\n  that could include private cryptographic keys and other sensitive data.\n\n\n  CVE-2009-2299: Web application firewall consumes excessive memory when an HTTP request\n  contains a large Content-Length value but no POST data.\n\n\n  CVE-2001-0825: Buffer overflow in internal string handling routine allows remote\n  attackers to execute arbitrary commands via a length argument of zero or less, which\n  disables the length check.\n\n\n  CVE-2001-1186: Web server allows remote attackers to cause a denial of service via\n  an HTTP request with a content-length value that is larger than the size of the\n  request, which prevents server from timing out the connection.\n\n\n  CVE-2001-0191: Service does not properly check the specified length of a cookie,\n  which allows remote attackers to execute arbitrary commands via a buffer overflow,\n  or brute force authentication by using a short cookie length.\n\n\n  CVE-2003-0429: Traffic analyzer allows remote attackers to cause a denial of service\n  and possibly execute arbitrary code via invalid IPv4 or IPv6 prefix lengths, possibly\n  triggering a buffer overflow.\n\n\n  CVE-2000-0655: Chat client allows remote attackers to cause a denial of service\n  or execute arbitrary commands via a JPEG image containing a comment with an illegal\n  field length of 1.\n\n\n  CVE-2004-0492: Server allows remote attackers to cause a denial of service and possibly\n  execute arbitrary code via a negative Content-Length HTTP header field causing a\n  heap-based buffer overflow.\n\n\n  CVE-2004-0201: Help program allows remote attackers to execute arbitrary commands\n  via a heap-based buffer overflow caused by a .CHM file with a large length field\n\n\n  CVE-2003-0825: Name services does not properly validate the length of certain packets,\n  which allows attackers to cause a denial of service and possibly execute arbitrary\n  code. Can overlap zero-length issues\n\n\n  CVE-2004-0095: Policy manager allows remote attackers to cause a denial of service\n  (memory consumption and crash) and possibly execute arbitrary code via an HTTP POST\n  request with an invalid Content-Length value.\n\n\n  CVE-2004-0826: Heap-based buffer overflow in library allows remote attackers to\n  execute arbitrary code via a modified record length field in an SSLv2 client hello\n  message.\n\n\n  CVE-2004-0808: When domain logons are enabled, server allows remote attackers to\n  cause a denial of service via a SAM_UAS_CHANGE request with a length value that\n  is larger than the number of structures that are provided.\n\n\n  CVE-2002-1357: Multiple SSH2 servers and clients do not properly handle packets\n  or data elements with incorrect length specifiers, which may allow remote attackers\n  to cause a denial of service or possibly execute arbitrary code.\n\n\n  CVE-2004-0774: Server allows remote attackers to cause a denial of service (CPU\n  and memory exhaustion) via a POST request with a Content-Length header set to -1.\n\n\n  CVE-2004-0989: Multiple buffer overflows in xml library that may allow remote attackers\n  to execute arbitrary code via long URLs.\n\n\n  CVE-2004-0568: Application does not properly validate the length of a value that\n  is saved in a session file, which allows remote attackers to execute arbitrary code\n  via a malicious session file (.ht), web site, or Telnet URL contained in an e-mail\n  message, triggering a buffer overflow.\n\n\n  CVE-2003-0327: Server allows remote attackers to cause a denial of service via a\n  remote password array with an invalid length, which triggers a heap-based buffer\n  overflow.\n\n\n  CVE-2003-0345: Product allows remote attackers to cause a denial of service and\n  possibly execute arbitrary code via an SMB packet that specifies a smaller buffer\n  length than is required.\n\n\n  CVE-2004-0430: Server allows remote attackers to execute arbitrary code via a LoginExt\n  packet for a Cleartext Password User Authentication Method (UAM) request with a\n  PathName argument that includes an AFPName type string that is longer than the associated\n  length field.\n\n\n  CVE-2005-0064: PDF viewer allows remote attackers to execute arbitrary code via\n  a PDF file with a large /Encrypt /Length keyLength value.\n\n\n  CVE-2004-0413: SVN client trusts the length field of SVN protocol URL strings, which\n  allows remote attackers to cause a denial of service and possibly execute arbitrary\n  code via an integer overflow that leads to a heap-based buffer overflow.\n\n\n  CVE-2004-0940: Is effectively an accidental double increment of a counter that prevents\n  a length check conditional from exiting a loop.\n\n\n  CVE-2002-1235: Length field of a request not verified.\n\n\n  CVE-2005-3184: Buffer overflow by modifying a length value.\n\n\n  SECUNIA:18747: Length field inconsistency crashes cell phone.'\nRelated_Attack_Patterns: '47: '\n",
  "ID: '1300'\nName: Improper Protection of Physical Side Channels\nDescription: \"The device does not contain sufficient protection\\n\\tmechanisms to prevent\\\n  \\ physical side channels from exposing\\n\\tsensitive information due to patterns\\\n  \\ in physically observable\\n\\tphenomena such as variations in power consumption,\\n\\\n  \\telectromagnetic emissions (EME), or acoustic emissions.\"\nExtended_Description: \"An adversary could monitor and measure physical\\n\\t  phenomena\\\n  \\ to detect patterns and make inferences, even if it\\n\\t  is not possible to extract\\\n  \\ the information in the digital\\n\\t  domain.\\nPhysical side channels have been\\\n  \\ well-studied for\\n\\t  decades in the context of breaking implementations of\\n\\t\\\n  \\  cryptographic algorithms or other attacks against security\\n\\t  features. These\\\n  \\ side channels may be easily observed by an\\n\\t  adversary with physical access\\\n  \\ to the device, or using a\\n\\t  tool that is in close proximity.  If the adversary\\\n  \\ can\\n\\t  monitor hardware operation and correlate its data processing\\n\\t  with\\\n  \\ power, EME, and acoustic measurements, the adversary\\n\\t  might be able to recover\\\n  \\ of secret keys and data.\"\nDetection_Methods: 'Manual Analysis: Perform a set of leakage detection tests such\n  as the procedure outlined in the Test Vector Leakage Assessment (TVLA) test requirements\n  for AES [REF-1230].  TVLA is the basis for the ISO standard 17825 [REF-1229]. A\n  separate methodology is provided by [REF-1228]. Note that sole reliance on this\n  method might not yield expected results [REF-1239] [REF-1240].\n\n\n  Manual Analysis: Post-silicon, perform full side-channel attacks (penetration testing)\n  covering as many known leakage models as possible against test code.\n\n\n  Manual Analysis: Pre-silicon - while the aforementioned TVLA methods can be performed\n  post-silicon, models of device power consumption or other physical emanations can\n  be built from information present at various stages of the hardware design process\n  before fabrication. TVLA or known side-channel attacks can be applied to these simulated\n  traces and countermeasures applied before tape-out.  Academic research in this field\n  includes [REF-1231] [REF-1232] [REF-1233].'\nPotential_Mitigations: 'Architecture and Design: Apply blinding or masking techniques\n  to implementations of cryptographic algorithms.\n\n\n  Implementation: Add shielding or tamper-resistant protections to the device to increase\n  the difficulty of obtaining measurements of the side-channel.'\nObserved_Examples: 'CVE-2021-3011: electromagnetic-wave side-channel in security-related\n  microcontrollers allows extraction of private key\n\n\n  CVE-2013-4576: message encryption software uses certain instruction sequences that\n  allows RSA key extraction using a chosen-ciphertext attack and acoustic cryptanalysis\n\n\n  CVE-2020-28368: virtualization product allows recovery of AES keys from the guest\n  OS using a side channel attack against a power/energy monitoring interface.\n\n\n  CVE-2019-18673: power consumption varies based on number of pixels being illuminated\n  in a display, allowing reading of secrets such as the PIN by using the USB interface\n  to measure power consumption'\nRelated_Attack_Patterns: \"189: \\n\\n699: \"\n",
  "ID: '1301'\nName: Insufficient or Incomplete Data Removal within Hardware Component\nDescription: The product's data removal process does not completely delete all data\n  and potentially sensitive information within hardware components.\nExtended_Description: 'Physical properties of hardware devices, such as remanence\n  of magnetic media, residual charge of ROMs/RAMs, or screen burn-in may still retain\n  sensitive data after a data removal process has taken place and power is removed.\n\n  Recovering data after erasure or overwriting is possible due to a phenomenon called\n  data remanence. For example, if the same value is written repeatedly to a memory\n  location, the corresponding memory cells can become physically altered to a degree\n  such that even after the original data is erased that data can still be recovered\n  through physical characterization of the memory cells.'\nPotential_Mitigations: 'Architecture and Design: Apply blinding or masking techniques\n  to implementations of cryptographic algorithms.\n\n\n  Implementation: Alter the method of erasure, add protection of media, or destroy\n  the media to protect the data.'\nRelated_Attack_Patterns: '37: '\n",
  "ID: '1302'\nName: Missing Security Identifier\nDescription: The product implements a security identifier mechanism to differentiate\n  what actions are allowed or disallowed when a transaction originates from an entity.\n  A transaction is sent without a security identifier.\nExtended_Description: 'In a System-On-Chip (SoC), various integrated circuits and\n  hardware engines generate transactions such as to access (reads/writes) assets or\n  perform certain actions (e.g., reset, fetch, compute). A typical transaction is\n  comprised of source identity (to identify the originator of the transaction) and\n  a destination identity (to route the transaction to the respective entity) in addition\n  to much more information in the message. Sometimes the transactions are qualified\n  with a Security Identifier.  This Security Identifier helps the destination agent\n  decide on the set of allowed or disallowed actions.\n\n  A common weakness that can exist in such transaction schemes is that the source\n  agent fails to include the necessary, security identifier with the transaction.  Because\n  of the missing security identifier, the destination agent might drop the message,\n  thus resulting in Denial-of-Service (DoS), or get confused in its attempt to execute\n  the given action, which confusion could result in privilege escalation or a gain\n  of unintended access.'\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during implementation and identified\n  later during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design: Transaction details must be reviewed\n  for design inconsistency and common weaknesses.\n\n\n  Implementation: Security identifier definition and programming flow must be tested\n  in pre-silicon and post-silicon testing.'\nRelated_Attack_Patterns: \"121: \\n\\n681: \"\n",
  "ID: '1303'\nName: Non-Transparent Sharing of Microarchitectural Resources\nDescription: Hardware structures shared across execution contexts (e.g., caches and\n  branch predictors) can violate the expected architecture isolation between contexts.\nExtended_Description: 'Modern processors use techniques such as out-of-order execution,\n  speculation, prefetching, data forwarding, and caching to increase performance.\n  Details about the implementation of these techniques are hidden from the programmer''s\n  view. This is problematic when the hardware implementation of these techniques results\n  in resources being shared across supposedly isolated contexts. Contention for shared\n  resources between different contexts opens covert channels that allow malicious\n  programs executing in one context to recover information from another context.\n\n  Some examples of shared micro-architectural resources that have been used to leak\n  information between contexts are caches, branch prediction logic, and load or store\n  buffers. Speculative and out-of-order execution provides an attacker with increased\n  control over which data is leaked through the covert channel.\n\n  If the extent of resource sharing between contexts in the design microarchitecture\n  is undocumented, it is extremely difficult to ensure system assets are protected\n  against disclosure.'\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during implementation and identified\n  later during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design: Microarchitectural covert channels\n  can be addressed using a mixture of hardware and software mitigation techniques.\n  These include partitioned caches, new barrier and flush instructions, and disabling\n  high resolution performance counters and timers.\n\n\n  Requirements: Microarchitectural covert channels can be addressed using a mixture\n  of hardware and software mitigation techniques. These include partitioned caches,\n  new barrier and flush instructions, and disabling high resolution performance counters\n  and timers.'\nRelated_Attack_Patterns: '663: '\n",
  "ID: '1304'\nName: Improperly Preserved Integrity of Hardware Configuration State During a Power\n  Save/Restore Operation\nDescription: \"The product performs a power save/restore\\n            operation, but\\\n  \\ it does not ensure that the integrity of\\n            the configuration state\\\n  \\ is maintained and/or verified between\\n\\t    the beginning and ending of the operation.\"\nExtended_Description: \"Before powering down, the Intellectual\\n                Property\\\n  \\ (IP) saves current state (S) to persistent\\n                storage such as flash\\\n  \\ or always-on memory in order to\\n                optimize the restore operation.\\\n  \\  During this process,\\n                an attacker with access to the persistent\\\n  \\ storage may\\n                alter (S) to a configuration that could potentially\\n\\\n  \\                modify privileges, disable protections, and/or cause\\n        \\\n  \\        damage to the hardware. If the IP does not validate\\n                the\\\n  \\ configuration state stored in persistent memory,\\n                upon regaining\\\n  \\ power or becoming operational again,\\n                the IP could be compromised\\\n  \\ through the activation of\\n                an unwanted/harmful configuration.\"\nModes_Of_Introduction: 'Architecture and Design: Weakness introduced via missing internal\n  integrity guarantees during power save/restore\n\n\n  Integration: Weakness introduced via missing external integrity verification during\n  power save/restore'\nPotential_Mitigations: \"Architecture and Design: Inside the IP, incorporate integrity\\\n  \\ checking\\n                        on the configuration state via a cryptographic\\n\\\n  \\                        hash. The hash can be protected inside the IP such as\\n\\\n  \\                        by storing it in internal registers which never lose\\n\\\n  \\                        power. Before powering down, the IP performs a hash of\\n\\\n  \\                        the configuration and saves it in these persistent\\n  \\\n  \\                      registers. Upon restore, the IP performs a hash of the\\n\\\n  \\                        saved configuration and compares it with the\\n        \\\n  \\                saved hash. If they do not match, then the IP should\\n        \\\n  \\                not trust the configuration.\\n\\nIntegration: Outside the IP, incorporate\\\n  \\ integrity checking\\n                        of the configuration state via a trusted\\\n  \\ agent. Before\\n                        powering down, the trusted agent performs\\\n  \\ a hash of the\\n                        configuration and saves the hash in persistent\\\n  \\ storage.\\n                        Upon restore, the IP requests the trusted agent\\n\\\n  \\                        validate its current configuration. If the\\n          \\\n  \\              configuration hash is invalid, then the IP should not\\n         \\\n  \\               trust the configuration.\\n\\nIntegration: Outside the IP, incorporate\\\n  \\ a protected\\n                        environment that prevents undetected modification\\\n  \\ of\\n                        the configuration state by untrusted agents. Before\\n\\\n  \\                        powering down, a trusted agent saves the IP's\\n       \\\n  \\                 configuration state in this protected location that\\n        \\\n  \\                only it is privileged to. Upon restore, the trusted\\n         \\\n  \\               agent loads the saved state into the IP.\"\nRelated_Attack_Patterns: '176: '\n",
  "ID: '131'\nName: Incorrect Calculation of Buffer Size\nDescription: The product does not correctly calculate the size to be used when allocating\n  a buffer, which could lead to a buffer overflow.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis generally does not account for environmental considerations\n  when reporting potential errors in buffer calculations. This can make it difficult\n  for users to determine which warnings should be investigated first. For example,\n  an analysis tool might report buffer overflows that originate from command line\n  arguments in a program that is not expected to run with setuid or other special\n  privileges.\n\n  Detection techniques for buffer-related errors are more mature than for most other\n  weakness types.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n  Without visibility into the code, black box methods may not be able to sufficiently\n  distinguish this weakness from others, requiring follow-up manual methods to diagnose\n  the underlying problem.\n\n\n  Manual Analysis: Manual analysis can be useful for finding this weakness, but it\n  might not achieve desired code coverage within limited time constraints. This becomes\n  difficult for weaknesses that must be considered for all inputs, since the attack\n  surface can be too large.\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  allocation calculations. This can be useful for detecting overflow conditions (CWE-190)\n  or similar weaknesses that might have serious security impacts on the program.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: When allocating a buffer for the purpose of\n  transforming, converting, or encoding an input, allocate enough memory to handle\n  the largest possible encoding. For example, in a routine that converts \"&\" characters\n  to \"&amp;\" for HTML entity encoding, the output buffer needs to be at least 5 times\n  as large as the input buffer.\n\n\n  Implementation: Understand the programming language''s underlying representation\n  and how it interacts with numeric calculation (CWE-681). Pay close attention to\n  byte size discrepancies, precision, signed/unsigned distinctions, truncation, conversion\n  and casting between types, \"not-a-number\" calculations, and how the language handles\n  numbers that are too large or too small for its underlying representation. [REF-7]\n\n  Also be careful to account for 32-bit, 64-bit, and other potential differences that\n  may affect the numeric representation.\n\n\n  Implementation: Perform input validation on any numeric input by ensuring that it\n  is within the expected range. Enforce that the input meets both the minimum and\n  maximum requirements for the expected range.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: When processing structured incoming data containing a size field\n  followed by raw data, identify and resolve any inconsistencies between the size\n  field and the actual size of the data (CWE-130).\n\n\n  Implementation: When allocating memory that uses sentinels to mark the end of a\n  data structure - such as NUL bytes in strings - make sure you also include the sentinel\n  in your calculation of the total amount of memory that must be allocated.\n\n\n  Implementation: Replace unbounded copy functions with analogous functions that support\n  length arguments, such as strcpy with strncpy. Create these if they are not available.\n\n\n  Implementation: Use sizeof() on the appropriate data type to avoid CWE-467.\n\n\n  Implementation: Use the appropriate type for the desired action. For example, in\n  C/C++, only use unsigned types for values that could never be negative, such as\n  height, width, or other numbers related to quantity. This will simplify validation\n  and will reduce surprises related to unexpected casting.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Use libraries or frameworks that make it easier to handle numbers without unexpected\n  consequences, or buffer allocation routines that automatically track buffer size.\n\n  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib\n  (C or C++). [REF-106]\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Implementation: Examine compiler warnings closely and eliminate problems with potential\n  security implications, such as signed / unsigned mismatch in memory operations,\n  or use of uninitialized variables. Even if the weakness is rarely exploitable, a\n  single failure may lead to the compromise of the entire system.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.'\nObserved_Examples: 'CVE-2020-17087: Chain: integer truncation (CWE-197) causes small\n  buffer allocation (CWE-131) leading to out-of-bounds write (CWE-787) in kernel pool,\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2004-1363: substitution overflow: buffer overflow using environment variables\n  that are expanded after the length check is performed\n\n\n  CVE-2004-0747: substitution overflow: buffer overflow using expansion of environment\n  variables\n\n\n  CVE-2005-2103: substitution overflow: buffer overflow using a large number of substitution\n  strings\n\n\n  CVE-2005-3120: transformation overflow: product adds extra escape characters to\n  incoming data, but does not account for them in the buffer length\n\n\n  CVE-2003-0899: transformation overflow: buffer overflow when expanding \">\" to \"&gt;\",\n  etc.\n\n\n  CVE-2001-0334: expansion overflow: buffer overflow using wildcards\n\n\n  CVE-2001-0248: expansion overflow: long pathname + glob = overflow\n\n\n  CVE-2001-0249: expansion overflow: long pathname + glob = overflow\n\n\n  CVE-2002-0184: special characters in argument are not properly expanded\n\n\n  CVE-2004-0434: small length value leads to heap overflow\n\n\n  CVE-2002-1347: multiple variants\n\n\n  CVE-2005-0490: needs closer investigation, but probably expansion-based\n\n\n  CVE-2004-0940: needs closer investigation, but probably expansion-based\n\n\n  CVE-2008-0599: Chain: Language interpreter calculates wrong buffer size (CWE-131)\n  by using \"size = ptr ? X : Y\" instead of \"size = (ptr ? X : Y)\" expression.'\nRelated_Attack_Patterns: \"100: \\n\\n47: \"\n",
  "ID: '1310'\nName: Missing Ability to Patch ROM Code\nDescription: Missing an ability to patch ROM code may leave a System or System-on-Chip\n  (SoC) in a vulnerable state.\nExtended_Description: 'A System or System-on-Chip (SoC) that implements a boot process\n  utilizing security mechanisms such as Root-of-Trust (RoT) typically starts by executing\n  code from a Read-only-Memory (ROM) component. The code in ROM is immutable, hence\n  any security vulnerabilities discovered in the ROM code can never be fixed for the\n  systems that are already in use.\n\n  A common weakness is that the ROM does not have the ability to patch if security\n  vulnerabilities are uncovered after the system gets shipped.  This leaves the system\n  in a vulnerable state where an adversary can compromise the SoC.'\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: This issue could be introduced during\n  hardware architecture and design and can be identified later during Testing.\n\n\n  Implementation: This issue could be introduced during implementation and can be\n  identified later during Testing.\n\n\n  Integration: This issue could be introduced during integration and can be identified\n  later during Testing.\n\n\n  Manufacturing: This issue could be introduced during manufacturing and can be identified\n  later during Testing.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Secure patch support to allow ROM code to be patched on the next\n  boot.\n\n\n  Architecture and Design\n\n  Implementation: Support patches that can be programmed in-field or during manufacturing\n  through hardware fuses. This feature can be used for limited patching of devices\n  after shipping, or for the next batch of silicon devices manufactured, without changing\n  the full device ROM.'\nRelated_Attack_Patterns: '682: '\n",
  "ID: '1311'\nName: Improper Translation of Security Attributes by Fabric Bridge\nDescription: The bridge incorrectly translates security attributes from either trusted\n  to untrusted or from untrusted to trusted when converting from one fabric protocol\n  to another.\nExtended_Description: 'A bridge allows IP blocks supporting different fabric protocols\n  to be integrated into the system.  Fabric end-points or interfaces usually have\n  dedicated signals to transport security attributes. For example, HPROT signals in\n  AHB, AxPROT signals in AXI, and MReqInfo and SRespInfo signals in OCP.\n\n  The values on these signals are used to indicate the security attributes of the\n  transaction. These include the immutable hardware identity of the controller initiating\n  the transaction, privilege level, and type of transaction (e.g., read/write, cacheable/non-cacheable,\n  posted/non-posted).\n\n  A weakness can arise if the bridge IP block, which translates the signals from the\n  protocol used in the IP block endpoint to the protocol used by the central bus,\n  does not properly translate the security attributes. As a result, the identity of\n  the initiator could be translated from untrusted to trusted or vice-versa. This\n  could result in access-control bypass, privilege escalation, or denial of service.'\nApplicable_Platforms:\n  Language: Verilog, VHDL\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: The translation must map signals\n  in such a way that untrusted agents cannot map to trusted agents or vice-versa.\n\n\n  Implementation: Ensure that the translation maps signals in such a way that untrusted\n  agents cannot map to trusted agents or vice-versa.'\nRelated_Attack_Patterns: \"1: \\n\\n180: \\n\\n233: \"\n",
  "ID: '1312'\nName: Missing Protection for Mirrored Regions in On-Chip Fabric Firewall\nDescription: The firewall in an on-chip fabric protects the main addressed region,\n  but it does not protect any mirrored memory or memory-mapped-IO (MMIO) regions.\nExtended_Description: Few fabrics mirror memory and address ranges, where mirrored\n  regions contain copies of the original data. This redundancy is used to achieve\n  fault tolerance. Whatever protections the fabric firewall implements for the original\n  region should also apply to the mirrored regions. If not, an attacker could bypass\n  existing read/write protections by reading from/writing to the mirrored regions\n  to leak or corrupt the original data.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Manual Dynamic Analysis: Using an external debugger, send write\n  transactions to mirrored regions to test if original, write-protected regions are\n  modified. Similarly, send read transactions to mirrored regions to test if the original,\n  read-protected signals can be read.'\nPotential_Mitigations: 'Architecture and Design: The fabric firewall should apply\n  the same protections as the original region to the mirrored regions.\n\n\n  Implementation: The fabric firewall should apply the same protections as the original\n  region to the mirrored regions.'\nRelated_Attack_Patterns: \"456: \\n\\n679: \"\n",
  "ID: '1313'\nName: Hardware Allows Activation of Test or Debug Logic at Runtime\nDescription: During runtime, the hardware allows for test or debug logic (feature)\n  to be activated, which allows for changing the state of the hardware. This feature\n  can alter the intended behavior of the system and allow for alteration and leakage\n  of sensitive data by an adversary.\nExtended_Description: An adversary can take advantage of test or debug logic that\n  is made accessible through the hardware during normal operation to modify the intended\n  behavior of the system. For example, an accessible Test/debug mode may allow read/write\n  access to any system data. Using error injection (a common test/debug feature) during\n  a transmit/receive operation on a bus, data may be modified to produce an unintended\n  message. Similarly, confidentiality could be compromised by such features allowing\n  access to secrets.\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during implementation and identified\n  later during Testing or System Configuration phases.\n\n\n  Integration: Such issues could be introduced during integration and identified later\n  during Testing or System configuration phases.'\nPotential_Mitigations: 'Architecture and Design: Insert restrictions on when the hardware''s\n  test or debug features can be activated. For example, during normal operating modes,\n  the hardware''s privileged modes that allow access to such features cannot be activated.\n  Configuring the hardware to only enter a test or debug mode within a window of opportunity\n  such as during boot or configuration stage. The result is disablement of such test/debug\n  features and associated modes during normal runtime operations.\n\n\n  Implementation: Insert restrictions on when the hardware''s test or debug features\n  can be activated. For example, during normal operating modes, the hardware''s privileged\n  modes that allow access to such features cannot be activated. Configuring the hardware\n  to only enter a test or debug mode within a window of opportunity such as during\n  boot or configuration stage. The result is disablement of such test/debug features\n  and associated modes during normal runtime operations.\n\n\n  Integration: Insert restrictions on when the hardware''s test or debug features\n  can be activated. For example, during normal operating modes, the hardware''s privileged\n  modes that allow access to such features cannot be activated. Configuring the hardware\n  to only enter a test or debug mode within a window of opportunity such as during\n  boot or configuration stage. The result is disablement of such test/debug features\n  and associated modes during normal runtime operations.'\nRelated_Attack_Patterns: '121: '\n",
  "ID: '1314'\nName: Missing Write Protection for Parametric Data Values\nDescription: The device does not write-protect the parametric data values for sensors\n  that scale the sensor value, allowing untrusted software to manipulate the apparent\n  result and potentially damage hardware or cause operational failure.\nExtended_Description: 'Various sensors are used by hardware to detect any devices\n  operating outside of the design limits. The threshold limit values are set by hardware\n  fuses or trusted software such as the BIOS. These limits may be related to thermal,\n  power, voltage, current, and frequency. Hardware mechanisms may be used to protect\n  against alteration of the threshold limit values by untrusted software.\n\n  The limit values are generally programmed in standard units for the type of value\n  being read. However, the hardware-sensor blocks may report the settings in different\n  units depending upon sensor design and operation. The raw sensor output value is\n  converted to the desired units using a scale conversion based on the parametric\n  data programmed into the sensor. The final converted value is then compared with\n  the previously programmed limits.\n\n  While the limit values are usually protected, the sensor parametric data values\n  may not be. By changing the parametric data, safe operational limits may be bypassed.'\nApplicable_Platforms:\n  Technology: Sensor Hardware\nModes_Of_Introduction: 'Architecture and Design: The lack of a requirement to protect\n  parametric values may contribute to this weakness.\n\n\n  Implementation: The lack of parametric value protection may be a cause of this weakness.'\nPotential_Mitigations: 'Architecture and Design: Access controls for sensor blocks\n  should ensure that only trusted software is allowed to change threshold limits and\n  sensor parametric data.'\nObserved_Examples: 'CVE-2017-8252: Kernel can inject faults in computations during\n  the execution of TrustZone leading to information disclosure in Snapdragon Auto,\n  Snapdragon Compute, Snapdragon Connectivity, Snapdragon Consumer Electronics Connectivity,\n  Snapdragon Consumer IOT, Snapdragon Industrial IOT, Snapdragon IoT, Snapdragon Mobile,\n  Snapdragon Voice and Music, Snapdragon Wearables, Snapdragon Wired Infrastructure\n  and Networking.'\nRelated_Attack_Patterns: '1: '\n",
  "ID: '1315'\nName: Improper Setting of Bus Controlling Capability in Fabric End-point\nDescription: The bus controller enables bits in the fabric end-point to allow responder\n  devices to control transactions on the fabric.\nExtended_Description: To support reusability, certain fabric interfaces and end points\n  provide a configurable register bit that allows IP blocks connected to the controller\n  to access other peripherals connected to the fabric. This allows the end point to\n  be used with devices that function as a controller or responder. If this bit is\n  set by default in hardware, or if firmware incorrectly sets it later, a device intended\n  to be a responder on a fabric is now capable of controlling transactions to other\n  devices and might compromise system security.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nSystem Configuration: \"\nPotential_Mitigations: 'Architecture and Design: For responder devices, the register\n  bit in the fabric end-point that enables the bus controlling capability must be\n  set to 0 by default. This bit should not be set during secure-boot flows. Also,\n  writes to this register must be access-protected to prevent malicious modifications\n  to obtain bus-controlling capability.\n\n\n  Implementation: For responder devices, the register bit in the fabric end-point\n  that enables the bus controlling capability must be set to 0 by default. This bit\n  should not be set during secure-boot flows. Also, writes to this register must be\n  access-protected to prevent malicious modifications to obtain bus-controlling capability.\n\n\n  System Configuration: For responder devices, the register bit in the fabric end-point\n  that enables the bus controlling capability must be set to 0 by default. This bit\n  should not be set during secure-boot flows. Also, writes to this register must be\n  access-protected to prevent malicious modifications to obtain bus-controlling capability.'\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '1316'\nName: Fabric-Address Map Allows Programming of Unwarranted Overlaps of Protected and\n  Unprotected Ranges\nDescription: The address map of the on-chip fabric has protected and unprotected regions\n  overlapping, allowing an attacker to bypass access control to the overlapping portion\n  of the protected region.\nExtended_Description: 'Various ranges can be defined in the system-address map, either\n  in the memory or in Memory-Mapped-IO (MMIO) space. These ranges are usually defined\n  using special range registers that contain information, such as base address and\n  size. Address decoding is the process of determining for which range the incoming\n  transaction is destined. To ensure isolation, ranges containing secret data are\n  access-control protected.\n\n  Occasionally, these ranges could overlap. The overlap could either be intentional\n  (e.g. due to a limited number of range registers or limited choice in choosing size\n  of the range) or unintentional (e.g. introduced by errors). Some hardware designs\n  allow dynamic remapping of address ranges assigned to peripheral MMIO ranges. In\n  such designs, intentional address overlaps can be created through misconfiguration\n  by malicious software. When protected and unprotected ranges overlap, an attacker\n  could send a transaction and potentially compromise the protections in place, violating\n  the principle of least privilege.'\nApplicable_Platforms:\n  Technology: Bus/Interface Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Dynamic Analysis: Review address map in specification\n  to see if there are any overlapping ranges.\n\n\n  Manual Static Analysis: Negative testing of access control on overlapped ranges.'\nPotential_Mitigations: 'Architecture and Design: When architecting the address map\n  of the chip, ensure that protected and unprotected ranges are isolated and do not\n  overlap. When designing, ensure that ranges hardcoded in Register-Transfer Level\n  (RTL) do not overlap.\n\n\n  Implementation: Ranges configured by firmware should not overlap. If overlaps are\n  mandatory because of constraints such as a limited number of registers, then ensure\n  that no assets are present in the overlapped portion.\n\n\n  Testing: Validate mitigation actions with robust testing.'\nObserved_Examples: 'CVE-2009-4419: Attacker can modify MCHBAR register to overlap\n  with an attacker-controlled region, which modification prevents the SENTER instruction\n  from properly applying VT-d protection while a Measured Launch Environment is being\n  launched.'\nRelated_Attack_Patterns: \"456: \\n\\n679: \"\n",
  "ID: '1317'\nName: Improper Access Control in Fabric Bridge\nDescription: The product uses a fabric bridge for transactions between two Intellectual\n  Property (IP) blocks, but the bridge does not properly perform the expected privilege,\n  identity, or other access control checks between those IP blocks.\nExtended_Description: 'In hardware designs, different IP blocks are connected through\n  interconnect-bus fabrics (e.g. AHB and OCP). Within a System on Chip (SoC), the\n  IP block subsystems could be using different bus protocols. In such a case, the\n  IP blocks are then linked to the central bus (and to other IP blocks) through a\n  fabric bridge. Bridges are used as bus-interconnect-routing modules that link different\n  protocols or separate, different segments of the overall SoC interconnect.\n\n  For overall system security, it is important that the access-control privileges\n  associated with any fabric transaction are consistently maintained and applied,\n  even when they are routed or translated by a fabric bridge. A bridge that is connected\n  to a fabric without security features forwards transactions to the slave without\n  checking the privilege level of the master and results in a weakness in SoC access-control\n  security. The same weakness occurs if a bridge does not check the hardware identity\n  of the transaction received from the slave interface of the bridge.'\nApplicable_Platforms:\n  Technology: Processor Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Simulation / Emulation: RTL simulation to ensure that bridge-access\n  controls are implemented properly.\n\n\n  Formal Verification: Formal verification of bridge RTL to ensure that access control\n  cannot be bypassed.'\nPotential_Mitigations: 'Architecture and Design: Ensure that the design includes provisions\n  for access-control checks in the bridge for both upstream and downstream transactions.\n\n\n  Implementation: Implement access-control checks in the bridge for both upstream\n  and downstream transactions.'\nObserved_Examples: 'CVE-2019-6260: Baseboard Management Controller (BMC) device implements\n  Advanced High-performance Bus (AHB) bridges that do not require authentication for\n  arbitrary read and write access to the BMC''s physical address space from the host,\n  and possibly the network [REF-1138].'\nRelated_Attack_Patterns: '122: '\n",
  "ID: '1318'\nName: Missing Support for Security Features in On-chip Fabrics or Buses\nDescription: On-chip fabrics or buses either do not support or are not configured\n  to support privilege separation or other security features, such as access control.\nExtended_Description: Certain on-chip fabrics and buses, especially simple and low-power\n  buses, do not support security features.  Apart from data transfer and addressing\n  ports, some fabrics and buses do not have any interfaces to transfer privilege,\n  immutable identity, or any other security attribute coming from the bus master.  Similarly,\n  they do not have dedicated signals to transport security-sensitive data from slave\n  to master, such as completions for certain types of transactions.  Few other on-chip\n  fabrics and buses support security features and define specific interfaces/signals\n  for transporting security attributes from master to slave or vice-versa.  However,\n  including these signals is not mandatory and could be left unconfigured when generating\n  the register-transfer-level (RTL) description for the fabric.  Such fabrics or buses\n  should not be used to transport any security attribute coming from the bus master.  In\n  general, peripherals with security assets should not be connected to such buses\n  before the transaction from the bus master reaches the bus, unless some form of\n  access control is performed at a fabric bridge or another intermediate module.\nApplicable_Platforms:\n  Technology: Processor Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Architecture or Design Review: Review the fabric specification\n  and ensure that it contains signals to transfer security-sensitive signals.\n\n\n  Manual Static Analysis - Source Code: Lack of security features can also be confirmed\n  through manual RTL review of the fabric RTL.'\nPotential_Mitigations: 'Architecture and Design: If fabric does not support security\n  features, implement security checks in a bridge or any component that is between\n  the master and the fabric.  Alternatively, connect all fabric slaves that do not\n  have any security assets under one such fabric and connect peripherals with security\n  assets to a different fabric that supports security features.'\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '1319'\nName: Improper Protection against Electromagnetic Fault Injection (EM-FI)\nDescription: The device is susceptible to electromagnetic fault injection attacks,\n  causing device internal information to be compromised or security mechanisms to\n  be bypassed.\nExtended_Description: 'Electromagnetic fault injection may allow an attacker to locally\n  and dynamically modify the signals (both internal and external) of an integrated\n  circuit. EM-FI attacks consist of producing a local, transient magnetic field near\n  the device, inducing current in the device wires. A typical EMFI setup is made up\n  of a pulse injection circuit that generates a high current transient in an EMI coil,\n  producing an abrupt magnetic pulse which couples to the target producing faults\n  in the device, which can lead to:'\nApplicable_Platforms:\n  Technology: System on Chip, Microcontroller Hardware, Memory Hardware, Power Management\n    Hardware, Processor Hardware, Test/Debug Hardware, Sensor Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: '\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '132'\nName: 'DEPRECATED: Miscalculated Null Termination'\nDescription: This entry has been deprecated because it was a duplicate of CWE-170.\n  All content has been transferred to CWE-170.\n",
  "ID: '1320'\nName: Improper Protection for Outbound Error Messages and Alert Signals\nDescription: Untrusted agents can disable alerts about signal conditions exceeding\n  limits or the response mechanism that handles such alerts.\nExtended_Description: \"Hardware sensors are used to detect whether a device is operating\\\n  \\ within design limits. The threshold values for these limits are set by hardware\\\n  \\ fuses or trusted software such as a BIOS.  \\n\\t\\t\\t\\tModification of these limits\\\n  \\ may be protected by hardware mechanisms.\\nWhen device sensors detect out of bound\\\n  \\ conditions, alert signals may be generated for remedial action, which may take\\\n  \\ the form of device shutdown or throttling.\\nWarning signals that are not properly\\\n  \\ secured may be disabled or used to generate spurious alerts, causing degraded\\\n  \\ performance or denial-of-service (DoS).\\n\\t\\t\\t\\tThese alerts may be masked by\\\n  \\ untrusted software. Examples of these alerts involve thermal and power sensor\\\n  \\ alerts.\"\nApplicable_Platforms:\n  Technology: System on Chip, Microcontroller Hardware, Memory Hardware, Power Management\n    Hardware, Processor Hardware, Test/Debug Hardware, Sensor Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Alert signals generated by critical\n  events should be protected from access by untrusted agents. Only hardware or trusted\n  firmware modules should be able to alter the alert configuration.'\nRelated_Attack_Patterns: \"1: \\n\\n180: \"\n",
  "ID: '1321'\nName: Improperly Controlled Modification of Object Prototype Attributes ('Prototype\n  Pollution')\nDescription: The product receives input from an upstream component that specifies\n  attributes that are to be initialized or updated in an object, but it does not properly\n  control modifications of attributes of the object prototype.\nExtended_Description: 'By adding or modifying attributes of an object prototype, it\n  is possible to create attributes that exist on every object, or replace critical\n  attributes with malicious ones. This can be problematic if the product depends on\n  existence or non-existence of certain attributes, or uses pre-defined attributes\n  of object prototype (such as hasOwnProperty, toString or valueOf).\n\n  This weakness is usually exploited by using a special attribute of objects called\n  proto,  constructor or prototype. Such attributes give access to the object prototype.\n  This weakness is often found in code that assigns object attributes based on user\n  input, or merges or clones objects recursively.'\nApplicable_Platforms:\n  Language: JavaScript\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: By freezing the object prototype first (for\n  example, Object.freeze(Object.prototype)), modification of the prototype becomes\n  impossible.\n\n\n  Architecture and Design: By blocking modifications of attributes that resolve to\n  object prototype, such as proto or prototype, this weakness can be mitigated.\n\n\n  Implementation: When handling untrusted objects, validating using a schema can be\n  used.\n\n\n  Implementation: By using an object without prototypes (via Object.create(null) ),\n  adding object prototype attributes by accessing the prototype via the special attributes\n  becomes impossible, mitigating this weakness.\n\n\n  Implementation: Map can be used instead of objects in most cases. If Map methods\n  are used instead of object attributes, it is not possible to access the object prototype\n  or modify it.'\nObserved_Examples: 'CVE-2018-3721: Prototype pollution by merging objects.\n\n\n  CVE-2019-10744: Prototype pollution by setting default values to object attributes\n  recursively.\n\n\n  CVE-2019-11358: Prototype pollution by merging objects recursively.\n\n\n  CVE-2020-8203: Prototype pollution by setting object attributes based on dot-separated\n  path.'\nRelated_Attack_Patterns: \"1: \\n\\n180: \\n\\n77: \"\n",
  "ID: '1322'\nName: Use of Blocking Code in Single-threaded, Non-blocking Context\nDescription: \"The product uses a non-blocking model that relies on a single threaded\\\n  \\ process\\n\\t\\t\\tfor features such as scalability, but it contains code that can\\\n  \\ block when it is invoked.\"\nExtended_Description: \"When an attacker can directly invoke the blocking code, or\\\n  \\ the blocking code can be affected by environmental conditions that can be influenced\\\n  \\ by an attacker, then this can lead to a denial of service by causing unexpected\\\n  \\ hang or freeze of the code. Examples of blocking code might be an expensive computation\\\n  \\ or calling\\n\\t\\t\\t\\tblocking library calls, such as those that perform exclusive\\\n  \\ file operations or require a successful network operation.\\nDue to limitations\\\n  \\ in multi-thread models, single-threaded\\n\\t\\t\\t\\tmodels are used to overcome the\\\n  \\ resource constraints that are caused by using\\n\\t\\t\\t\\tmany threads. In such a\\\n  \\ model, all code should generally be\\n\\t\\t\\t\\tnon-blocking. If blocking code is\\\n  \\ called, then the event loop will\\n\\t\\t\\t\\teffectively be stopped, which can be\\\n  \\ undesirable or dangerous.  Such\\n\\t\\t\\t\\tmodels are used in Python asyncio, Vert.x,\\\n  \\ and Node.js, or other\\n\\t\\t\\t\\tcustom event loop code.\"\nPotential_Mitigations: \"Implementation: Generally speaking, blocking calls should\\\n  \\ be\\n\\t\\t\\t\\t\\treplaced with non-blocking alternatives that can be used asynchronously.\\n\\\n  \\t\\t\\t\\t\\tExpensive computations should be passed off to worker threads, although\\n\\\n  \\t\\t\\t\\t\\tthe correct approach depends on the framework being used.\\n\\nImplementation:\\\n  \\ For expensive computations, consider breaking them up into\\n\\t\\t\\t\\t\\tmultiple\\\n  \\ smaller computations. Refer to the documentation of the\\n\\t\\t\\t\\t\\tframework being\\\n  \\ used for guidance.\"\nRelated_Attack_Patterns: '25: '\n",
  "ID: '1323'\nName: Improper Management of Sensitive Trace Data\nDescription: \"Trace data collected from several sources on the\\n                System-on-Chip\\\n  \\ (SoC) is stored in unprotected locations or\\n                transported to untrusted\\\n  \\ agents.\"\nExtended_Description: \"To facilitate verification of complex System-on-Chip\\n    \\\n  \\                (SoC) designs, SoC integrators add specific IP blocks that\\n  \\\n  \\                  trace the SoC's internal signals in real-time. This\\n       \\\n  \\             infrastructure enables observability of the SoC's internal\\n     \\\n  \\               behavior, validation of its functional design,\\n               \\\n  \\     and detection of hardware and software bugs. Such tracing\\n              \\\n  \\      IP blocks collect traces from several sources on the SoC\\n              \\\n  \\      including the CPU, crypto coprocessors, and on-chip fabrics. Traces collected\\\n  \\ from these sources are then\\n                    aggregated inside trace IP block\\\n  \\ and forwarded to trace\\n                    sinks, such as debug-trace ports that\\\n  \\ facilitate debugging by\\n                    external hardware and software debuggers.\\n\\\n  Since\\n                    these traces are collected from several security-sensitive\\n\\\n  \\                    sources, they must be protected against untrusted\\n       \\\n  \\             debuggers. If they are stored in unprotected memory, an\\n        \\\n  \\            untrusted software debugger can access these traces and\\n         \\\n  \\           extract secret information. Additionally, if\\n                    security-sensitive\\\n  \\ traces are not tagged as secure, an\\n                    untrusted hardware debugger\\\n  \\ might access them to extract\\n                    confidential information.\"\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Tag traces to indicate owner and debugging\n  privilege level (designer, OEM, or end user) needed to access that trace.'\nRelated_Attack_Patterns: \"150: \\n\\n167: \\n\\n545: \"\n",
  "ID: '1324'\nName: 'DEPRECATED: Sensitive Information Accessible by Physical Probing of JTAG Interface'\nDescription: This entry has been deprecated because it was at a lower level of abstraction\n  than supported by CWE. All relevant content has been integrated into CWE-319.\n",
  "ID: '1325'\nName: Improperly Controlled Sequential Memory Allocation\nDescription: The product manages a group of objects or resources and performs a separate\n  memory allocation for each object, but it does not properly limit the total amount\n  of memory that is consumed by all of the combined objects.\nExtended_Description: While the product might limit the amount of memory that is allocated\n  in a single operation for a single object (such as a malloc of an array), if an\n  attacker can cause multiple objects to be allocated in separate operations, then\n  this might cause higher total memory consumption than the developer intended, leading\n  to a denial of service.\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: 'Stack Exhaustion: When a weakness allocates excessive memory on\n  the stack, it is often described as \"stack exhaustion,\" which is a technical impact\n  of the weakness. This technical impact is often encountered as a consequence of\n  CWE-789 and/or CWE-1325.'\nPotential_Mitigations: 'Implementation: Ensure multiple allocations of the same kind\n  of object are properly tracked - possibly across multiple sessions, requests, or\n  messages. Define an appropriate strategy for handling requests that exceed the limit,\n  and consider supporting a configuration option so that the administrator can extend\n  the amount of memory to be used if necessary.\n\n\n  Operation: Run the program using system-provided resource limits for memory. This\n  might still cause the program to crash or exit, but the impact to the rest of the\n  system will be minimized.'\nObserved_Examples: 'CVE-2020-36049: JavaScript-based packet decoder uses concatenation\n  of many small strings, causing out-of-memory (OOM) condition\n\n\n  CVE-2019-20176: Product allocates a new buffer on the stack for each file in a directory,\n  allowing stack exhaustion\n\n\n  CVE-2013-1591: Chain: an integer overflow (CWE-190) in the image size calculation\n  causes an infinite loop (CWE-835) which sequentially allocates buffers without limits\n  (CWE-1325) until the stack is full.'\nRelated_Attack_Patterns: '130: '\n",
  "ID: '1326'\nName: Missing Immutable Root of Trust in Hardware\nDescription: A missing immutable root of trust in the hardware results in the ability\n  to bypass secure boot or execute untrusted or adversarial boot code.\nExtended_Description: 'A System-on-Chip (SoC) implements secure boot by verifying\n  or authenticating signed boot code. The signing of the code is achieved by an entity\n  that the SoC trusts.  Before executing the boot code, the SoC verifies that the\n  code or the public key with which the code has been signed has not been tampered\n  with. The other data upon which the SoC depends are system-hardware settings in\n  fuses such as whether \"Secure Boot is enabled\". These data play a crucial role in\n  establishing a Root of Trust (RoT) to execute secure-boot flows.\n\n  One of the many ways RoT is achieved is by storing the code and data in memory or\n  fuses. This memory should be immutable, i.e., once the RoT is programmed/provisioned\n  in memory, that memory should be locked and prevented from further programming or\n  writes. If the memory contents (i.e., RoT) are mutable, then an adversary can modify\n  the RoT to execute their choice of code, resulting in a compromised secure boot.\n\n  Note that, for components like ROM, secure patching/update features should be supported\n  to allow authenticated and authorized updates in the field.'\nApplicable_Platforms:\n  Technology: Security Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: Such issues could\\\n  \\ be introduced during policy definition, hardware architecture, design, manufacturing,\\\n  \\ and/or provisioning. They can be identified later during testing or system configuration\\\n  \\ phases.\"\nDetection_Methods: 'Automated Dynamic Analysis: Automated testing can verify that\n  RoT components are immutable.\n\n\n  Architecture or Design Review: Root of trust elements and memory should be part\n  of architecture and design reviews.'\nPotential_Mitigations: 'Architecture and Design: When architecting the system, the\n  RoT should be designated for storage in a memory that does not allow further programming/writes.\n\n\n  Implementation: During implementation and test, the RoT memory location should be\n  demonstrated to not allow further programming/writes.'\nRelated_Attack_Patterns: \"679: \\n\\n68: \"\n",
  "ID: '1327'\nName: Binding to an Unrestricted IP Address\nDescription: The product assigns the address 0.0.0.0 for a database server, a cloud\n  service/instance, or any computing resource that communicates remotely.\nExtended_Description: When a server binds to the address 0.0.0.0, it allows connections\n  from every IP address on the local machine, effectively exposing the server to every\n  possible network. This might be much broader access than intended by the developer\n  or administrator, who might only be expecting the server to be reachable from a\n  single interface/network.\nApplicable_Platforms:\n  Language: Other\n  Technology: Web Server, Client Server, Cloud Computing\nPotential_Mitigations: 'System Configuration: Assign IP addresses that are not 0.0.0.0.\n\n\n  System Configuration: Unwanted connections to the configured server may be denied\n  through a firewall or other packet filtering measures.'\nRelated_Attack_Patterns: '1: '\n",
  "ID: '1328'\nName: Security Version Number Mutable to Older Versions\nDescription: Security-version number in hardware is mutable, resulting in the ability\n  to downgrade (roll-back) the boot firmware to vulnerable code versions.\nExtended_Description: 'A System-on-Chip (SoC) implements secure boot or verified boot.\n  It might support a security version number, which prevents downgrading the current\n  firmware to a vulnerable version. Once downgraded to a previous version, an adversary\n  can launch exploits on the SoC and thus compromise the security of the SoC. These\n  downgrade attacks are also referred to as roll-back attacks.\n\n  The security version number must be stored securely and persistently across power-on\n  resets. A common weakness is that the security version number is modifiable by an\n  adversary, allowing roll-back or downgrade attacks or, under certain circumstances,\n  preventing upgrades (i.e. Denial-of-Service on upgrades). In both cases, the SoC\n  is in a vulnerable state.'\nApplicable_Platforms:\n  Technology: Security Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: Such issues could\\\n  \\ be introduced during hardware architecture and design, and can be identified later\\\n  \\ during testing or system configuration phases.\"\nDetection_Methods: 'Automated Dynamic Analysis: Mutability of stored security version\n  numbers and programming with older firmware images should be part of automated testing.\n\n\n  Architecture or Design Review: Anti-roll-back features should be reviewed as part\n  of Architecture or Design review.'\nPotential_Mitigations: 'Architecture and Design: When architecting the system, security\n  version data should be designated for storage in registers that are either read-only\n  or have access controls that prevent modification by an untrusted agent.\n\n\n  Implementation: During implementation and test, security version data should be\n  demonstrated to be read-only and access controls should be validated.'\nRelated_Attack_Patterns: '176: '\n",
  "ID: '1329'\nName: Reliance on Component That is Not Updateable\nDescription: The product contains a component that cannot be updated or patched in\n  order to remove vulnerabilities or significant bugs.\nExtended_Description: \"If the component is discovered to contain a vulnerability or\\\n  \\ critical bug, but the issue cannot be fixed using an update or patch, then the\\\n  \\ product's owner will not be able to protect against the issue.  The only option\\\n  \\ might be replacement of the product, which could be too financially or operationally\\\n  \\ expensive for the product owner.  As a result, the inability to patch or update\\\n  \\ can leave the product open to attacker exploitation or critical operation failures.\\\n  \\ This weakness can be especially difficult to manage when using ROM, firmware,\\\n  \\ or similar components that traditionally have had limited or no update capabilities.\\n\\\n  In industries such as healthcare, \\\"legacy\\\"\\n\\t\\t\\t    devices can be operated\\\n  \\ for decades.  As a\\n\\t\\t\\t    US task force report [REF-1197] notes, \\\"the inability\\n\\\n  \\t\\t\\t    to update or replace equipment has both\\n\\t\\t\\t    large and small health\\\n  \\ care delivery\\n\\t\\t\\t    organizations struggle with numerous\\n\\t\\t\\t    unsupported\\\n  \\ legacy systems that cannot\\n\\t\\t\\t    easily be replaced (hardware, software,\\\n  \\ and\\n\\t\\t\\t    operating systems) with large numbers of\\n\\t\\t\\t    vulnerabilities\\\n  \\ and few modern\\n\\t\\t\\t    countermeasures.\\\"\\nWhile hardware can be prone to this\\\n  \\ weakness, software systems can also be affected, such as when a third-party driver\\\n  \\ or library is no longer actively maintained or supported but is still critical\\\n  \\ for the required functionality.\"\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Requirements: Requirements development might not consider\n  the importance of updates over the lifetime of the product or might intentionally\n  exclude this capability due to concerns such as expense or speed to market.\n\n\n  Architecture and Design: Lack of planning during architecture development and design,\n  or external pressures such as speed to market, could ignore the capability to update.\n\n\n  Architecture and Design: Designers might omit capabilities for updating a component\n  due to time pressures to release the product or assumptions about the stability\n  of the component.\n\n\n  Implementation: The weakness can appear through oversight during implementation.'\nDetection_Methods: 'Architecture or Design Review: Check the consumer or maintainer\n  documentation, the architecture/design documentation, or the original requirements\n  to ensure that the documentation includes details for how to update the firmware.'\nPotential_Mitigations: 'Requirements: Specify requirements that each component should\n  be updateable, including ROM, firmware, etc.\n\n\n  Architecture and Design: Design the product to allow for updating of its components.\n  Include the external infrastructure that might be necessary to support updates,\n  such as distribution servers.\n\n\n  Architecture and Design\n\n  Implementation: With hardware, support patches that can be programmed in-field or\n  during manufacturing through hardware fuses. This feature can be used for limited\n  patching of devices after shipping, or for the next batch of silicon devices manufactured,\n  without changing the full device ROM.\n\n\n  Implementation: Implement the necessary functionality to allow each component to\n  be updated.'\nObserved_Examples: 'CVE-2020-9054: Chain: network-attached storage (NAS) device has\n  a critical OS command injection (CWE-78) vulnerability that is actively exploited\n  to place IoT devices into a botnet, but some products are \"end-of-support\" and cannot\n  be patched (CWE-1277). [REF-1097]'\n",
  "ID: '1330'\nName: Remanent Data Readable after Memory Erase\nDescription: Confidential information stored in memory circuits is readable or recoverable\n  after being cleared or erased.\nExtended_Description: 'Data remanence occurs when stored, memory content is not fully\n  lost after a memory-clear or -erase operation. Confidential memory contents can\n  still be readable through data remanence in the hardware.\n\n  Data remanence can occur because of performance optimization or memory organization\n  during ''clear'' or ''erase'' operations, like a design that allows the memory-organization\n  metadata (e.g., file pointers) to be erased without erasing the actual memory content.\n  To protect against this weakness, memory devices will often support different commands\n  for optimized memory erase and explicit secure erase.\n\n  Data remanence can also happen because of the physical properties of memory circuits\n  in use. For example, static, random-access-memory (SRAM) and dynamic, random-access-memory\n  (DRAM) data retention is based on the charge retained in the memory cell, which\n  depends on factors such as power supply, refresh rates, and temperature.\n\n  Other than explicit erase commands, self-encrypting, secure-memory devices can also\n  support secure erase through cryptographic erase commands. In such designs, only\n  the decryption keys for encrypted data stored on the device are erased. That is,\n  the stored data are always remnant in the media after a cryptographic erase. However,\n  only the encrypted data can be extracted. Thus, protection against data recovery\n  in such designs relies on the strength of the encryption algorithm.'\nApplicable_Platforms:\n  Technology: Security Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: \"Architecture or Design Review: \\n\\nDynamic Analysis with Manual\\\n  \\ Results Interpretation: \"\nPotential_Mitigations: 'Architecture and Design: '\nObserved_Examples: 'CVE-2019-8575: Firmware Data Deletion Vulnerability in which a\n  base station factory reset might not delete all user information. The impact of\n  this enables a new owner of a used device that has been \"factory-default reset\"\n  with a vulnerable firmware version can still retrieve, at least, the previous owner''s\n  wireless network name, and the previous owner''s wireless security (such as WPA2)\n  key. This issue was addressed with improved, data deletion.'\nRelated_Attack_Patterns: \"150: \\n\\n37: \\n\\n545: \"\n",
  "ID: '1331'\nName: Improper Isolation of Shared Resources in Network On Chip (NoC)\nDescription: The Network On Chip (NoC) does not isolate or incorrectly isolates its\n  on-chip-fabric and internal resources such that they are shared between trusted\n  and untrusted agents, creating timing channels.\nExtended_Description: Typically, network on chips (NoC) have many internal resources\n  that are shared between packets from different trust domains. These resources include\n  internal buffers, crossbars and switches, individual ports, and channels. The sharing\n  of resources causes contention and introduces interference between differently trusted\n  domains, which poses a security threat via a timing channel, allowing attackers\n  to infer data that belongs to a trusted agent. This may also result in introducing\n  network interference, resulting in degraded throughput and latency.\nApplicable_Platforms:\n  Technology: Security Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Manual Analysis: Providing marker flags to send through the interfaces\n  coupled with examination of which users are able to read or manipulate the flags\n  will help verify that the proper isolation has been achieved and is effective.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Implement priority-based arbitration inside the NoC and have dedicated\n  buffers or virtual channels for routing secret data from trusted agents.'\nRelated_Attack_Patterns: '124: '\n",
  "ID: '1332'\nName: Improper Handling of Faults that Lead to Instruction Skips\nDescription: The device is missing or incorrectly implements circuitry or sensors\n  that detect and mitigate the skipping of security-critical CPU instructions when\n  they occur.\nExtended_Description: \"The operating conditions of hardware may change\\n         \\\n  \\     in ways that cause unexpected behavior to occur,\\n              including\\\n  \\ the skipping of security-critical CPU\\n              instructions. Generally,\\\n  \\ this can occur due to\\n              electrical disturbances or when the device\\\n  \\ operates\\n              outside of its expected conditions.\\nIn practice, application\\\n  \\ code may contain\\n\\t\\t\\t  conditional branches that are security-sensitive (e.g.,\\n\\\n  \\t\\t\\t  accepting or rejecting a user-provided password). These\\n\\t\\t\\t  conditional\\\n  \\ branches are typically implemented by a\\n\\t\\t\\t  single conditional branch instruction\\\n  \\ in the program\\n\\t\\t\\t  binary which, if skipped, may lead to effectively\\n\\t\\t\\\n  \\t  flipping the branch condition - i.e., causing the wrong\\n\\t\\t\\t  security-sensitive\\\n  \\ branch to be taken. This affects\\n\\t\\t\\t  processes such as firmware authentication,\\\n  \\ password\\n\\t\\t\\t  verification, and other security-sensitive decision\\n\\t\\t\\t\\\n  \\  points.\\nAttackers can use fault injection techniques to\\n\\t\\t\\t  alter the operating\\\n  \\ conditions of hardware so that\\n\\t\\t\\t  security-critical instructions are skipped\\\n  \\ more\\n\\t\\t\\t  frequently or more reliably than they would in a\\n\\t\\t\\t  \\\"natural\\\"\\\n  \\ setting.\"\nApplicable_Platforms:\n  Technology: System on Chip\nModes_Of_Introduction: 'Architecture and Design: Failure to design appropriate countermeasures\n  to common fault injection techniques can manifest this weakness.\n\n\n  Implementation: This weakness can arise if the hardware design incorrectly implements\n  countermeasures to prevent fault injection.'\nDetection_Methods: 'Automated Static Analysis: This weakness can be found using automated\n  static analysis once a developer has indicated which code paths are critical to\n  protect.\n\n\n  Simulation / Emulation: This weakness can be found using automated dynamic analysis.\n  Both emulation of a CPU with instruction skips, as well as RTL simulation of a CPU\n  IP, can indicate parts of the code that are sensitive to faults due to instruction\n  skips.\n\n\n  Manual Analysis: This weakness can be found using manual (static) analysis. The\n  analyst has security objectives that are matched against the high-level code. This\n  method is less precise than emulation, especially if the analysis is done at the\n  higher level language rather than at assembly level.'\nPotential_Mitigations: \"Architecture and Design: Design strategies for ensuring safe\\\n  \\ failure if\\n                        inputs, such as Vcc, are modified out of acceptable\\n\\\n  \\                        ranges.\\n\\nArchitecture and Design: Design strategies for\\\n  \\ ensuring safe behavior if\\n                        instructions attempt to be\\\n  \\ skipped.\\n\\nArchitecture and Design: Identify mission critical secrets that should\\n\\\n  \\                          be wiped if faulting is detected, and design a\\n    \\\n  \\                      mechanism to do the deletion.\\n\\nImplementation: Add redundancy\\\n  \\ by performing an operation\\n                          multiple times, either in\\\n  \\ space or time, and perform\\n                          majority voting. Additionally,\\\n  \\ make conditional\\n                          instruction timing unpredictable.\\n\\\n  \\nImplementation: Use redundant operations or canaries to\\n                    \\\n  \\      detect and respond to faults.\\n\\nImplementation: Ensure that fault mitigations\\\n  \\ are strong enough\\n                        in practice. For example, a low power\\\n  \\ detection\\n                        mechanism that takes 50 clock cycles to trigger\\\n  \\ at lower\\n                        voltages may be an insufficient security mechanism\\\n  \\ if\\n                        the instruction counter has already progressed with\\\n  \\ no\\n                        other CPU activity occurring.\"\nObserved_Examples: 'CVE-2019-15894: fault injection attack bypasses the verification\n  mode, potentially allowing arbitrary code execution.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1333'\nName: Inefficient Regular Expression Complexity\nDescription: The product uses a regular expression with an inefficient, possibly exponential\n  worst-case computational complexity that consumes excessive CPU cycles.\nExtended_Description: \"Attackers can create crafted inputs that\\n\\t\\t  intentionally\\\n  \\ cause the regular expression to use\\n\\t\\t  excessive backtracking in a way that\\\n  \\ causes the CPU\\n\\t\\t  consumption to spike.\"\nAlternate_Terms: 'ReDoS: ReDoS is an abbreviation of \"Regular expression Denial of\n  Service\".\n\n\n  Regular Expression Denial of Service: While this term is attack-focused, this is\n  commonly used to describe the weakness.\n\n\n  Catastrophic backtracking: This term is used to describe the behavior of the regular\n  expression as a negative technical impact.'\nModes_Of_Introduction: 'Implementation: A RegEx can be easy to create and read using\n  unbounded matching characters, but the programmer might not consider the risk of  excessive\n  backtracking.'\nPotential_Mitigations: 'Architecture and Design: Use regular expressions that do not\n  support backtracking, e.g. by removing nested quantifiers.\n\n\n  System Configuration: Set backtracking limits in the configuration of the regular\n  expression implementation, such as PHP''s pcre.backtrack_limit. Also consider limits\n  on execution time for the process.\n\n\n  Implementation: Do not use regular expressions with untrusted input. If regular\n  expressions must be used, avoid using backtracking in the expression.\n\n\n  Implementation: Limit the length of the input that the regular expression will process.'\nObserved_Examples: 'CVE-2020-5243: server allows ReDOS with crafted User-Agent strings,\n  due to overlapping capture groups that cause excessive backtracking.\n\n\n  CVE-2021-21317: npm package for user-agent parser prone to ReDoS due to overlapping\n  capture groups\n\n\n  CVE-2019-16215: Markdown parser uses inefficient regex when processing a message,\n  allowing users to cause CPU consumption and delay preventing processing of other\n  messages.\n\n\n  CVE-2019-6785: Long string in a version control product allows DoS due to an inefficient\n  regex.\n\n\n  CVE-2019-12041: Javascript code allows ReDoS via a long string due to excessive\n  backtracking.\n\n\n  CVE-2015-8315: ReDoS when parsing time.\n\n\n  CVE-2015-8854: ReDoS when parsing documents.\n\n\n  CVE-2017-16021: ReDoS when validating URL.'\nRelated_Attack_Patterns: '492: '\n",
  "ID: '1334'\nName: Unauthorized Error Injection Can Degrade Hardware Redundancy\nDescription: An unauthorized agent can inject errors into a redundant block to deprive\n  the system of redundancy or put the system in a degraded operating mode.\nExtended_Description: To ensure the performance and functional reliability of certain\n  components, hardware designers can implement hardware blocks for redundancy in the\n  case that others fail. This redundant block can be prevented from performing as\n  intended if the design allows unauthorized agents to inject errors into it. In this\n  way, a path with injected errors may become unavailable to serve as a redundant\n  channel. This may put the system into a degraded mode of operation which could be\n  exploited by a subsequent attack.\nModes_Of_Introduction: 'Architecture and Design: Such issues could be introduced during\n  hardware architecture and design and identified later during Testing or System Configuration\n  phases.\n\n\n  Implementation: Such issues could be introduced during implementation and identified\n  later during Testing or System Configuration phases.\n\n\n  Integration: Such issues could be introduced during integration and identified later\n  during Testing or System Configuration phases.'\nPotential_Mitigations: 'Architecture and Design: Ensure the design does not allow\n  error injection in modes intended for normal run-time operation. Provide access\n  controls on interfaces for injecting errors.\n\n\n  Implementation: Disallow error injection in modes which are expected to be used\n  for normal run-time operation. Provide access controls on interfaces for injecting\n  errors.\n\n\n  Integration: Add an access control layer atop any unprotected interfaces for injecting\n  errors.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1335'\nName: Incorrect Bitwise Shift of Integer\nDescription: An integer value is specified to be shifted by a negative amount or an\n  amount greater than or equal to the number of bits contained in the value causing\n  an unexpected or indeterminate result.\nExtended_Description: 'Specifying a value to be shifted by a negative amount is undefined\n  in various languages. Various computer architectures implement this action in different\n  ways. The compilers and interpreters when generating code to accomplish a shift\n  generally do not do a check for this issue.\n\n  Specifying an over-shift, a shift greater than or equal to the number of bits contained\n  in a value to be shifted, produces a result which varies by architecture and compiler.\n  In some languages, this action is specifically listed as producing an undefined\n  result.'\nApplicable_Platforms:\n  Language: C, C++, C#, Java, JavaScript\nModes_Of_Introduction: 'Implementation: Adding shifts without properly verifying the\n  size and sign of the shift amount.'\nPotential_Mitigations: 'Implementation: Implicitly or explicitly add checks and mitigation\n  for negative or over-shift values.'\nObserved_Examples: 'CVE-2009-4307: An unexpected large value in the ext4 filesystem\n  causes an overshift condition resulting in a divide by zero.\n\n\n  CVE-2012-2100: An unexpected large value in the ext4 filesystem causes an overshift\n  condition resulting in a divide by zero - fix of CVE-2009-4307.\n\n\n  CVE-2020-8835: An overshift in a kernel allowed out of bounds reads and writes resulting\n  in a root takeover.\n\n\n  CVE-2015-1607: Program is not properly handling signed bitwise left-shifts causing\n  an overlapping memcpy memory range error.\n\n\n  CVE-2016-9842: Compression function improperly executes a signed left shift of a\n  negative integer.\n\n\n  CVE-2018-18445: Some kernels improperly handle right shifts of 32 bit numbers in\n  a 64 bit register.\n\n\n  CVE-2013-4206: Putty  has an incorrectly sized shift value resulting in an overshift.\n\n\n  CVE-2018-20788: LED driver overshifts under certain conditions resulting in a DoS.'\n",
  "ID: '1336'\nName: Improper Neutralization of Special Elements Used in a Template Engine\nDescription: The product uses a template engine to insert or process externally-influenced\n  input, but it does not neutralize or incorrectly neutralizes special elements or\n  syntax that can be interpreted as template expressions or other code directives\n  when processed by the engine.\nExtended_Description: 'Many web applications use template engines that allow developers\n  to insert externally-influenced values into free text or messages in order to generate\n  a full web page, document, message, etc. Such engines include Twig, Jinja2, Pug,\n  Java Server Pages, FreeMarker, Velocity, ColdFusion, Smarty, and many others - including\n  PHP itself. Some CMS (Content Management Systems) also use templates.\n\n  Template engines often have their own custom command or expression language. If\n  an attacker can influence input into a template before it is processed, then the\n  attacker can invoke arbitrary expressions, i.e. perform injection attacks. For example,\n  in some template languages, an attacker could inject the expression \"{{7*7}}\" and\n  determine if the output returns \"49\" instead. The syntax varies depending on the\n  language.\n\n  In some cases, XSS-style attacks can work, which can obscure the root cause if the\n  developer does not closely investigate the root cause of the error.\n\n  Template engines can be used on the server or client, so both \"sides\" could be affected\n  by injection. The mechanisms of attack or the affected technologies might be different,\n  but the mistake is fundamentally the same.'\nApplicable_Platforms:\n  Language: Java, PHP, Python, JavaScript, Interpreted\n  Technology: Client Server\nAlternate_Terms: 'Server-Side Template Injection / SSTI: This term is used for injection\n  into template engines being used by a server.\n\n\n  Client-Side Template Injection / CSTI: This term is used for injection into template\n  engines being used by a client.'\nModes_Of_Introduction: 'Architecture and Design: The developer might choose a template\n  engine that makes it easier for programmers to write vulnerable code.\n\n\n  Implementation: The programmer might not use engine''s built-in sandboxes or other\n  capabilities to escape or otherwise prevent template injection from untrusted input.'\nPotential_Mitigations: 'Architecture and Design: Choose a template engine that offers\n  a sandbox or restricted mode, or at least limits the power of any available expressions,\n  function calls, or commands.\n\n\n  Implementation: Use the template engine''s sandbox or restricted mode, if available.'\nObserved_Examples: 'CVE-2017-16783: server-side template injection in content management\n  server\n\n\n  CVE-2020-9437: authentication / identity management product has client-side template\n  injection\n\n\n  CVE-2020-12790: Server-Side Template Injection using a Twig template\n\n\n  CVE-2021-21244: devops platform allows SSTI\n\n\n  CVE-2020-4027: bypass of Server-Side Template Injection protection mechanism with\n  macros in Velocity templates\n\n\n  CVE-2020-26282: web browser proxy server allows Java EL expressions from Server-Side\n  Template Injection\n\n\n  CVE-2020-1961: SSTI involving mail templates and JEXL expressions\n\n\n  CVE-2019-19999: product does not use a \"safe\" setting for a FreeMarker configuration,\n  allowing SSTI\n\n\n  CVE-2018-20465: product allows read of sensitive database username/password variables\n  using server-side template injection'\n",
  "ID: '1338'\nName: Improper Protections Against Hardware Overheating\nDescription: A hardware device is missing or has inadequate protection features to\n  prevent overheating.\nExtended_Description: 'Hardware, electrical circuits, and semiconductor silicon have\n  thermal side effects, such that some of the energy consumed by the device gets dissipated\n  as heat and increases the temperature of the device. For example, in semiconductors,\n  higher-operating frequency of silicon results in higher power dissipation and heat.\n  The leakage current in CMOS circuits increases with temperature, and this creates\n  positive feedback that can result in thermal runaway and damage the device permanently.\n\n  Any device lacking protections such as thermal sensors, adequate platform cooling,\n  or thermal insulation is susceptible to attacks by malicious software that might\n  deliberately operate the device in modes that result in overheating. This can be\n  used as an effective denial of service (DoS) or permanent denial of service (PDoS)\n  attack.\n\n  Depending on the type of hardware device and its expected usage, such thermal overheating\n  can also cause safety hazards and reliability issues. Note that battery failures\n  can also cause device overheating but the mitigations and examples included in this\n  submission cannot reliably protect against a battery failure.\n\n  There can be similar weaknesses with lack of protection from attacks based on overvoltage\n  or overcurrent conditions. However, thermal heat is generated by hardware operation\n  and the device should implement protection from overheating.'\nApplicable_Platforms:\n  Technology: ICS/OT, Power Management Hardware, Processor Hardware\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: Such issues could\\\n  \\ be introduced during hardware architecture, design or implementation.\"\nDetection_Methods: 'Dynamic Analysis with Manual Results Interpretation: Dynamic tests\n  should be performed to stress-test temperature controls.\n\n\n  Architecture or Design Review: Power management controls should be part of Architecture\n  and Design reviews.'\nPotential_Mitigations: 'Architecture and Design: Temperature maximum and minimum limits\n  should be enforced using thermal sensors both in silicon and at the platform level.\n\n\n  Implementation: The platform should support cooling solutions such as fans that\n  can be modulated based on device-operation needs to maintain a stable temperature.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1339'\nName: Insufficient Precision or Accuracy of a Real Number\nDescription: The product processes a real number with an implementation in which the\n  number's representation does not preserve required accuracy and precision in its\n  fractional part, causing an incorrect result.\nExtended_Description: \"When a security decision or calculation requires highly precise,\\\n  \\ accurate numbers such as financial calculations or prices, then small variations\\\n  \\ in the number could be exploited by an attacker.\\nThere are multiple ways to store\\\n  \\ the fractional part of a real number in a computer. In all of these cases, there\\\n  \\ is a limit to the accuracy of recording a fraction. If the fraction can be represented\\\n  \\ in a fixed number of digits (binary or decimal), there might not be enough digits\\\n  \\ assigned to represent the number. In other cases the number cannot be represented\\\n  \\ in a fixed number of digits due to repeating in decimal or binary notation (e.g.\\\n  \\ 0.333333...) or due to a transcendental number such as \\u03A0 or \\u221A2. Rounding\\\n  \\ of numbers can lead to situations where the computer results do not adequately\\\n  \\ match the result of sufficiently accurate math.\"\nModes_Of_Introduction: 'Implementation: This weakness is introduced when the developer\n  picks a method to represent a real number. The weakness may only be visible with\n  very specific numeric inputs.'\nPotential_Mitigations: 'Implementation\n\n  Patching and Maintenance: The developer or maintainer can move to a more accurate\n  representation of real numbers.  In extreme cases, the programmer can move to representations\n  such as ratios of BigInts which can represent real numbers to extremely fine precision.\n  The programmer can also use the concept of an Unum real. The memory and CPU tradeoffs\n  of this change must be examined. Since floating point reals are used in many products\n  and many locations, they are implemented in hardware and most format changes will\n  cause the calculations to be moved into software resulting in slower products.'\nObserved_Examples: \"CVE-2018-16069: Chain: series of floating-point precision errors\\n\\\n  \\t\\t\\t(CWE-1339) in a web browser rendering engine causes out-of-bounds read\\n\\t\\\n  \\t\\t(CWE-125), giving access to cross-origin data\\n\\nCVE-2017-7619: Chain: rounding\\\n  \\ error in floating-point calculations\\n\\t\\t\\t(CWE-1339) in image processor leads\\\n  \\ to infinite loop (CWE-835)\\n\\nCVE-2021-29529: Chain: machine-learning product\\\n  \\ can have a heap-based\\n\\t\\t\\tbuffer overflow (CWE-122) when some integer-oriented\\\n  \\ bounds are\\n\\t\\t\\tcalculated by using ceiling() and floor() on floating point\\\n  \\ values\\n\\t\\t\\t(CWE-1339)\\n\\nCVE-2008-2108: Chain: insufficient precision (CWE-1339)\\\n  \\ in\\n\\t\\t\\trandom-number generator causes some zero bits to be reliably\\n\\t\\t\\t\\\n  generated, reducing the amount of entropy (CWE-331)\\n\\nCVE-2006-6499: Chain: web\\\n  \\ browser crashes due to infinite loop - \\\"bad\\n\\t\\t\\tlooping logic [that relies\\\n  \\ on] floating point math [CWE-1339] to exit\\n\\t\\t\\tthe loop [CWE-835]\\\"\"\n",
  "ID: '134'\nName: Use of Externally-Controlled Format String\nDescription: The product uses a function that accepts a format string as an argument,\n  but the format string originates from an external source.\nExtended_Description: 'When an attacker can modify an externally-controlled format\n  string, this can lead to buffer overflows, denial of service, or data representation\n  problems.\n\n  It should be noted that in some circumstances, such as internationalization, the\n  set of format strings is externally controlled by design. If the source of these\n  format strings is trusted (e.g. only contained in library files that are only modifiable\n  by the system administrator), then the external control might not itself pose a\n  vulnerability.'\nApplicable_Platforms:\n  Language: C, C++, Perl\nModes_Of_Introduction: 'Implementation: The programmer rarely intends for a format\n  string to be externally-controlled at all. This weakness is frequently introduced\n  in code that constructs log messages, where a constant format string is omitted.\n\n\n  Implementation: In cases such as localization and internationalization, the language-specific\n  message repositories could be an avenue for exploitation, but the format string\n  issue would be resultant, since attacker control of those repositories would also\n  allow modification of message length, format, and content.'\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n\n  Black Box: Since format strings often occur in rarely-occurring erroneous conditions\n  (e.g. for error message logging), they can be difficult to detect using black box\n  methods. It is highly likely that many latent issues exist in executables that do\n  not have associated source code (or equivalent source.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Requirements: Choose a language that is not subject to this\n  flaw.\n\n\n  Implementation: Ensure that all format string functions are passed a static string\n  which cannot be controlled by the user, and that the proper number of arguments\n  are always sent to that function as well. If at all possible, use functions that\n  do not support the %n operator in format strings. [REF-116] [REF-117]\n\n\n  Build and Compilation: Run compilers and linkers with high warning levels, since\n  they may detect incorrect usage.'\nObserved_Examples: 'CVE-2002-1825: format string in Perl program\n\n\n  CVE-2001-0717: format string in bad call to syslog function\n\n\n  CVE-2002-0573: format string in bad call to syslog function\n\n\n  CVE-2002-1788: format strings in NNTP server responses\n\n\n  CVE-2006-2480: Format string vulnerability exploited by triggering errors or warnings,\n  as demonstrated via format string specifiers in a .bmp filename.\n\n\n  CVE-2007-2027: Chain: untrusted search path enabling resultant format string by\n  loading malicious internationalization messages'\nRelated_Attack_Patterns: \"135: \\n\\n67: \"\n",
  "ID: '1341'\nName: Multiple Releases of Same Resource or Handle\nDescription: The product attempts to close or release a resource or handle more than\n  once, without any successful open between the close operations.\nExtended_Description: 'Code typically requires \"opening\" handles or references to\n  resources such as memory, files, devices, socket connections, services, etc. When\n  the code is finished with using the resource, it is typically expected to \"close\"\n  or \"release\" the resource, which indicates to the environment (such as the OS) that\n  the resource can be re-assigned or reused by unrelated processes or actors - or\n  in some cases, within the same process. API functions or other abstractions are\n  often used to perform this release, such as free() or delete() within C/C++, or\n  file-handle close() operations that are used in many languages.\n\n  Unfortunately, the implementation or design of such APIs might expect the developer\n  to be responsible for ensuring that such APIs are only called once per release of\n  the resource. If the developer attempts to release the same resource/handle more\n  than once, then the API''s expectations are not met, resulting in undefined and/or\n  insecure behavior. This could lead to consequences such as memory corruption, data\n  corruption, execution path corruption, or other consequences.\n\n  Note that while the implementation for most (if not all) resource reservation allocations\n  involve a unique identifier/pointer/symbolic reference, then if this identifier\n  is reused, checking the identifier for resource closure may result in a false state\n  of openness and closing of the wrong resource. For this reason, reuse of identifiers\n  is discouraged.'\nApplicable_Platforms:\n  Language: Java, Rust, C, C++\nDetection_Methods: 'Automated Static Analysis: For commonly-used APIs and resource\n  types, automated tools often have signatures that can spot this issue.\n\n\n  Automated Dynamic Analysis: Some compiler instrumentation tools such as AddressSanitizer\n  (ASan) can indirectly detect some instances of this weakness.'\nPotential_Mitigations: 'Implementation: Change the code''s logic so that the resource\n  is only closed once. This might require simplifying or refactoring. This fix can\n  be simple to do in small code blocks, but more difficult when multiple closes are\n  buried within complex conditionals.\n\n\n  Implementation: It can be effective to implement a flag that is (1) set when the\n  resource is opened, (2) cleared when it is closed, and (3) checked before closing.\n  This approach can be useful when there are disparate cases in which closes must\n  be performed. However, flag-tracking can increase code complexity and requires diligent\n  compliance by the programmer.\n\n\n  Implementation: When closing a resource, set the resource''s associated variable\n  to NULL or equivalent value for the given language. Some APIs will ignore this null\n  value without causing errors. For other APIs, this can lead to application crashes\n  or exceptions, which may still be preferable to corrupting an unintended resource\n  such as memory or data.'\nObserved_Examples: 'CVE-2019-13351: file descriptor double close can cause the wrong\n  file to be associated with a file descriptor.\n\n\n  CVE-2006-5051: Chain: Signal handler contains too much functionality (CWE-828),\n  introducing a race condition that leads to a double free (CWE-415).\n\n\n  CVE-2004-0772: Double free resultant from certain error conditions.'\n",
  "ID: '1342'\nName: Information Exposure through Microarchitectural State after Transient Execution\nDescription: The processor does not properly clear microarchitectural state after\n  incorrect microcode assists or speculative execution, resulting in transient execution.\nExtended_Description: 'In many processor architectures an exception, mis-speculation,\n  or microcode assist results in a flush operation to clear results that are no longer\n  required. This action prevents these results from influencing architectural state\n  that is intended to be visible from software. However, traces of this transient\n  execution may remain in microarchitectural buffers, resulting in a change in microarchitectural\n  state that can expose sensitive information to an attacker using side-channel analysis.\n  For example, Load Value Injection (LVI) [REF-1202] can exploit direct injection\n  of erroneous values into intermediate load and store buffers.\n\n  Several conditions may need to be fulfilled for a successful attack:'\nApplicable_Platforms:\n  Architecture: Workstation, x86, ARM, Other\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nRequirements: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Requirements: Hardware ensures that no illegal data flows from faulting micro-ops\n  exists at the microarchitectural level.\n\n\n  Build and Compilation: Include instructions that explicitly remove traces of unneeded\n  computations from software interactions with microarchitectural elements e.g. lfence,\n  sfence, mfence, clflush.'\nObserved_Examples: 'CVE-2020-0551: Load value injection in some processors utilizing\n  speculative execution may allow an authenticated user to enable information disclosure\n  via a side-channel with local access.'\nRelated_Attack_Patterns: '696: '\n",
  "ID: '135'\nName: Incorrect Calculation of Multi-Byte String Length\nDescription: The product does not correctly calculate the length of strings that can\n  contain wide or multi-byte characters.\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: 'Implementation: There are several ways in which improper string\n  length checking may result in an exploitable condition. All of these, however, involve\n  the introduction of buffer overflow conditions in order to reach an exploitable\n  state.\n\n  The first of these issues takes place when the output of a wide or multi-byte character\n  string, string-length function is used as a size for the allocation of memory. While\n  this will result in an output of the number of characters in the string, note that\n  the characters are most likely not a single byte, as they are with standard character\n  strings. So, using the size returned as the size sent to new or malloc and copying\n  the string to this newly allocated memory will result in a buffer overflow.\n\n  Another common way these strings are misused involves the mixing of standard string\n  and wide or multi-byte string functions on a single string. Invariably, this mismatched\n  information will result in the creation of a possibly exploitable buffer overflow\n  condition.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Always verify the length of the string unit\n  character.\n\n\n  Implementation: Use length computing functions (e.g. strlen, wcslen, etc.) appropriately\n  with their equivalent type (e.g.: byte, wchar_t, etc.)'\n",
  "ID: '1351'\nName: Improper Handling of Hardware Behavior in Exceptionally Cold Environments\nDescription: \"A hardware device, or the firmware running on it, is\\n             \\\n  \\   missing or has incorrect protection features to maintain\\n                goals\\\n  \\ of security primitives when the device is cooled below\\n                standard\\\n  \\ operating temperatures.\"\nExtended_Description: \"The hardware designer may improperly anticipate\\n         \\\n  \\           hardware behavior when exposed to exceptionally cold\\n             \\\n  \\       conditions. As a result they may introduce a weakness by not\\n         \\\n  \\           accounting for the modified behavior of critical components\\n      \\\n  \\              when in extreme environments.\\nAn example of a change in behavior\\\n  \\ is that power loss\\n                    won't clear/reset any volatile state when\\\n  \\ cooled below\\n                    standard operating temperatures. This may result\\\n  \\ in\\n                    a weakness when the starting state of the volatile memory\\\n  \\ is\\n                    being relied upon for a security decision. For example,\\\n  \\ a\\n                    Physical Unclonable Function (PUF) may be supplied as a\\n\\\n  \\                    security primitive to improve confidentiality,\\n          \\\n  \\          authenticity, and integrity guarantees. However, when the\\n         \\\n  \\           PUF is paired with DRAM, SRAM, or another temperature\\n            \\\n  \\        sensitive entropy source, the system designer may introduce\\n         \\\n  \\           weakness by failing to account for the chosen entropy\\n            \\\n  \\        source's behavior at exceptionally low temperatures. In the\\n         \\\n  \\           case of DRAM and SRAM, when power is cycled at low\\n               \\\n  \\     temperatures, the device will not contain the bitwise\\n                  \\\n  \\  biasing caused by inconsistencies in manufacturing and will\\n               \\\n  \\     instead contain the data from previous boot. Should the PUF\\n            \\\n  \\        primitive be used in a cryptographic construction which\\n             \\\n  \\       does not account for full adversary control of PUF seed\\n              \\\n  \\      data, weakness would arise.\\nThis weakness does not cover \\\"Cold Boot Attacks\\\"\\\n  \\n                    wherein RAM or other external storage is super cooled and\\n\\\n  \\                    read externally by an attacker.\"\nApplicable_Platforms:\n  Architecture: Embedded, Microcomputer\n  Technology: System on Chip\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: The system should account for security\n  primitive behavior when cooled outside standard temperatures.'\nRelated_Attack_Patterns: \"624: \\n\\n625: \"\n",
  "ID: '1357'\nName: Reliance on Insufficiently Trustworthy Component\nDescription: The product is built from multiple separate components, but it uses a\n  component that is not sufficiently trusted to meet expectations for security, reliability,\n  updateability, and maintainability.\nExtended_Description: 'Many modern hardware and software products are built by combining\n  multiple smaller components together into one larger entity, often during the design\n  or architecture phase. For example, a hardware component might be built by a separate\n  supplier, or the product might use an open-source software library from a third\n  party.\n\n  Regardless of the source, each component should be sufficiently trusted to ensure\n  correct, secure operation of the product. If a component is not trustworthy, it\n  can produce significant risks for the overall product, such as vulnerabilities that\n  cannot be patched fast enough (if at all); hidden functionality such as malware;\n  inability to update or replace the component if needed for security purposes; hardware\n  components built from parts that do not meet specifications in ways that can lead\n  to weaknesses; etc. Note that a component might not be trustworthy even if it is\n  owned by the product vendor, such as a software component whose source code is lost\n  and was built by developers who left the company, or a component that was developed\n  by a separate company that was acquired and brought into the product''s own company.\n\n  Note that there can be disagreement as to whether a component is sufficiently trustworthy,\n  since trust is ultimately subjective. Different stakeholders (e.g., customers, vendors,\n  governments) have various threat models and ways to assess trust, and design/architecture\n  choices might make tradeoffs between security, reliability, safety, privacy, cost,\n  and other characteristics.'\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Requirements: Requirements might include criteria for which\n  the only available solutions are provided by insufficiently trusted components.\n\n\n  Architecture and Design: An insufficiently trusted component might be selected because\n  it is less expensive to do in-house, requires expertise that is not available in-house,\n  or might allow the product to reach the market faster.'\nPotential_Mitigations: 'Requirements\n\n  Architecture and Design\n\n  Implementation: For each component, ensure that its supply chain is well-controlled\n  with sub-tier suppliers using best practices. For third-party software components\n  such as libraries, ensure that they are developed and actively maintained by reputable\n  vendors.\n\n\n  Architecture and Design\n\n  Implementation\n\n  Integration\n\n  Manufacturing: Maintain a Bill of Materials for all components and sub-components\n  of the product. For software, maintain a Software Bill of Materials (SBOM). According\n  to [REF-1247], \"An SBOM is a formal, machine-readable inventory of software components\n  and dependencies, information about those components, and their hierarchical relationships.\"\n\n\n  Operation\n\n  Patching and Maintenance: Continue to monitor changes in each of the product''s\n  components, especially when the changes indicate new vulnerabilities, end-of-life\n  (EOL) plans, supplier practices that affect trustworthiness, etc.'\nObserved_Examples: 'CVE-2020-9054: Chain: network-attached storage (NAS) device has\n  a critical OS command injection (CWE-78) vulnerability that is actively exploited\n  to place IoT devices into a botnet, but some products are \"end-of-support\" and cannot\n  be patched (CWE-1277). [REF-1097]'\n",
  "ID: '138'\nName: Improper Neutralization of Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as control elements or syntactic markers when they are sent to a downstream component.\nExtended_Description: Most languages and protocols have their own special elements\n  such as characters and reserved words. These special elements can carry control\n  implications. If product does not prevent external control or influence over the\n  inclusion of such special elements, the control flow of the program may be altered\n  from what was intended. For example, both Unix and Windows interpret the symbol\n  < (\"less than\") as meaning \"read input from a file\".\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Implementation: Developers should anticipate that special\n  elements (e.g. delimiters, symbols) will be injected into input vectors of their\n  product. One defense is to create an allowlist (e.g. a regular expression) that\n  defines valid input according to the requirements specifications. Strictly filter\n  any input that does not match against the allowlist. Properly encode your output,\n  and quote any elements that have special meaning to the component with which you\n  are communicating.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an appropriate output encoding to ensure that the\n  special elements are well-defined. A normal byte sequence in one encoding could\n  be a special element in another.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).'\nObserved_Examples: 'CVE-2001-0677: Read arbitrary files from mail client by providing\n  a special MIME header that is internally used to store pathnames for attachments.\n\n\n  CVE-2000-0703: Setuid program does not cleanse special escape sequence before sending\n  data to a mail program, causing the mail program to process those sequences.\n\n\n  CVE-2003-0020: Multi-channel issue. Terminal escape sequences not filtered from\n  log files.\n\n\n  CVE-2003-0083: Multi-channel issue. Terminal escape sequences not filtered from\n  log files.'\nRelated_Attack_Patterns: \"105: \\n\\n15: \\n\\n34: \"\n",
  "ID: '1384'\nName: Improper Handling of Physical or Environmental Conditions\nDescription: The product does not properly handle unexpected physical or environmental\n  conditions that occur naturally or are artificially induced.\nExtended_Description: 'Hardware products are typically only guaranteed to behave correctly\n  within certain physical limits or environmental conditions. Such products cannot\n  necessarily control the physical or external conditions to which they are subjected.\n  However, the inability to handle such conditions can undermine a product''s security.\n  For example, an unexpected physical or environmental condition may cause the flipping\n  of a bit that is used for an authentication decision. This unexpected condition\n  could occur naturally or be induced artificially by an adversary.\n\n  Physical or environmental conditions of concern are:'\nApplicable_Platforms:\n  Technology: System on Chip, ICS/OT\nModes_Of_Introduction: 'Architecture and Design: The product''s design might not consider\n  checking and handling extreme conditions.\n\n\n  Manufacturing: For hardware manufacturing, sub-par components might be chosen that\n  are not able to handle the expected environmental conditions.'\nPotential_Mitigations: 'Requirements: In requirements, be specific about expectations\n  for how the product will perform when it exceeds physical and environmental boundary\n  conditions, e.g., by shutting down.\n\n\n  Architecture and Design\n\n  Implementation: Where possible, include independent components that can detect excess\n  environmental conditions and have the capability to shut down the product.\n\n\n  Architecture and Design\n\n  Implementation: Where possible, use shielding or other materials that can increase\n  the adversary''s workload and reduce the likelihood of being able to successfully\n  trigger a security-related failure.'\n",
  "ID: '1385'\nName: Missing Origin Validation in WebSockets\nDescription: The product uses a WebSocket, but it does not properly verify that the\n  source of data or communication is valid.\nExtended_Description: 'WebSockets provide a bi-directional low latency communication\n  (near real-time) between a client and a server. WebSockets are different than HTTP\n  in that the connections are long-lived, as the channel will remain open until the\n  client or the server is ready to send the message, whereas in HTTP, once the response\n  occurs (which typically happens immediately), the transaction completes.\n\n  A WebSocket can leverage the existing HTTP protocol over ports 80 and 443, but it\n  is not limited to HTTP. WebSockets can make cross-origin requests that are not restricted\n  by browser-based protection mechanisms such as the Same Origin Policy (SOP) or Cross-Origin\n  Resource Sharing (CORS). Without explicit origin validation, this makes CSRF attacks\n  more powerful.'\nApplicable_Platforms:\n  Technology: Web Server\nAlternate_Terms: 'Cross-Site WebSocket hijacking (CSWSH): this term is used for attacks\n  that exploit this weakness'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Enable CORS-like access restrictions by verifying\n  the ''Origin'' header during the WebSocket handshake.\n\n\n  Implementation: Use a randomized CSRF token to verify requests.\n\n\n  Implementation: Use TLS to securely communicate using ''wss'' (WebSocket Secure)\n  instead of ''ws''.\n\n\n  Architecture and Design\n\n  Implementation: Require user authentication prior to the WebSocket connection being\n  established. For example, the WS library in Node has a ''verifyClient'' function.\n\n\n  Implementation: Leverage rate limiting to prevent against DoS. Use of the leaky\n  bucket algorithm can help with this.\n\n\n  Implementation: Use a library that provides restriction of the payload size. For\n  example, WS library for Node includes ''maxPayloadoption'' that can be set.\n\n\n  Implementation: Treat data/input as untrusted in both directions and apply the same\n  data/input sanitization as XSS, SQLi, etc.'\nObserved_Examples: 'CVE-2020-25095: web console for SIEM product does not check Origin\n  header, allowing Cross Site WebSocket Hijacking (CSWH)\n\n\n  CVE-2018-6651: Chain: gaming client attempts to validate the Origin header, but\n  only uses a substring, allowing Cross-Site WebSocket hijacking by forcing requests\n  from an origin whose hostname is a substring of the valid origin.\n\n\n  CVE-2018-14730: WebSocket server does not check the origin of requests, allowing\n  attackers to steal developer''s code using a ws://127.0.0.1:3123/ connection.\n\n\n  CVE-2018-14731: WebSocket server does not check the origin of requests, allowing\n  attackers to steal developer''s code using a ws://127.0.0.1/ connection to a randomized\n  port number.\n\n\n  CVE-2018-14732: WebSocket server does not check the origin of requests, allowing\n  attackers to steal developer''s code using a ws://127.0.0.1:8080/ connection.'\n",
  "ID: '1386'\nName: Insecure Operation on Windows Junction / Mount Point\nDescription: The product opens a file or directory, but it does not properly prevent\n  the name from being associated with a junction or mount point to a destination that\n  is outside of the intended control sphere.\nExtended_Description: \"Depending on the intended action\\n\\t\\t\\t  being performed,\\\n  \\ this could allow an\\n\\t\\t\\t  attacker to cause the product to read,\\n\\t\\t\\t  write,\\\n  \\ delete, or otherwise operate on\\n\\t\\t\\t  unauthorized files.\\nIn Windows, NTFS5\\\n  \\ allows for file\\n\\t\\t\\t  system objects called reparse points.\\n\\t\\t\\t  Applications\\\n  \\ can create a hard link from one\\n\\t\\t\\t  directory to another directory, called\\\n  \\ a\\n\\t\\t\\t  junction point. They can also create a\\n\\t\\t\\t  mapping from a directory\\\n  \\ to a drive letter,\\n\\t\\t\\t  called a mount point. If a file is used by a\\n\\t\\t\\\n  \\t  privileged program, but it can be replaced\\n\\t\\t\\t  with a hard link to a sensitive\\\n  \\ file (e.g.,\\n\\t\\t\\t  AUTOEXEC.BAT), an attacker could excalate\\n\\t\\t\\t  privileges.\\\n  \\ When the process opens the file,\\n\\t\\t\\t  the attacker can assume the privileges\\\n  \\ of\\n\\t\\t\\t  that process, tricking the privileged\\n\\t\\t\\t  process to read, modify,\\\n  \\ or delete the\\n\\t\\t\\t  sensitive file, preventing the program from\\n\\t\\t\\t  accurately\\\n  \\ processing data. Note that one\\n\\t\\t\\t  can also point to registries and\\n\\t\\t\\\n  \\t  semaphores.\"\nApplicable_Platforms:\n  Operating_System: Windows\nModes_Of_Introduction: 'Implementation: The developer might not consider that when\n  a program in Windows operates with different permissions than the executing user,\n  the use of links, mount points, and junctions might cause the program to access\n  files or directories that are outside of the intended storage location.'\nPotential_Mitigations: 'Architecture and Design: When designing software that will\n  have different rights than the executer, the software should check that files that\n  it is interacting with are not improper hard links or mount points.  One way to\n  do this in Windows is to use the functionality embedded in the following command:\n  \"dir /al /s /b\" or, in PowerShell, use LinkType as a filter. In addition, some software\n  uses authentication via signing to ensure that the file is the correct one to use.\n  Make checks atomic with the file action, otherwise a TOCTOU weakness (CWE-367) can\n  be introduced.'\nObserved_Examples: 'CVE-2021-26426: Privileged service allows attackers to delete\n  unauthorized files using a directory junction, leading to arbitrary code execution\n  as SYSTEM.\n\n\n  CVE-2020-0863: By creating a mount point and hard links, an attacker can abuse a\n  service to allow users arbitrary file read permissions.\n\n\n  CVE-2019-1161: Chain: race condition (CWE-362) in anti-malware product allows deletion\n  of files by creating a junction (CWE-1386) and using hard links during the time\n  window in which a temporary file is created and deleted.\n\n\n  CVE-2014-0568: Escape from sandbox for document reader by using a mountpoint [REF-1264]'\n",
  "ID: '1389'\nName: Incorrect Parsing of Numbers with Different Radices\nDescription: The product parses numeric input assuming base 10 (decimal) values, but\n  it does not account for inputs that use a different base number (radix).\nExtended_Description: 'Frequently, a numeric input that begins with \"0\" is treated\n  as octal, or \"0x\" causes it to be treated as hexadecimal, e.g. by the inet_addr()\n  function. For example, \"023\" (octal) is 35 decimal, or \"0x31\" is 49 decimal. Other\n  bases may be used as well. If the developer assumes decimal-only inputs, the code\n  could produce incorrect numbers when the inputs are parsed using a different base.\n  This can result in unexpected and/or dangerous behavior. For example, a \"0127.0.0.1\"\n  IP address is parsed as octal due to the leading \"0\", whose numeric value would\n  be the same as 87.0.0.1 (decimal), where the developer likely expected to use 127.0.0.1.\n\n  The consequences vary depending on the surrounding code in which this weakness occurs,\n  but they can include bypassing network-based access control using unexpected IP\n  addresses or netmasks, or causing apparently-symbolic identifiers to be processed\n  as if they are numbers. In web applications, this can enable bypassing of SSRF restrictions.'\nModes_Of_Introduction: 'Implementation: Input validation used may assume decimal bases\n  during conditional checks, when it may not always be the case.\n\n\n  Implementation: The application may rely on a service that supports different numerical\n  bases.'\nPotential_Mitigations: 'Implementation: If only decimal-based values are expected\n  in the application, conditional checks should be created in a way that prevent octal\n  or hexadecimal strings from being checked. This can be achieved by converting any\n  numerical string to an explicit base-10 integer prior to the conditional check,\n  to prevent octal or hex values from ever being checked against the condition.\n\n\n  Implementation: If various numerical bases do need to be supported, check for leading\n  values indicating the non-decimal base you wish to support (such as 0x for hex)\n  and convert the numeric strings to integers of the respective base. Reject any other\n  alternative-base string that is not intentionally supported by the application.\n\n\n  Implementation: If regular expressions are used to validate IP addresses, ensure\n  that they are bounded using ^ and $ to prevent base-prepended IP addresses from\n  being matched.'\nObserved_Examples: 'CVE-2021-29662: Chain: Use of zero-prepended IP addresses in Perl-based\n  IP validation module can lead to an access control bypass.\n\n\n  CVE-2021-28918: Chain: Use of zero-prepended IP addresses in a product that manages\n  IP blocks can lead to an SSRF.\n\n\n  CVE-2021-29921: Chain: Use of zero-prepended IP addresses in a Python standard library\n  package can lead to an SSRF.\n\n\n  CVE-2021-29923: Chain: Use of zero-prepended IP addresses in the net Golang library\n  can lead to an access control bypass.\n\n\n  CVE-2021-29424: Chain: Use of zero-prepended IP addresses in Perl netmask module\n  allows bypass of IP-based access control.\n\n\n  CVE-2016-4029: Chain: incorrect validation of intended decimal-based IP address\n  format (CWE-1286) enables parsing of octal or hexadecimal formats (CWE-1389), allowing\n  bypass of an SSRF protection mechanism (CWE-918).\n\n\n  CVE-2020-13776: Mishandling of hex-valued usernames leads to unexpected decimal\n  conversion and privilege escalation in the systemd Linux suite.'\n",
  "ID: '1390'\nName: Weak Authentication\nDescription: The product uses an authentication mechanism to restrict access to specific\n  users or identities, but the mechanism does not sufficiently prove that the claimed\n  identity is correct.\nExtended_Description: Attackers may be able to bypass weak authentication faster and/or\n  with less effort than expected.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2022-30034: Chain: Web UI for a Python RPC framework does\n  not use regex anchors to validate user login emails (CWE-777), potentially allowing\n  bypass of OAuth (CWE-1390).\n\n\n  CVE-2021-3116: Chain: Python-based HTTP Proxy server uses the wrong boolean operators\n  (CWE-480) causing an  incorrect comparison (CWE-697) that identifies an authN failure\n  if all three conditions are met instead of only one, allowing bypass of the proxy\n  authentication (CWE-1390)\n\n\n  CVE-2022-29965: Distributed Control System (DCS) uses a deterministic algorithm\n  to generate utility passwords\n\n\n  CVE-2022-29959: Initialization file contains  credentials that can be decoded using\n  a \"simple string transformation\"'\n",
  "ID: '1391'\nName: Use of Weak Credentials\nDescription: The product uses weak credentials (such as a default key or hard-coded\n  password) that can be calculated, derived, reused, or guessed by an attacker.\nExtended_Description: 'By design, authentication protocols try to ensure that attackers\n  must perform brute force attacks if they do not know the credentials such as a key\n  or password. However, when these credentials are easily predictable or even fixed\n  (as with default or hard-coded passwords and keys), then the attacker can defeat\n  the mechanism without relying on brute force.\n\n  Credentials may be weak for different reasons, such as:\n\n  Even if a new, unique credential is intended to be generated for each product installation,\n  if the generation is predictable, then that may also simplify guessing attacks.'\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Requirements: \\n\\nArchitecture and Design: \\n\\nInstallation:\\\n  \\ \\n\\nOperation: \"\nObserved_Examples: 'CVE-2022-30270: Remote Terminal Unit (RTU) uses default credentials\n  for some SSH accounts\n\n\n  CVE-2022-29965: Distributed Control System (DCS) uses a deterministic algorithm\n  to generate utility passwords\n\n\n  CVE-2022-30271: Remote Terminal Unit (RTU) uses a hard-coded SSH private key that\n  is likely to be used in typical deployments\n\n\n  CVE-2021-38759: microcontroller board has default password, allowing admin access\n\n\n  CVE-2021-41192: data visualization/sharing package uses default secret keys or cookie\n  values if they are not specified in environment variables\n\n\n  CVE-2020-27020: password manager does not generate cryptographically strong passwords,\n  allowing prediction of passwords using guessable details such as time of generation\n\n\n  CVE-2020-8632: password generator for cloud application has small length value,\n  making it easier for brute-force guessing\n\n\n  CVE-2020-5365: network-attached storage (NAS) system has predictable default passwords\n  for a diagnostics/support account\n\n\n  CVE-2020-5248: IT asset management app has a default encryption key that is the\n  same across installations\n\n\n  CVE-2012-3503: Installation script has a hard-coded secret token value, allowing\n  attackers to bypass authentication\n\n\n  CVE-2010-2306: Intrusion Detection System (IDS) uses the same static, private SSL\n  keys for multiple devices and installations, allowing decryption of SSL traffic\n\n\n  CVE-2001-0618: Residential gateway uses the last 5 digits of the ''Network Name''\n  or SSID as the default WEP key, which allows attackers to get the key by sniffing\n  the SSID, which is sent in the clear'\n",
  "ID: '1392'\nName: Use of Default Credentials\nDescription: The product uses default credentials (such as passwords or cryptographic\n  keys) for potentially critical functionality.\nExtended_Description: \"It is common practice for products to be designed to use\\n\\t\\\n  default keys, passwords, or other mechanisms for\\n\\tauthentication.  The rationale\\\n  \\ is to simplify the\\n\\tmanufacturing process or the system administrator's task\\\n  \\ of\\n\\tinstallation and deployment into an enterprise. However, if\\n\\tadmins do\\\n  \\ not change the defaults, it is easier for attackers\\n\\tto bypass authentication\\\n  \\ quickly across multiple\\n\\torganizations.\"\nApplicable_Platforms:\n  Technology: ICS/OT\nPotential_Mitigations: 'Requirements: Prohibit use of default, hard-coded, or other\n  values that do not vary for each installation of the product - especially for separate\n  organizations.\n\n\n  Architecture and Design: Force the administrator to change the credential upon installation.\n\n\n  Installation, Operation: The product administrator could change the defaults upon\n  installation or during operation.'\nObserved_Examples: 'CVE-2022-30270: Remote Terminal Unit (RTU) uses default credentials\n  for some SSH accounts\n\n\n  CVE-2021-41192: data visualization/sharing package uses default secret keys or cookie\n  values if they are not specified in environment variables\n\n\n  CVE-2021-38759: microcontroller board has default password\n\n\n  CVE-2010-2306: Intrusion Detection System (IDS) uses the same static, private SSL\n  keys for multiple devices and installations, allowing decryption of SSL traffic'\n",
  "ID: '1393'\nName: Use of Default Password\nDescription: The product uses default passwords for potentially critical functionality.\nExtended_Description: \"It is common practice for products to be designed to use\\n\\t\\\n  default passwords for authentication.  The rationale is to\\n\\tsimplify the manufacturing\\\n  \\ process or the system\\n\\tadministrator's task of installation and deployment into\\\n  \\ an\\n\\tenterprise. However, if admins do not change the defaults,\\n\\tthen it makes\\\n  \\ it easier for attackers to quickly bypass\\n\\tauthentication across multiple organizations.\\\n  \\ There are many\\n\\tlists of default passwords and default-password scanning tools\\n\\\n  \\tthat are easily available from the World Wide Web.\"\nApplicable_Platforms:\n  Technology: ICS/OT\nPotential_Mitigations: 'Requirements: Prohibit use of default, hard-coded, or other\n  values that do not vary for each installation of the product - especially for separate\n  organizations.\n\n\n  Documentation: Ensure that product documentation clearly emphasizes the presence\n  of default passwords and provides steps for the administrator to change them.\n\n\n  Architecture and Design: Force the administrator to change the credential upon installation.\n\n\n  Installation, Operation: The product administrator could change the defaults upon\n  installation or during operation.'\nObserved_Examples: 'CVE-2022-30270: Remote Terminal Unit (RTU) uses default credentials\n  for some SSH accounts\n\n\n  CVE-2022-2336: OPC Unified Architecture (OPC UA) industrial automation product has\n  a default password\n\n\n  CVE-2021-38759: microcontroller board has default password\n\n\n  CVE-2021-44480: children''s smart watch has default passwords allowing attackers\n  to send SMS commands and listen to the device''s surroundings\n\n\n  CVE-2020-11624: surveillance camera has default password for the admin account\n\n\n  CVE-2018-15719: medical dental records product installs a MySQL database with a\n  blank default password\n\n\n  CVE-2014-9736: healthcare system for archiving patient images has default passwords\n  for key management and storage databases\n\n\n  CVE-2000-1209: database product installs admin account with default null password,\n  allowing privileges, as exploited by various worms'\n",
  "ID: '1394'\nName: Use of Default Cryptographic Key\nDescription: The product uses a default cryptographic key for potentially critical\n  functionality.\nExtended_Description: \"It is common practice for products to be designed to use\\n\\t\\\n  default keys.  The rationale is to simplify the manufacturing\\n\\tprocess or the\\\n  \\ system administrator's task of installation and\\n\\tdeployment into an enterprise.\\\n  \\ However, if admins do not\\n\\tchange the defaults, it is easier for attackers to\\\n  \\ bypass\\n\\tauthentication quickly across multiple organizations.\"\nPotential_Mitigations: 'Requirements: Prohibit use of default, hard-coded, or other\n  values that do not vary for each installation of the product - especially for separate\n  organizations.\n\n\n  Architecture and Design: Force the administrator to change the credential upon installation.\n\n\n  Installation, Operation: The product administrator could change the defaults upon\n  installation or during operation.'\nObserved_Examples: 'CVE-2018-3825: cloud cluster management product has a default\n  master encryption key\n\n\n  CVE-2016-1561: backup storage product has a default SSH public key in the authorized_keys\n  file, allowing root access\n\n\n  CVE-2010-2306: Intrusion Detection System (IDS) uses the same static, private SSL\n  keys for multiple devices and installations, allowing decryption of SSL traffic'\n",
  "ID: '1395'\nName: Dependency on Vulnerable Third-Party Component\nDescription: The product has a dependency on a third-party component that contains\n  one or more known vulnerabilities.\nExtended_Description: Many products are large enough or complex enough that part of\n  their functionality uses libraries, modules, or other intellectual property developed\n  by third parties who are not the product creator. For example, even an entire operating\n  system might be from a third-party supplier in some hardware products. Whether open\n  or closed source, these components may contain publicly known vulnerabilities that\n  could be exploited by adversaries to compromise the product.\nModes_Of_Introduction: 'Architecture and Design: The product architect or designer\n  might choose a component that is already known to contain vulnerabilities or has\n  a high likelihood of containing vulnerabilities in the future.\n\n\n  Implementation: For reasons of compatibility or stability, developers might choose\n  a third-party component, such as a library, that is already known to contain vulnerabilities.\n\n\n  Patching and Maintenance: Since all products contain vulnerabilities, over time,\n  a third-party component will be discovered to have a vulnerability.'\nDetection_Methods: 'Automated Analysis: For software, use Software Composition Analysis\n  (SCA) tools, which automatically analyze products to identify third-party dependencies.\n  Often, SCA tools can be used to link with known vulnerabilities in the dependencies\n  that they detect. There are commercial and open-source alternatives, such as OWASP\n  Dependency-Check [REF-1312]. Many languages or frameworks have package managers\n  with similar capabilities, such as npm audit for JavaScript, pip-audit for Python,\n  govulncheck for Go, and many others. Dynamic methods can detect loading of third-party\n  components.\n\n  Software Composition Analysis (SCA) tools face a number of technical challenges\n  that can lead to false positives and false negatives. Dynamic methods have other\n  technical challenges.'\nPotential_Mitigations: 'Requirements, Policy: In some industries such as healthcare\n  [REF-1320] [REF-1322] or technologies such as the cloud [REF-1321], it might be\n  unclear about who is responsible for applying patches for third-party vulnerabilities:\n  the vendor, the operator/customer, or a separate service. Clarifying roles and responsibilities\n  can be important to minimize confusion or unnecessary delay when third-party vulnerabilities\n  are disclosed.\n\n\n  Requirements: Require a Bill of Materials for all components and sub-components\n  of the product. For software, require a Software Bill of Materials (SBOM) [REF-1247]\n  [REF-1311].\n\n\n  Architecture and Design\n\n  Implementation\n\n  Integration\n\n  Manufacturing: Maintain a Bill of Materials for all components and sub-components\n  of the product. For software, maintain a Software Bill of Materials (SBOM). According\n  to [REF-1247], \"An SBOM is a formal, machine-readable inventory of software components\n  and dependencies, information about those components, and their hierarchical relationships.\"\n\n\n  Operation\n\n  Patching and Maintenance: Actively monitor when a third-party component vendor announces\n  vulnerability patches; fix the third-party component as soon as possible; and make\n  it easy for operators/customers to obtain and apply the patch.\n\n\n  Operation\n\n  Patching and Maintenance: Continuously monitor changes in each of the product''s\n  components, especially when the changes indicate new vulnerabilities, end-of-life\n  (EOL) plans, etc.'\n",
  "ID: '14'\nName: Compiler Removal of Code to Clear Buffers\nDescription: Sensitive memory is cleared according to the source code, but compiler\n  optimizations leave the memory untouched when it is not read from again, aka \"dead\n  store removal.\"\nExtended_Description: 'This compiler optimization error occurs when:'\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: \"Implementation: \\n\\nBuild and Compilation: \"\nDetection_Methods: 'Black Box: This specific weakness is impossible to detect using\n  black box methods. While an analyst could examine memory to see that it has not\n  been scrubbed, an analysis of the executable would not be successful. This is because\n  the compiler has already removed the relevant code. Only the source code shows whether\n  the programmer intended to clear the memory or not, so this weakness is indistinguishable\n  from others.\n\n\n  White Box: This weakness is only detectable using white box methods (see black box\n  detection factor). Careful analysis is required to determine if the code is likely\n  to be removed by the compiler.'\nPotential_Mitigations: 'Implementation: Store the sensitive data in a \"volatile\" memory\n  location if available.\n\n\n  Build and Compilation: If possible, configure your compiler so that it does not\n  remove dead stores.\n\n\n  Architecture and Design: Where possible, encrypt sensitive data that are used by\n  a software system.'\n",
  "ID: '140'\nName: Improper Neutralization of Delimiters\nDescription: The product does not neutralize or incorrectly neutralizes delimiters.\nPotential_Mitigations: 'Implementation: Developers should anticipate that delimiters\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nRelated_Attack_Patterns: '15: '\n",
  "ID: '141'\nName: Improper Neutralization of Parameter/Argument Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as parameter or argument delimiters when they are sent to a downstream component.\nExtended_Description: As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that parameter/argument delimiters\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2003-0307: Attacker inserts field separator into input to\n  specify admin privileges.'\n",
  "ID: '142'\nName: Improper Neutralization of Value Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as value delimiters when they are sent to a downstream component.\nExtended_Description: As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that value delimiters will be\n  injected/removed/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0293: Multiple internal space, insufficient quoting -\n  program does not use proper delimiter between values.'\n",
  "ID: '143'\nName: Improper Neutralization of Record Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as record delimiters when they are sent to a downstream component.\nExtended_Description: As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that record delimiters will be\n  injected/removed/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2004-1982: Carriage returns in subject field allow adding\n  new records to data file.\n\n\n  CVE-2001-0527: Attacker inserts carriage returns and \"|\" field separator characters\n  to add new user/privileges.'\n",
  "ID: '144'\nName: Improper Neutralization of Line Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as line delimiters when they are sent to a downstream component.\nExtended_Description: As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that line delimiters will be\n  injected/removed/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0267: Linebreak in field of PHP script allows admin privileges\n  when written to data file.'\n",
  "ID: '145'\nName: Improper Neutralization of Section Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as section delimiters when they are sent to a downstream component.\nExtended_Description: 'As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\n\n  One example of a section delimiter is the boundary string in a multipart MIME message.\n  In many cases, doubled line delimiters can serve as a section delimiter.'\nPotential_Mitigations: 'Developers should anticipate that section delimiters will\n  be injected/removed/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '146'\nName: Improper Neutralization of Expression/Command Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as expression or command delimiters when they are sent to a downstream component.\nExtended_Description: As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that inter-expression and inter-command\n  delimiters will be injected/removed/manipulated in the input vectors of their product.\n  Use an appropriate combination of denylists and allowlists to ensure only valid,\n  expected and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nRelated_Attack_Patterns: \"15: \\n\\n6: \"\n",
  "ID: '147'\nName: Improper Neutralization of Input Terminators\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as input terminators when they are sent to a downstream component.\nExtended_Description: For example, a \".\" in SMTP signifies the end of mail message\n  data, whereas a null character can be used for the end of a string.\nPotential_Mitigations: 'Developers should anticipate that terminators will be injected/removed/manipulated\n  in the input vectors of their product. Use an appropriate combination of denylists\n  and allowlists to ensure only valid, expected and appropriate input is processed\n  by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0319: MFV. mail server does not properly identify terminator\n  string to signify end of message, causing corruption, possibly in conjunction with\n  off-by-one error.\n\n\n  CVE-2000-0320: MFV. mail server does not properly identify terminator string to\n  signify end of message, causing corruption, possibly in conjunction with off-by-one\n  error.\n\n\n  CVE-2001-0996: Mail server does not quote end-of-input terminator if it appears\n  in the middle of a message.\n\n\n  CVE-2002-0001: Improperly terminated comment or phrase allows commands.'\nRelated_Attack_Patterns: '460: '\n",
  "ID: '148'\nName: Improper Neutralization of Input Leaders\nDescription: The product does not properly handle when a leading character or sequence\n  (\"leader\") is missing or malformed, or if multiple leaders are used when only one\n  should be allowed.\nPotential_Mitigations: 'Developers should anticipate that leading characters will\n  be injected/removed/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '149'\nName: Improper Neutralization of Quoting Syntax\nDescription: Quotes injected into a product can be used to compromise a system. As\n  data are parsed, an injected/absent/duplicate/malformed use of quotes may cause\n  the process to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that quotes will be injected/removed/manipulated\n  in the input vectors of their product. Use an appropriate combination of denylists\n  and allowlists to ensure only valid, expected and appropriate input is processed\n  by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2004-0956: Database allows remote attackers to cause a denial\n  of service (application crash) via a MATCH AGAINST query with an opening double\n  quote but no closing double quote.\n\n\n  CVE-2003-1016: MIE. MFV too? bypass AV/security with fields that should not be quoted,\n  duplicate quotes, missing leading/trailing quotes.'\nRelated_Attack_Patterns: '468: '\n",
  "ID: '15'\nName: External Control of System or Configuration Setting\nDescription: One or more system settings or configuration elements can be externally\n  controlled by a user.\nExtended_Description: Allowing external control of system settings can disrupt service\n  or cause an application to behave in unexpected, and potentially malicious ways.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Implementation: Setting manipulation vulnerabilities occur\n  when an attacker can control values that govern the behavior of the system, manage\n  specific resources, or in some way affect the functionality of the application.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation\n\n  Architecture and Design: Because setting manipulation covers a diverse set of functions,\n  any attempt at illustrating it will inevitably be incomplete. Rather than searching\n  for a tight-knit relationship between the functions addressed in the setting manipulation\n  category, take a step back and consider the sorts of system values that an attacker\n  should not be allowed to control.\n\n\n  Implementation\n\n  Architecture and Design: In general, do not allow user-provided or otherwise untrusted\n  data to control sensitive values. The leverage that an attacker gains by controlling\n  these values is not always immediately obvious, but do not underestimate the creativity\n  of the attacker.'\nRelated_Attack_Patterns: \"13: \\n\\n146: \\n\\n176: \\n\\n203: \\n\\n270: \\n\\n271: \\n\\n579:\\\n  \\ \\n\\n69: \\n\\n76: \\n\\n77: \"\n",
  "ID: '150'\nName: Improper Neutralization of Escape, Meta, or Control Sequences\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as escape, meta, or control character sequences when they are sent to a downstream\n  component.\nExtended_Description: As data is parsed, an injected/absent/malformed delimiter may\n  cause the process to take unexpected actions.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Developers should anticipate that escape, meta and control\n  characters/sequences will be injected/removed/manipulated in the input vectors of\n  their product. Use an appropriate combination of denylists and allowlists to ensure\n  only valid, expected and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0542: The mail program processes special \"~\" escape sequence\n  even when not in interactive mode.\n\n\n  CVE-2000-0703: Setuid program does not filter escape sequences before calling mail\n  program.\n\n\n  CVE-2002-0986: Mail function does not filter control characters from arguments,\n  allowing mail message content to be modified.\n\n\n  CVE-2003-0020: Multi-channel issue. Terminal escape sequences not filtered from\n  log files.\n\n\n  CVE-2003-0083: Multi-channel issue. Terminal escape sequences not filtered from\n  log files.\n\n\n  CVE-2003-0021: Terminal escape sequences not filtered by terminals when displaying\n  files.\n\n\n  CVE-2003-0022: Terminal escape sequences not filtered by terminals when displaying\n  files.\n\n\n  CVE-2003-0023: Terminal escape sequences not filtered by terminals when displaying\n  files.\n\n\n  CVE-2003-0063: Terminal escape sequences not filtered by terminals when displaying\n  files.\n\n\n  CVE-2000-0476: Terminal escape sequences not filtered by terminals when displaying\n  files.\n\n\n  CVE-2001-1556: MFV. (multi-channel). Injection of control characters into log files\n  that allow information hiding when using raw Unix programs to read the files.'\nRelated_Attack_Patterns: \"134: \\n\\n41: \\n\\n81: \\n\\n93: \"\n",
  "ID: '151'\nName: Improper Neutralization of Comment Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as comment delimiters when they are sent to a downstream component.\nPotential_Mitigations: 'Developers should anticipate that comments will be injected/removed/manipulated\n  in the input vectors of their product. Use an appropriate combination of denylists\n  and allowlists to ensure only valid, expected and appropriate input is processed\n  by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0001: Mail client command execution due to improperly\n  terminated comment in address list.\n\n\n  CVE-2004-0162: MIE. RFC822 comment fields may be processed as other fields by clients.\n\n\n  CVE-2004-1686: Well-placed comment bypasses security warning.\n\n\n  CVE-2005-1909: Information hiding using a manipulation involving injection of comment\n  code into product. Note: these vulnerabilities are likely vulnerable to more general\n  XSS problems, although a regexp might allow \">!--\" while denying most other tags.\n\n\n  CVE-2005-1969: Information hiding using a manipulation involving injection of comment\n  code into product. Note: these vulnerabilities are likely vulnerable to more general\n  XSS problems, although a regexp might allow \"<!--\" while denying most other tags.'\n",
  "ID: '152'\nName: Improper Neutralization of Macro Symbols\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as macro symbols when they are sent to a downstream component.\nPotential_Mitigations: 'Implementation: Developers should anticipate that macro symbols\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0770: Server trusts client to expand macros, allows macro\n  characters to be expanded to trigger resultant information exposure.\n\n\n  CVE-2008-2018: Attacker can obtain sensitive information from a database by using\n  a comment containing a macro, which inserts the data during expansion.'\n",
  "ID: '153'\nName: Improper Neutralization of Substitution Characters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as substitution characters when they are sent to a downstream component.\nPotential_Mitigations: 'Developers should anticipate that substitution characters\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0770: Server trusts client to expand macros, allows macro\n  characters to be expanded to trigger resultant information exposure.'\n",
  "ID: '154'\nName: Improper Neutralization of Variable Name Delimiters\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as variable name delimiters when they are sent to a downstream component.\nExtended_Description: 'As data is parsed, an injected delimiter may cause the process\n  to take unexpected actions that result in an attack. Example: \"$\" for an environment\n  variable.'\nPotential_Mitigations: 'Developers should anticipate that variable name delimiters\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2005-0129: \"%\" variable is expanded by wildcard function into\n  disallowed commands.\n\n\n  CVE-2002-0770: Server trusts client to expand macros, allows macro characters to\n  be expanded to trigger resultant information exposure.'\nRelated_Attack_Patterns: '15: '\n",
  "ID: '155'\nName: Improper Neutralization of Wildcards or Matching Symbols\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as wildcards or matching symbols when they are sent to a downstream component.\nExtended_Description: As data is parsed, an injected element may cause the process\n  to take unexpected actions.\nPotential_Mitigations: 'Developers should anticipate that wildcard or matching elements\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0433: Bypass file restrictions using wildcard character.\n\n\n  CVE-2002-1010: Bypass file restrictions using wildcard character.\n\n\n  CVE-2001-0334: Wildcards generate long string on expansion.\n\n\n  CVE-2004-1962: SQL injection involving \"/**/\" sequences.'\n",
  "ID: '156'\nName: Improper Neutralization of Whitespace\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special elements that could be interpreted\n  as whitespace when they are sent to a downstream component.\nExtended_Description: This can include space, tab, etc.\nPotential_Mitigations: 'Developers should anticipate that whitespace will be injected/removed/manipulated\n  in the input vectors of their product. Use an appropriate combination of denylists\n  and allowlists to ensure only valid, expected and appropriate input is processed\n  by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0637: MIE. virus protection bypass with RFC violations\n  involving extra whitespace, or missing whitespace.\n\n\n  CVE-2004-0942: CPU consumption with MIME headers containing lines with many space\n  characters, probably due to algorithmic complexity (RESOURCE.AMP.ALG).\n\n\n  CVE-2003-1015: MIE. whitespace interpreted differently by mail clients.'\n",
  "ID: '157'\nName: Failure to Sanitize Paired Delimiters\nDescription: The product does not properly handle the characters that are used to\n  mark the beginning and ending of a group of entities, such as parentheses, brackets,\n  and braces.\nExtended_Description: 'Paired delimiters might include:'\nPotential_Mitigations: 'Developers should anticipate that grouping elements will be\n  injected/removed/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2004-0956: Crash via missing paired delimiter (open double-quote\n  but no closing double-quote).\n\n\n  CVE-2000-1165: Crash via message without closing \">\".\n\n\n  CVE-2005-2933: Buffer overflow via mailbox name with an opening double quote but\n  missing a closing double quote, causing a larger copy than expected.'\nRelated_Attack_Patterns: '15: '\n",
  "ID: '158'\nName: Improper Neutralization of Null Byte or NUL Character\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes NUL characters or null bytes when they are\n  sent to a downstream component.\nExtended_Description: As data is parsed, an injected NUL character or null byte may\n  cause the product to believe the input is terminated earlier than it actually is,\n  or otherwise cause the input to be misinterpreted. This could then be used to inject\n  potentially dangerous input that occurs after the null byte or otherwise bypass\n  validation routines and other protection mechanisms.\nPotential_Mitigations: 'Developers should anticipate that null characters or null\n  bytes will be injected/removed/manipulated in the input vectors of their product.\n  Use an appropriate combination of denylists and allowlists to ensure only valid,\n  expected and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2008-1284: NUL byte in theme name causes directory traversal\n  impact to be worse\n\n\n  CVE-2005-2008: Source code disclosure using trailing null.\n\n\n  CVE-2005-3293: Source code disclosure using trailing null.\n\n\n  CVE-2005-2061: Trailing null allows file include.\n\n\n  CVE-2002-1774: Null character in MIME header allows detection bypass.\n\n\n  CVE-2000-0149: Web server allows remote attackers to view the source code for CGI\n  programs via a null character (%00) at the end of a URL.\n\n\n  CVE-2000-0671: Web server earlier allows allows remote attackers to bypass access\n  restrictions, list directory contents, and read source code by inserting a null\n  character (%00) in the URL.\n\n\n  CVE-2001-0738: Logging system allows an attacker to cause a denial of service (hang)\n  by causing null bytes to be placed in log messages.\n\n\n  CVE-2001-1140: Web server allows source code for executable programs to be read\n  via a null character (%00) at the end of a request.\n\n\n  CVE-2002-1031: Protection mechanism for limiting file access can be bypassed using\n  a null character (%00) at the end of the directory name.\n\n\n  CVE-2002-1025: Application server allows remote attackers to read JSP source code\n  via an encoded null byte in an HTTP GET request, which causes the server to send\n  the .JSP file unparsed.\n\n\n  CVE-2003-0768: XSS protection mechanism only checks for sequences with an alphabetical\n  character following a (<), so a non-alphabetical or null character (%00) following\n  a < may be processed.\n\n\n  CVE-2004-0189: Decoding function in proxy allows regular expression bypass in ACLs\n  via URLs with null characters.\n\n\n  CVE-2005-3153: Null byte bypasses PHP regexp check (interaction error).\n\n\n  CVE-2005-4155: Null byte bypasses PHP regexp check (interaction error).'\nRelated_Attack_Patterns: \"52: \\n\\n53: \"\n",
  "ID: '159'\nName: Improper Handling of Invalid Use of Special Elements\nDescription: The product does not properly filter, remove, quote, or otherwise manage\n  the invalid use of special elements in user-controlled input, which could cause\n  adverse effect on its behavior and integrity.\nPotential_Mitigations: 'Developers should anticipate that special elements will be\n  injected/removed/manipulated in the input vectors of their software system. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '160'\nName: Improper Neutralization of Leading Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes leading special elements that could be interpreted\n  in unexpected ways when they are sent to a downstream component.\nExtended_Description: As data is parsed, improperly handled leading special elements\n  may cause the process to take unexpected actions that result in an attack.\nPotential_Mitigations: 'Developers should anticipate that leading special elements\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '161'\nName: Improper Neutralization of Multiple Leading Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes multiple leading special elements that could\n  be interpreted in unexpected ways when they are sent to a downstream component.\nExtended_Description: As data is parsed, improperly handled multiple leading special\n  elements may cause the process to take unexpected actions that result in an attack.\nPotential_Mitigations: 'Developers should anticipate that multiple leading special\n  elements will be injected/removed/manipulated in the input vectors of their product.\n  Use an appropriate combination of denylists and allowlists to ensure only valid,\n  expected and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '162'\nName: Improper Neutralization of Trailing Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes trailing special elements that could be interpreted\n  in unexpected ways when they are sent to a downstream component.\nExtended_Description: As data is parsed, improperly handled trailing special elements\n  may cause the process to take unexpected actions that result in an attack.\nPotential_Mitigations: 'Developers should anticipate that trailing special elements\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nRelated_Attack_Patterns: '635: '\n",
  "ID: '163'\nName: Improper Neutralization of Multiple Trailing Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes multiple trailing special elements that could\n  be interpreted in unexpected ways when they are sent to a downstream component.\nExtended_Description: As data is parsed, improperly handled multiple trailing special\n  elements may cause the process to take unexpected actions that result in an attack.\nPotential_Mitigations: 'Developers should anticipate that multiple trailing special\n  elements will be injected/removed/manipulated in the input vectors of their product.\n  Use an appropriate combination of denylists and allowlists to ensure only valid,\n  expected and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '164'\nName: Improper Neutralization of Internal Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes internal special elements that could be interpreted\n  in unexpected ways when they are sent to a downstream component.\nExtended_Description: As data is parsed, improperly handled internal special elements\n  may cause the process to take unexpected actions that result in an attack.\nPotential_Mitigations: 'Developers should anticipate that internal special elements\n  will be injected/removed/manipulated in the input vectors of their product. Use\n  an appropriate combination of denylists and allowlists to ensure only valid, expected\n  and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '165'\nName: Improper Neutralization of Multiple Internal Special Elements\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes multiple internal special elements that could\n  be interpreted in unexpected ways when they are sent to a downstream component.\nExtended_Description: As data is parsed, improperly handled multiple internal special\n  elements may cause the process to take unexpected actions that result in an attack.\nPotential_Mitigations: 'Developers should anticipate that multiple internal special\n  elements will be injected/removed/manipulated in the input vectors of their product.\n  Use an appropriate combination of denylists and allowlists to ensure only valid,\n  expected and appropriate input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '166'\nName: Improper Handling of Missing Special Element\nDescription: The product receives input from an upstream component, but it does not\n  handle or incorrectly handles when an expected special element is missing.\nPotential_Mitigations: 'Developers should anticipate that special elements will be\n  removed in the input vectors of their product. Use an appropriate combination of\n  denylists and allowlists to ensure only valid, expected and appropriate input is\n  processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-1362: Crash via message type without separator character\n\n\n  CVE-2002-0729: Missing special character (separator) causes crash\n\n\n  CVE-2002-1532: HTTP GET without \\r\\n\\r\\n CRLF sequences causes product to wait indefinitely\n  and prevents other users from accessing it'\n",
  "ID: '167'\nName: Improper Handling of Additional Special Element\nDescription: The product receives input from an upstream component, but it does not\n  handle or incorrectly handles when an additional unexpected special element is provided.\nPotential_Mitigations: 'Developers should anticipate that extra special elements will\n  be injected in the input vectors of their product. Use an appropriate combination\n  of denylists and allowlists to ensure only valid, expected and appropriate input\n  is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0116: Extra \"<\" in front of SCRIPT tag.\n\n\n  CVE-2001-1157: Extra \"<\" in front of SCRIPT tag.\n\n\n  CVE-2002-2086: \"<script\" - probably a cleansing error'\n",
  "ID: '168'\nName: Improper Handling of Inconsistent Special Elements\nDescription: The product does not properly handle input in which an inconsistency\n  exists between two or more special characters or reserved words.\nExtended_Description: An example of this problem would be if paired characters appear\n  in the wrong order, or if the special characters are not properly nested.\nPotential_Mitigations: 'Developers should anticipate that inconsistent special elements\n  will be injected/manipulated in the input vectors of their product. Use an appropriate\n  combination of denylists and allowlists to ensure only valid, expected and appropriate\n  input is processed by the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '170'\nName: Improper Null Termination\nDescription: The product does not terminate or incorrectly terminates a string or\n  array with a null character or equivalent terminator.\nExtended_Description: Null termination errors frequently occur in two different ways.\n  An off-by-one error could cause a null to be written out of bounds, leading to an\n  overflow. Or, a program could use a strncpy() function call incorrectly, which prevents\n  a null terminator from being added at all. Other scenarios are possible.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Use a language that is not susceptible to these\n  issues. However, be careful of null byte interaction errors (CWE-626) with lower-level\n  constructs that may be written in a language that is susceptible.\n\n\n  Implementation: Ensure that all string functions used are understood fully as to\n  how they append null characters. Also, be wary of off-by-one errors when appending\n  nulls to the end of strings.\n\n\n  Implementation: If performance constraints permit, special code can be added that\n  validates null-termination of string buffers, this is a rather naive and error-prone\n  solution.\n\n\n  Implementation: Switch to bounded string manipulation functions. Inspect buffer\n  lengths involved in the buffer overrun trace reported with the defect.\n\n\n  Implementation: Add code that fills buffers with nulls (however, the length of buffers\n  still needs to be inspected, to ensure that the non null-terminated string is not\n  written at the physical end of the buffer).'\nObserved_Examples: 'CVE-2000-0312: Attacker does not null-terminate argv[] when invoking\n  another program.\n\n\n  CVE-2003-0777: Interrupted step causes resultant lack of null termination.\n\n\n  CVE-2004-1072: Fault causes resultant lack of null termination, leading to buffer\n  expansion.\n\n\n  CVE-2001-1389: Multiple vulnerabilities related to improper null termination.\n\n\n  CVE-2003-0143: Product does not null terminate a message buffer after snprintf-like\n  call, leading to overflow.\n\n\n  CVE-2009-2523: Chain: product does not handle when an input string is not NULL terminated\n  (CWE-170), leading to buffer over-read (CWE-125) or heap-based buffer overflow (CWE-122).'\n",
  "ID: '172'\nName: Encoding Error\nDescription: The product does not properly encode or decode the data, resulting in\n  unexpected values.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nRelated_Attack_Patterns: \"120: \\n\\n267: \\n\\n3: \\n\\n52: \\n\\n53: \\n\\n64: \\n\\n71: \\n\\n\\\n  72: \\n\\n78: \\n\\n80: \"\n",
  "ID: '173'\nName: Improper Handling of Alternate Encoding\nDescription: The product does not properly handle when an input uses an alternate\n  encoding that is valid for the control sphere to which the input is being sent.\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nRelated_Attack_Patterns: \"120: \\n\\n267: \\n\\n3: \\n\\n4: \\n\\n52: \\n\\n53: \\n\\n64: \\n\\n\\\n  71: \\n\\n72: \\n\\n78: \\n\\n79: \\n\\n80: \"\n",
  "ID: '174'\nName: Double Decoding of the Same Data\nDescription: The product decodes the same input twice, which can limit the effectiveness\n  of any protection mechanism that occurs in between the decoding operations.\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2004-1315: Forum software improperly URL decodes the highlight\n  parameter when extracting text to highlight, which allows remote attackers to execute\n  arbitrary PHP code by double-encoding the highlight value so that special characters\n  are inserted into the result.\n\n\n  CVE-2004-1939: XSS protection mechanism attempts to remove \"/\" that could be used\n  to close tags, but it can be bypassed using double encoded slashes (%252F)\n\n\n  CVE-2001-0333: Directory traversal using double encoding.\n\n\n  CVE-2004-1938: \"%2527\" (double-encoded single quote) used in SQL injection.\n\n\n  CVE-2005-1945: Double hex-encoded data.\n\n\n  CVE-2005-0054: Browser executes HTML at higher privileges via URL with hostnames\n  that are double hex encoded, which are decoded twice to generate a malicious hostname.'\n",
  "ID: '175'\nName: Improper Handling of Mixed Encoding\nDescription: The product does not properly handle when the same input uses several\n  different (mixed) encodings.\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '176'\nName: Improper Handling of Unicode Encoding\nDescription: The product does not properly handle when an input contains Unicode encoding.\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0884: Server allows remote attackers to read documents\n  outside of the web root, and possibly execute arbitrary commands, via malformed\n  URLs that contain Unicode encoded characters.\n\n\n  CVE-2001-0709: Server allows a remote attacker to obtain source code of ASP files\n  via a URL encoded with Unicode.\n\n\n  CVE-2001-0669: Overlaps interaction error.'\nRelated_Attack_Patterns: '71: '\n",
  "ID: '177'\nName: Improper Handling of URL Encoding (Hex Encoding)\nDescription: The product does not properly handle when all or part of an input has\n  been URL encoded.\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0900: Hex-encoded path traversal variants - \"%2e%2e\",\n  \"%2e%2e%2f\", \"%5c%2e%2e\"\n\n\n  CVE-2005-2256: Hex-encoded path traversal variants - \"%2e%2e\", \"%2e%2e%2f\", \"%5c%2e%2e\"\n\n\n  CVE-2004-2121: Hex-encoded path traversal variants - \"%2e%2e\", \"%2e%2e%2f\", \"%5c%2e%2e\"\n\n\n  CVE-2004-0280: \"%20\" (encoded space)\n\n\n  CVE-2003-0424: \"%20\" (encoded space)\n\n\n  CVE-2001-0693: \"%20\" (encoded space)\n\n\n  CVE-2001-0778: \"%20\" (encoded space)\n\n\n  CVE-2002-1831: Crash via hex-encoded space \"%20\".\n\n\n  CVE-2000-0671: \"%00\" (encoded null)\n\n\n  CVE-2004-0189: \"%00\" (encoded null)\n\n\n  CVE-2002-1291: \"%00\" (encoded null)\n\n\n  CVE-2002-1031: \"%00\" (encoded null)\n\n\n  CVE-2001-1140: \"%00\" (encoded null)\n\n\n  CVE-2004-0760: \"%00\" (encoded null)\n\n\n  CVE-2002-1025: \"%00\" (encoded null)\n\n\n  CVE-2002-1213: \"%2f\" (encoded slash)\n\n\n  CVE-2004-0072: \"%5c\" (encoded backslash) and \"%2e\" (encoded dot) sequences\n\n\n  CVE-2004-0847: \"%5c\" (encoded backslash)\n\n\n  CVE-2002-1575: \"%0a\" (overlaps CRLF)'\nRelated_Attack_Patterns: \"120: \\n\\n468: \\n\\n64: \\n\\n72: \"\n",
  "ID: '178'\nName: Improper Handling of Case Sensitivity\nDescription: The product does not properly account for differences in case sensitivity\n  when accessing or determining the properties of a resource, leading to inconsistent\n  results.\nExtended_Description: 'Improperly handled case sensitive data can lead to several\n  possible consequences, including:'\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0499: Application server allows attackers to bypass execution\n  of a jsp page and read the source code using an upper case JSP extension in the\n  request.\n\n\n  CVE-2000-0497: The server is case sensitive, so filetype handlers treat .jsp and\n  .JSP as different extensions. JSP source code may be read because .JSP defaults\n  to the filetype \"text\".\n\n\n  CVE-2000-0498: The server is case sensitive, so filetype handlers treat .jsp and\n  .JSP as different extensions. JSP source code may be read because .JSP defaults\n  to the filetype \"text\".\n\n\n  CVE-2001-0766: A URL that contains some characters whose case is not matched by\n  the server''s filters may bypass access restrictions because the case-insensitive\n  file system will then handle the request after it bypasses the case sensitive filter.\n\n\n  CVE-2001-0795: Server allows remote attackers to obtain source code of CGI scripts\n  via URLs that contain MS-DOS conventions such as (1) upper case letters or (2) 8.3\n  file names.\n\n\n  CVE-2001-1238: Task Manager does not allow local users to end processes with uppercase\n  letters named (1) winlogon.exe, (2) csrss.exe, (3) smss.exe and (4) services.exe\n  via the Process tab which could allow local users to install Trojan horses that\n  cannot be stopped.\n\n\n  CVE-2003-0411: chain: Code was ported from a case-sensitive Unix platform to a case-insensitive\n  Windows platform where filetype handlers treat .jsp and .JSP as different extensions.\n  JSP source code may be read because .JSP defaults to the filetype \"text\".\n\n\n  CVE-2002-0485: Leads to interpretation error\n\n\n  CVE-1999-0239: Directories may be listed because lower case web requests are not\n  properly handled by the server.\n\n\n  CVE-2005-0269: File extension check in forum software only verifies extensions that\n  contain all lowercase letters, which allows remote attackers to upload arbitrary\n  files via file extensions that include uppercase letters.\n\n\n  CVE-2004-1083: Web server restricts access to files in a case sensitive manner,\n  but the filesystem accesses files in a case insensitive manner, which allows remote\n  attackers to read privileged files using alternate capitalization.\n\n\n  CVE-2002-2119: Case insensitive passwords lead to search space reduction.\n\n\n  CVE-2004-2214: HTTP server allows bypass of access restrictions using URIs with\n  mixed case.\n\n\n  CVE-2004-2154: Mixed upper/lowercase allows bypass of ACLs.\n\n\n  CVE-2005-4509: Bypass malicious script detection by using tokens that aren''t case\n  sensitive.\n\n\n  CVE-2002-1820: Mixed case problem allows \"admin\" to have \"Admin\" rights (alternate\n  name property).\n\n\n  CVE-2007-3365: Chain: uppercase file extensions causes web server to return script\n  source code instead of executing the script.\n\n\n  CVE-2021-39155: Chain: A microservice integration and management platform compares\n  the hostname in the HTTP Host header in a case-sensitive way (CWE-178, CWE-1289),\n  allowing bypass of the authorization policy (CWE-863) using a hostname with mixed\n  case or other variations.'\n",
  "ID: '179'\nName: 'Incorrect Behavior Order: Early Validation'\nDescription: The product validates input before applying protection mechanisms that\n  modify the input, which could allow an attacker to bypass the validation via dangerous\n  inputs that only arise after the modification.\nExtended_Description: Product needs to validate data at the proper time, after data\n  has been canonicalized and cleansed. Early validation is susceptible to various\n  manipulations that result in dangerous inputs that are produced by canonicalization\n  and cleansing.\nModes_Of_Introduction: 'Implementation: Since early validation errors usually arise\n  from improperly implemented defensive mechanisms, it is likely that these will be\n  introduced more frequently as secure programming becomes implemented more widely.'\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2002-0433: Product allows remote attackers to view restricted\n  files via an HTTP request containing a \"*\" (wildcard or asterisk) character.\n\n\n  CVE-2003-0332: Product modifies the first two letters of a filename extension after\n  performing a security check, which allows remote attackers to bypass authentication\n  via a filename with a .ats extension instead of a .hts extension.\n\n\n  CVE-2002-0802: Database consumes an extra character when processing a character\n  that cannot be converted, which could remove an escape character from the query\n  and make the application subject to SQL injection attacks.\n\n\n  CVE-2000-0191: Overlaps \"fakechild/../realchild\"\n\n\n  CVE-2004-2363: Product checks URI for \"<\" and other literal characters, but does\n  it before hex decoding the URI, so \"%3E\" and other sequences are allowed.\n\n\n  CVE-2002-0934: Directory traversal vulnerability allows remote attackers to read\n  or modify arbitrary files via invalid characters between two . (dot) characters,\n  which are filtered and result in a \"..\" sequence.\n\n\n  CVE-2003-0282: Directory traversal vulnerability allows attackers to overwrite arbitrary\n  files via invalid characters between two . (dot) characters, which are filtered\n  and result in a \"..\" sequence.'\nRelated_Attack_Patterns: \"3: \\n\\n43: \\n\\n71: \"\n",
  "ID: '180'\nName: 'Incorrect Behavior Order: Validate Before Canonicalize'\nDescription: The product validates input before it is canonicalized, which prevents\n  the product from detecting data that becomes invalid after the canonicalization\n  step.\nExtended_Description: This can be used by an attacker to bypass the validation and\n  launch attacks that expose weaknesses that would otherwise be prevented, such as\n  injection.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2002-0433: Product allows remote attackers to view restricted\n  files via an HTTP request containing a \"*\" (wildcard or asterisk) character.\n\n\n  CVE-2003-0332: Product modifies the first two letters of a filename extension after\n  performing a security check, which allows remote attackers to bypass authentication\n  via a filename with a .ats extension instead of a .hts extension.\n\n\n  CVE-2002-0802: Database consumes an extra character when processing a character\n  that cannot be converted, which could remove an escape character from the query\n  and make the application subject to SQL injection attacks.\n\n\n  CVE-2000-0191: Overlaps \"fakechild/../realchild\"\n\n\n  CVE-2004-2363: Product checks URI for \"<\" and other literal characters, but does\n  it before hex decoding the URI, so \"%3E\" and other sequences are allowed.'\nRelated_Attack_Patterns: \"267: \\n\\n3: \\n\\n71: \\n\\n78: \\n\\n79: \\n\\n80: \"\n",
  "ID: '181'\nName: 'Incorrect Behavior Order: Validate Before Filter'\nDescription: The product validates data before it has been filtered, which prevents\n  the product from detecting data that becomes invalid after the filtering step.\nExtended_Description: This can be used by an attacker to bypass the validation and\n  launch attacks that expose weaknesses that would otherwise be prevented, such as\n  injection.\nPotential_Mitigations: 'Implementation\n\n  Architecture and Design: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being filtered.'\nObserved_Examples: 'CVE-2002-0934: Directory traversal vulnerability allows remote\n  attackers to read or modify arbitrary files via invalid characters between two .\n  (dot) characters, which are filtered and result in a \"..\" sequence.\n\n\n  CVE-2003-0282: Directory traversal vulnerability allows attackers to overwrite arbitrary\n  files via invalid characters between two . (dot) characters, which are filtered\n  and result in a \"..\" sequence.'\nRelated_Attack_Patterns: \"120: \\n\\n267: \\n\\n3: \\n\\n43: \\n\\n78: \\n\\n79: \\n\\n80: \"\n",
  "ID: '182'\nName: Collapse of Data into Unsafe Value\nDescription: The product filters data in a way that causes it to be reduced or \"collapsed\"\n  into an unsafe value that violates an expected security property.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.\n\n\n  Canonicalize the name to match that of the file system''s representation of the\n  name. This can sometimes be achieved with an available API (e.g. in Win32 the GetFullPathName\n  function).'\nObserved_Examples: 'CVE-2004-0815: \"/.////\" in pathname collapses to absolute path.\n\n\n  CVE-2005-3123: \"/.//..//////././\" is collapsed into \"/.././\" after \"..\" and \"//\"\n  sequences are removed.\n\n\n  CVE-2002-0325: \".../...//\" collapsed to \"...\" due to removal of \"./\" in web server.\n\n\n  CVE-2002-0784: chain: HTTP server protects against \"..\" but allows \".\" variants\n  such as \"////./../.../\". If the server removes \"/..\" sequences, the result would\n  collapse into an unsafe value \"////../\" (CWE-182).\n\n\n  CVE-2005-2169: MFV. Regular expression intended to protect against directory traversal\n  reduces \".../...//\" to \"../\".\n\n\n  CVE-2001-1157: XSS protection mechanism strips a <script> sequence that is nested\n  in another <script> sequence.'\n",
  "ID: '183'\nName: Permissive List of Allowed Inputs\nDescription: The product implements a protection mechanism that relies on a list of\n  inputs (or properties of inputs) that are explicitly allowed by policy because the\n  inputs are assumed to be safe, but the list is too permissive - that is, it allows\n  an input that is unsafe, leading to resultant weaknesses.\nAlternate_Terms: 'Allowlist / Allow List: This is used by CWE and CAPEC instead of\n  other commonly-used terms.  Its counterpart is denylist.\n\n\n  Safelist / Safe List: This is often used by security tools such as firewalls, email\n  or web gateways, proxies, etc.\n\n\n  Whitelist / White List: This term is frequently used, but usage has been declining\n  as organizations have started to adopt other terms.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2019-12799: chain: bypass of untrusted deserialization issue\n  (CWE-502) by using an assumed-trusted class (CWE-183)\n\n\n  CVE-2019-10458: sandbox bypass using a method that is on an allowlist\n\n\n  CVE-2017-1000095: sandbox bypass using unsafe methods that are on an allowlist\n\n\n  CVE-2019-10458: CI/CD pipeline feature has unsafe elements in allowlist, allowing\n  bypass of script restrictions\n\n\n  CVE-2017-1000095: Default allowlist includes unsafe methods, allowing bypass of\n  sandbox'\nRelated_Attack_Patterns: \"120: \\n\\n3: \\n\\n43: \\n\\n71: \"\n",
  "ID: '184'\nName: Incomplete List of Disallowed Inputs\nDescription: The product implements a protection mechanism that relies on a list of\n  inputs (or properties of inputs) that are not allowed by policy or otherwise require\n  other action to neutralize before additional processing takes place, but the list\n  is incomplete, leading to resultant weaknesses.\nExtended_Description: Developers often try to protect their products against malicious\n  input by performing tests against inputs that are known to be bad, such as special\n  characters that can invoke new commands.  However, such lists often only account\n  for the most well-known bad inputs. Attackers may be able to find other malicious\n  inputs that were not expected by the developer, allowing them to bypass the intended\n  protection mechanism.\nAlternate_Terms: 'Denylist / Deny List: This is used by CWE and CAPEC instead of other\n  commonly-used terms.  Its counterpart is allowlist.\n\n\n  Blocklist / Block List: This is often used by security tools such as firewalls,\n  email or web gateways, proxies, etc.\n\n\n  Blacklist / Black List: This term is frequently used, but usage has been declining\n  as organizations have started to adopt other terms.'\nModes_Of_Introduction: 'Implementation: Developers might begin to develop a list of\n  bad inputs as a fast way to fix a particular weakness, instead of fixing the root\n  cause. See [REF-141].\n\n\n  Architecture and Design: The design might rely solely on detection of malicious\n  inputs as a protection mechanism.'\nDetection_Methods: 'Black Box: Exploitation of a vulnerability with commonly-used\n  manipulations might fail, but minor variations might succeed.'\nPotential_Mitigations: 'Implementation: Do not rely exclusively on detecting disallowed\n  inputs.  There are too many variants to encode a character, especially when different\n  environments are used, so there is a high likelihood of missing some variants.  Only\n  use detection of disallowed inputs as a mechanism for detecting suspicious activity.\n  Ensure that you are using other protection mechanisms that only identify \"good\"\n  input - such as lists of allowed inputs - and ensure that you are properly encoding\n  your outputs.'\nObserved_Examples: 'CVE-2008-2309: product uses a denylist to identify potentially\n  dangerous content, allowing attacker to bypass a warning\n\n\n  CVE-2005-2782: PHP remote file inclusion in web application that filters \"http\"\n  and \"https\" URLs, but not \"ftp\".\n\n\n  CVE-2004-0542: Programming language does not filter certain shell metacharacters\n  in Windows environment.\n\n\n  CVE-2004-0595: XSS filter doesn''t filter null characters before looking for dangerous\n  tags, which are ignored by web browsers. MIE and validate-before-cleanse.\n\n\n  CVE-2005-3287: Web-based mail product doesn''t restrict dangerous extensions such\n  as ASPX on a web server, even though others are prohibited.\n\n\n  CVE-2004-2351: Resultant XSS when only <script> and <style> are checked.\n\n\n  CVE-2005-2959: Privileged program does not clear sensitive environment variables\n  that are used by bash. Overlaps multiple interpretation error.\n\n\n  CVE-2005-1824: SQL injection protection scheme does not quote the \"\\\" special character.\n\n\n  CVE-2005-2184: Detection of risky filename extensions prevents users from automatically\n  executing .EXE files, but .LNK is accepted, allowing resultant Windows symbolic\n  link.\n\n\n  CVE-2007-1343: Product uses list of protected variables, but accidentally omits\n  one dangerous variable, allowing external modification\n\n\n  CVE-2007-5727: Chain: product only removes SCRIPT tags (CWE-184), enabling XSS (CWE-79)\n\n\n  CVE-2006-4308: Chain: product only checks for use of \"javascript:\" tag (CWE-184),\n  allowing XSS (CWE-79) using other tags\n\n\n  CVE-2007-3572: Chain: OS command injection (CWE-78) enabled by using an unexpected\n  character that is not explicitly disallowed (CWE-184)\n\n\n  CVE-2002-0661: \"\\\" not in list of disallowed values for web server, allowing path\n  traversal attacks when the server is run on Windows and other OSes.'\nRelated_Attack_Patterns: \"120: \\n\\n15: \\n\\n182: \\n\\n3: \\n\\n43: \\n\\n6: \\n\\n71: \\n\\n\\\n  73: \\n\\n85: \"\n",
  "ID: '185'\nName: Incorrect Regular Expression\nDescription: The product specifies a regular expression in a way that causes data\n  to be improperly matched or compared.\nExtended_Description: When the regular expression is used in protection mechanisms\n  such as filtering or validation, this may allow an attacker to bypass the intended\n  restrictions on the incoming data.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Regular expressions can become error\n  prone when defining a complex language even for those experienced in writing grammars.\n  Determine if several smaller regular expressions simplify one large regular expression.\n  Also, subject the regular expression to thorough testing techniques such as equivalence\n  partitioning, boundary value analysis, and robustness. After testing and a reasonable\n  confidence level is achieved, a regular expression may not be foolproof. If an exploit\n  is allowed to slip through, then record the exploit and refactor the regular expression.'\nObserved_Examples: 'CVE-2002-2109: Regexp isn''t \"anchored\" to the beginning or end,\n  which allows spoofed values that have trusted values as substrings.\n\n\n  CVE-2005-1949: Regexp for IP address isn''t anchored at the end, allowing appending\n  of shell metacharacters.\n\n\n  CVE-2001-1072: Bypass access restrictions via multiple leading slash, which causes\n  a regular expression to fail.\n\n\n  CVE-2000-0115: Local user DoS via invalid regular expressions.\n\n\n  CVE-2002-1527: chain: Malformed input generates a regular expression error that\n  leads to information exposure.\n\n\n  CVE-2005-1061: Certain strings are later used in a regexp, leading to a resultant\n  crash.\n\n\n  CVE-2005-2169: MFV. Regular expression intended to protect against directory traversal\n  reduces \".../...//\" to \"../\".\n\n\n  CVE-2005-0603: Malformed regexp syntax leads to information exposure in error message.\n\n\n  CVE-2005-1820: Code injection due to improper quoting of regular expression.\n\n\n  CVE-2005-3153: Null byte bypasses PHP regexp check.\n\n\n  CVE-2005-4155: Null byte bypasses PHP regexp check.'\nRelated_Attack_Patterns: \"15: \\n\\n6: \\n\\n79: \"\n",
  "ID: '186'\nName: Overly Restrictive Regular Expression\nDescription: A regular expression is overly restrictive, which prevents dangerous\n  values from being detected.\nExtended_Description: This weakness is not about regular expression complexity. Rather,\n  it is about a regular expression that does not match all values that are intended.\n  Consider the use of a regexp to identify acceptable values or to spot unwanted terms.\n  An overly restrictive regexp misses some potentially security-relevant values leading\n  to either false positives *or* false negatives, depending on how the regexp is being\n  used within the code. Consider the expression /[0-8]/ where the intention was /[0-9]/.  This\n  expression is not \"complex\" but the value \"9\" is not matched when maybe the programmer\n  planned to check for it.\nPotential_Mitigations: 'Implementation: Regular expressions can become error prone\n  when defining a complex language even for those experienced in writing grammars.\n  Determine if several smaller regular expressions simplify one large regular expression.\n  Also, subject your regular expression to thorough testing techniques such as equivalence\n  partitioning, boundary value analysis, and robustness. After testing and a reasonable\n  confidence level is achieved, a regular expression may not be foolproof. If an exploit\n  is allowed to slip through, then record the exploit and refactor your regular expression.'\nObserved_Examples: 'CVE-2005-1604: MIE. \".php.ns\" bypasses \".php$\" regexp but is still\n  parsed as PHP by Apache. (manipulates an equivalence property under Apache)'\n",
  "ID: '187'\nName: Partial String Comparison\nDescription: The product performs a comparison that only examines a portion of a factor\n  before determining whether there is a match, such as a substring, leading to resultant\n  weaknesses.\nExtended_Description: For example, an attacker might succeed in authentication by\n  providing a small password that matches the associated portion of the larger, correct\n  password.\nPotential_Mitigations: 'Testing: Thoroughly test the comparison scheme before deploying\n  code into production. Perform positive testing as well as negative testing.'\nObserved_Examples: 'CVE-2014-6394: Product does not prevent access to restricted directories\n  due to partial string comparison with a public directory\n\n\n  CVE-2004-1012: Argument parser of an IMAP server treats a partial command \"body[p\"\n  as if it is \"body.peek\", leading to index error and out-of-bounds corruption.\n\n\n  CVE-2004-0765: Web browser only checks the hostname portion of a certificate when\n  the hostname portion of the URI is not a fully qualified domain name (FQDN), which\n  allows remote attackers to spoof trusted certificates.\n\n\n  CVE-2002-1374: One-character password by attacker checks only against first character\n  of real password.\n\n\n  CVE-2000-0979: One-character password by attacker checks only against first character\n  of real password.'\n",
  "ID: '188'\nName: Reliance on Data/Memory Layout\nDescription: The product makes invalid assumptions about how protocol data or memory\n  is organized at a lower level, resulting in unintended program behavior.\nExtended_Description: 'When changing platforms or protocol versions, in-memory organization\n  of data may change in unintended ways. For example, some architectures may place\n  local variables A and B right next to each other with A on top; some may place them\n  next to each other with B on top; and others may add some padding to each. The padding\n  size may vary to ensure that each variable is aligned to a proper word size.\n\n  In protocol implementations, it is common to calculate an offset relative to another\n  field to pick out a specific piece of data. Exceptional conditions, often involving\n  new protocol versions, may add corner cases that change the data layout in an unusual\n  way. The result can be that an implementation accesses an unintended field in the\n  packet, treating data of one type as data of another type.'\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nPotential_Mitigations: 'Implementation\n\n  Architecture and Design: In flat address space situations, never allow computing\n  memory addresses as offsets from another memory address.\n\n\n  Architecture and Design: Fully specify protocol layout unambiguously, providing\n  a structured grammar (e.g., a compilable yacc grammar).\n\n\n  Testing: Testing: Test that the implementation properly handles each case in the\n  protocol grammar.'\n",
  "ID: '190'\nName: Integer Overflow or Wraparound\nDescription: The product performs a calculation that can produce an integer overflow\n  or wraparound, when the logic assumes that the resulting value will always be larger\n  than the original value. This can introduce other weaknesses when the calculation\n  is used for resource management or execution control.\nExtended_Description: An integer overflow or wraparound occurs when an integer value\n  is incremented to a value that is too large to store in the associated representation.\n  When this occurs, the value may wrap to become a very small or negative number.\n  While this may be intended behavior in circumstances that rely on wrapping, it can\n  have security consequences if the wrap is unexpected. This is especially the case\n  if the integer overflow can be triggered using user-supplied inputs. This becomes\n  security-critical when the result is used to control looping, make a security decision,\n  or determine the offset or size in behaviors such as memory allocation, copying,\n  concatenation, etc.\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n\n  Black Box: Sometimes, evidence of this weakness can be detected using dynamic tools\n  and techniques that interact with the product using large test suites with many\n  diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The product''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n  Without visibility into the code, black box methods may not be able to sufficiently\n  distinguish this weakness from others, requiring follow-up manual methods to diagnose\n  the underlying problem.\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  allocation calculations. This can be useful for detecting overflow conditions (CWE-190)\n  or similar weaknesses that might have serious security impacts on the program.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Requirements: Ensure that all protocols are strictly defined,\n  such that all out-of-bounds behavior can be identified simply, and require strict\n  conformance to the protocol.\n\n\n  Requirements: Use a language that does not allow this weakness to occur or provides\n  constructs that make this weakness easier to avoid.\n\n  If possible, choose a language or compiler that performs automatic bounds checking.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Use libraries or frameworks that make it easier to handle numbers without unexpected\n  consequences.\n\n  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib\n  (C or C++). [REF-106]\n\n\n  Implementation: Perform input validation on any numeric input by ensuring that it\n  is within the expected range. Enforce that the input meets both the minimum and\n  maximum requirements for the expected range.\n\n  Use unsigned integers where possible. This makes it easier to perform validation\n  for integer overflows. When signed integers are required, ensure that the range\n  check includes minimum values as well as maximum values.\n\n\n  Implementation: Understand the programming language''s underlying representation\n  and how it interacts with numeric calculation (CWE-681). Pay close attention to\n  byte size discrepancies, precision, signed/unsigned distinctions, truncation, conversion\n  and casting between types, \"not-a-number\" calculations, and how the language handles\n  numbers that are too large or too small for its underlying representation. [REF-7]\n\n  Also be careful to account for 32-bit, 64-bit, and other potential differences that\n  may affect the numeric representation.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: Examine compiler warnings closely and eliminate problems with potential\n  security implications, such as signed / unsigned mismatch in memory operations,\n  or use of uninitialized variables. Even if the weakness is rarely exploitable, a\n  single failure may lead to the compromise of the entire system.'\nObserved_Examples: 'CVE-2022-21668: Chain: Python library does not limit the resources\n  used to process images that specify a very large number of bands (CWE-1284), leading\n  to excessive memory consumption (CWE-789) or an integer overflow (CWE-190).\n\n\n  CVE-2021-30860: Chain: improper input validation (CWE-20) leads to integer overflow\n  (CWE-190) in mobile OS, as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-30663: Chain: improper input validation (CWE-20) leads to integer overflow\n  (CWE-190) in mobile OS, as exploited in the wild per CISA KEV.\n\n\n  CVE-2018-10887: Chain: unexpected sign extension (CWE-194) leads to integer overflow\n  (CWE-190), causing an out-of-bounds read (CWE-125)\n\n\n  CVE-2019-1010006: Chain: compiler optimization (CWE-733) removes or modifies code\n  used to detect integer overflow (CWE-190), allowing out-of-bounds write (CWE-787).\n\n\n  CVE-2010-2753: Chain: integer overflow leads to use-after-free\n\n\n  CVE-2005-1513: Chain: integer overflow in securely-coded mail program leads to buffer\n  overflow. In 2005, this was regarded as unrealistic to exploit, but in 2020, it\n  was rediscovered to be easier to exploit due to evolutions of the technology.\n\n\n  CVE-2002-0391: Integer overflow via a large number of arguments.\n\n\n  CVE-2002-0639: Integer overflow in OpenSSH as listed in the demonstrative examples.\n\n\n  CVE-2005-1141: Image with large width and height leads to integer overflow.\n\n\n  CVE-2005-0102: Length value of -1 leads to allocation of 0 bytes and resultant heap\n  overflow.\n\n\n  CVE-2004-2013: Length value of -1 leads to allocation of 0 bytes and resultant heap\n  overflow.\n\n\n  CVE-2017-1000121: chain: unchecked message size metadata allows integer overflow\n  (CWE-190) leading to buffer overflow (CWE-119).\n\n\n  CVE-2013-1591: Chain: an integer overflow (CWE-190) in the image size calculation\n  causes an infinite loop (CWE-835) which sequentially allocates buffers without limits\n  (CWE-1325) until the stack is full.'\nRelated_Attack_Patterns: '92: '\n",
  "ID: '191'\nName: Integer Underflow (Wrap or Wraparound)\nDescription: The product subtracts one value from another, such that the result is\n  less than the minimum allowable integer value, which produces a value that is not\n  equal to the correct result.\nExtended_Description: This can happen in signed and unsigned cases.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nAlternate_Terms: 'Integer underflow: \"Integer underflow\" is sometimes used to identify\n  signedness errors in which an originally positive number becomes negative as a result\n  of subtraction. However, there are cases of bad subtraction in which unsigned integers\n  are involved, so it''s not always a signedness issue.\n\n  \"Integer underflow\" is occasionally used to describe array index errors in which\n  the index is negative.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2004-0816: Integer underflow in firewall via malformed packet.\n\n\n  CVE-2004-1002: Integer underflow by packet with invalid length.\n\n\n  CVE-2005-0199: Long input causes incorrect length calculation.\n\n\n  CVE-2005-1891: Malformed icon causes integer underflow in loop counter variable.'\n",
  "ID: '192'\nName: Integer Coercion Error\nDescription: Integer coercion refers to a set of flaws pertaining to the type casting,\n  extension, or truncation of primitive data types.\nExtended_Description: Several flaws fall under the category of integer coercion errors.\n  For the most part, these errors in and of themselves result only in availability\n  and data integrity issues. However, in some circumstances, they may result in other,\n  more complicated security related flaws, such as buffer overflow conditions.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: A language which throws exceptions on ambiguous\n  data casts might be chosen.\n\n\n  Architecture and Design: Design objects and program flow such that multiple or complex\n  casts are unnecessary\n\n\n  Implementation: Ensure that any data type casting that you must used is entirely\n  understood in order to reduce the plausibility of error in use.'\n",
  "ID: '193'\nName: Off-by-one Error\nDescription: A product calculates or uses an incorrect maximum or minimum value that\n  is 1 more, or 1 less, than the correct value.\nAlternate_Terms: 'off-by-five: An \"off-by-five\" error was reported for sudo in 2002\n  (CVE-2002-0184), but that is more like a \"length calculation\" error.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: When copying character arrays or using character\n  manipulation methods, the correct size parameter must be used to account for the\n  null terminator that needs to be added at the end of the array. Some examples of\n  functions susceptible to this weakness in C include strcpy(), strncpy(), strcat(),\n  strncat(), printf(), sprintf(), scanf() and sscanf().'\nObserved_Examples: 'CVE-2003-0252: Off-by-one error allows remote attackers to cause\n  a denial of service and possibly execute arbitrary code via requests that do not\n  contain newlines.\n\n\n  CVE-2001-1391: Off-by-one vulnerability in driver allows users to modify kernel\n  memory.\n\n\n  CVE-2002-0083: Off-by-one error allows local users or remote malicious servers to\n  gain privileges.\n\n\n  CVE-2002-0653: Off-by-one buffer overflow in function usd by server allows local\n  users to execute arbitrary code as the server user via .htaccess files with long\n  entries.\n\n\n  CVE-2002-0844: Off-by-one buffer overflow in version control system allows local\n  users to execute arbitrary code.\n\n\n  CVE-1999-1568: Off-by-one error in FTP server allows a remote attacker to cause\n  a denial of service (crash) via a long PORT command.\n\n\n  CVE-2004-0346: Off-by-one buffer overflow in FTP server allows local users to gain\n  privileges via a 1024 byte RETR command.\n\n\n  CVE-2004-0005: Multiple buffer overflows in chat client allow remote attackers to\n  cause a denial of service and possibly execute arbitrary code.\n\n\n  CVE-2003-0356: Multiple off-by-one vulnerabilities in product allow remote attackers\n  to cause a denial of service and possibly execute arbitrary code.\n\n\n  CVE-2001-1496: Off-by-one buffer overflow in server allows remote attackers to cause\n  a denial of service and possibly execute arbitrary code.\n\n\n  CVE-2004-0342: This is an interesting example that might not be an off-by-one.\n\n\n  CVE-2001-0609: An off-by-one enables a terminating null to be overwritten, which\n  causes 2 strings to be merged and enable a format string.\n\n\n  CVE-2002-1745: Off-by-one error allows source code disclosure of files with 4 letter\n  extensions that match an accepted 3-letter extension.\n\n\n  CVE-2002-1816: Off-by-one buffer overflow.\n\n\n  CVE-2002-1721: Off-by-one error causes an snprintf call to overwrite a critical\n  internal variable with a null value.\n\n\n  CVE-2003-0466: Off-by-one error in function used in many products leads to a buffer\n  overflow during pathname management, as demonstrated using multiple commands in\n  an FTP server.\n\n\n  CVE-2003-0625: Off-by-one error allows read of sensitive memory via a malformed\n  request.\n\n\n  CVE-2006-4574: Chain: security monitoring product has an off-by-one error that leads\n  to unexpected length values, triggering an assertion.'\n",
  "ID: '194'\nName: Unexpected Sign Extension\nDescription: The product performs an operation on a number that causes it to be sign\n  extended when it is transformed into a larger data type. When the original number\n  is negative, this can produce unexpected values that lead to resultant weaknesses.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Implementation: Avoid using signed variables if you don''t\n  need to represent negative values. When negative values are needed, perform validation\n  after you save those values to larger data types, or before passing them to functions\n  that are expecting unsigned values.'\nObserved_Examples: 'CVE-2018-10887: Chain: unexpected sign extension (CWE-194) leads\n  to integer overflow (CWE-190), causing an out-of-bounds read (CWE-125)\n\n\n  CVE-1999-0234: Sign extension error produces -1 value that is treated as a command\n  separator, enabling OS command injection.\n\n\n  CVE-2003-0161: Product uses \"char\" type for input character. When char is implemented\n  as a signed type, ASCII value 0xFF (255), a sign extension produces a -1 value that\n  is treated as a program-specific separator value, effectively disabling a length\n  check and leading to a buffer overflow. This is also a multiple interpretation error.\n\n\n  CVE-2007-4988: chain: signed short width value in image processor is sign extended\n  during conversion to unsigned int, which leads to integer overflow and heap-based\n  buffer overflow.\n\n\n  CVE-2006-1834: chain: signedness error allows bypass of a length check; later sign\n  extension makes exploitation easier.\n\n\n  CVE-2005-2753: Sign extension when manipulating Pascal-style strings leads to integer\n  overflow and improper memory copy.'\n",
  "ID: '195'\nName: Signed to Unsigned Conversion Error\nDescription: The product uses a signed primitive and performs a cast to an unsigned\n  primitive, which can produce an unexpected value if the value of the signed primitive\n  can not be represented using an unsigned primitive.\nExtended_Description: 'It is dangerous to rely on implicit casts between signed and\n  unsigned numbers because the result can take on an unexpected value and violate\n  assumptions made by the program.\n\n  Often, functions will return negative values to indicate a failure. When the result\n  of a function is to be used as a size parameter, using these negative return values\n  can have unexpected results. For example, if negative size values are passed to\n  the standard memory copy or allocation functions they will be implicitly cast to\n  a large unsigned value. This may lead to an exploitable buffer overflow or underflow\n  condition.'\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2007-4268: Chain: integer signedness error (CWE-195) passes\n  signed comparison, leading to heap overflow (CWE-122)'\n",
  "ID: '196'\nName: Unsigned to Signed Conversion Error\nDescription: The product uses an unsigned primitive and performs a cast to a signed\n  primitive, which can produce an unexpected value if the value of the unsigned primitive\n  can not be represented using a signed primitive.\nExtended_Description: Although less frequent an issue than signed-to-unsigned conversion,\n  unsigned-to-signed conversion can be the perfect precursor to dangerous buffer underwrite\n  conditions that allow attackers to move down the stack where they otherwise might\n  not have access in a normal buffer overflow condition. Buffer underwrites occur\n  frequently when large unsigned values are cast to signed values, and then used as\n  indexes into a buffer or for pointer arithmetic.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Requirements: Choose a language which is not subject to these\n  casting flaws.\n\n\n  Architecture and Design: Design object accessor functions to implicitly check values\n  for valid sizes. Ensure that all functions which will be used as a size are checked\n  previous to use as a size. If the language permits, throw exceptions rather than\n  using in-band errors.\n\n\n  Implementation: Error check the return values of all functions. Be aware of implicit\n  casts made, and use unsigned variables for sizes if at all possible.'\nRelated_Attack_Patterns: '92: '\n",
  "ID: '197'\nName: Numeric Truncation Error\nDescription: Truncation errors occur when a primitive is cast to a primitive of a\n  smaller size and data is lost in the conversion.\nExtended_Description: When a primitive is cast to a smaller primitive, the high order\n  bits of the large value are lost in the conversion, potentially resulting in an\n  unexpected value that is not equal to the original value. This value may be required\n  as an index into a buffer, a loop iterator, or simply necessary state data. In any\n  case, the value cannot be trusted and the system will be in an undefined state.\n  While this method may be employed viably to isolate the low bits of a value, this\n  usage is rare, and truncation usually implies that an implementation error has occurred.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Ensure that no casts, implicit or explicit,\n  take place that move from a larger size primitive or a smaller size primitive.'\nObserved_Examples: 'CVE-2020-17087: Chain: integer truncation (CWE-197) causes small\n  buffer allocation (CWE-131) leading to out-of-bounds write (CWE-787) in kernel pool,\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2009-0231: Integer truncation of length value leads to heap-based buffer overflow.\n\n\n  CVE-2008-3282: Size of a particular type changes for 64-bit platforms, leading to\n  an integer truncation in document processor causes incorrect index to be generated.'\n",
  "ID: '198'\nName: Use of Incorrect Byte Ordering\nDescription: The product receives input from an upstream component, but it does not\n  account for byte ordering (e.g. big-endian and little-endian) when processing the\n  input, causing an incorrect number or value to be used.\nDetection_Methods: 'Black Box: Because byte ordering bugs are usually very noticeable\n  even with normal inputs, this bug is more likely to occur in rarely triggered error\n  conditions, making them difficult to detect using black box methods.'\n",
  "ID: '20'\nName: Improper Input Validation\nDescription: \"The product receives input or data, but it does\\n        not validate\\\n  \\ or incorrectly validates that the input has the\\n        properties that are required\\\n  \\ to process the data safely and\\n        correctly.\"\nExtended_Description: \"Input validation is a frequently-used technique\\n\\t   for checking\\\n  \\ potentially dangerous inputs in order to\\n\\t   ensure that the inputs are safe\\\n  \\ for processing within the\\n\\t   code, or when communicating with other components.\\\n  \\  When\\n\\t   software does not validate input properly, an attacker is\\n\\t   able\\\n  \\ to craft the input in a form that is not expected by\\n\\t   the rest of the application.\\\n  \\ This will lead to parts of the\\n\\t   system receiving unintended input, which\\\n  \\ may result in\\n\\t   altered control flow, arbitrary control of a resource, or\\n\\\n  \\t   arbitrary code execution.\\nInput validation is not the only technique for\\n\\\n  \\t   processing input, however.  Other techniques attempt to\\n\\t   transform potentially-dangerous\\\n  \\ input into something safe, such\\n\\t   as filtering (CWE-790) - which attempts\\\n  \\ to remove dangerous\\n\\t   inputs - or encoding/escaping (CWE-116), which attempts\\\n  \\ to\\n\\t   ensure that the input is not misinterpreted when it is included\\n\\t \\\n  \\  in output to another component. Other techniques exist as well\\n\\t   (see CWE-138\\\n  \\ for more examples.)\\nInput validation can be applied to:\\nData can be simple or\\\n  \\ structured.  Structured data\\n\\t   can be composed of many nested layers, composed\\\n  \\ of\\n\\t   combinations of metadata and raw data, with other simple or\\n\\t   structured\\\n  \\ data.\\nMany properties of raw data or metadata may need\\n\\t   to be validated\\\n  \\ upon entry into the code, such\\n\\t   as:\\nImplied or derived properties of data\\\n  \\ must often\\n\\t   be calculated or inferred by the code itself.  Errors in\\n\\t\\\n  \\   deriving properties may be considered a contributing factor\\n\\t   to improper\\\n  \\ input validation.\\nNote that \\\"input validation\\\" has very different\\n\\t   meanings\\\n  \\ to different people, or within different\\n\\t   classification schemes.  Caution\\\n  \\ must be used when\\n\\t   referencing this CWE entry or mapping to it.  For example,\\n\\\n  \\t   some weaknesses might involve inadvertently giving control\\n\\t   to an attacker\\\n  \\ over an input when they should not be able\\n\\t   to provide an input at all, but\\\n  \\ sometimes this is referred\\n\\t   to as input validation.\\nFinally, it is important\\\n  \\ to emphasize that the\\n\\t   distinctions between input validation and output escaping\\n\\\n  \\t   are often blurred, and developers must be careful to\\n\\t   understand the difference,\\\n  \\ including how input validation\\n\\t   is not always sufficient to prevent vulnerabilities,\\n\\\n  \\t   especially when less stringent data types must be\\n\\t   supported, such as\\\n  \\ free-form text. Consider a SQL injection\\n\\t   scenario in which a person's last\\\n  \\ name is inserted into a\\n\\t   query. The name \\\"O'Reilly\\\" would likely pass the\\\n  \\ validation\\n\\t   step since it is a common last name in the English\\n\\t   language.\\\n  \\ However, this valid name cannot be directly\\n\\t   inserted into the database because\\\n  \\ it contains the \\\"'\\\"\\n\\t   apostrophe character, which would need to be escaped\\\n  \\ or\\n\\t   otherwise transformed. In this case, removing the\\n\\t   apostrophe might\\\n  \\ reduce the risk of SQL injection, but it\\n\\t   would produce incorrect behavior\\\n  \\ because the wrong name\\n\\t   would be recorded.\"\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  If a programmer believes that an attacker cannot modify certain inputs, then the\\\n  \\ programmer might not perform any input validation at all. For example, in web\\\n  \\ applications, many programmers believe that cookies and hidden form fields can\\\n  \\ not be modified from a web browser (CWE-472), although they can be altered using\\\n  \\ a proxy or a custom program. In a client-server architecture, the programmer might\\\n  \\ assume that client-side security checks cannot be bypassed, even when a custom\\\n  \\ client could be written that skips those checks (CWE-602).\"\nDetection_Methods: 'Automated Static Analysis: Some instances of improper input validation\n  can be detected using automated static analysis.\n\n  A static analysis tool might allow the user to specify which application-specific\n  methods or functions perform input validation; the tool might also have built-in\n  knowledge of validation frameworks such as Struts. The tool may then suppress or\n  de-prioritize any associated warnings. This allows the analyst to focus on areas\n  of the software in which input validation does not appear to be present.\n\n  Except in the cases described in the previous paragraph, automated static analysis\n  might not be able to recognize when proper input validation is being performed,\n  leading to false positives - i.e., warnings that do not have any security consequences\n  or require any code changes.\n\n\n  Manual Static Analysis: When custom input validation is required, such as when enforcing\n  business rules, manual analysis is necessary to ensure that the validation is properly\n  implemented.\n\n\n  Fuzzing: Fuzzing techniques can be useful for detecting input validation errors.\n  When unexpected inputs are provided to the software, the software should not crash\n  or otherwise become unstable, and it should generate application-controlled error\n  messages. If exceptions or interpreter-generated error messages occur, this indicates\n  that the input was not detected and handled within the application logic itself.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Consider using language-theoretic\n  security (LangSec) techniques that characterize inputs using a formal language and\n  build \"recognizers\" for that language.  This effectively requires parsing to be\n  a distinct layer that effectively enforces a boundary between raw input and internal\n  data representations, instead of allowing parser code to be scattered throughout\n  the program, where it could be subject to errors or inconsistencies that create\n  weaknesses. [REF-1109] [REF-1110] [REF-1111]\n\n\n  Architecture and Design: Use an input validation framework such as Struts or the\n  OWASP ESAPI Validation API. Note that using a framework does not automatically address\n  all input validation problems; be mindful of weaknesses that could arise from misusing\n  the framework itself (CWE-1173).\n\n\n  Architecture and Design\n\n  Implementation: Understand all the potential areas where untrusted inputs can enter\n  your software: parameters or arguments, cookies, anything read from the network,\n  environment variables, reverse DNS lookups, query results, request headers, URL\n  components, e-mail, files, filenames, databases, and any external systems that provide\n  data to the application. Remember that such inputs may be obtained indirectly through\n  API calls.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n  Even though client-side checks provide minimal benefits with respect to server-side\n  security, they are still useful. First, they can support intrusion detection. If\n  the server receives input that should have been rejected by the client, then it\n  may be an indication of an attack. Second, client-side error-checking can provide\n  helpful feedback to the user about the expectations for valid input. Third, there\n  may be a reduction in server-side processing time for accidental input errors, although\n  this is typically a small savings.\n\n\n  Implementation: When your application combines data from multiple sources, perform\n  the validation after the sources have been combined. The individual data elements\n  may pass the validation step but violate the intended restrictions after they have\n  been combined.\n\n\n  Implementation: Be especially careful to validate all input when invoking code that\n  crosses language boundaries, such as from an interpreted language to native code.\n  This could create an unexpected interaction between the language boundaries. Ensure\n  that you are not violating any of the expectations of the language with which you\n  are interfacing. For example, even though Java may not be susceptible to buffer\n  overflows, providing a large argument in a call to native code might trigger an\n  overflow.\n\n\n  Implementation: Directly convert your input type into the expected data type, such\n  as using a conversion function that translates a string into a number. After converting\n  to the expected data type, ensure that the input''s values fall within the expected\n  range of allowable values and that multi-field consistencies are maintained.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180, CWE-181). Make\n  sure that your application does not inadvertently decode the same input twice (CWE-174).\n  Such errors could be used to bypass allowlist schemes by introducing dangerous inputs\n  after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization\n  control.\n\n  Consider performing repeated canonicalization until your input does not change any\n  more. This will avoid double-decoding and similar scenarios, but it might inadvertently\n  modify inputs that are allowed to contain properly-encoded dangerous content.\n\n\n  Implementation: When exchanging data between components, ensure that both components\n  are using the same character encoding. Ensure that the proper encoding is applied\n  at each interface. Explicitly set the encoding you are using whenever the protocol\n  allows you to do so.'\nObserved_Examples: 'CVE-2021-30860: Chain: improper input validation (CWE-20) leads\n  to integer overflow (CWE-190) in mobile OS, as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-30663: Chain: improper input validation (CWE-20) leads to integer overflow\n  (CWE-190) in mobile OS, as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-22205: Chain: backslash followed by a newline can bypass a validation step\n  (CWE-20), leading to eval injection (CWE-95), as exploited in the wild per CISA\n  KEV.\n\n\n  CVE-2021-21220: Chain: insufficient input validation (CWE-20) in browser allows\n  heap corruption (CWE-787), as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-9054: Chain: improper input validation (CWE-20) in username parameter,\n  leading to OS command injection (CWE-78), as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-3452: Chain: security product has improper input validation (CWE-20) leading\n  to directory traversal (CWE-22), as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-3161: Improper input validation of HTTP requests in IP phone, as exploited\n  in the wild per CISA KEV.\n\n\n  CVE-2020-3580: Chain: improper input validation (CWE-20) in firewall product leads\n  to XSS (CWE-79), as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-37147: Chain: caching proxy server has improper input validation (CWE-20)\n  of headers, allowing HTTP response smuggling (CWE-444) using an \"LF line ending\"\n\n\n  CVE-2008-5305: Eval injection in Perl program using an ID that should only contain\n  hyphens and numbers.\n\n\n  CVE-2008-2223: SQL injection through an ID that was supposed to be numeric.\n\n\n  CVE-2008-3477: lack of input validation in spreadsheet program leads to buffer overflows,\n  integer overflows, array index errors, and memory corruption.\n\n\n  CVE-2008-3843: insufficient validation enables XSS\n\n\n  CVE-2008-3174: driver in security product allows code execution due to insufficient\n  validation\n\n\n  CVE-2007-3409: infinite loop from DNS packet with a label that points to itself\n\n\n  CVE-2006-6870: infinite loop from DNS packet with a label that points to itself\n\n\n  CVE-2008-1303: missing parameter leads to crash\n\n\n  CVE-2007-5893: HTTP request with missing protocol version number leads to crash\n\n\n  CVE-2006-6658: request with missing parameters leads to information exposure\n\n\n  CVE-2008-4114: system crash with offset value that is inconsistent with packet size\n\n\n  CVE-2006-3790: size field that is inconsistent with packet size leads to buffer\n  over-read\n\n\n  CVE-2008-2309: product uses a denylist to identify potentially dangerous content,\n  allowing attacker to bypass a warning\n\n\n  CVE-2008-3494: security bypass via an extra header\n\n\n  CVE-2008-3571: empty packet triggers reboot\n\n\n  CVE-2006-5525: incomplete denylist allows SQL injection\n\n\n  CVE-2008-1284: NUL byte in theme name causes directory traversal impact to be worse\n\n\n  CVE-2008-0600: kernel does not validate an incoming pointer before dereferencing\n  it\n\n\n  CVE-2008-1738: anti-virus product has insufficient input validation of hooked SSDT\n  functions, allowing code execution\n\n\n  CVE-2008-1737: anti-virus product allows DoS via zero-length field\n\n\n  CVE-2008-3464: driver does not validate input from userland to the kernel\n\n\n  CVE-2008-2252: kernel does not validate parameters sent in from userland, allowing\n  code execution\n\n\n  CVE-2008-2374: lack of validation of string length fields allows memory consumption\n  or buffer over-read\n\n\n  CVE-2008-1440: lack of validation of length field leads to infinite loop\n\n\n  CVE-2008-1625: lack of validation of input to an IOCTL allows code execution\n\n\n  CVE-2008-3177: zero-length attachment causes crash\n\n\n  CVE-2007-2442: zero-length input causes free of uninitialized pointer\n\n\n  CVE-2008-5563: crash via a malformed frame structure\n\n\n  CVE-2008-5285: infinite loop from a long SMTP request\n\n\n  CVE-2008-3812: router crashes with a malformed packet\n\n\n  CVE-2008-3680: packet with invalid version number leads to NULL pointer dereference\n\n\n  CVE-2008-3660: crash via multiple \".\" characters in file extension'\nRelated_Attack_Patterns: \"10: \\n\\n101: \\n\\n104: \\n\\n108: \\n\\n109: \\n\\n110: \\n\\n120:\\\n  \\ \\n\\n13: \\n\\n135: \\n\\n136: \\n\\n14: \\n\\n153: \\n\\n182: \\n\\n209: \\n\\n22: \\n\\n23: \\n\\\n  \\n230: \\n\\n231: \\n\\n24: \\n\\n250: \\n\\n261: \\n\\n267: \\n\\n28: \\n\\n3: \\n\\n31: \\n\\n42:\\\n  \\ \\n\\n43: \\n\\n45: \\n\\n46: \\n\\n47: \\n\\n473: \\n\\n52: \\n\\n53: \\n\\n588: \\n\\n63: \\n\\n\\\n  64: \\n\\n664: \\n\\n67: \\n\\n7: \\n\\n71: \\n\\n72: \\n\\n73: \\n\\n78: \\n\\n79: \\n\\n8: \\n\\n\\\n  80: \\n\\n81: \\n\\n83: \\n\\n85: \\n\\n88: \\n\\n9: \"\n",
  "ID: '200'\nName: Exposure of Sensitive Information to an Unauthorized Actor\nDescription: The product exposes sensitive information to an actor that is not explicitly\n  authorized to have access to that information.\nExtended_Description: 'There are many different kinds of mistakes that introduce information\n  exposures. The severity of the error can range widely, depending on the context\n  in which the product operates, the type of sensitive information that is revealed,\n  and the benefits it may provide to an attacker.  Some kinds of sensitive information\n  include:\n\n  Information might be sensitive to different parties, each of which may have their\n  own expectations for whether the information should be protected.  These parties\n  include:\n\n  Information exposures can occur in different ways:\n\n  It is common practice to describe any loss of confidentiality as an \"information\n  exposure,\" but this can lead to overuse of CWE-200 in CWE mapping. From the CWE\n  perspective, loss of confidentiality is a technical impact that can arise from dozens\n  of different weaknesses, such as insecure file permissions or out-of-bounds read.  CWE-200\n  and its lower-level descendants are intended to cover the mistakes that occur in\n  behaviors that explicitly manage, store, transfer, or cleanse sensitive information.'\nApplicable_Platforms:\n  Technology: Mobile\nAlternate_Terms: 'Information Disclosure: This term is frequently used in vulnerability\n  advisories to describe a consequence or technical impact, for any vulnerability\n  that has a loss of confidentiality. Often, CWE-200 can be misused to represent the\n  loss of confidentiality, even when the mistake - i.e., the weakness - is not directly\n  related to the mishandling of the information itself, such as an out-of-bounds read\n  that accesses sensitive memory contents; here, the out-of-bounds read is the primary\n  weakness, not the disclosure of the memory.  In addition, this phrase is also used\n  frequently in policies and legal documents, but it does not refer to any disclosure\n  of security-relevant information.\n\n\n  Information Leak: This is a frequently used term, however the \"leak\" term has multiple\n  uses within security. In some cases it deals with the accidental exposure of information\n  from a different weakness, but in other cases (such as \"memory leak\"), this deals\n  with improper tracking of resources, which can lead to exhaustion. As a result,\n  CWE is actively avoiding usage of the \"leak\" term.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2001-1483: Enumeration of valid usernames based on inconsistent\n  responses\n\n\n  CVE-2001-1528: Account number enumeration via inconsistent responses.\n\n\n  CVE-2004-2150: User enumeration via discrepancies in error messages.\n\n\n  CVE-2005-1205: Telnet protocol allows servers to obtain sensitive environment information\n  from clients.\n\n\n  CVE-2002-1725: Script calls phpinfo(), revealing system configuration to web user\n\n\n  CVE-2002-0515: Product sets a different TTL when a port is being filtered than when\n  it is not being filtered, which allows remote attackers to identify filtered ports\n  by comparing TTLs.\n\n\n  CVE-2004-0778: Version control system allows remote attackers to determine the existence\n  of arbitrary files and directories via the -X command for an alternate history file,\n  which causes different error messages to be returned.\n\n\n  CVE-2000-1117: Virtual machine allows malicious web site operators to determine\n  the existence of files on the client by measuring delays in the execution of the\n  getSystemResource method.\n\n\n  CVE-2003-0190: Product immediately sends an error message when a user does not exist,\n  which allows remote attackers to determine valid usernames via a timing attack.\n\n\n  CVE-2008-2049: POP3 server reveals a password in an error message after multiple\n  APOP commands are sent. Might be resultant from another weakness.\n\n\n  CVE-2007-5172: Program reveals password in error message if attacker can trigger\n  certain database errors.\n\n\n  CVE-2008-4638: Composite: application running with high privileges (CWE-250) allows\n  user to specify a restricted file to process, which generates a parsing error that\n  leaks the contents of the file (CWE-209).\n\n\n  CVE-2007-1409: Direct request to library file in web application triggers pathname\n  leak in error message.\n\n\n  CVE-2005-0603: Malformed regexp syntax leads to information exposure in error message.\n\n\n  CVE-2004-2268: Password exposed in debug information.\n\n\n  CVE-2003-1078: FTP client with debug option enabled shows password to the screen.\n\n\n  CVE-2022-0708: Collaboration platform does not clear team emails in a response,\n  allowing leak of email addresses'\nRelated_Attack_Patterns: \"116: \\n\\n13: \\n\\n169: \\n\\n22: \\n\\n224: \\n\\n285: \\n\\n287:\\\n  \\ \\n\\n290: \\n\\n291: \\n\\n292: \\n\\n293: \\n\\n294: \\n\\n295: \\n\\n296: \\n\\n297: \\n\\n298:\\\n  \\ \\n\\n299: \\n\\n300: \\n\\n301: \\n\\n302: \\n\\n303: \\n\\n304: \\n\\n305: \\n\\n306: \\n\\n307:\\\n  \\ \\n\\n308: \\n\\n309: \\n\\n310: \\n\\n312: \\n\\n313: \\n\\n317: \\n\\n318: \\n\\n319: \\n\\n320:\\\n  \\ \\n\\n321: \\n\\n322: \\n\\n323: \\n\\n324: \\n\\n325: \\n\\n326: \\n\\n327: \\n\\n328: \\n\\n329:\\\n  \\ \\n\\n330: \\n\\n472: \\n\\n497: \\n\\n508: \\n\\n573: \\n\\n574: \\n\\n575: \\n\\n576: \\n\\n577:\\\n  \\ \\n\\n59: \\n\\n60: \\n\\n616: \\n\\n643: \\n\\n646: \\n\\n651: \\n\\n79: \"\n",
  "ID: '201'\nName: Insertion of Sensitive Information Into Sent Data\nDescription: The code transmits data to another actor, but a portion of the data includes\n  sensitive information that should not be accessible to that actor.\nExtended_Description: Sensitive information could include data that is sensitive in\n  and of itself (such as credentials or private messages), or otherwise useful in\n  the further exploitation of the system (such as internal file system structure).\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Specify which data in the software should be\n  regarded as sensitive. Consider which types of users should have access to which\n  types of data.\n\n\n  Implementation: Ensure that any possibly sensitive data specified in the requirements\n  is verified with designers to ensure that it is either a calculated risk or mitigated\n  elsewhere. Any information that is not necessary to the functionality should be\n  removed in order to lower both the overhead and the possibility of security sensitive\n  data being sent.\n\n\n  System Configuration: Setup default error messages so that unexpected errors do\n  not disclose sensitive information.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2022-0708: Collaboration platform does not clear team emails\n  in a response, allowing leak of email addresses'\nRelated_Attack_Patterns: \"12: \\n\\n217: \\n\\n612: \\n\\n613: \\n\\n618: \\n\\n619: \\n\\n621:\\\n  \\ \\n\\n622: \\n\\n623: \"\n",
  "ID: '202'\nName: Exposure of Sensitive Information Through Data Queries\nDescription: When trying to keep information confidential, an attacker can often infer\n  some of the information by using statistics.\nExtended_Description: In situations where data should not be tied to individual users,\n  but a large number of users should be able to make queries that \"scrub\" the identity\n  of users, it may be possible to get information about a user -- e.g., by specifying\n  search terms that are known to be unique to that user.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: This is a complex topic. See the\n  book Translucent Databases for a good discussion of best practices.'\n",
  "ID: '203'\nName: Observable Discrepancy\nDescription: The product behaves differently or sends different responses under different\n  circumstances in a way that is observable to an unauthorized actor, which exposes\n  security-relevant information about the state of the product, such as whether a\n  particular operation was successful or not.\nExtended_Description: Discrepancies can take many forms, and variations may be detectable\n  in timing, control flow, communications such as replies or requests, or general\n  behavior. These discrepancies can reveal information about the product's operation\n  or internal state to an unauthorized actor. In some cases, discrepancies can be\n  used by attackers to form a side channel.\nAlternate_Terms: 'Side Channel Attack: Observable Discrepancies are at the root of\n  side channel attacks.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation: Ensure that error messages only contain minimal details that are\n  useful to the intended audience and no one else. The messages need to strike the\n  balance between being too cryptic (which can confuse users) or being too detailed\n  (which may reveal more than intended). The messages should not reveal the methods\n  that were used to determine the error. Attackers can use detailed information to\n  refine or optimize their original attack, thereby increasing their chances of success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.'\nObserved_Examples: 'CVE-2020-8695: Observable discrepancy in the RAPL interface for\n  some Intel processors allows information disclosure.\n\n\n  CVE-2002-2094: This, and others, use \"..\" attacks and monitor error responses, so\n  there is overlap with directory traversal.\n\n\n  CVE-2001-1483: Enumeration of valid usernames based on inconsistent responses\n\n\n  CVE-2001-1528: Account number enumeration via inconsistent responses.\n\n\n  CVE-2004-2150: User enumeration via discrepancies in error messages.\n\n\n  CVE-2005-1650: User enumeration via discrepancies in error messages.\n\n\n  CVE-2004-0294: Bulletin Board displays different error messages when a user exists\n  or not, which makes it easier for remote attackers to identify valid users and conduct\n  a brute force password guessing attack.\n\n\n  CVE-2004-0243: Operating System, when direct remote login is disabled, displays\n  a different message if the password is correct, which allows remote attackers to\n  guess the password via brute force methods.\n\n\n  CVE-2002-0514: Product allows remote attackers to determine if a port is being filtered\n  because the response packet TTL is different than the default TTL.\n\n\n  CVE-2002-0515: Product sets a different TTL when a port is being filtered than when\n  it is not being filtered, which allows remote attackers to identify filtered ports\n  by comparing TTLs.\n\n\n  CVE-2002-0208: Product modifies TCP/IP stack and ICMP error messages in unusual\n  ways that show the product is in use.\n\n\n  CVE-2004-2252: Behavioral infoleak by responding to SYN-FIN packets.\n\n\n  CVE-2001-1387: Product may generate different responses than specified by the administrator,\n  possibly leading to an information leak.\n\n\n  CVE-2004-0778: Version control system allows remote attackers to determine the existence\n  of arbitrary files and directories via the -X command for an alternate history file,\n  which causes different error messages to be returned.\n\n\n  CVE-2004-1428: FTP server generates an error message if the user name does not exist\n  instead of prompting for a password, which allows remote attackers to determine\n  valid usernames.\n\n\n  CVE-2003-0078: SSL implementation does not perform a MAC computation if an incorrect\n  block cipher padding is used, which causes an information leak (timing discrepancy)\n  that may make it easier to launch cryptographic attacks that rely on distinguishing\n  between padding and MAC verification errors, possibly leading to extraction of the\n  original plaintext, aka the \"Vaudenay timing attack.\"\n\n\n  CVE-2000-1117: Virtual machine allows malicious web site operators to determine\n  the existence of files on the client by measuring delays in the execution of the\n  getSystemResource method.\n\n\n  CVE-2003-0637: Product uses a shorter timeout for a non-existent user than a valid\n  user, which makes it easier for remote attackers to guess usernames and conduct\n  brute force password guessing.\n\n\n  CVE-2003-0190: Product immediately sends an error message when a user does not exist,\n  which allows remote attackers to determine valid usernames via a timing attack.\n\n\n  CVE-2004-1602: FTP server responds in a different amount of time when a given username\n  exists, which allows remote attackers to identify valid usernames by timing the\n  server response.\n\n\n  CVE-2005-0918: Browser allows remote attackers to determine the existence of arbitrary\n  files by setting the src property to the target filename and using Javascript to\n  determine if the web page immediately stops loading, which indicates whether the\n  file exists or not.'\nRelated_Attack_Patterns: '189: '\n",
  "ID: '204'\nName: Observable Response Discrepancy\nDescription: The product provides different responses to incoming requests in a way\n  that reveals internal state information to an unauthorized actor outside of the\n  intended control sphere.\nExtended_Description: This issue frequently occurs during authentication, where a\n  difference in failed-login messages could allow an attacker to determine if the\n  username is valid or not. These exposures can be inadvertent (bug) or intentional\n  (design).\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation: Ensure that error messages only contain minimal details that are\n  useful to the intended audience and no one else. The messages need to strike the\n  balance between being too cryptic (which can confuse users) or being too detailed\n  (which may reveal more than intended). The messages should not reveal the methods\n  that were used to determine the error. Attackers can use detailed information to\n  refine or optimize their original attack, thereby increasing their chances of success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.'\nObserved_Examples: 'CVE-2002-2094: This, and others, use \"..\" attacks and monitor\n  error responses, so there is overlap with directory traversal.\n\n\n  CVE-2001-1483: Enumeration of valid usernames based on inconsistent responses\n\n\n  CVE-2001-1528: Account number enumeration via inconsistent responses.\n\n\n  CVE-2004-2150: User enumeration via discrepancies in error messages.\n\n\n  CVE-2005-1650: User enumeration via discrepancies in error messages.\n\n\n  CVE-2004-0294: Bulletin Board displays different error messages when a user exists\n  or not, which makes it easier for remote attackers to identify valid users and conduct\n  a brute force password guessing attack.\n\n\n  CVE-2004-0243: Operating System, when direct remote login is disabled, displays\n  a different message if the password is correct, which allows remote attackers to\n  guess the password via brute force methods.\n\n\n  CVE-2002-0514: Product allows remote attackers to determine if a port is being filtered\n  because the response packet TTL is different than the default TTL.\n\n\n  CVE-2002-0515: Product sets a different TTL when a port is being filtered than when\n  it is not being filtered, which allows remote attackers to identify filtered ports\n  by comparing TTLs.\n\n\n  CVE-2001-1387: Product may generate different responses than specified by the administrator,\n  possibly leading to an information leak.\n\n\n  CVE-2004-0778: Version control system allows remote attackers to determine the existence\n  of arbitrary files and directories via the -X command for an alternate history file,\n  which causes different error messages to be returned.\n\n\n  CVE-2004-1428: FTP server generates an error message if the user name does not exist\n  instead of prompting for a password, which allows remote attackers to determine\n  valid usernames.'\nRelated_Attack_Patterns: \"331: \\n\\n332: \\n\\n541: \\n\\n580: \"\n",
  "ID: '205'\nName: Observable Behavioral Discrepancy\nDescription: The product's behaviors indicate important differences that may be observed\n  by unauthorized actors in a way that reveals (1) its internal state or decision\n  process, or (2) differences from other products with equivalent functionality.\nExtended_Description: Ideally, a product should provide as little information about\n  its internal operations as possible.  Otherwise, attackers could use knowledge of\n  these internal operations to simplify or optimize their attack.  In some cases,\n  behavioral discrepancies can be used by attackers to form a side channel.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2002-0208: Product modifies TCP/IP stack and ICMP error messages\n  in unusual ways that show the product is in use.\n\n\n  CVE-2004-2252: Behavioral infoleak by responding to SYN-FIN packets.'\nRelated_Attack_Patterns: \"541: \\n\\n580: \"\n",
  "ID: '206'\nName: Observable Internal Behavioral Discrepancy\nDescription: The product performs multiple behaviors that are combined to produce\n  a single result, but the individual behaviors are observable separately in a way\n  that allows attackers to reveal internal state or internal decision points.\nExtended_Description: 'Ideally, a product should provide as little information as\n  possible to an attacker.  Any hints that the attacker may be making progress can\n  then be used to simplify or optimize the attack.  For example, in a login procedure\n  that requires a username and password, ultimately there is only one decision: success\n  or failure.  However, internally, two separate actions are performed: determining\n  if the username exists, and checking if the password is correct.  If the product\n  behaves differently based on whether the username exists or not, then the attacker\n  only needs to concentrate on the password.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2002-2031: File existence via infoleak monitoring whether\n  \"onerror\" handler fires or not.\n\n\n  CVE-2005-2025: Valid groupname enumeration via behavioral infoleak (sends response\n  if valid, doesn''t respond if not).\n\n\n  CVE-2001-1497: Behavioral infoleak in GUI allows attackers to distinguish between\n  alphanumeric and non-alphanumeric characters in a password, thus reducing the search\n  space.\n\n\n  CVE-2003-0190: Product immediately sends an error message when user does not exist\n  instead of waiting until the password is provided, allowing username enumeration.'\n",
  "ID: '207'\nName: Observable Behavioral Discrepancy With Equivalent Products\nDescription: The product operates in an environment in which its existence or specific\n  identity should not be known, but it behaves differently than other products with\n  equivalent functionality, in a way that is observable to an attacker.\nExtended_Description: For many kinds of products, multiple products may be available\n  that perform the same functionality, such as a web server, network interface, or\n  intrusion detection system.  Attackers often perform \"fingerprinting,\" which uses\n  discrepancies in order to identify which specific product is in use.  Once the specific\n  product has been identified, the attacks can be made more customized and efficient.  Often,\n  an organization might intentionally allow the specific product to be identifiable.  However,\n  in some environments, the ability to identify a distinct product is unacceptable,\n  and it is expected that every product would behave in exactly the same way.  In\n  these more restricted environments, a behavioral difference might pose an unacceptable\n  risk if it makes it easier to identify the product's vendor, model, configuration,\n  version, etc.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2002-0208: Product modifies TCP/IP stack and ICMP error messages\n  in unusual ways that show the product is in use.\n\n\n  CVE-2004-2252: Behavioral infoleak by responding to SYN-FIN packets.\n\n\n  CVE-2000-1142: Honeypot generates an error with a \"pwd\" command in a particular\n  directory, allowing attacker to know they are in a honeypot system.'\n",
  "ID: '208'\nName: Observable Timing Discrepancy\nDescription: Two separate operations in a product require different amounts of time\n  to complete, in a way that is observable to an actor and reveals security-relevant\n  information about the state of the product, such as whether a particular operation\n  was successful or not.\nExtended_Description: In security-relevant contexts, even small variations in timing\n  can be exploited by attackers to indirectly infer certain details about the product's\n  internal operations.  For example, in some cryptographic algorithms, attackers can\n  use timing differences to infer certain properties about a private key, making the\n  key easier to guess.  Timing discrepancies effectively form a timing side channel.\nModes_Of_Introduction: \"Architecture and Design: COMMISSION: This weakness refers\\\n  \\ to an incorrect design related to an architectural security tactic.\\n\\nImplementation:\\\n  \\ \\n\\nOperation: \"\nObserved_Examples: 'CVE-2019-10482: Smartphone OS uses comparison functions that are\n  not in constant time, allowing side channels\n\n\n  CVE-2014-0984: Password-checking function in router terminates validation of a password\n  entry when it encounters the first incorrect character, which allows remote attackers\n  to obtain passwords via a brute-force attack that relies on timing differences in\n  responses to incorrect password guesses, aka a timing side-channel attack.\n\n\n  CVE-2003-0078: SSL implementation does not perform a MAC computation if an incorrect\n  block cipher padding is used, which causes an information leak (timing discrepancy)\n  that may make it easier to launch cryptographic attacks that rely on distinguishing\n  between padding and MAC verification errors, possibly leading to extraction of the\n  original plaintext, aka the \"Vaudenay timing attack.\"\n\n\n  CVE-2000-1117: Virtual machine allows malicious web site operators to determine\n  the existence of files on the client by measuring delays in the execution of the\n  getSystemResource method.\n\n\n  CVE-2003-0637: Product uses a shorter timeout for a non-existent user than a valid\n  user, which makes it easier for remote attackers to guess usernames and conduct\n  brute force password guessing.\n\n\n  CVE-2003-0190: Product immediately sends an error message when a user does not exist,\n  which allows remote attackers to determine valid usernames via a timing attack.\n\n\n  CVE-2004-1602: FTP server responds in a different amount of time when a given username\n  exists, which allows remote attackers to identify valid usernames by timing the\n  server response.\n\n\n  CVE-2005-0918: Browser allows remote attackers to determine the existence of arbitrary\n  files by setting the src property to the target filename and using Javascript to\n  determine if the web page immediately stops loading, which indicates whether the\n  file exists or not.'\nRelated_Attack_Patterns: \"462: \\n\\n541: \\n\\n580: \"\n",
  "ID: '209'\nName: Generation of Error Message Containing Sensitive Information\nDescription: The product generates an error message that includes sensitive information\n  about its environment, users, or associated data.\nExtended_Description: 'The sensitive information may be valuable information on its\n  own (such as a password), or it may be useful for launching other, more serious\n  attacks. The error message may be created in different ways:\n\n  An attacker may use the contents of error messages to help launch another, more\n  focused attack. For example, an attempt to exploit a path traversal weakness (CWE-22)\n  might yield the full pathname of the installed application. In turn, this could\n  be used to select the proper number of \"..\" sequences to navigate to the targeted\n  file. An attack using SQL injection (CWE-89) might not initially succeed, but an\n  error message could reveal the malformed query, which would expose query logic and\n  possibly even passwords or other sensitive information used within the query.'\nApplicable_Platforms:\n  Language: PHP, Java\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nSystem Configuration: \\n\\nOperation: \"\nDetection_Methods: 'Manual Analysis: This weakness generally requires domain-specific\n  interpretation using manual analysis. However, the number of potential error conditions\n  may be too large to cover completely within limited time constraints.\n\n\n  Automated Analysis: Automated methods may be able to detect certain idioms automatically,\n  such as exposed stack traces or pathnames, but violation of business rules or privacy\n  requirements is not typically feasible.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n  Error conditions may be triggered with a stress-test by calling the software simultaneously\n  from a large number of threads or processes, and look for evidence of any unexpected\n  behavior.\n\n\n  Manual Dynamic Analysis: Identify error conditions that are not likely to occur\n  during normal usage and trigger them. For example, run the program under low memory\n  conditions, run with insufficient privileges or permissions, interrupt a transaction\n  before it is completed, or disable connectivity to basic network services such as\n  DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled\n  exception or similar error that was discovered and handled by the application''s\n  environment, it may still indicate unexpected conditions that were not handled by\n  the application itself.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Ensure that error messages only contain minimal\n  details that are useful to the intended audience and no one else. The messages need\n  to strike the balance between being too cryptic (which can confuse users) or being\n  too detailed (which may reveal more than intended). The messages should not reveal\n  the methods that were used to determine the error. Attackers can use detailed information\n  to refine or optimize their original attack, thereby increasing their chances of\n  success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.\n\n\n  Implementation: Handle exceptions internally and do not display errors containing\n  potentially sensitive information to a user.\n\n\n  Implementation: Use naming conventions and strong types to make it easier to spot\n  when sensitive data is being used. When creating structures, objects, or other complex\n  entities, separate the sensitive and non-sensitive data as much as possible.\n\n\n  Implementation\n\n  Build and Compilation: Debugging information should not make its way into a production\n  release.\n\n\n  Implementation\n\n  Build and Compilation: Debugging information should not make its way into a production\n  release.\n\n\n  System Configuration: Where available, configure the environment to use less verbose\n  error messages. For example, in PHP, disable the display_errors setting during configuration,\n  or at runtime using the error_reporting() function.\n\n\n  System Configuration: Create default error pages or messages that do not leak any\n  information.'\nObserved_Examples: 'CVE-2008-2049: POP3 server reveals a password in an error message\n  after multiple APOP commands are sent. Might be resultant from another weakness.\n\n\n  CVE-2007-5172: Program reveals password in error message if attacker can trigger\n  certain database errors.\n\n\n  CVE-2008-4638: Composite: application running with high privileges (CWE-250) allows\n  user to specify a restricted file to process, which generates a parsing error that\n  leaks the contents of the file (CWE-209).\n\n\n  CVE-2008-1579: Existence of user names can be determined by requesting a nonexistent\n  blog and reading the error message.\n\n\n  CVE-2007-1409: Direct request to library file in web application triggers pathname\n  leak in error message.\n\n\n  CVE-2008-3060: Malformed input to login page causes leak of full path when IMAP\n  call fails.\n\n\n  CVE-2005-0603: Malformed regexp syntax leads to information exposure in error message.\n\n\n  CVE-2017-9615: verbose logging stores admin credentials in a world-readablelog file\n\n\n  CVE-2018-1999036: SSH password for private key stored in build log'\nRelated_Attack_Patterns: \"215: \\n\\n463: \\n\\n54: \\n\\n7: \"\n",
  "ID: '210'\nName: Self-generated Error Message Containing Sensitive Information\nDescription: The product identifies an error condition and creates its own diagnostic\n  or error messages that contain sensitive information.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Implementation\n\n  Build and Compilation: Debugging information should not make its way into a production\n  release.\n\n\n  Implementation\n\n  Build and Compilation: Debugging information should not make its way into a production\n  release.'\nObserved_Examples: 'CVE-2005-1745: Infoleak of sensitive information in error message\n  (physical access required).'\n",
  "ID: '211'\nName: Externally-Generated Error Message Containing Sensitive Information\nDescription: The product performs an operation that triggers an external diagnostic\n  or error message that is not directly generated or controlled by the product, such\n  as an error generated by the programming language interpreter that a software application\n  uses. The error can contain sensitive system information.\nApplicable_Platforms:\n  Language: PHP\nModes_Of_Introduction: 'Architecture and Design: PHP applications are often targeted\n  for having this issue when the PHP interpreter generates the error outside of the\n  application''s control. However, other languages/environments exhibit the same issue.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.\n\n\n  Operation: '\nPotential_Mitigations: 'System Configuration: Configure the application''s environment\n  in a way that prevents errors from being generated. For example, in PHP, disable\n  display_errors.\n\n\n  Implementation\n\n  Build and Compilation: Debugging information should not make its way into a production\n  release.\n\n\n  Implementation\n\n  Build and Compilation: Debugging information should not make its way into a production\n  release.\n\n\n  Implementation: Handle exceptions internally and do not display errors containing\n  potentially sensitive information to a user. Create default error pages if necessary.\n\n\n  Implementation: The best way to prevent this weakness during implementation is to\n  avoid any bugs that could trigger the external error message. This typically happens\n  when the program encounters fatal errors, such as a divide-by-zero. You will not\n  always be able to control the use of error pages, and you might not be using a language\n  that handles exceptions.'\nObserved_Examples: 'CVE-2004-1581: chain: product does not protect against direct\n  request of an include file, leading to resultant path disclosure when the include\n  file does not successfully execute.\n\n\n  CVE-2004-1579: Single \"''\" inserted into SQL query leads to invalid SQL query execution,\n  triggering full path disclosure. Possibly resultant from more general SQL injection\n  issue.\n\n\n  CVE-2005-0459: chain: product does not protect against direct request of a library\n  file, leading to resultant path disclosure when the file does not successfully execute.\n\n\n  CVE-2005-0443: invalid parameter triggers a failure to find an include file, leading\n  to infoleak in error message.\n\n\n  CVE-2005-0433: Various invalid requests lead to information leak in verbose error\n  messages describing the failure to instantiate a class, open a configuration file,\n  or execute an undefined function.\n\n\n  CVE-2004-1101: Improper handling of filename request with trailing \"/\" causes multiple\n  consequences, including information leak in Visual Basic error message.'\n",
  "ID: '212'\nName: Improper Removal of Sensitive Information Before Storage or Transfer\nDescription: The product stores, transfers, or shares a resource that contains sensitive\n  information, but it does not properly remove that information before the product\n  makes the resource available to unauthorized actors.\nExtended_Description: 'Resources that may contain sensitive data include documents,\n  packets, messages, databases, etc. While this data may be useful to an individual\n  user or small set of users who share the resource, it may need to be removed before\n  the resource can be shared outside of the trusted group. The process of removal\n  is sometimes called cleansing or scrubbing.\n\n  For example, a product for editing documents might not remove sensitive data such\n  as reviewer comments or the local pathname where the document is stored. Or, a proxy\n  might not remove an internal IP address from headers before making an outgoing request\n  to an Internet site.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Requirements: Clearly specify which information should be\n  regarded as private or sensitive, and require that the product offers functionality\n  that allows the user to cleanse the sensitive information from the resource before\n  it is published or exported to other parties.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation: Use naming conventions and strong types to make it easier to spot\n  when sensitive data is being used. When creating structures, objects, or other complex\n  entities, separate the sensitive and non-sensitive data as much as possible.\n\n\n  Implementation: Avoid errors related to improper resource shutdown or release (CWE-404),\n  which may leave the sensitive data within the resource if it is in an incomplete\n  state.'\nObserved_Examples: 'CVE-2005-0406: Some image editors modify a JPEG image, but the\n  original EXIF thumbnail image is left intact within the JPEG. (Also an interaction\n  error).\n\n\n  CVE-2002-0704: NAT feature in firewall leaks internal IP addresses in ICMP error\n  messages.'\nRelated_Attack_Patterns: '168: '\n",
  "ID: '213'\nName: Exposure of Sensitive Information Due to Incompatible Policies\nDescription: The product's intended functionality exposes information to certain actors\n  in accordance with the developer's security policy, but this information is regarded\n  as sensitive according to the intended security policies of other stakeholders such\n  as the product's administrator, users, or others whose information is being processed.\nExtended_Description: When handling information, the developer must consider whether\n  the information is regarded as sensitive by different stakeholders, such as users\n  or administrators.  Each stakeholder effectively has its own intended security policy\n  that the product is expected to uphold.  When a developer does not treat that information\n  as sensitive, this can introduce a vulnerability that violates the expectations\n  of the product's users.\nModes_Of_Introduction: 'Policy: This can occur when the product''s policy does not\n  account for all relevant stakeholders, or when the policies of other stakeholders\n  are not interpreted properly.\n\n\n  Requirements: This can occur when requirements do not explicitly account for all\n  relevant stakeholders.\n\n\n  Architecture and Design: Communications or data exchange frameworks may be chosen\n  that exchange or provide access to more information than strictly needed.\n\n\n  Implementation: This can occur when the developer does not properly track the flow\n  of sensitive information and how it is exposed, e.g., via an API.'\nObserved_Examples: 'CVE-2002-1725: Script calls phpinfo()\n\n\n  CVE-2004-0033: Script calls phpinfo()\n\n\n  CVE-2003-1181: Script calls phpinfo()\n\n\n  CVE-2004-1422: Script calls phpinfo()\n\n\n  CVE-2004-1590: Script calls phpinfo()\n\n\n  CVE-2003-1038: Product lists DLLs and full pathnames.\n\n\n  CVE-2005-1205: Telnet protocol allows servers to obtain sensitive environment information\n  from clients.\n\n\n  CVE-2005-0488: Telnet protocol allows servers to obtain sensitive environment information\n  from clients.'\n",
  "ID: '214'\nName: Invocation of Process Using Visible Sensitive Information\nDescription: A process is invoked with sensitive command-line arguments, environment\n  variables, or other elements that can be seen by other processes on the operating\n  system.\nExtended_Description: Many operating systems allow a user to list information about\n  processes that are owned by other users. Other users could see information such\n  as command line arguments or environment variable settings. When this data contains\n  sensitive information such as credentials, it might allow other users to launch\n  an attack against the product or related resources.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nObserved_Examples: 'CVE-2005-1387: password passed on command line\n\n\n  CVE-2005-2291: password passed on command line\n\n\n  CVE-2001-1565: username/password on command line allows local users to view via\n  \"ps\" or other process listing programs\n\n\n  CVE-2004-1948: Username/password on command line allows local users to view via\n  \"ps\" or other process listing programs.\n\n\n  CVE-1999-1270: PGP passphrase provided as command line argument.\n\n\n  CVE-2004-1058: Kernel race condition allows reading of environment variables of\n  a process that is still spawning.\n\n\n  CVE-2021-32638: Code analysis product passes access tokens as a command-line parameter\n  or through an environment variable, making them visible to other processes via the\n  ps command.'\n",
  "ID: '215'\nName: Insertion of Sensitive Information Into Debugging Code\nDescription: The product inserts sensitive information into debugging code, which\n  could expose this information if the debugging code is not disabled in production.\nExtended_Description: When debugging, it may be necessary to report detailed information\n  to the programmer.  However, if the debugging code is not disabled when the product\n  is operating in a production environment, then this sensitive information may be\n  exposed to attackers.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Do not leave debug statements that could be\n  executed in the source code. Ensure that all debug information is eradicated before\n  releasing the software.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2004-2268: Password exposed in debug information.\n\n\n  CVE-2002-0918: CGI script includes sensitive information in debug messages when\n  an error is triggered.\n\n\n  CVE-2003-1078: FTP client with debug option enabled shows password to the screen.'\n",
  "ID: '216'\nName: 'DEPRECATED: Containment Errors (Container Errors)'\nDescription: This entry has been deprecated, as it was not effective as a weakness\n  and was structured more like a category. In addition, the name is inappropriate,\n  since the \"container\" term is widely understood by developers in different ways\n  than originally intended by PLOVER, the original source for this entry.\n",
  "ID: '217'\nName: 'DEPRECATED: Failure to Protect Stored Data from Modification'\nDescription: This entry has been deprecated because it incorporated and confused multiple\n  weaknesses. The issues formerly covered in this entry can be found at CWE-766 and\n  CWE-767.\n",
  "ID: '218'\nName: 'DEPRECATED: Failure to provide confidentiality for stored data'\nDescription: This weakness has been deprecated because it was a duplicate of CWE-493.\n  All content has been transferred to CWE-493.\n",
  "ID: '219'\nName: Storage of File with Sensitive Data Under Web Root\nDescription: The product stores sensitive data under the web document root with insufficient\n  access control, which might make it accessible to untrusted parties.\nExtended_Description: Besides public-facing web pages and code, products may store\n  sensitive data, code that is not directly invoked, or other files under the web\n  document root of the web server.  If the server is not configured or otherwise used\n  to prevent direct access to those files, then attackers may obtain this sensitive\n  data.\nModes_Of_Introduction: 'Operation: COMMISSION: This weakness refers to an incorrect\n  design related to an architectural security tactic.\n\n\n  Implementation: COMMISSION: This weakness refers to an incorrect design related\n  to an architectural security tactic.'\nPotential_Mitigations: 'Implementation, System Configuration: Avoid storing information\n  under the web root directory.\n\n\n  System Configuration: Access control permissions should be set to prevent reading/writing\n  of sensitive files inside/outside of the web directory.'\nObserved_Examples: 'CVE-2005-1835: Data file under web root.\n\n\n  CVE-2005-2217: Data file under web root.\n\n\n  CVE-2002-1449: Username/password in data file under web root.\n\n\n  CVE-2002-0943: Database file under web root.\n\n\n  CVE-2005-1645: database file under web root.'\n",
  "ID: '22'\nName: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')\nDescription: The product uses external input to construct a pathname that is intended\n  to identify a file or directory that is located underneath a restricted parent directory,\n  but the product does not properly neutralize special elements within the pathname\n  that can cause the pathname to resolve to a location that is outside of the restricted\n  directory.\nExtended_Description: 'Many file operations are intended to take place within a restricted\n  directory. By using special elements such as \"..\" and \"/\" separators, attackers\n  can escape outside of the restricted location to access files or directories that\n  are elsewhere on the system. One of the most common special elements is the \"../\"\n  sequence, which in most modern operating systems is interpreted as the parent directory\n  of the current location. This is referred to as relative path traversal. Path traversal\n  also covers the use of absolute pathnames such as \"/usr/local/bin\", which may also\n  be useful in accessing unexpected files. This is referred to as absolute path traversal.\n\n  In many programming languages, the injection of a null byte (the 0 or NUL) may allow\n  an attacker to truncate a generated filename to widen the scope of attack. For example,\n  the product may add \".txt\" to any pathname, thus limiting the attacker to text files,\n  but a null injection may effectively remove this restriction.'\nAlternate_Terms: \"Directory traversal: \\n\\nPath traversal: \\\"Path traversal\\\" is preferred\\\n  \\ over \\\"directory traversal,\\\" but both terms are attack-focused.\"\nDetection_Methods: 'Automated Static Analysis: Automated techniques can find areas\n  where path traversal weaknesses exist. However, tuning or customization may be required\n  to remove or de-prioritize path-traversal problems that are only exploitable by\n  the product''s administrator - or other privileged users - and thus potentially\n  valid behavior or, at worst, a bug instead of a vulnerability.\n\n\n  Manual Static Analysis: Manual white box techniques may be able to provide sufficient\n  code coverage and reduction of false positives if all file access operations can\n  be assessed within limited time constraints.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.\n\n  Use a built-in path canonicalization function (such as realpath() in C) that produces\n  the canonical version of the pathname, which effectively removes \"..\" sequences\n  and symbolic links (CWE-23, CWE-59). This includes:\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n  For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\".\n  Features such as the ESAPI AccessReferenceMap [REF-185] provide this capability.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Architecture and Design\n\n  Operation: Store library, include, and utility files outside of the web document\n  root, if possible. Otherwise, store them in a separate directory and use the web\n  server''s access control capabilities to prevent attackers from directly requesting\n  them. One common practice is to define a fixed constant in each calling program,\n  then check for the existence of the constant in the library/include file; if the\n  constant does not exist, then the file was directly requested, and it can exit immediately.\n\n  This significantly reduces the chance of an attacker being able to bypass any protection\n  mechanisms that are in the base program but not in the include files. It will also\n  reduce the attack surface.\n\n\n  Implementation: Ensure that error messages only contain minimal details that are\n  useful to the intended audience and no one else. The messages need to strike the\n  balance between being too cryptic (which can confuse users) or being too detailed\n  (which may reveal more than intended). The messages should not reveal the methods\n  that were used to determine the error. Attackers can use detailed information to\n  refine or optimize their original attack, thereby increasing their chances of success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.\n\n  In the context of path traversal, error messages which disclose path information\n  can help attackers craft the appropriate attack strings to move through the file\n  system hierarchy.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.'\nObserved_Examples: 'CVE-2019-20916: Python package manager does not correctly restrict\n  the filename specified in a Content-Disposition header, allowing arbitrary file\n  read using path traversal sequences such as \"../\"\n\n\n  CVE-2022-31503: Python package constructs filenames using an unsafe os.path.join\n  call on untrusted input, allowing absolute path traversal because os.path.join resets\n  the pathname to an absolute path that is specified as part of the input.\n\n\n  CVE-2022-24877: directory traversal in Go-based Kubernetes operator app allows accessing\n  data from the controller''s pod file system via ../ sequences in a yaml file\n\n\n  CVE-2021-21972: Chain: Cloud computing virtualization platform does not require\n  authentication for upload of a tar format file (CWE-306), then uses .. path traversal\n  sequences (CWE-23) in the file to access unexpected files, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2020-4053: a Kubernetes package manager written in Go allows malicious plugins\n  to inject path traversal sequences into a plugin archive (\"Zip slip\") to copy a\n  file outside the intended directory\n\n\n  CVE-2020-3452: Chain: security product has improper input validation (CWE-20) leading\n  to directory traversal (CWE-22), as exploited in the wild per CISA KEV.\n\n\n  CVE-2019-10743: Go-based archive library allows extraction of  files to locations\n  outside of the target folder with \"../\" path traversal sequences in filenames in\n  a zip file, aka \"Zip Slip\"\n\n\n  CVE-2010-0467: Newsletter module allows reading arbitrary files using \"../\" sequences.\n\n\n  CVE-2009-4194: FTP server allows deletion of arbitrary files using \"..\" in the DELE\n  command.\n\n\n  CVE-2009-4053: FTP server allows creation of arbitrary directories using \"..\" in\n  the MKD command.\n\n\n  CVE-2009-0244: FTP service for a Bluetooth device allows listing of directories,\n  and creation or reading of files using \"..\" sequences.\n\n\n  CVE-2009-4013: Software package maintenance program allows overwriting arbitrary\n  files using \"../\" sequences.\n\n\n  CVE-2009-4449: Bulletin board allows attackers to determine the existence of files\n  using the avatar.\n\n\n  CVE-2009-4581: PHP program allows arbitrary code execution using \"..\" in filenames\n  that are fed to the include() function.\n\n\n  CVE-2010-0012: Overwrite of files using a .. in a Torrent file.\n\n\n  CVE-2010-0013: Chat program allows overwriting files using a custom smiley request.\n\n\n  CVE-2008-5748: Chain: external control of values for user''s desired language and\n  theme enables path traversal.\n\n\n  CVE-2009-1936: Chain: library file sends a redirect if it is directly requested\n  but continues to execute, allowing remote file inclusion and path traversal.'\nRelated_Attack_Patterns: \"126: \\n\\n64: \\n\\n76: \\n\\n78: \\n\\n79: \"\n",
  "ID: '220'\nName: Storage of File With Sensitive Data Under FTP Root\nDescription: The product stores sensitive data under the FTP server root with insufficient\n  access control, which might make it accessible to untrusted parties.\nModes_Of_Introduction: \"Operation: \\n\\nArchitecture and Design: COMMISSION: This weakness\\\n  \\ refers to an incorrect design related to an architectural security tactic.\"\nPotential_Mitigations: 'Implementation, System Configuration: Avoid storing information\n  under the FTP root directory.\n\n\n  System Configuration: Access control permissions should be set to prevent reading/writing\n  of sensitive files inside/outside of the FTP directory.'\n",
  "ID: '221'\nName: Information Loss or Omission\nDescription: The product does not record, or improperly records, security-relevant\n  information that leads to an incorrect decision or hampers later analysis.\nExtended_Description: This can be resultant, e.g. a buffer overflow might trigger\n  a crash before the product can log the event.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nRelated_Attack_Patterns: '81: '\n",
  "ID: '222'\nName: Truncation of Security-relevant Information\nDescription: The product truncates the display, recording, or processing of security-relevant\n  information in a way that can obscure the source or nature of an attack.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nObserved_Examples: 'CVE-2005-0585: Web browser truncates long sub-domains or paths,\n  facilitating phishing.\n\n\n  CVE-2004-2032: Bypass URL filter via a long URL with a large number of trailing\n  hex-encoded space characters.\n\n\n  CVE-2003-0412: Does not log complete URI of a long request (truncation).'\n",
  "ID: '223'\nName: Omission of Security-relevant Information\nDescription: The product does not record or display information that would be important\n  for identifying the source or nature of an attack, or determining if an action is\n  safe.\nModes_Of_Introduction: \"Architecture and Design: OMISSION: This weakness is caused\\\n  \\ by missing a security tactic during the architecture and design phase.\\n\\nImplementation:\\\n  \\ \\n\\nOperation: \"\nObserved_Examples: 'CVE-1999-1029: Login attempts not recorded if user disconnects\n  before maximum number of tries.\n\n\n  CVE-2002-1839: Sender''s IP address not recorded in outgoing e-mail.\n\n\n  CVE-2000-0542: Failed authentication attempt not recorded if later attempt succeeds.'\n",
  "ID: '224'\nName: Obscured Security-relevant Information by Alternate Name\nDescription: The product records security-relevant information according to an alternate\n  name of the affected entity, instead of the canonical name.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Operation: '\nObserved_Examples: 'CVE-2002-0725: Attacker performs malicious actions on a hard link\n  to a file, obscuring the real target file.'\n",
  "ID: '225'\nName: 'DEPRECATED: General Information Management Problems'\nDescription: This weakness can be found at CWE-199.\n",
  "ID: '226'\nName: Sensitive Information in Resource Not Removed Before Reuse\nDescription: The product releases a resource such as memory or a file so that it can\n  be made available for reuse, but it does not clear or \"zeroize\" the information\n  contained in the resource before the product performs a critical state transition\n  or makes the resource available for reuse by other entities.\nExtended_Description: 'When resources are released, they can be made available for\n  reuse. For example, after memory is de-allocated, an operating system may make the\n  memory available to another process, or disk space may be reallocated when a file\n  is deleted. As removing information requires time and additional resources, operating\n  systems do not usually clear the previously written information.\n\n  Even when the resource is reused by the same process, this weakness can arise when\n  new data is not as large as the old data, which leaves portions of the old data\n  still available. Equivalent errors can occur in other situations where the length\n  of data is variable but the associated data structure is not. If memory is not cleared\n  after use, the information may be read by less trustworthy parties when the memory\n  is reallocated.\n\n  This weakness can apply in hardware, such as when a device or system switches between\n  power, sleep, or debug states during normal operation, or when execution changes\n  to different users or privilege levels.'\nDetection_Methods: 'Manual Analysis: Write a known pattern into each sensitive location.\n  Trigger the release of the resource or cause the desired state transition to occur.\n  Read data back from the sensitive locations. If the reads are successful, and the\n  data is the same as the pattern that was originally written, the test fails and\n  the product needs to be fixed. Note that this test can likely be automated.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: During critical state transitions, information not needed in the\n  next state should be removed or overwritten with fixed patterns (such as all 0''s)\n  or random data, before the transition to the next state.\n\n\n  Architecture and Design\n\n  Implementation: When releasing, de-allocating, or deleting a resource, overwrite\n  its data and relevant metadata with fixed patterns or random data. Be cautious about\n  complex resource types whose underlying representation might be non-contiguous or\n  change at a low level, such as how a file might be split into different chunks on\n  a file system, even though \"logical\" file positions are contiguous at the application\n  layer. Such resource types might require invocation of special modes or APIs to\n  tell the underlying operating system to perform the necessary clearing, such as\n  SDelete (Secure Delete) on Windows, although the appropriate functionality might\n  not be available at the application layer.'\nObserved_Examples: 'CVE-2003-0001: Ethernet NIC drivers do not pad frames with null\n  bytes, leading to infoleak from malformed packets.\n\n\n  CVE-2003-0291: router does not clear information from DHCP packets that have been\n  previously used\n\n\n  CVE-2005-1406: Products do not fully clear memory buffers when less data is stored\n  into the buffer than previous.\n\n\n  CVE-2005-1858: Products do not fully clear memory buffers when less data is stored\n  into the buffer than previous.\n\n\n  CVE-2005-3180: Products do not fully clear memory buffers when less data is stored\n  into the buffer than previous.\n\n\n  CVE-2005-3276: Product does not clear a data structure before writing to part of\n  it, yielding information leak of previously used memory.\n\n\n  CVE-2002-2077: Memory not properly cleared before reuse.'\nRelated_Attack_Patterns: '37: '\n",
  "ID: '228'\nName: Improper Handling of Syntactically Invalid Structure\nDescription: The product does not handle or incorrectly handles input that is not\n  syntactically well-formed with respect to the associated specification.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '229'\nName: Improper Handling of Values\nDescription: The product does not properly handle when the expected number of values\n  for parameters, fields, or arguments is not provided in input, or if those values\n  are undefined.\n",
  "ID: '23'\nName: Relative Path Traversal\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize sequences such\n  as \"..\" that can resolve to a location that is outside of that directory.\nExtended_Description: This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\nAlternate_Terms: 'Zip Slip: \"Zip slip\" is an attack that uses file archives (e.g.,\n  ZIP, tar, rar, etc.) that contain filenames with path traversal sequences that cause\n  the files to be written outside of the directory under which the archive is expected\n  to be extracted [REF-1282]. It is most commonly used for relative path traversal\n  (CWE-23) and link following (CWE-59).'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.\n\n  Use a built-in path canonicalization function (such as realpath() in C) that produces\n  the canonical version of the pathname, which effectively removes \"..\" sequences\n  and symbolic links (CWE-23, CWE-59). This includes:'\nObserved_Examples: 'CVE-2019-20916: Python package manager does not correctly restrict\n  the filename specified in a Content-Disposition header, allowing arbitrary file\n  read using path traversal sequences such as \"../\"\n\n\n  CVE-2022-24877: directory traversal in Go-based Kubernetes operator app allows accessing\n  data from the controller''s pod file system via ../ sequences in a yaml file\n\n\n  CVE-2020-4053: a Kubernetes package manager written in Go allows malicious plugins\n  to inject path traversal sequences into a plugin archive (\"Zip slip\") to copy a\n  file outside the intended directory\n\n\n  CVE-2021-21972: Chain: Cloud computing virtualization platform does not require\n  authentication for upload of a tar format file (CWE-306), then uses .. path traversal\n  sequences (CWE-23) in the file to access unexpected files, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2019-10743: Go-based archive library allows extraction of  files to locations\n  outside of the target folder with \"../\" path traversal sequences in filenames in\n  a zip file, aka \"Zip Slip\"\n\n\n  CVE-2002-0298: Server allows remote attackers to cause a denial of service via certain\n  HTTP GET requests containing a %2e%2e (encoded dot-dot), several \"/../\" sequences,\n  or several \"../\" in a URI.\n\n\n  CVE-2002-0661: \"\\\" not in denylist for web server, allowing path traversal attacks\n  when the server is run in Windows and other OSes.\n\n\n  CVE-2002-0946: Arbitrary files may be read files via ..\\ (dot dot) sequences in\n  an HTTP request.\n\n\n  CVE-2002-1042: Directory traversal vulnerability in search engine for web server\n  allows remote attackers to read arbitrary files via \"..\\\" sequences in queries.\n\n\n  CVE-2002-1209: Directory traversal vulnerability in FTP server allows remote attackers\n  to read arbitrary files via \"..\\\" sequences in a GET request.\n\n\n  CVE-2002-1178: Directory traversal vulnerability in servlet allows remote attackers\n  to execute arbitrary commands via \"..\\\" sequences in an HTTP request.\n\n\n  CVE-2002-1987: Protection mechanism checks for \"/..\" but doesn''t account for Windows-specific\n  \"\\..\" allowing read of arbitrary files.\n\n\n  CVE-2005-2142: Directory traversal vulnerability in FTP server allows remote authenticated\n  attackers to list arbitrary directories via a \"\\..\" sequence in an LS command.\n\n\n  CVE-2002-0160: The administration function in Access Control Server allows remote\n  attackers to read HTML, Java class, and image files outside the web root via a \"..\\..\"\n  sequence in the URL to port 2002.\n\n\n  CVE-2001-0467: \"\\...\" in web server\n\n\n  CVE-2001-0963: \"...\" in cd command in FTP server\n\n\n  CVE-2001-1193: \"...\" in cd command in FTP server\n\n\n  CVE-2001-1131: \"...\" in cd command in FTP server\n\n\n  CVE-2001-0480: read of arbitrary files and directories using GET or CD with \"...\"\n  in Windows-based FTP server.\n\n\n  CVE-2002-0288: read files using \".\" and Unicode-encoded \"/\" or \"\\\" characters in\n  the URL.\n\n\n  CVE-2003-0313: Directory listing of web server using \"...\"\n\n\n  CVE-2005-1658: Triple dot\n\n\n  CVE-2000-0240: read files via \"/........../\" in URL\n\n\n  CVE-2000-0773: read files via \"....\" in web server\n\n\n  CVE-1999-1082: read files via \"......\" in web server (doubled triple dot?)\n\n\n  CVE-2004-2121: read files via \"......\" in web server (doubled triple dot?)\n\n\n  CVE-2001-0491: multiple attacks using \"..\", \"...\", and \"....\" in different commands\n\n\n  CVE-2001-0615: \"...\" or \"....\" in chat server\n\n\n  CVE-2005-2169: chain: \".../...//\" bypasses protection mechanism using regexp''s\n  that remove \"../\" resulting in collapse into an unsafe value \"../\" (CWE-182) and\n  resultant path traversal.\n\n\n  CVE-2005-0202: \".../....///\" bypasses regexp''s that remove \"./\" and \"../\"\n\n\n  CVE-2004-1670: Mail server allows remote attackers to create arbitrary directories\n  via a \"..\" or rename arbitrary files via a \"....//\" in user supplied parameters.'\nRelated_Attack_Patterns: \"139: \\n\\n76: \"\n",
  "ID: '230'\nName: Improper Handling of Missing Values\nDescription: The product does not handle or incorrectly handles when a parameter,\n  field, or argument name is specified, but the associated value is missing, i.e.\n  it is empty, blank, or null.\nObserved_Examples: 'CVE-2002-0422: Blank Host header triggers resultant infoleak.\n\n\n  CVE-2000-1006: Blank \"charset\" attribute in MIME header triggers crash.\n\n\n  CVE-2004-1504: Blank parameter causes external error infoleak.\n\n\n  CVE-2005-2053: Blank parameter causes external error infoleak.'\n",
  "ID: '231'\nName: Improper Handling of Extra Values\nDescription: The product does not handle or incorrectly handles when more values are\n  provided than expected.\nModes_Of_Introduction: 'Implementation: This typically occurs in situations when only\n  one value is expected.'\n",
  "ID: '232'\nName: Improper Handling of Undefined Values\nDescription: The product does not handle or incorrectly handles when a value is not\n  defined or supported for the associated parameter, field, or argument name.\nObserved_Examples: 'CVE-2000-1003: Client crash when server returns unknown driver\n  type.'\n",
  "ID: '233'\nName: Improper Handling of Parameters\nDescription: The product does not properly handle when the expected number of parameters,\n  fields, or arguments is not provided in input, or if those parameters are undefined.\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nRelated_Attack_Patterns: '39: '\n",
  "ID: '234'\nName: Failure to Handle Missing Parameter\nDescription: If too few arguments are sent to a function, the function will still\n  pop the expected number of arguments from the stack. Potentially, a variable number\n  of arguments could be exhausted in a function as well.\nPotential_Mitigations: 'Build and Compilation: This issue can be simply combated with\n  the use of proper build process.\n\n\n  Implementation: Forward declare all functions. This is the recommended solution.\n  Properly forward declaration of all used functions will result in a compiler error\n  if too few arguments are sent to a function.'\nObserved_Examples: 'CVE-2004-0276: Server earlier allows remote attackers to cause\n  a denial of service (crash) via an HTTP request with a sequence of \"%\" characters\n  and a missing Host field.\n\n\n  CVE-2002-1488: Chat client allows remote malicious IRC servers to cause a denial\n  of service (crash) via a PART message with (1) a missing channel or (2) a channel\n  that the user is not in.\n\n\n  CVE-2002-1169: Proxy allows remote attackers to cause a denial of service (crash)\n  via an HTTP request to helpout.exe with a missing HTTP version numbers.\n\n\n  CVE-2000-0521: Web server allows disclosure of CGI source code via an HTTP request\n  without the version number.\n\n\n  CVE-2001-0590: Application server allows a remote attacker to read the source code\n  to arbitrary ''jsp'' files via a malformed URL request which does not end with an\n  HTTP protocol specification.\n\n\n  CVE-2003-0239: Chat software allows remote attackers to cause a denial of service\n  via malformed GIF89a headers that do not contain a GCT (Global Color Table) or an\n  LCT (Local Color Table) after an Image Descriptor.\n\n\n  CVE-2002-1023: Server allows remote attackers to cause a denial of service (crash)\n  via an HTTP GET request without a URI.\n\n\n  CVE-2002-1236: CGI crashes when called without any arguments.\n\n\n  CVE-2003-0422: CGI crashes when called without any arguments.\n\n\n  CVE-2002-1531: Crash in HTTP request without a Content-Length field.\n\n\n  CVE-2002-1077: Crash in HTTP request without a Content-Length field.\n\n\n  CVE-2002-1358: Empty elements/strings in protocol test suite affect many SSH2 servers/clients.\n\n\n  CVE-2003-0477: FTP server crashes in PORT command without an argument.\n\n\n  CVE-2002-0107: Resultant infoleak in web server via GET requests without HTTP/1.0\n  version string.\n\n\n  CVE-2002-0596: GET request with empty parameter leads to error message infoleak\n  (path disclosure).'\n",
  "ID: '235'\nName: Improper Handling of Extra Parameters\nDescription: The product does not handle or incorrectly handles when the number of\n  parameters, fields, or arguments with the same name exceeds the expected amount.\nModes_Of_Introduction: 'Implementation: This typically occurs in situations when only\n  one element is expected to be specified.'\nObserved_Examples: 'CVE-2003-1014: MIE. multiple gateway/security products allow restriction\n  bypass using multiple MIME fields with the same name, which are interpreted differently\n  by clients.'\nRelated_Attack_Patterns: '460: '\n",
  "ID: '236'\nName: Improper Handling of Undefined Parameters\nDescription: The product does not handle or incorrectly handles when a particular\n  parameter, field, or argument name is not defined or supported by the product.\nObserved_Examples: 'CVE-2002-1488: Crash in IRC client via PART message from a channel\n  the user is not in.\n\n\n  CVE-2001-0650: Router crash or bad route modification using BGP updates with invalid\n  transitive attribute.'\n",
  "ID: '237'\nName: Improper Handling of Structural Elements\nDescription: The product does not handle or incorrectly handles inputs that are related\n  to complex structures.\n",
  "ID: '238'\nName: Improper Handling of Incomplete Structural Elements\nDescription: The product does not handle or incorrectly handles when a particular\n  structural element is not completely specified.\n",
  "ID: '239'\nName: Failure to Handle Incomplete Element\nDescription: The product does not properly handle when a particular element is not\n  completely specified.\nObserved_Examples: 'CVE-2002-1532: HTTP GET without \\r\\n\\r\\n CRLF sequences causes\n  product to wait indefinitely and prevents other users from accessing it.\n\n\n  CVE-2003-0195: Partial request is not timed out.\n\n\n  CVE-2005-2526: MFV. CPU exhaustion in printer via partial printing request then\n  early termination of connection.\n\n\n  CVE-2002-1906: CPU consumption by sending incomplete HTTP requests and leaving the\n  connections open.'\n",
  "ID: '24'\nName: 'Path Traversal: ''../filedir'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize \"../\" sequences\n  that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The \"../\" manipulation is the canonical manipulation for operating systems that\n  use \"/\" as directory separators, such as UNIX- and Linux-based systems. In some\n  cases, it is useful for bypassing protection schemes in environments for which \"/\"\n  is supported but not the primary separator, such as Windows, which uses \"\\\" but\n  can also accept \"/\".'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '240'\nName: Improper Handling of Inconsistent Structural Elements\nDescription: The product does not handle or incorrectly handles when two or more structural\n  elements should be consistent, but are not.\n",
  "ID: '241'\nName: Improper Handling of Unexpected Data Type\nDescription: The product does not handle or incorrectly handles when a particular\n  element is not the expected type, e.g. it expects a digit (0-9) but is provided\n  with a letter (A-Z).\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-1999-1156: FTP server crash via PORT command with non-numeric\n  character.\n\n\n  CVE-2004-0270: Anti-virus product has assert error when line length is non-numeric.'\nRelated_Attack_Patterns: '48: '\n",
  "ID: '242'\nName: Use of Inherently Dangerous Function\nDescription: The product calls a function that can never be guaranteed to work safely.\nExtended_Description: Certain functions behave in dangerous ways regardless of how\n  they are used. Functions in this category were often implemented without taking\n  security concerns into account. The gets() function is unsafe because it does not\n  perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized\n  input to gets() and overflow the destination buffer. Similarly, the >> operator\n  is unsafe to use when reading into a statically-allocated character array because\n  it does not perform bounds checking on the size of its input. An attacker can easily\n  send arbitrarily-sized input to the >> operator and overflow the destination buffer.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation, Requirements: Ban the use of dangerous functions.\n  Use their safe equivalent.\n\n\n  Testing: Use grep or static analysis tools to spot usage of dangerous functions.'\n",
  "ID: '243'\nName: Creation of chroot Jail Without Changing Working Directory\nDescription: The product uses the chroot() system call to create a jail, but does\n  not change the working directory afterward. This does not prevent access to files\n  outside of the jail.\nExtended_Description: Improper use of chroot() may allow attackers to escape from\n  the chroot jail. The chroot() function call does not change the process's current\n  working directory, so relative paths may still refer to file system resources outside\n  of the chroot jail after chroot() has been called.\nApplicable_Platforms:\n  Language: C, C++\n  Operating_System: Unix\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '244'\nName: Improper Clearing of Heap Memory Before Release ('Heap Inspection')\nDescription: Using realloc() to resize buffers that store sensitive information can\n  leave the sensitive information exposed to attack, because it is not removed from\n  memory.\nExtended_Description: When sensitive data such as a password or an encryption key\n  is not removed from memory, it could be exposed to an attacker using a \"heap inspection\"\n  attack that reads the sensitive data using memory dumps or other methods. The realloc()\n  function is commonly used to increase the size of a block of allocated memory. This\n  operation often requires copying the contents of the old memory block into a new\n  and larger block. This operation leaves the contents of the original block intact\n  but inaccessible to the program, preventing the program from being able to scrub\n  sensitive data from memory. If an attacker can later examine the contents of a memory\n  dump, the sensitive data could be exposed.\nApplicable_Platforms:\n  Language: C, C++\n",
  "ID: '245'\nName: 'J2EE Bad Practices: Direct Management of Connections'\nDescription: The J2EE application directly manages connections, instead of using the\n  container's connection management facilities.\nExtended_Description: The J2EE standard forbids the direct management of connections.\n  It requires that applications use the container's resource management facilities\n  to obtain connections to resources. Every major web application container provides\n  pooled database connection management as part of its resource management framework.\n  Duplicating this functionality in an application is difficult and error prone, which\n  is part of the reason it is forbidden under the J2EE standard.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '246'\nName: 'J2EE Bad Practices: Direct Use of Sockets'\nDescription: The J2EE application directly uses sockets instead of using framework\n  method calls.\nExtended_Description: 'The J2EE standard permits the use of sockets only for the purpose\n  of communication with legacy systems when no higher-level protocol is available.\n  Authoring your own communication protocol requires wrestling with difficult security\n  issues.\n\n  Without significant scrutiny by a security expert, chances are good that a custom\n  communication protocol will suffer from security problems. Many of the same issues\n  apply to a custom implementation of a standard protocol. While there are usually\n  more resources available that address security concerns related to implementing\n  a standard protocol, these resources are also available to attackers.'\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use framework method calls instead\n  of using sockets directly.'\n",
  "ID: '247'\nName: 'DEPRECATED: Reliance on DNS Lookups in a Security Decision'\nDescription: This entry has been deprecated because it was a duplicate of CWE-350.\n  All content has been transferred to CWE-350.\n",
  "ID: '248'\nName: Uncaught Exception\nDescription: An exception is thrown from a function, but it is not caught.\nExtended_Description: When an exception is not caught, it may cause the program to\n  crash or expose sensitive information.\nApplicable_Platforms:\n  Language: C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '249'\nName: 'DEPRECATED: Often Misused: Path Manipulation'\nDescription: \"This entry has been deprecated because of name\\n\\tconfusion and an accidental\\\n  \\ combination of multiple\\n\\tweaknesses. Most of its content has been transferred\\\n  \\ to\\n\\tCWE-785.\"\nExtended_Description: \"This entry was deprecated for several reasons. The primary\\n\\\n  \\        reason is over-loading of the \\\"path manipulation\\\" term and the\\n    \\\n  \\    description. The original description for this entry was the\\n        same\\\n  \\ as that for the \\\"Often Misused: File System\\\" item in the\\n        original Seven\\\n  \\ Pernicious Kingdoms paper. However, Seven\\n        Pernicious Kingdoms also has\\\n  \\ a \\\"Path Manipulation\\\" phrase that\\n        is for external control of pathnames\\\n  \\ (CWE-73), which is a\\n        factor in symbolic link following and path traversal,\\\n  \\ neither\\n        of which is explicitly mentioned in 7PK. Fortify uses the\\n \\\n  \\       phrase \\\"Often Misused: Path Manipulation\\\" for a broader range\\n      \\\n  \\  of problems, generally for issues related to buffer\\n        management. Given\\\n  \\ the multiple conflicting uses of this term,\\n        there is a chance that CWE\\\n  \\ users may have incorrectly mapped\\n        to this entry.\\nThe second reason for\\\n  \\ deprecation is an implied combination of\\n\\tmultiple weaknesses within buffer-handling\\\n  \\ functions. The\\n\\tfocus of this entry was generally on the path-conversion\\n\\t\\\n  functions and their association with buffer\\n\\toverflows. However, some of Fortify's\\\n  \\ Vulncat entries have the\\n\\tterm \\\"path manipulation\\\" but describe a non-overflow\\\n  \\ weakness\\n\\tin which the buffer is not guaranteed to contain the entire\\n\\tpathname,\\\n  \\ i.e., there is information truncation (see CWE-222\\n\\tfor a similar concept).\\\n  \\ A new entry for this non-overflow\\n\\tweakness may be created in a future version\\\n  \\ of CWE.\"\n",
  "ID: '25'\nName: 'Path Traversal: ''/../filedir'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize \"/../\" sequences\n  that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  Sometimes a program checks for \"../\" at the beginning of the input, so a \"/../\"\n  can bypass that check.'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '250'\nName: Execution with Unnecessary Privileges\nDescription: The product performs an operation at a privilege level that is higher\n  than the minimum level required, which creates new weaknesses or amplifies the consequences\n  of other weaknesses.\nExtended_Description: 'New weaknesses can be exposed because running with extra privileges,\n  such as root or Administrator, can disable the normal security checks being performed\n  by the operating system or surrounding environment. Other pre-existing weaknesses\n  can turn into security vulnerabilities if they occur while operating at raised privileges.\n\n  Privilege management functions can behave in some less-than-obvious ways, and they\n  have different quirks on different platforms. These inconsistencies are particularly\n  pronounced if you are transitioning from one non-root user to another. Signal handlers\n  and spawned processes run at the privilege of the owning process, so if a process\n  is running as root when a signal fires or a sub-process is executed, the signal\n  handler or sub-process will operate with root privileges.'\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: \"Implementation: REALIZATION: This weakness is caused during\\\n  \\ implementation of an architectural security tactic.\\n\\nInstallation: \\n\\nArchitecture\\\n  \\ and Design: If an application has this design problem, then it can be easier for\\\n  \\ the developer to make implementation-related errors such as CWE-271 (Privilege\\\n  \\ Dropping / Lowering Errors). In addition, the consequences of Privilege Chaining\\\n  \\ (CWE-268) can become more severe.\\n\\nOperation: \"\nDetection_Methods: 'Manual Analysis: This weakness can be detected using tools and\n  techniques that require manual (human) analysis, such as penetration testing, threat\n  modeling, and interactive tools that allow the tester to record and modify an active\n  session.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Black Box: Use monitoring tools that examine the software''s process as it interacts\n  with the operating system and the network. This technique is useful in cases when\n  source code is unavailable, if the software was not developed by you, or if you\n  want to verify that the build phase did not introduce any new weaknesses. Examples\n  include debuggers that directly attach to the running process; system-call tracing\n  utilities such as truss (Solaris) and strace (Linux); system activity monitors such\n  as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and perform a login. Look for library functions\n  and system calls that indicate when privileges are being raised or dropped. Look\n  for accesses of resources that are restricted to normal users.\n\n  Note that this technique is only useful for privilege issues related to system resources.\n  It is not likely to detect application-level business rules that are related to\n  privileges, such as if a blog system allows a user to delete a blog entry without\n  first checking that the user has administrator privileges.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design: Identify the functionality that requires additional privileges,\n  such as access to privileged operating system resources. Wrap and centralize this\n  functionality if possible, and isolate the privileged code as much as possible from\n  other code [REF-76]. Raise privileges as late as possible, and drop them as soon\n  as possible to avoid CWE-271. Avoid weaknesses such as CWE-288 and CWE-420 by protecting\n  all possible communication channels that could interact with the privileged code,\n  such as a secondary socket that is only intended to be accessed by administrators.\n\n\n  Architecture and Design: Identify the functionality that requires additional privileges,\n  such as access to privileged operating system resources. Wrap and centralize this\n  functionality if possible, and isolate the privileged code as much as possible from\n  other code [REF-76]. Raise privileges as late as possible, and drop them as soon\n  as possible to avoid CWE-271. Avoid weaknesses such as CWE-288 and CWE-420 by protecting\n  all possible communication channels that could interact with the privileged code,\n  such as a secondary socket that is only intended to be accessed by administrators.\n\n\n  Implementation: Perform extensive input validation for any privileged code that\n  must be exposed to the user and reject anything that does not fit your strict requirements.\n\n\n  Implementation: When dropping privileges, ensure that they have been dropped successfully\n  to avoid CWE-273. As protection mechanisms in the environment get stronger, privilege-dropping\n  calls may fail even if it seems like they would always succeed.\n\n\n  Implementation: If circumstances force you to run with extra privileges, then determine\n  the minimum access level necessary. First identify the different permissions that\n  the software and its users will need to perform their actions, such as file read\n  and write permissions, network socket permissions, and so forth. Then explicitly\n  allow those actions while denying all else [REF-76]. Perform extensive input validation\n  and canonicalization to minimize the chances of introducing a separate vulnerability.\n  This mitigation is much more prone to error than dropping the privileges in the\n  first place.\n\n\n  Operation, System Configuration: Ensure that the software runs properly under the\n  United States Government Configuration Baseline (USGCB) [REF-199] or an equivalent\n  hardening configuration guide, which many organizations use to limit the attack\n  surface and potential risk of deployed software.'\nObserved_Examples: 'CVE-2007-4217: FTP client program on a certain OS runs with setuid\n  privileges and has a buffer overflow. Most clients do not need extra privileges,\n  so an overflow is not a vulnerability for those clients.\n\n\n  CVE-2008-1877: Program runs with privileges and calls another program with the same\n  privileges, which allows read of arbitrary files.\n\n\n  CVE-2007-5159: OS incorrectly installs a program with setuid privileges, allowing\n  users to gain privileges.\n\n\n  CVE-2008-4638: Composite: application running with high privileges (CWE-250) allows\n  user to specify a restricted file to process, which generates a parsing error that\n  leaks the contents of the file (CWE-209).\n\n\n  CVE-2008-0162: Program does not drop privileges before calling another program,\n  allowing code execution.\n\n\n  CVE-2008-0368: setuid root program allows creation of arbitrary files through command\n  line argument.\n\n\n  CVE-2007-3931: Installation script installs some programs as setuid when they shouldn''t\n  be.\n\n\n  CVE-2020-3812: mail program runs as root but does not drop its privileges before\n  attempting to access a file. Attacker can use a symlink from their home directory\n  to a directory only readable by root, then determine whether the file exists based\n  on the response.'\nRelated_Attack_Patterns: \"104: \\n\\n470: \\n\\n69: \"\n",
  "ID: '252'\nName: Unchecked Return Value\nDescription: The product does not check the return value from a method or function,\n  which can prevent it from detecting unexpected states and conditions.\nExtended_Description: Two common programmer assumptions are \"this function call can\n  never fail\" and \"it doesn't matter if this function call fails\". If an attacker\n  can force the function to fail or otherwise return a value that is not expected,\n  then the subsequent program logic could lead to a vulnerability, because the product\n  is not in a state that the programmer assumes. For example, if the program calls\n  a function to drop privileges but does not check the return code to ensure that\n  privileges were successfully dropped, then the program will continue to operate\n  with the higher privileges.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Check the results of all functions that return\n  a value and verify that the value is expected.\n\n\n  Implementation: Ensure that you account for all possible return values from the\n  function.\n\n\n  Implementation: When designing a function, make sure you return a value or throw\n  an exception in case of an error.'\nObserved_Examples: 'CVE-2020-17533: Chain: unchecked return value (CWE-252) of some\n  functions for policy enforcement leads to authorization bypass (CWE-862)\n\n\n  CVE-2020-6078: Chain: The return value of a function returning a pointer is not\n  checked for success (CWE-252) resulting in the later use of an uninitialized variable\n  (CWE-456) and a null pointer dereference (CWE-476)\n\n\n  CVE-2019-15900: Chain: sscanf() call is used to check if a username and group exists,\n  but the return value of sscanf() call is not checked (CWE-252), causing an uninitialized\n  variable to be checked (CWE-457), returning success to allow authorization bypass\n  for executing a privileged (CWE-863).\n\n\n  CVE-2007-3798: Unchecked return value leads to resultant integer overflow and code\n  execution.\n\n\n  CVE-2006-4447: Program does not check return value when invoking functions to drop\n  privileges, which could leave users with higher privileges than expected by forcing\n  those functions to fail.\n\n\n  CVE-2006-2916: Program does not check return value when invoking functions to drop\n  privileges, which could leave users with higher privileges than expected by forcing\n  those functions to fail.\n\n\n  CVE-2008-5183: chain: unchecked return value can lead to NULL dereference\n\n\n  CVE-2010-0211: chain: unchecked return value (CWE-252) leads to free of invalid,\n  uninitialized pointer (CWE-824).\n\n\n  CVE-2017-6964: Linux-based device mapper encryption program does not check the return\n  value of setuid and setgid allowing attackers to execute code with unintended privileges.'\n",
  "ID: '253'\nName: Incorrect Check of Function Return Value\nDescription: The product incorrectly checks a return value from a function, which\n  prevents it from detecting errors or exceptional conditions.\nExtended_Description: Important and common functions will return some value about\n  the success of its actions. This will alert the program whether or not to handle\n  any errors caused by that function.\nPotential_Mitigations: 'Architecture and Design: Use a language or compiler that uses\n  exceptions and requires the catching of those exceptions.\n\n\n  Implementation: Properly check all functions which return a value.\n\n\n  Implementation: When designing any function make sure you return a value or throw\n  an exception in case of an error.'\n",
  "ID: '256'\nName: Plaintext Storage of a Password\nDescription: Storing a password in plaintext may result in a system compromise.\nExtended_Description: Password management issues occur when a password is stored in\n  plaintext in an application's properties, configuration file, or memory. Storing\n  a plaintext password in a configuration file allows anyone who can read the file\n  access to the password-protected resource. In some contexts, even storage of a plaintext\n  password in memory is considered a security risk if the password is not cleared\n  immediately after it is used.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Architecture and Design: Developers sometimes believe that they cannot defend the\n  application from someone who has access to the configuration, but this belief makes\n  an attacker''s job easier.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Avoid storing passwords in easily\n  accessible locations.\n\n\n  Architecture and Design: Consider storing cryptographic hashes of passwords as an\n  alternative to storing in plaintext.\n\n\n  A programmer might attempt to remedy the password management problem by obscuring\n  the password with an encoding function, such as base 64 encoding, but this effort\n  does not adequately protect the password because the encoding can be detected and\n  decoded easily.'\nObserved_Examples: 'CVE-2022-30275: Remote Terminal Unit (RTU) uses a driver that\n  relies on a password stored in plaintext.'\n",
  "ID: '257'\nName: Storing Passwords in a Recoverable Format\nDescription: The storage of passwords in a recoverable format makes them subject to\n  password reuse attacks by malicious users. In fact, it should be noted that recoverable\n  encrypted passwords provide no significant benefit over plaintext passwords since\n  they are subject not only to reuse by malicious attackers but also by malicious\n  insiders. If a system administrator can recover a password directly, or use a brute\n  force search on the available information, the administrator can use the password\n  on other accounts.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use strong, non-reversible encryption\n  to protect stored passwords.'\nRelated_Attack_Patterns: '49: '\n",
  "ID: '258'\nName: Empty Password in Configuration File\nDescription: Using an empty string as a password is insecure.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'System Configuration: Passwords should be at least eight characters\n  long -- the longer the better. Avoid passwords that are in any way similar to other\n  passwords you have. Avoid using words that may be found in a dictionary, names book,\n  on a map, etc. Consider incorporating numbers and/or punctuation into your password.\n  If you do use common words, consider replacing letters in that word with numbers\n  and punctuation. However, do not use \"similar-looking\" punctuation. For example,\n  it is not a good idea to change cat to c@t, ca+, (@+, or anything similar. Finally,\n  it is never appropriate to use an empty string as a password.'\n",
  "ID: '259'\nName: Use of Hard-coded Password\nDescription: The product contains a hard-coded password, which it uses for its own\n  inbound authentication or for outbound communication to external components.\nExtended_Description: 'A hard-coded password typically leads to a significant authentication\n  failure that can be difficult for the system administrator to detect. Once detected,\n  it can be difficult to fix, so the administrator may be forced into disabling the\n  product entirely. There are two main variations:\n\n  In the Inbound variant, a default administration account is created, and a simple\n  password is hard-coded into the product and associated with that account. This hard-coded\n  password is the same for each installation of the product, and it usually cannot\n  be changed or disabled by system administrators without manually modifying the program,\n  or otherwise patching the product. If the password is ever discovered or published\n  (a common occurrence on the Internet), then anybody with knowledge of this password\n  can access the product. Finally, since all installations of the product will have\n  the same password, even across different organizations, this enables massive attacks\n  such as worms to take place.\n\n  The Outbound variant applies to front-end systems that authenticate with a back-end\n  service. The back-end service may require a fixed password which can be easily discovered.\n  The programmer may simply hard-code those back-end credentials into the front-end\n  product. Any user of that program may be able to extract the password. Client-side\n  systems with hard-coded passwords pose even more of a threat, since the extraction\n  of a password from a binary is usually very simple.'\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Architecture and Design: '\nDetection_Methods: 'Manual Analysis: This weakness can be detected using tools and\n  techniques that require manual (human) analysis, such as penetration testing, threat\n  modeling, and interactive tools that allow the tester to record and modify an active\n  session.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Black Box: Use monitoring tools that examine the software''s process as it interacts\n  with the operating system and the network. This technique is useful in cases when\n  source code is unavailable, if the software was not developed by you, or if you\n  want to verify that the build phase did not introduce any new weaknesses. Examples\n  include debuggers that directly attach to the running process; system-call tracing\n  utilities such as truss (Solaris) and strace (Linux); system activity monitors such\n  as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and perform a login. Using disassembled code,\n  look at the associated instructions and see if any of them appear to be comparing\n  the input to a fixed string or value.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: For outbound authentication: store\n  passwords outside of the code in a strongly-protected, encrypted configuration file\n  or database that is protected from access by all outsiders, including other local\n  users on the same system. Properly protect the key (CWE-320). If you cannot use\n  encryption to protect the file, then make sure that the permissions are as restrictive\n  as possible.\n\n\n  Architecture and Design: For inbound authentication: Rather than hard-code a default\n  username and password for first time logins, utilize a \"first login\" mode that requires\n  the user to enter a unique strong password.\n\n\n  Architecture and Design: Perform access control checks and limit which entities\n  can access the feature that requires the hard-coded password. For example, a feature\n  might only be enabled through the system console instead of through a network connection.\n\n\n  Architecture and Design: For inbound authentication: apply strong one-way hashes\n  to your passwords and store those hashes in a configuration file or database with\n  appropriate access control. That way, theft of the file/database still requires\n  the attacker to try to crack the password. When receiving an incoming password during\n  authentication, take the hash of the password and compare it to the hash that you\n  have saved.\n\n  Use randomly assigned salts for each separate hash that you generate. This increases\n  the amount of computation that an attacker needs to conduct a brute-force attack,\n  possibly limiting the effectiveness of the rainbow table method.\n\n\n  Architecture and Design: For front-end to back-end connections: Three solutions\n  are possible, although none are complete.'\nObserved_Examples: 'CVE-2022-29964: Distributed Control System (DCS) has hard-coded\n  passwords for local shell access\n\n\n  CVE-2021-37555: Telnet service for IoT feeder for dogs and cats has hard-coded password\n  [REF-1288]'\n",
  "ID: '26'\nName: 'Path Traversal: ''/dir/../filename'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize \"/dir/../filename\"\n  sequences that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''/dir/../filename'' manipulation is useful for bypassing some path traversal\n  protection schemes. Sometimes a program only checks for \"../\" at the beginning of\n  the input, so a \"/../\" can bypass that check.'\nApplicable_Platforms:\n  Technology: Web Server\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '260'\nName: Password in Configuration File\nDescription: The product stores a password in a configuration file that might be accessible\n  to actors who do not know the password.\nExtended_Description: This can result in compromise of the system for which the password\n  is used. An attacker could gain access to this file and learn the stored password\n  or worse yet, change the password to one of their choosing.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Avoid storing passwords in easily\n  accessible locations.\n\n\n  Architecture and Design: Consider storing cryptographic hashes of passwords as an\n  alternative to storing in plaintext.'\n",
  "ID: '261'\nName: Weak Encoding for Password\nDescription: Obscuring a password with a trivial encoding does not protect the password.\nExtended_Description: Password management issues occur when a password is stored in\n  plaintext in an application's properties or configuration file. A programmer can\n  attempt to remedy the password management problem by obscuring the password with\n  an encoding function, such as base 64 encoding, but this effort does not adequately\n  protect the password.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nRelated_Attack_Patterns: '55: '\n",
  "ID: '262'\nName: Not Using Password Aging\nDescription: The product does not have a mechanism in place for managing password\n  aging.\nExtended_Description: 'Password aging (or password rotation) is a policy that forces\n  users to change their passwords after a defined time period passes, such as every\n  30 or 90 days. Without mechanisms such as aging, users might not change their passwords\n  in a timely manner.\n\n  Note that while password aging was once considered an important security feature,\n  it has since fallen out of favor by many, because it is not as effective against\n  modern threats compared to other mechanisms such as slow hashes. In addition, forcing\n  frequent changes can unintentionally encourage users to select less-secure passwords.\n  However, password aging is still in use due to factors such as compliance requirements,\n  e.g., Payment Card Industry Data Security Standard (PCI DSS).'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: As part of a product''s design, require\n  users to change their passwords regularly and avoid reusing previous passwords.\n\n\n  Implementation: Developers might disable clipboard paste operations into password\n  fields as a way to discourage users from pasting a password into a clipboard. However,\n  this might encourage users to choose less-secure passwords that are easier to type,\n  and it can reduce the usability of password managers [REF-1294].'\nRelated_Attack_Patterns: \"16: \\n\\n49: \\n\\n509: \\n\\n55: \\n\\n555: \\n\\n560: \\n\\n561:\\\n  \\ \\n\\n565: \\n\\n600: \\n\\n652: \\n\\n653: \\n\\n70: \"\n",
  "ID: '263'\nName: Password Aging with Long Expiration\nDescription: The product supports password aging, but the expiration period is too\n  long.\nExtended_Description: 'Password aging (or password rotation) is a policy that forces\n  users to change their passwords after a defined time period passes, such as every\n  30 or 90 days. A long expiration provides more time for attackers to conduct password\n  cracking before users are forced to change to a new password.\n\n  Note that while password aging was once considered an important security feature,\n  it has since fallen out of favor by many, because it is not as effective against\n  modern threats compared to other mechanisms such as slow hashes. In addition, forcing\n  frequent changes can unintentionally encourage users to select less-secure passwords.\n  However, password aging is still in use due to factors such as compliance requirements,\n  e.g., Payment Card Industry Data Security Standard (PCI DSS).'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Ensure that password aging is limited\n  so that there is a defined maximum age for passwords. Note that if the expiration\n  window is too short, it can cause users to generate poor or predictable passwords.\n\n\n  Architecture and Design: Ensure that the user is notified several times leading\n  up to the password expiration.\n\n\n  Architecture and Design: Create mechanisms to prevent users from reusing passwords\n  or creating similar passwords.\n\n\n  Implementation: Developers might disable clipboard paste operations into password\n  fields as a way to discourage users from pasting a password into a clipboard. However,\n  this might encourage users to choose less-secure passwords that are easier to type,\n  and it can reduce the usability of password managers [REF-1294].'\nRelated_Attack_Patterns: \"16: \\n\\n49: \\n\\n509: \\n\\n55: \\n\\n555: \\n\\n560: \\n\\n561:\\\n  \\ \\n\\n565: \\n\\n600: \\n\\n652: \\n\\n653: \\n\\n70: \"\n",
  "ID: '266'\nName: Incorrect Privilege Assignment\nDescription: A product incorrectly assigns a privilege to a particular actor, creating\n  an unintended sphere of control for that actor.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.'\nObserved_Examples: 'CVE-1999-1193: untrusted user placed in unix \"wheel\" group\n\n\n  CVE-2005-2741: Product allows users to grant themselves certain rights that can\n  be used to escalate privileges.\n\n\n  CVE-2005-2496: Product uses group ID of a user instead of the group, causing it\n  to run with different privileges. This is resultant from some other unknown issue.\n\n\n  CVE-2004-0274: Product mistakenly assigns a particular status to an entity, leading\n  to increased privileges.'\n",
  "ID: '267'\nName: Privilege Defined With Unsafe Actions\nDescription: A particular privilege, role, capability, or right can be used to perform\n  unsafe actions that were not intended, even when it is assigned to the correct entity.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.'\nObserved_Examples: 'CVE-2002-1981: Roles have access to dangerous procedures (Accessible\n  entities).\n\n\n  CVE-2002-1671: Untrusted object/method gets access to clipboard (Accessible entities).\n\n\n  CVE-2004-2204: Gain privileges using functions/tags that should be restricted (Accessible\n  entities).\n\n\n  CVE-2000-0315: Traceroute program allows unprivileged users to modify source address\n  of packet (Accessible entities).\n\n\n  CVE-2004-0380: Bypass domain restrictions using a particular file that references\n  unsafe URI schemes (Accessible entities).\n\n\n  CVE-2002-1154: Script does not restrict access to an update command, leading to\n  resultant disk consumption and filled error logs (Accessible entities).\n\n\n  CVE-2002-1145: \"public\" database user can use stored procedure to modify data controlled\n  by the database owner (Unsafe privileged actions).\n\n\n  CVE-2000-0506: User with capability can prevent setuid program from dropping privileges\n  (Unsafe privileged actions).\n\n\n  CVE-2002-2042: Allows attachment to and modification of privileged processes (Unsafe\n  privileged actions).\n\n\n  CVE-2000-1212: User with privilege can edit raw underlying object using unprotected\n  method (Unsafe privileged actions).\n\n\n  CVE-2005-1742: Inappropriate actions allowed by a particular role(Unsafe privileged\n  actions).\n\n\n  CVE-2001-1480: Untrusted entity allowed to access the system clipboard (Unsafe privileged\n  actions).\n\n\n  CVE-2001-1551: Extra Linux capability allows bypass of system-specified restriction\n  (Unsafe privileged actions).\n\n\n  CVE-2001-1166: User with debugging rights can read entire process (Unsafe privileged\n  actions).\n\n\n  CVE-2005-1816: Non-root admins can add themselves or others to the root admin group\n  (Unsafe privileged actions).\n\n\n  CVE-2005-2173: Users can change certain properties of objects to perform otherwise\n  unauthorized actions (Unsafe privileged actions).\n\n\n  CVE-2005-2027: Certain debugging commands not restricted to just the administrator,\n  allowing registry modification and infoleak (Unsafe privileged actions).'\nRelated_Attack_Patterns: \"58: \\n\\n634: \\n\\n637: \\n\\n643: \\n\\n648: \"\n",
  "ID: '268'\nName: Privilege Chaining\nDescription: Two distinct privileges, roles, capabilities, or rights can be combined\n  in a way that allows an entity to perform unsafe actions that would not be allowed\n  without that combination.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Consider following the principle\n  of separation of privilege. Require multiple conditions to be met before permitting\n  access to a system resource.\n\n\n  Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.'\nObserved_Examples: 'CVE-2005-1736: Chaining of user rights.\n\n\n  CVE-2002-1772: Gain certain rights via privilege chaining in alternate channel.\n\n\n  CVE-2005-1973: Application is allowed to assign extra permissions to itself.\n\n\n  CVE-2003-0640: \"operator\" user can overwrite usernames and passwords to gain admin\n  privileges.'\n",
  "ID: '269'\nName: Improper Privilege Management\nDescription: The product does not properly assign, modify, track, or check privileges\n  for an actor, creating an unintended sphere of control for that actor.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Follow the principle of least privilege when assigning\n  access rights to entities in a software system.\n\n\n  Architecture and Design: Consider following the principle of separation of privilege.\n  Require multiple conditions to be met before permitting access to a system resource.'\nObserved_Examples: 'CVE-2001-1555: Terminal privileges are not reset when a user logs\n  out.\n\n\n  CVE-2001-1514: Does not properly pass security context to child processes in certain\n  cases, allows privilege escalation.\n\n\n  CVE-2001-0128: Does not properly compute roles.\n\n\n  CVE-1999-1193: untrusted user placed in unix \"wheel\" group\n\n\n  CVE-2005-2741: Product allows users to grant themselves certain rights that can\n  be used to escalate privileges.\n\n\n  CVE-2005-2496: Product uses group ID of a user instead of the group, causing it\n  to run with different privileges. This is resultant from some other unknown issue.\n\n\n  CVE-2004-0274: Product mistakenly assigns a particular status to an entity, leading\n  to increased privileges.\n\n\n  CVE-2007-4217: FTP client program on a certain OS runs with setuid privileges and\n  has a buffer overflow. Most clients do not need extra privileges, so an overflow\n  is not a vulnerability for those clients.\n\n\n  CVE-2007-5159: OS incorrectly installs a program with setuid privileges, allowing\n  users to gain privileges.\n\n\n  CVE-2008-4638: Composite: application running with high privileges (CWE-250) allows\n  user to specify a restricted file to process, which generates a parsing error that\n  leaks the contents of the file (CWE-209).\n\n\n  CVE-2007-3931: Installation script installs some programs as setuid when they shouldn''t\n  be.\n\n\n  CVE-2002-1981: Roles have access to dangerous procedures (Accessible entities).\n\n\n  CVE-2002-1671: Untrusted object/method gets access to clipboard (Accessible entities).\n\n\n  CVE-2000-0315: Traceroute program allows unprivileged users to modify source address\n  of packet (Accessible entities).\n\n\n  CVE-2000-0506: User with capability can prevent setuid program from dropping privileges\n  (Unsafe privileged actions).'\nRelated_Attack_Patterns: \"122: \\n\\n233: \\n\\n58: \"\n",
  "ID: '27'\nName: 'Path Traversal: ''dir/../../filename'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize multiple internal\n  \"../\" sequences that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''directory/../../filename'' manipulation is useful for bypassing some path\n  traversal protection schemes. Sometimes a program only removes one \"../\" sequence,\n  so multiple \"../\" can bypass that check. Alternately, this manipulation could be\n  used to bypass a check for \"../\" at the beginning of the pathname, moving up more\n  than one directory level.'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0298: Server allows remote attackers to cause a denial\n  of service via certain HTTP GET requests containing a %2e%2e (encoded dot-dot),\n  several \"/../\" sequences, or several \"../\" in a URI.'\n",
  "ID: '270'\nName: Privilege Context Switching Error\nDescription: The product does not properly manage privileges while it is switching\n  between different contexts that have different privileges or spheres of control.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design: Consider following the principle of separation of privilege.\n  Require multiple conditions to be met before permitting access to a system resource.'\nObserved_Examples: 'CVE-2002-1688: Web browser cross domain problem when user hits\n  \"back\" button.\n\n\n  CVE-2003-1026: Web browser cross domain problem when user hits \"back\" button.\n\n\n  CVE-2002-1770: Cross-domain issue - third party product passes code to web browser,\n  which executes it in unsafe zone.\n\n\n  CVE-2005-2263: Run callback in different security context after it has been changed\n  from untrusted to trusted. * note that \"context switch before actions are completed\"\n  is one type of problem that happens frequently, espec. in browsers.'\nRelated_Attack_Patterns: \"17: \\n\\n30: \\n\\n35: \"\n",
  "ID: '271'\nName: Privilege Dropping / Lowering Errors\nDescription: The product does not drop privileges before passing control of a resource\n  to an actor that does not have those privileges.\nExtended_Description: In some contexts, a system executing with elevated permissions\n  will hand off a process/file/etc. to another process or user. If the privileges\n  of an entity are not reduced, then elevated privileges are spread throughout a system\n  and possibly to an attacker.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Consider following the principle of separation of privilege.\n  Require multiple conditions to be met before permitting access to a system resource.'\nObserved_Examples: 'CVE-2000-1213: Program does not drop privileges after acquiring\n  the raw socket.\n\n\n  CVE-2001-0559: Setuid program does not drop privileges after a parsing error occurs,\n  then calls another program to handle the error.\n\n\n  CVE-2001-0787: Does not drop privileges in related groups when lowering privileges.\n\n\n  CVE-2002-0080: Does not drop privileges in related groups when lowering privileges.\n\n\n  CVE-2001-1029: Does not drop privileges before determining access to certain files.\n\n\n  CVE-1999-0813: Finger daemon does not drop privileges when executing programs on\n  behalf of the user being fingered.\n\n\n  CVE-1999-1326: FTP server does not drop privileges if a connection is aborted during\n  file transfer.\n\n\n  CVE-2000-0172: Program only uses seteuid to drop privileges.\n\n\n  CVE-2004-2504: Windows program running as SYSTEM does not drop privileges before\n  executing other programs (many others like this, especially involving the Help facility).\n\n\n  CVE-2004-0213: Utility Manager launches winhlp32.exe while running with raised privileges,\n  which allows local users to gain system privileges.\n\n\n  CVE-2004-0806: Setuid program does not drop privileges before executing program\n  specified in an environment variable.\n\n\n  CVE-2004-0828: Setuid program does not drop privileges before processing file specified\n  on command line.\n\n\n  CVE-2004-2070: Service on Windows does not drop privileges before using \"view file\"\n  option, allowing code execution.'\n",
  "ID: '272'\nName: Least Privilege Violation\nDescription: The elevated privilege level required to perform operations such as chroot()\n  should be dropped immediately after the operation is performed.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Operation: '\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Follow the principle of least privilege when assigning\n  access rights to entities in a software system.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nRelated_Attack_Patterns: \"17: \\n\\n35: \\n\\n76: \"\n",
  "ID: '273'\nName: Improper Check for Dropped Privileges\nDescription: The product attempts to drop privileges but does not check or incorrectly\n  checks to see if the drop succeeded.\nExtended_Description: If the drop fails, the product will continue to run with the\n  raised privileges, which might provide additional access to unprivileged users.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n  This issue is likely to occur in restrictive environments in which the operating\n  system or application provides fine-grained control over privilege management.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation: Check the results of all functions that return a value and verify\n  that the value is expected.\n\n\n  Implementation: In Windows, make sure that the process token has the SeImpersonatePrivilege(Microsoft\n  Server 2003). Code that relies on impersonation for security must ensure that the\n  impersonation succeeded, i.e., that a proper privilege demotion happened.'\nObserved_Examples: 'CVE-2006-4447: Program does not check return value when invoking\n  functions to drop privileges, which could leave users with higher privileges than\n  expected by forcing those functions to fail.\n\n\n  CVE-2006-2916: Program does not check return value when invoking functions to drop\n  privileges, which could leave users with higher privileges than expected by forcing\n  those functions to fail.'\n",
  "ID: '274'\nName: Improper Handling of Insufficient Privileges\nDescription: The product does not handle or incorrectly handles when it has insufficient\n  privileges to perform an operation, leading to resultant weaknesses.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Operation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2001-1564: System limits are not properly enforced after privileges\n  are dropped.\n\n\n  CVE-2005-3286: Firewall crashes when it can''t read a critical memory block that\n  was protected by a malicious process.\n\n\n  CVE-2005-1641: Does not give admin sufficient privileges to overcome otherwise legitimate\n  user actions.'\n",
  "ID: '276'\nName: Incorrect Default Permissions\nDescription: During installation, installed file permissions are set to allow anyone\n  to modify those files.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nInstallation:\\\n  \\ \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: The architecture needs to access and modification attributes for files\n  to only those users who actually require those actions.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2005-1941: Executables installed world-writable.\n\n\n  CVE-2002-1713: Home directories installed world-readable.\n\n\n  CVE-2001-1550: World-writable log files allow information loss; world-readable file\n  has cleartext passwords.\n\n\n  CVE-2002-1711: World-readable directory.\n\n\n  CVE-2002-1844: Windows product uses insecure permissions when installing on Solaris\n  (genesis: port error).\n\n\n  CVE-2001-0497: Insecure permissions for a shared secret key file. Overlaps cryptographic\n  problem.\n\n\n  CVE-1999-0426: Default permissions of a device allow IP spoofing.'\nRelated_Attack_Patterns: \"1: \\n\\n127: \\n\\n81: \"\n",
  "ID: '277'\nName: Insecure Inherited Permissions\nDescription: A product defines a set of insecure permissions that are inherited by\n  objects that are created by the program.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2005-1841: User''s umask is used when creating temp files.\n\n\n  CVE-2002-1786: Insecure umask for core dumps [is the umask preserved or assigned?].'\n",
  "ID: '278'\nName: Insecure Preserved Inherited Permissions\nDescription: A product inherits a set of insecure permissions for an object, e.g.\n  when copying from an archive file, without user awareness or involvement.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2005-1724: Does not obey specified permissions when exporting.'\n",
  "ID: '279'\nName: Incorrect Execution-Assigned Permissions\nDescription: While it is executing, the product sets the permissions of an object\n  in a way that violates the intended permissions that have been specified by the\n  user.\nModes_Of_Introduction: \"Implementation: REALIZATION: This weakness is caused during\\\n  \\ implementation of an architectural security tactic.\\n\\nArchitecture and Design:\\\n  \\ \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2002-0265: Log files opened read/write.\n\n\n  CVE-2003-0876: Log files opened read/write.\n\n\n  CVE-2002-1694: Log files opened read/write.'\nRelated_Attack_Patterns: '81: '\n",
  "ID: '28'\nName: 'Path Traversal: ''..\\filedir'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize \"..\\\" sequences\n  that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''..\\'' manipulation is the canonical manipulation for operating systems that\n  use \"\\\" as directory separators, such as Windows. However, it is also useful for\n  bypassing path traversal protection schemes that only assume that the \"/\" separator\n  is valid.'\nApplicable_Platforms:\n  Operating_System: Windows\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0661: \"\\\" not in denylist for web server, allowing path\n  traversal attacks when the server is run in Windows and other OSes.\n\n\n  CVE-2002-0946: Arbitrary files may be read files via ..\\ (dot dot) sequences in\n  an HTTP request.\n\n\n  CVE-2002-1042: Directory traversal vulnerability in search engine for web server\n  allows remote attackers to read arbitrary files via \"..\\\" sequences in queries.\n\n\n  CVE-2002-1209: Directory traversal vulnerability in FTP server allows remote attackers\n  to read arbitrary files via \"..\\\" sequences in a GET request.\n\n\n  CVE-2002-1178: Directory traversal vulnerability in servlet allows remote attackers\n  to execute arbitrary commands via \"..\\\" sequences in an HTTP request.'\n",
  "ID: '280'\nName: 'Improper Handling of Insufficient Permissions or Privileges '\nDescription: The product does not handle or incorrectly handles when it has insufficient\n  privileges to access resources or functionality as specified by their permissions.\n  This may cause it to follow unexpected code paths that may leave the product in\n  an invalid state.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Compartmentalize the system to have\n  \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive\n  data to go outside of the trust boundary and always be careful when interfacing\n  with a compartment outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation: Always check to see if you have successfully accessed a resource\n  or system functionality, and use proper error handling if it is unsuccessful. Do\n  this even when you are operating in a highly privileged mode, because errors or\n  environmental conditions might still cause a failure. For example, environments\n  with highly granular permissions/privilege models, such as Windows or Linux capabilities,\n  can cause unexpected failures.'\nObserved_Examples: 'CVE-2003-0501: Special file system allows attackers to prevent\n  ownership/permission change of certain entries by opening the entries before calling\n  a setuid program.\n\n\n  CVE-2004-0148: FTP server places a user in the root directory when the user''s permissions\n  prevent access to the their own home directory.'\n",
  "ID: '281'\nName: Improper Preservation of Permissions\nDescription: The product does not preserve permissions or incorrectly preserves permissions\n  when copying, restoring, or sharing objects, which can cause them to have less restrictive\n  permissions than intended.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Operation: '\nObserved_Examples: 'CVE-2002-2323: Incorrect ACLs used when restoring backups from\n  directories that use symbolic links.\n\n\n  CVE-2001-1515: Automatic modification of permissions inherited from another file\n  system.\n\n\n  CVE-2005-1920: Permissions on backup file are created with defaults, possibly less\n  secure than original file.\n\n\n  CVE-2001-0195: File is made world-readable when being cloned.'\n",
  "ID: '282'\nName: Improper Ownership Management\nDescription: The product assigns the wrong ownership, or does not properly verify\n  the ownership, of an object or resource.\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.'\nObserved_Examples: 'CVE-1999-1125: Program runs setuid root but relies on a configuration\n  file owned by a non-root user.'\nRelated_Attack_Patterns: \"17: \\n\\n35: \"\n",
  "ID: '283'\nName: Unverified Ownership\nDescription: The product does not properly verify that a critical resource is owned\n  by the proper entity.\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Consider following the principle of separation of privilege.\n  Require multiple conditions to be met before permitting access to a system resource.'\nObserved_Examples: 'CVE-2001-0178: Program does not verify the owner of a UNIX socket\n  that is used for sending a password.\n\n\n  CVE-2004-2012: Owner of special device not checked, allowing root.'\n",
  "ID: '284'\nName: Improper Access Control\nDescription: The product does not restrict or incorrectly restricts access to a resource\n  from an unauthorized actor.\nExtended_Description: 'Access control involves the use of several protection mechanisms\n  such as:\n\n  When any mechanism is not applied or otherwise fails, attackers can compromise the\n  security of the product by gaining privileges, reading sensitive information, executing\n  commands, evading detection, etc.\n\n  There are two distinct behaviors that can introduce access control weaknesses:'\nApplicable_Platforms:\n  Technology: ICS/OT\nAlternate_Terms: 'Authorization: The terms \"access control\" and \"authorization\" are\n  often used interchangeably, although many people have distinct definitions. The\n  CWE usage of \"access control\" is intended as a general term for the various mechanisms\n  that restrict which users can access which resources, and \"authorization\" is more\n  narrowly defined. It is unlikely that there will be community consensus on the use\n  of these terms.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Very carefully manage the setting, management, and handling of privileges.\n  Explicitly manage trust zones in the software.\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.'\nObserved_Examples: 'CVE-2022-29238: Access-control setting in web-based document collaboration\n  tool is not properly implemented by the code, which prevents listing hidden directories\n  but does not prevent direct requests to files in those directories.\n\n\n  CVE-2022-23607: Python-based HTTP library did not scope cookies to a particular\n  domain such that \"supercookies\" could be sent to any domain on redirect\n\n\n  CVE-2021-21972: Chain: Cloud computing virtualization platform does not require\n  authentication for upload of a tar format file (CWE-306), then uses .. path traversal\n  sequences (CWE-23) in the file to access unexpected files, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2021-37415: IT management product does not perform authentication for some REST\n  API requests, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-13927: Default setting in workflow management product allows all API requests\n  without authentication, as exploited in the wild per CISA KEV.\n\n\n  CVE-2010-4624: Bulletin board applies restrictions on number of images during post\n  creation, but does not enforce this on editing.'\nRelated_Attack_Patterns: \"19: \\n\\n441: \\n\\n478: \\n\\n479: \\n\\n502: \\n\\n503: \\n\\n536:\\\n  \\ \\n\\n546: \\n\\n550: \\n\\n551: \\n\\n552: \\n\\n556: \\n\\n558: \\n\\n562: \\n\\n563: \\n\\n564:\\\n  \\ \\n\\n578: \"\n",
  "ID: '285'\nName: Improper Authorization\nDescription: The product does not perform or incorrectly performs an authorization\n  check when an actor attempts to access a resource or perform an action.\nExtended_Description: 'Assuming a user with a given identity, authorization is the\n  process of determining whether that user can access a given resource, based on the\n  user''s privileges and any permissions or other access-control specifications that\n  apply to the resource.\n\n  When access control checks are not applied consistently - or not at all - users\n  are able to access data or perform actions that they should not be allowed to perform.\n  This can lead to a wide range of problems, including information exposures, denial\n  of service, and arbitrary code execution.'\nApplicable_Platforms:\n  Technology: Web Server, Database Server\nAlternate_Terms: 'AuthZ: \"AuthZ\" is typically used as an abbreviation of \"authorization\"\n  within the web application security community. It is distinct from \"AuthN\" (or,\n  sometimes, \"AuthC\") which is an abbreviation of \"authentication.\" The use of \"Auth\"\n  as an abbreviation is discouraged, since it could be used for either authentication\n  or authorization.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n  A developer may introduce authorization weaknesses because of a lack of understanding\n  about the underlying technologies. For example, a developer may assume that attackers\n  cannot modify certain inputs such as headers or cookies.\n\n\n  Architecture and Design: Authorization weaknesses may arise when a single-user application\n  is ported to a multi-user environment.\n\n\n  Operation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis is useful\n  for detecting commonly-used idioms for authorization. A tool may be able to analyze\n  related configuration files, such as .htaccess in Apache web servers, or detect\n  the usage of commonly-used authorization libraries.\n\n  Generally, automated static analysis tools have difficulty detecting custom authorization\n  schemes. In addition, the software''s design may include some functionality that\n  is accessible to any user and does not require an authorization check; an automated\n  technique that detects the absence of authorization may report false positives.\n\n\n  Automated Dynamic Analysis: Automated dynamic analysis may find many or all possible\n  interfaces that do not require authorization, but manual analysis is required to\n  determine if the lack of authorization violates business logic\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  custom authorization mechanisms.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules. However,\n  manual efforts might not achieve desired code coverage within limited time constraints.\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Divide the product into anonymous,\n  normal, privileged, and administrative areas. Reduce the attack surface by carefully\n  mapping roles with data and functionality. Use role-based access control (RBAC)\n  to enforce the roles at the appropriate boundaries.\n\n  Note that this approach may not protect against horizontal authorization, i.e.,\n  it will not protect a user from attacking others with the same role.\n\n\n  Architecture and Design: Ensure that you perform access control checks related to\n  your business logic. These checks may be different than the access control checks\n  that you apply to more generic resources such as files, connections, processes,\n  memory, and database records. For example, a database may restrict access for medical\n  records to a specific database user, but each record might only be intended to be\n  accessible to the patient and the patient''s doctor.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, consider using authorization frameworks such as the JAAS Authorization\n  Framework [REF-233] and the OWASP ESAPI Access Control feature [REF-45].\n\n\n  Architecture and Design: For web applications, make sure that the access control\n  mechanism is enforced correctly at the server side on every page. Users should not\n  be able to access any unauthorized functionality or information by simply requesting\n  direct access to that page.\n\n  One way to do this is to ensure that all pages containing sensitive information\n  are not cached, and that all such pages restrict access to requests that are accompanied\n  by an active and authenticated session token associated with a user who has the\n  required permissions to access that page.\n\n\n  System Configuration, Installation: Use the access control capabilities of your\n  operating system and server environment and define your access control lists accordingly.\n  Use a \"default deny\" policy when defining these ACLs.'\nObserved_Examples: 'CVE-2022-24730: Go-based continuous deployment product does not\n  check that a user has certain privileges to update or create an app, allowing adversaries\n  to read sensitive repository information\n\n\n  CVE-2009-3168: Web application does not restrict access to admin scripts, allowing\n  authenticated users to reset administrative passwords.\n\n\n  CVE-2009-2960: Web application does not restrict access to admin scripts, allowing\n  authenticated users to modify passwords of other users.\n\n\n  CVE-2009-3597: Web application stores database file under the web root with insufficient\n  access control (CWE-219), allowing direct request.\n\n\n  CVE-2009-2282: Terminal server does not check authorization for guest access.\n\n\n  CVE-2009-3230: Database server does not use appropriate privileges for certain sensitive\n  operations.\n\n\n  CVE-2009-2213: Gateway uses default \"Allow\" configuration for its authorization\n  settings.\n\n\n  CVE-2009-0034: Chain: product does not properly interpret a configuration option\n  for a system group, allowing users to gain privileges.\n\n\n  CVE-2008-6123: Chain: SNMP product does not properly parse a configuration option\n  for which hosts are allowed to connect, allowing unauthorized IP addresses to connect.\n\n\n  CVE-2008-5027: System monitoring software allows users to bypass authorization by\n  creating custom forms.\n\n\n  CVE-2008-7109: Chain: reliance on client-side security (CWE-602) allows attackers\n  to bypass authorization using a custom client.\n\n\n  CVE-2008-3424: Chain: product does not properly handle wildcards in an authorization\n  policy list, allowing unintended access.\n\n\n  CVE-2009-3781: Content management system does not check access permissions for private\n  files, allowing others to view those files.\n\n\n  CVE-2008-4577: ACL-based protection mechanism treats negative access rights as if\n  they are positive, allowing bypass of intended restrictions.\n\n\n  CVE-2008-6548: Product does not check the ACL of a page accessed using an \"include\"\n  directive, allowing attackers to read unauthorized files.\n\n\n  CVE-2007-2925: Default ACL list for a DNS server does not set certain ACLs, allowing\n  unauthorized DNS queries.\n\n\n  CVE-2006-6679: Product relies on the X-Forwarded-For HTTP header for authorization,\n  allowing unintended access by spoofing the header.\n\n\n  CVE-2005-3623: OS kernel does not check for a certain privilege before setting ACLs\n  for files.\n\n\n  CVE-2005-2801: Chain: file-system code performs an incorrect comparison (CWE-697),\n  preventing default ACLs from being properly applied.\n\n\n  CVE-2001-1155: Chain: product does not properly check the result of a reverse DNS\n  lookup because of operator precedence (CWE-783), allowing bypass of DNS-based access\n  restrictions.'\nRelated_Attack_Patterns: \"1: \\n\\n104: \\n\\n127: \\n\\n13: \\n\\n17: \\n\\n39: \\n\\n402: \\n\\\n  \\n45: \\n\\n5: \\n\\n51: \\n\\n59: \\n\\n60: \\n\\n647: \\n\\n668: \\n\\n76: \\n\\n77: \\n\\n87: \"\n",
  "ID: '286'\nName: Incorrect User Management\nDescription: The product does not properly manage a user within its environment.\nExtended_Description: Users can be assigned to the wrong group (class) of permissions\n  resulting in unintended access rights to sensitive objects.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\n",
  "ID: '287'\nName: Improper Authentication\nDescription: When an actor claims to have a given identity, the product does not prove\n  or insufficiently proves that the claim is correct.\nApplicable_Platforms:\n  Technology: ICS/OT\nAlternate_Terms: 'authentification: An alternate term is \"authentification\", which\n  appears to be most commonly used by people from non-English-speaking countries.\n\n\n  AuthN: \"AuthN\" is typically used as an abbreviation of \"authentication\" within the\n  web application security community. It is also distinct from \"AuthZ,\" which is an\n  abbreviation of \"authorization.\" The use of \"Auth\" as an abbreviation is discouraged,\n  since it could be used for either authentication or authorization.\n\n\n  AuthC: \"AuthC\" is used as an abbreviation of \"authentication,\" but it appears to\n  used less frequently than \"AuthN.\"'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis is useful\n  for detecting certain types of authentication. A tool may be able to analyze related\n  configuration files, such as .htaccess in Apache web servers, or detect the usage\n  of commonly-used authentication libraries.\n\n  Generally, automated static analysis tools have difficulty detecting custom authentication\n  schemes. In addition, the software''s design may include some functionality that\n  is accessible to any user and does not require an established identity; an automated\n  technique that detects the absence of authentication may report false positives.\n\n\n  Manual Static Analysis: This weakness can be detected using tools and techniques\n  that require manual (human) analysis, such as penetration testing, threat modeling,\n  and interactive tools that allow the tester to record and modify an active session.\n\n  Manual static analysis is useful for evaluating the correctness of custom authentication\n  mechanisms.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use an authentication framework or\n  library such as the OWASP ESAPI Authentication feature.'\nObserved_Examples: 'CVE-2022-36436: Python-based authentication proxy does not enforce\n  password authentication during the initial handshake, allowing the client to bypass\n  authentication by specifying a ''None'' authentication type.\n\n\n  CVE-2022-30034: Chain: Web UI for a Python RPC framework does not use regex anchors\n  to validate user login emails (CWE-777), potentially allowing bypass of OAuth (CWE-1390).\n\n\n  CVE-2022-29951: TCP-based protocol in Programmable Logic Controller (PLC) has no\n  authentication.\n\n\n  CVE-2022-29952: Condition Monitor uses a protocol that does not require authentication.\n\n\n  CVE-2022-30313: Safety Instrumented System uses proprietary TCP protocols with no\n  authentication.\n\n\n  CVE-2022-30317: Distributed Control System (DCS) uses a protocol that has no authentication.\n\n\n  CVE-2022-33139: SCADA system only uses client-side authentication, allowing adversaries\n  to impersonate other users.\n\n\n  CVE-2021-3116: Chain: Python-based HTTP Proxy server uses the wrong boolean operators\n  (CWE-480) causing an  incorrect comparison (CWE-697) that identifies an authN failure\n  if all three conditions are met instead of only one, allowing bypass of the proxy\n  authentication (CWE-1390)\n\n\n  CVE-2021-21972: Chain: Cloud computing virtualization platform does not require\n  authentication for upload of a tar format file (CWE-306), then uses .. path traversal\n  sequences (CWE-23) in the file to access unexpected files, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2021-37415: IT management product does not perform authentication for some REST\n  API requests, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-13927: Default setting in workflow management product allows all API requests\n  without authentication, as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-35395: Stack-based buffer overflows in SFK for wifi chipset used for IoT/embedded\n  devices, as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-34523: Mail server does not properly check an access token before executing\n  a Powershell command, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-12812: Chain: user is not prompted for a second authentication factor (CWE-287)\n  when changing the case of their username (CWE-178), as exploited in the wild per\n  CISA KEV.\n\n\n  CVE-2020-10148: Authentication bypass by appending specific parameters and values\n  to a URI, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-0688: Mail server does not generate a unique key during installation, as\n  exploited in the wild per CISA KEV.\n\n\n  CVE-2017-14623: LDAP Go package allows authentication bypass using an empty password,\n  causing an unauthenticated LDAP bind\n\n\n  CVE-2009-3421: login script for guestbook allows bypassing authentication by setting\n  a \"login_ok\" parameter to 1.\n\n\n  CVE-2009-2382: admin script allows authentication bypass by setting a cookie value\n  to \"LOGGEDIN\".\n\n\n  CVE-2009-1048: VOIP product allows authentication bypass using 127.0.0.1 in the\n  Host header.\n\n\n  CVE-2009-2213: product uses default \"Allow\" action, instead of default deny, leading\n  to authentication bypass.\n\n\n  CVE-2009-2168: chain: redirect without exit (CWE-698) leads to resultant authentication\n  bypass.\n\n\n  CVE-2009-3107: product does not restrict access to a listening port for a critical\n  service, allowing authentication to be bypassed.\n\n\n  CVE-2009-1596: product does not properly implement a security-related configuration\n  setting, allowing authentication bypass.\n\n\n  CVE-2009-2422: authentication routine returns \"nil\" instead of \"false\" in some situations,\n  allowing authentication bypass using an invalid username.\n\n\n  CVE-2009-3232: authentication update script does not properly handle when admin\n  does not select any authentication modules, allowing authentication bypass.\n\n\n  CVE-2009-3231: use of LDAP authentication with anonymous binds causes empty password\n  to result in successful authentication\n\n\n  CVE-2005-3435: product authentication succeeds if user-provided MD5 hash matches\n  the hash in its database; this can be subjected to replay attacks.\n\n\n  CVE-2005-0408: chain: product generates predictable MD5 hashes using a constant\n  value combined with username, allowing authentication bypass.'\nRelated_Attack_Patterns: \"114: \\n\\n115: \\n\\n151: \\n\\n194: \\n\\n22: \\n\\n57: \\n\\n593:\\\n  \\ \\n\\n633: \\n\\n650: \\n\\n94: \"\n",
  "ID: '288'\nName: Authentication Bypass Using an Alternate Path or Channel\nDescription: A product requires authentication, but the product has an alternate path\n  or channel that does not require authentication.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Architecture and Design: This is often seen in web applications that assume that\n  access to a particular CGI program can only be obtained through a \"front\" screen,\n  when the supporting programs are directly accessible. But this problem is not just\n  in web apps.'\nPotential_Mitigations: 'Architecture and Design: Funnel all access through a single\n  choke point to simplify how users can access a resource. For every access, perform\n  a check to determine if the user has permissions to access the resource.'\nObserved_Examples: 'CVE-2000-1179: Router allows remote attackers to read system logs\n  without authentication by directly connecting to the login screen and typing certain\n  control characters.\n\n\n  CVE-1999-1454: Attackers with physical access to the machine may bypass the password\n  prompt by pressing the ESC (Escape) key.\n\n\n  CVE-1999-1077: OS allows local attackers to bypass the password protection of idled\n  sessions via the programmer''s switch or CMD-PWR keyboard sequence, which brings\n  up a debugger that the attacker can use to disable the lock.\n\n\n  CVE-2003-0304: Direct request of installation file allows attacker to create administrator\n  accounts.\n\n\n  CVE-2002-0870: Attackers may gain additional privileges by directly requesting the\n  web management URL.\n\n\n  CVE-2002-0066: Bypass authentication via direct request to named pipe.\n\n\n  CVE-2003-1035: User can avoid lockouts by using an API instead of the GUI to conduct\n  brute force password guessing.'\nRelated_Attack_Patterns: \"127: \\n\\n665: \"\n",
  "ID: '289'\nName: Authentication Bypass by Alternate Name\nDescription: The product performs authentication based on the name of a resource being\n  accessed, or the name of the actor performing the access, but it does not properly\n  check all possible names for that resource or actor.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Avoid making decisions based on names\n  of resources (e.g. files) if those resources can have alternate names.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2003-0317: Protection mechanism that restricts URL access\n  can be bypassed using URL encoding.\n\n\n  CVE-2004-0847: Bypass of authentication for files using \"\\\" (backslash) or \"%5C\"\n  (encoded backslash).'\n",
  "ID: '29'\nName: 'Path Traversal: ''\\..\\filename'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize '\\..\\filename'\n  (leading backslash dot dot) sequences that can resolve to a location that is outside\n  of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  This is similar to CWE-25, except using \"\\\" instead of \"/\". Sometimes a program\n  checks for \"..\\\" at the beginning of the input, so a \"\\..\\\" can bypass that check.\n  It is also useful for bypassing path traversal protection schemes that only assume\n  that the \"/\" separator is valid.'\nApplicable_Platforms:\n  Operating_System: Windows\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-1987: Protection mechanism checks for \"/..\" but doesn''t\n  account for Windows-specific \"\\..\" allowing read of arbitrary files.\n\n\n  CVE-2005-2142: Directory traversal vulnerability in FTP server allows remote authenticated\n  attackers to list arbitrary directories via a \"\\..\" sequence in an LS command.'\n",
  "ID: '290'\nName: Authentication Bypass by Spoofing\nDescription: This attack-focused weakness is caused by incorrectly implemented authentication\n  schemes that are subject to spoofing attacks.\nObserved_Examples: 'CVE-2009-1048: VOIP product allows authentication bypass using\n  127.0.0.1 in the Host header.'\nRelated_Attack_Patterns: \"21: \\n\\n22: \\n\\n459: \\n\\n461: \\n\\n473: \\n\\n476: \\n\\n59:\\\n  \\ \\n\\n60: \\n\\n667: \\n\\n94: \"\n",
  "ID: '291'\nName: Reliance on IP Address for Authentication\nDescription: The product uses an IP address for authentication.\nExtended_Description: IP addresses can be easily spoofed. Attackers can forge the\n  source IP address of the packets they send, but response packets will return to\n  the forged IP address. To see the response packets, the attacker has to sniff the\n  traffic between the victim machine and the forged IP address. In order to accomplish\n  the required sniffing, attackers typically attempt to locate themselves on the same\n  subnet as the victim machine. Attackers may be able to circumvent this requirement\n  by using source routing, but source routing is disabled across much of the Internet\n  today. In summary, IP address verification can be a useful part of an authentication\n  scheme, but it should not be the single factor required for authentication.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Use other means of identity verification\n  that cannot be simply spoofed. Possibilities include a username/password or certificate.'\nRelated_Attack_Patterns: '4: '\n",
  "ID: '292'\nName: 'DEPRECATED: Trusting Self-reported DNS Name'\nDescription: This entry has been deprecated because it was a duplicate of CWE-350.\n  All content has been transferred to CWE-350.\n",
  "ID: '293'\nName: Using Referer Field for Authentication\nDescription: The referer field in HTTP requests can be easily modified and, as such,\n  is not a valid means of message integrity checking.\nAlternate_Terms: 'referrer: While the proper spelling might be regarded as \"referrer,\"\n  the HTTP RFCs and their implementations use \"referer,\" so this is regarded as the\n  correct spelling.'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: In order to usefully check if a given\n  action is authorized, some means of strong authentication and method protection\n  must be used. Use other means of authorization that cannot be simply spoofed. Possibilities\n  include a username/password or certificate.'\n",
  "ID: '294'\nName: Authentication Bypass by Capture-replay\nDescription: A capture-replay flaw exists when the design of the product makes it\n  possible for a malicious user to sniff network traffic and bypass authentication\n  by replaying it to the server in question to the same effect as the original message\n  (or with minor changes).\nExtended_Description: Capture-replay attacks are common and can be difficult to defeat\n  without cryptography. They are a subset of network injection attacks that rely on\n  observing previously-sent valid commands, then changing them slightly if necessary\n  and resending the same commands to the server.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Utilize some sequence or time stamping\n  functionality along with a checksum which takes this into account in order to ensure\n  that messages can be parsed only once.\n\n\n  Architecture and Design: Since any attacker who can listen to traffic can see sequence\n  numbers, it is necessary to sign messages with some kind of cryptography to ensure\n  that sequence numbers are not simply doctored along with content.'\nObserved_Examples: 'CVE-2005-3435: product authentication succeeds if user-provided\n  MD5 hash matches the hash in its database; this can be subjected to replay attacks.\n\n\n  CVE-2007-4961: Chain: cleartext transmission of the MD5 hash of password (CWE-319)\n  enables attacks against a server that is susceptible to replay (CWE-294).'\nRelated_Attack_Patterns: \"102: \\n\\n509: \\n\\n555: \\n\\n561: \\n\\n60: \\n\\n644: \\n\\n645:\\\n  \\ \\n\\n652: \\n\\n701: \\n\\n94: \"\n",
  "ID: '295'\nName: Improper Certificate Validation\nDescription: The product does not validate, or incorrectly validates, a certificate.\nExtended_Description: When a certificate is invalid or malicious, it might allow an\n  attacker to spoof a trusted entity by interfering in the communication path between\n  the host and client. The product might connect to a malicious host while believing\n  it is a trusted host, or the product might be deceived into accepting spoofed data\n  that appears to originate from a trusted host.\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nImplementation: When the product uses certificate pinning, the developer might\\\n  \\ not properly validate all relevant components of the certificate before pinning\\\n  \\ the certificate. This can make it difficult or expensive to test after the pinning\\\n  \\ is complete.\"\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Certificates should be carefully managed and checked to assure that\n  data are encrypted with the intended owner''s public key.\n\n\n  Implementation: If certificate pinning is being used, ensure that all relevant properties\n  of the certificate are fully validated before the certificate is pinned, including\n  the hostname.'\nObserved_Examples: 'CVE-2019-12496: A Go framework for robotics, drones, and IoT devices\n  skips verification of root CA certificates by default.\n\n\n  CVE-2014-1266: chain: incorrect \"goto\" in Apple SSL product bypasses certificate\n  validation, allowing Adversary-in-the-Middle (AITM) attack (Apple \"goto fail\" bug).\n  CWE-705 (Incorrect Control Flow Scoping) -> CWE-561 (Dead Code) -> CWE-295 (Improper\n  Certificate Validation) -> CWE-393 (Return of Wrong Status Code) -> CWE-300 (Channel\n  Accessible by Non-Endpoint).\n\n\n  CVE-2021-22909: Chain: router''s firmware update procedure uses curl with \"-k\" (insecure)\n  option that disables certificate validation (CWE-295), allowing adversary-in-the-middle\n  (AITM) compromise with a malicious firmware image (CWE-494).\n\n\n  CVE-2008-4989: Verification function trusts certificate chains in which the last\n  certificate is self-signed.\n\n\n  CVE-2012-5821: Web browser uses a TLS-related function incorrectly, preventing it\n  from verifying that a server''s certificate is signed by a trusted certification\n  authority (CA)\n\n\n  CVE-2009-3046: Web browser does not check if any intermediate certificates are revoked.\n\n\n  CVE-2011-0199: Operating system does not check Certificate Revocation List (CRL)\n  in some cases, allowing spoofing using a revoked certificate.\n\n\n  CVE-2012-5810: Mobile banking application does not verify hostname, leading to financial\n  loss.\n\n\n  CVE-2012-3446: Cloud-support library written in Python uses incorrect regular expression\n  when matching hostname.\n\n\n  CVE-2009-2408: Web browser does not correctly handle ''\\0'' character (NUL) in Common\n  Name, allowing spoofing of https sites.\n\n\n  CVE-2012-2993: Smartphone device does not verify hostname, allowing spoofing of\n  mail services.\n\n\n  CVE-2012-5822: Application uses third-party library that does not validate hostname.\n\n\n  CVE-2012-5819: Cloud storage management application does not validate hostname.\n\n\n  CVE-2012-5817: Java library uses JSSE SSLSocket and SSLEngine classes, which do\n  not verify the hostname.\n\n\n  CVE-2010-1378: chain: incorrect calculation allows attackers to bypass certificate\n  checks.\n\n\n  CVE-2005-3170: LDAP client accepts certificates even if they are not from a trusted\n  CA.\n\n\n  CVE-2009-0265: chain: DNS server does not correctly check return value from the\n  OpenSSL EVP_VerifyFinal function allows bypass of validation of the certificate\n  chain.\n\n\n  CVE-2003-1229: chain: product checks if client is trusted when it intended to check\n  if the server is trusted, allowing validation of signed code.\n\n\n  CVE-2002-0862: Cryptographic API, as used in web browsers, mail clients, and other\n  software, does not properly validate Basic Constraints.\n\n\n  CVE-2009-1358: chain: OS package manager does not check properly check the return\n  value, allowing bypass using a revoked certificate.'\nRelated_Attack_Patterns: \"459: \\n\\n475: \"\n",
  "ID: '296'\nName: Improper Following of a Certificate's Chain of Trust\nDescription: The product does not follow, or incorrectly follows, the chain of trust\n  for a certificate back to a trusted root certificate, resulting in incorrect trust\n  of any resource that is associated with that certificate.\nExtended_Description: 'If a system does not follow the chain of trust of a certificate\n  to a root server, the certificate loses all usefulness as a metric of trust. Essentially,\n  the trust gained from a certificate is derived from a chain of trust -- with a reputable\n  trusted entity at the end of that list. The end user must trust that reputable source,\n  and this reputable source must vouch for the resource in question through the medium\n  of the certificate.\n\n  In some cases, this trust traverses several entities who vouch for one another.\n  The entity trusted by the end user is at one end of this trust chain, while the\n  certificate-wielding resource is at the other end of the chain. If the user receives\n  a certificate at the end of one of these trust chains and then proceeds to check\n  only that the first link in the chain, no real trust has been derived, since the\n  entire chain must be traversed back to a trusted source to verify the certificate.\n\n  There are several ways in which the chain of trust might be broken, including but\n  not limited to:'\nModes_Of_Introduction: 'Implementation: When the product uses certificate pinning,\n  the developer might not properly validate all relevant components of the certificate\n  before pinning the certificate. This can make it difficult or expensive to test\n  after the pinning is complete.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Ensure that proper certificate checking\n  is included in the system design.\n\n\n  Implementation: Understand, and properly implement all checks necessary to ensure\n  the integrity of certificate trust integrity.\n\n\n  Implementation: If certificate pinning is being used, ensure that all relevant properties\n  of the certificate are fully validated before the certificate is pinned, including\n  the full chain of trust.'\nObserved_Examples: 'CVE-2016-2402: Server allows bypass of certificate pinning by\n  sending a chain of trust that includes a trusted CA that is not pinned.\n\n\n  CVE-2008-4989: Verification function trusts certificate chains in which the last\n  certificate is self-signed.\n\n\n  CVE-2012-5821: Chain: Web browser uses a TLS-related function incorrectly, preventing\n  it from verifying that a server''s certificate is signed by a trusted certification\n  authority (CA).\n\n\n  CVE-2009-3046: Web browser does not check if any intermediate certificates are revoked.\n\n\n  CVE-2009-0265: chain: DNS server does not correctly check return value from the\n  OpenSSL EVP_VerifyFinal function allows bypass of validation of the certificate\n  chain.\n\n\n  CVE-2009-0124: chain: incorrect check of return value from the OpenSSL EVP_VerifyFinal\n  function allows bypass of validation of the certificate chain.\n\n\n  CVE-2002-0970: File-transfer software does not validate Basic Constraints of an\n  intermediate CA-signed certificate.\n\n\n  CVE-2002-0862: Cryptographic API, as used in web browsers, mail clients, and other\n  software, does not properly validate Basic Constraints.'\n",
  "ID: '297'\nName: Improper Validation of Certificate with Host Mismatch\nDescription: The product communicates with a host that provides a certificate, but\n  the product does not properly ensure that the certificate is actually associated\n  with that host.\nExtended_Description: 'Even if a certificate is well-formed, signed, and follows the\n  chain of trust, it may simply be a valid certificate for a different site than the\n  site that the product is interacting with. If the certificate''s host-specific data\n  is not properly checked - such as the Common Name (CN) in the Subject or the Subject\n  Alternative Name (SAN) extension of an X.509 certificate - it may be possible for\n  a redirection or spoofing attack to allow a malicious host with a valid certificate\n  to provide data, impersonating a trusted host. In order to ensure data integrity,\n  the certificate must be valid and it must pertain to the site that is being accessed.\n\n  Even if the product attempts to check the hostname, it is still possible to incorrectly\n  check the hostname. For example, attackers could create a certificate with a name\n  that begins with a trusted name followed by a NUL byte, which could cause some string-based\n  comparisons to only examine the portion that contains the trusted name.\n\n  This weakness can occur even when the product uses Certificate Pinning, if the product\n  does not verify the hostname at the time a certificate is pinned.'\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: 'Implementation: When the product uses certificate pinning,\n  the developer might not properly validate all relevant components of the certificate\n  before pinning the certificate. This can make it difficult or expensive to test\n  after the pinning is complete.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)\n\n\n  Dynamic Analysis with Manual Results Interpretation: Set up an untrusted endpoint\n  (e.g. a server) with which the product will connect.  Create a test certificate\n  that uses an invalid hostname but is signed by a trusted CA and provide this certificate\n  from the untrusted endpoint. If the product performs any operations instead of disconnecting\n  and reporting an error, then this indicates that the hostname is not being checked\n  and the test certificate has been accepted.\n\n\n  Black Box: When Certificate Pinning is being used in a mobile application, consider\n  using a tool such as Spinner [REF-955].  This methodology might be extensible to\n  other technologies.'\nPotential_Mitigations: 'Architecture and Design: Fully check the hostname of the certificate\n  and provide the user with adequate information about the nature of the problem and\n  how to proceed.\n\n\n  Implementation: If certificate pinning is being used, ensure that all relevant properties\n  of the certificate are fully validated before the certificate is pinned, including\n  the hostname.'\nObserved_Examples: 'CVE-2012-5810: Mobile banking application does not verify hostname,\n  leading to financial loss.\n\n\n  CVE-2012-5811: Mobile application for printing documents does not verify hostname,\n  allowing attackers to read sensitive documents.\n\n\n  CVE-2012-5807: Software for electronic checking does not verify hostname, leading\n  to financial loss.\n\n\n  CVE-2012-3446: Cloud-support library written in Python uses incorrect regular expression\n  when matching hostname.\n\n\n  CVE-2009-2408: Web browser does not correctly handle ''\\0'' character (NUL) in Common\n  Name, allowing spoofing of https sites.\n\n\n  CVE-2012-0867: Database program truncates the Common Name during hostname verification,\n  allowing spoofing.\n\n\n  CVE-2010-2074: Incorrect handling of ''\\0'' character (NUL) in hostname verification\n  allows spoofing.\n\n\n  CVE-2009-4565: Mail server''s incorrect handling of ''\\0'' character (NUL) in hostname\n  verification allows spoofing.\n\n\n  CVE-2009-3767: LDAP server''s incorrect handling of ''\\0'' character (NUL) in hostname\n  verification allows spoofing.\n\n\n  CVE-2012-5806: Payment processing module does not verify hostname when connecting\n  to PayPal using PHP fsockopen function.\n\n\n  CVE-2012-2993: Smartphone device does not verify hostname, allowing spoofing of\n  mail services.\n\n\n  CVE-2012-5804: E-commerce module does not verify hostname when connecting to payment\n  site.\n\n\n  CVE-2012-5824: Chat application does not validate hostname, leading to loss of privacy.\n\n\n  CVE-2012-5822: Application uses third-party library that does not validate hostname.\n\n\n  CVE-2012-5819: Cloud storage management application does not validate hostname.\n\n\n  CVE-2012-5817: Java library uses JSSE SSLSocket and SSLEngine classes, which do\n  not verify the hostname.\n\n\n  CVE-2012-5784: SOAP platform does not verify the hostname.\n\n\n  CVE-2012-5782: PHP library for payments does not verify the hostname.\n\n\n  CVE-2012-5780: Merchant SDK for payments does not verify the hostname.\n\n\n  CVE-2003-0355: Web browser does not validate Common Name, allowing spoofing of https\n  sites.'\n",
  "ID: '298'\nName: Improper Validation of Certificate Expiration\nDescription: A certificate expiration is not validated or is incorrectly validated,\n  so trust may be assigned to certificates that have been abandoned due to age.\nExtended_Description: When the expiration of a certificate is not taken into account,\n  no trust has necessarily been conveyed through it. Therefore, the validity of the\n  certificate cannot be verified and all benefit of the certificate is lost.\nModes_Of_Introduction: 'Implementation: When the software uses certificate pinning,\n  the developer might not properly validate all relevant components of the certificate\n  before pinning the certificate. This can make it difficult or expensive to test\n  after the pinning is complete.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Check for expired certificates and\n  provide the user with adequate information about the nature of the problem and how\n  to proceed.\n\n\n  Implementation: If certificate pinning is being used, ensure that all relevant properties\n  of the certificate are fully validated before the certificate is pinned, including\n  the expiration.'\n",
  "ID: '299'\nName: Improper Check for Certificate Revocation\nDescription: The product does not check or incorrectly checks the revocation status\n  of a certificate, which may cause it to use a certificate that has been compromised.\nExtended_Description: An improper check for certificate revocation is a far more serious\n  flaw than related certificate failures. This is because the use of any revoked certificate\n  is almost certainly malicious. The most common reason for certificate revocation\n  is compromise of the system in question, with the result that no legitimate servers\n  will be using a revoked certificate, unless they are sorely out of sync.\nModes_Of_Introduction: 'Implementation: When the product uses certificate pinning,\n  the developer might not properly validate all relevant components of the certificate\n  before pinning the certificate. This can make it difficult or expensive to test\n  after the pinning is complete.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Ensure that certificates are checked\n  for revoked status.\n\n\n  Implementation: If certificate pinning is being used, ensure that all relevant properties\n  of the certificate are fully validated before the certificate is pinned, including\n  the revoked status.'\nObserved_Examples: 'CVE-2011-2014: LDAP-over-SSL implementation does not check Certificate\n  Revocation List (CRL), allowing spoofing using a revoked certificate.\n\n\n  CVE-2011-0199: Operating system does not check Certificate Revocation List (CRL)\n  in some cases, allowing spoofing using a revoked certificate.\n\n\n  CVE-2010-5185: Antivirus product does not check whether certificates from signed\n  executables have been revoked.\n\n\n  CVE-2009-3046: Web browser does not check if any intermediate certificates are revoked.\n\n\n  CVE-2009-0161: chain: Ruby module for OCSP misinterprets a response, preventing\n  detection of a revoked certificate.\n\n\n  CVE-2011-2701: chain: incorrect parsing of replies from OCSP responders allows bypass\n  using a revoked certificate.\n\n\n  CVE-2011-0935: Router can permanently cache certain public keys, which would allow\n  bypass if the certificate is later revoked.\n\n\n  CVE-2009-1358: chain: OS package manager does not properly check the return value,\n  allowing bypass using a revoked certificate.\n\n\n  CVE-2009-0642: chain: language interpreter does not properly check the return value\n  from an OSCP function, allowing bypass using a revoked certificate.\n\n\n  CVE-2008-4679: chain: web service component does not call the expected method, which\n  prevents a check for revoked certificates.\n\n\n  CVE-2006-4410: Certificate revocation list not searched for certain certificates.\n\n\n  CVE-2006-4409: Product cannot access certificate revocation list when an HTTP proxy\n  is being used.'\n",
  "ID: '30'\nName: 'Path Traversal: ''\\dir\\..\\filename'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize '\\dir\\..\\filename'\n  (leading backslash dot dot) sequences that can resolve to a location that is outside\n  of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  This is similar to CWE-26, except using \"\\\" instead of \"/\". The ''\\dir\\..\\filename''\n  manipulation is useful for bypassing some path traversal protection schemes. Sometimes\n  a program only checks for \"..\\\" at the beginning of the input, so a \"\\..\\\" can bypass\n  that check.'\nApplicable_Platforms:\n  Operating_System: Windows\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-1987: Protection mechanism checks for \"/..\" but doesn''t\n  account for Windows-specific \"\\..\" allowing read of arbitrary files.'\n",
  "ID: '300'\nName: Channel Accessible by Non-Endpoint\nDescription: The product does not adequately verify the identity of actors at both\n  ends of a communication channel, or does not adequately ensure the integrity of\n  the channel, in a way that allows the channel to be accessed or influenced by an\n  actor that is not an endpoint.\nExtended_Description: In order to establish secure communication between two parties,\n  it is often important to adequately verify the identity of entities at each end\n  of the communication channel. Inadequate or inconsistent verification may result\n  in insufficient or incorrect identification of either communicating entity. This\n  can have negative consequences such as misplaced trust in the entity at the other\n  end of the channel. An attacker can leverage this by interposing between the communicating\n  entities and masquerading as the original entity. In the absence of sufficient verification\n  of identity, such an attacker can eavesdrop and potentially modify the communication\n  between the original entities.\nAlternate_Terms: \"Adversary-in-the-Middle / AITM: \\n\\nMan-in-the-Middle / MITM: \\n\\\n  \\nPerson-in-the-Middle / PITM: \\n\\nMonkey-in-the-Middle: \\n\\nMonster-in-the-Middle:\\\n  \\ \\n\\nOn-path attack: \\n\\nInterception attack: \"\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Always fully authenticate both ends of any\n  communications channel.\n\n\n  Architecture and Design: Adhere to the principle of complete mediation.\n\n\n  Implementation: A certificate binds an identity to a cryptographic key to authenticate\n  a communicating party. Often, the certificate takes the encrypted form of the hash\n  of the identity of the subject, the public key, and information such as time of\n  issue or expiration using the issuer''s private key. The certificate can be validated\n  by deciphering the certificate with the issuer''s public key. See also X.509 certificate\n  signature chains and the PGP certification structure.'\nObserved_Examples: 'CVE-2014-1266: chain: incorrect \"goto\" in Apple SSL product bypasses\n  certificate validation, allowing Adversry-in-the-Middle (AITM) attack (Apple \"goto\n  fail\" bug). CWE-705 (Incorrect Control Flow Scoping) -> CWE-561 (Dead Code) -> CWE-295\n  (Improper Certificate Validation) -> CWE-393 (Return of Wrong Status Code) -> CWE-300\n  (Channel Accessible by Non-Endpoint).'\nRelated_Attack_Patterns: \"466: \\n\\n57: \\n\\n589: \\n\\n590: \\n\\n612: \\n\\n613: \\n\\n615:\\\n  \\ \\n\\n662: \\n\\n94: \"\n",
  "ID: '301'\nName: Reflection Attack in an Authentication Protocol\nDescription: Simple authentication protocols are subject to reflection attacks if\n  a malicious user can use the target machine to impersonate a trusted user.\nExtended_Description: 'A mutual authentication protocol requires each party to respond\n  to a random challenge by the other party by encrypting it with a pre-shared key.\n  Often, however, such protocols employ the same pre-shared key for communication\n  with a number of different entities. A malicious user or an attacker can easily\n  compromise this protocol without possessing the correct key by employing a reflection\n  attack on the protocol.\n\n  Reflection attacks capitalize on mutual authentication schemes in order to trick\n  the target into revealing the secret shared between it and another valid user. In\n  a basic mutual-authentication scheme, a secret is known to both the valid user and\n  the server; this allows them to authenticate. In order that they may verify this\n  shared secret without sending it plainly over the wire, they utilize a Diffie-Hellman-style\n  scheme in which they each pick a value, then request the hash of that value as keyed\n  by the shared secret. In a reflection attack, the attacker claims to be a valid\n  user and requests the hash of a random value from the server. When the server returns\n  this value and requests its own value to be hashed, the attacker opens another connection\n  to the server. This time, the hash requested by the attacker is the value which\n  the server requested in the first connection. When the server returns this hashed\n  value, it is used in the first connection, authenticating the attacker successfully\n  as the impersonated valid user.'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Use different keys for the initiator\n  and responder or of a different type of challenge for the initiator and responder.\n\n\n  Architecture and Design: Let the initiator prove its identity before proceeding.'\nObserved_Examples: 'CVE-2005-3435: product authentication succeeds if user-provided\n  MD5 hash matches the hash in its database; this can be subjected to replay attacks.'\nRelated_Attack_Patterns: '90: '\n",
  "ID: '302'\nName: Authentication Bypass by Assumed-Immutable Data\nDescription: The authentication scheme or implementation uses key data elements that\n  are assumed to be immutable, but can be controlled or modified by the attacker.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design\n\n  Operation\n\n  Implementation: Implement proper protection for immutable data (e.g. environment\n  variable, hidden form fields, etc.)'\nObserved_Examples: 'CVE-2002-0367: DebPloit\n\n\n  CVE-2004-0261: Web auth\n\n\n  CVE-2002-1730: Authentication bypass by setting certain cookies to \"true\".\n\n\n  CVE-2002-1734: Authentication bypass by setting certain cookies to \"true\".\n\n\n  CVE-2002-2064: Admin access by setting a cookie.\n\n\n  CVE-2002-2054: Gain privileges by setting cookie.\n\n\n  CVE-2004-1611: Product trusts authentication information in cookie.\n\n\n  CVE-2005-1708: Authentication bypass by setting admin-testing variable to true.\n\n\n  CVE-2005-1787: Bypass auth and gain privileges by setting a variable.'\nRelated_Attack_Patterns: \"10: \\n\\n13: \\n\\n21: \\n\\n274: \\n\\n31: \\n\\n39: \\n\\n45: \\n\\n\\\n  77: \"\n",
  "ID: '303'\nName: Incorrect Implementation of Authentication Algorithm\nDescription: The requirements for the product dictate the use of an established authentication\n  algorithm, but the implementation of the algorithm is incorrect.\nExtended_Description: This incorrect implementation may allow authentication to be\n  bypassed.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2003-0750: Conditional should have been an ''or'' not an ''and''.'\nRelated_Attack_Patterns: '90: '\n",
  "ID: '304'\nName: Missing Critical Step in Authentication\nDescription: The product implements an authentication technique, but it skips a step\n  that weakens the technique.\nExtended_Description: Authentication techniques should follow the algorithms that\n  define them exactly, otherwise authentication can be bypassed or more easily subjected\n  to brute force attacks.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2004-2163: Shared secret not verified in a RADIUS response\n  packet, allowing authentication bypass by spoofing server replies.'\n",
  "ID: '305'\nName: Authentication Bypass by Primary Weakness\nDescription: The authentication algorithm is sound, but the implemented mechanism\n  can be bypassed as the result of a separate weakness that is primary to the authentication\n  error.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2002-1374: The provided password is only compared against\n  the first character of the real password.\n\n\n  CVE-2000-0979: The password is not properly checked, which allows remote attackers\n  to bypass access controls by sending a 1-byte password that matches the first character\n  of the real password.\n\n\n  CVE-2001-0088: Chain: Forum software does not properly initialize an array, which\n  inadvertently sets the password to a single character, allowing remote attackers\n  to easily guess the password and gain administrative privileges.'\n",
  "ID: '306'\nName: Missing Authentication for Critical Function\nDescription: The product does not perform any authentication for functionality that\n  requires a provable user identity or consumes a significant amount of resources.\nExtended_Description: As data is migrated to the cloud, if access does not require\n  authentication, it can be easier for attackers to access the data from anywhere\n  on the Internet.\nApplicable_Platforms:\n  Technology: Cloud Computing, ICS/OT\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nDetection_Methods: 'Manual Analysis: This weakness can be detected using tools and\n  techniques that require manual (human) analysis, such as penetration testing, threat\n  modeling, and interactive tools that allow the tester to record and modify an active\n  session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  custom authentication mechanisms.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Automated Static Analysis: Automated static analysis is useful for detecting commonly-used\n  idioms for authentication. A tool may be able to analyze related configuration files,\n  such as .htaccess in Apache web servers, or detect the usage of commonly-used authentication\n  libraries.\n\n  Generally, automated static analysis tools have difficulty detecting custom authentication\n  schemes. In addition, the software''s design may include some functionality that\n  is accessible to any user and does not require an established identity; an automated\n  technique that detects the absence of authentication may report false positives.\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Divide the software into anonymous,\n  normal, privileged, and administrative areas. Identify which of these areas require\n  a proven user identity, and use a centralized authentication capability.\n\n  Identify all potential communication channels, or other means of interaction with\n  the software, to ensure that all channels are appropriately protected. Developers\n  sometimes perform authentication at the primary channel, but open up a secondary\n  channel that is assumed to be private. For example, a login mechanism may be listening\n  on one network port, but after successful authentication, it may open up a second\n  port where it waits for the connection, but avoids authentication because it assumes\n  that only the authenticated party will connect to the port.\n\n  In general, if the software or protocol allows a single session or user state to\n  persist across multiple connections or channels, authentication and appropriate\n  credential management need to be used throughout.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Architecture and Design: Where possible, avoid implementing custom authentication\n  routines and consider using authentication capabilities as provided by the surrounding\n  framework, operating system, or environment. These may make it easier to provide\n  a clear separation between authentication tasks and authorization tasks.\n\n  In environments such as the World Wide Web, the line between authentication and\n  authorization is sometimes blurred. If custom authentication routines are required\n  instead of those provided by the server, then these routines must be applied to\n  every single page, since these pages could be requested directly.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, consider using libraries with authentication capabilities such as OpenSSL\n  or the ESAPI Authenticator [REF-45].\n\n\n  Implementation, System Configuration, Operation: When storing data in the cloud\n  (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider''s\n  controls to require strong authentication for users who should be allowed to access\n  the data [REF-1297] [REF-1298] [REF-1302].'\nObserved_Examples: 'CVE-2022-29951: TCP-based protocol in Programmable Logic Controller\n  (PLC) has no authentication.\n\n\n  CVE-2022-29952: Condition Monitor firmware uses a protocol that does not require\n  authentication.\n\n\n  CVE-2022-30276: SCADA-based protocol for bridging WAN and LAN traffic has no authentication.\n\n\n  CVE-2022-30313: Safety Instrumented System uses proprietary TCP protocols with no\n  authentication.\n\n\n  CVE-2022-30317: Distributed Control System (DCS) uses a protocol that has no authentication.\n\n\n  CVE-2021-21972: Chain: Cloud computing virtualization platform does not require\n  authentication for upload of a tar format file (CWE-306), then uses .. path traversal\n  sequences (CWE-23) in the file to access unexpected files, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2021-37415: IT management product does not perform authentication for some REST\n  API requests, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-13927: Default setting in workflow management product allows all API requests\n  without authentication, as exploited in the wild per CISA KEV.\n\n\n  CVE-2002-1810: MFV. Access TFTP server without authentication and obtain configuration\n  file with sensitive plaintext information.\n\n\n  CVE-2008-6827: Agent software running at privileges does not authenticate incoming\n  requests over an unprotected channel, allowing a Shatter\" attack.\n\n\n  CVE-2004-0213: Product enforces restrictions through a GUI but not through privileged\n  APIs.\n\n\n  CVE-2020-15483: monitor device allows access to physical UART debug port without\n  authentication\n\n\n  CVE-2019-9201: Programmable Logic Controller (PLC) does not have an authentication\n  feature on its communication protocols.'\nRelated_Attack_Patterns: \"12: \\n\\n166: \\n\\n216: \\n\\n36: \\n\\n62: \"\n",
  "ID: '307'\nName: Improper Restriction of Excessive Authentication Attempts\nDescription: The product does not implement sufficient measures to prevent multiple\n  failed authentication attempts within a short time frame, making it more susceptible\n  to brute force attacks.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Dynamic Analysis with Automated Results Interpretation: According\n  to SOAR, the following detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Common protection mechanisms include:\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Consider using libraries with authentication capabilities such as OpenSSL or the\n  ESAPI Authenticator. [REF-45]'\nObserved_Examples: 'CVE-2019-0039: the REST API for a network OS has a high limit\n  for number of connections, allowing brute force password guessing\n\n\n  CVE-1999-1152: Product does not disconnect or timeout after multiple failed logins.\n\n\n  CVE-2001-1291: Product does not disconnect or timeout after multiple failed logins.\n\n\n  CVE-2001-0395: Product does not disconnect or timeout after multiple failed logins.\n\n\n  CVE-2001-1339: Product does not disconnect or timeout after multiple failed logins.\n\n\n  CVE-2002-0628: Product does not disconnect or timeout after multiple failed logins.\n\n\n  CVE-1999-1324: User accounts not disabled when they exceed a threshold; possibly\n  a resultant problem.'\nRelated_Attack_Patterns: \"16: \\n\\n49: \\n\\n560: \\n\\n565: \\n\\n600: \\n\\n652: \\n\\n653: \"\n",
  "ID: '308'\nName: Use of Single-factor Authentication\nDescription: The use of single-factor authentication can lead to unnecessary risk\n  of compromise when compared with the benefits of a dual-factor authentication scheme.\nExtended_Description: While the use of multiple authentication schemes is simply piling\n  on more complexity on top of authentication, it is inestimably valuable to have\n  such measures of redundancy. The use of weak, reused, and common passwords is rampant\n  on the internet. Without the added protection of multiple authentication schemes,\n  a single mistake can result in the compromise of an account. For this reason, if\n  multiple schemes are possible and also easy to use, they should be implemented and\n  required.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Use multiple independent authentication\n  schemes, which ensures that -- if one of the methods is compromised -- the system\n  itself is still likely safe from compromise.'\nRelated_Attack_Patterns: \"16: \\n\\n49: \\n\\n509: \\n\\n55: \\n\\n555: \\n\\n560: \\n\\n561:\\\n  \\ \\n\\n565: \\n\\n600: \\n\\n644: \\n\\n645: \\n\\n652: \\n\\n653: \\n\\n70: \"\n",
  "ID: '309'\nName: Use of Password System for Primary Authentication\nDescription: The use of password systems as the primary means of authentication may\n  be subject to several flaws or shortcomings, each reducing the effectiveness of\n  the mechanism.\nPotential_Mitigations: 'Architecture and Design: In order to protect password systems\n  from compromise, the following should be noted:\n\n\n  Architecture and Design: Use a zero-knowledge password protocol, such as SRP.\n\n\n  Architecture and Design: Ensure that passwords are stored safely and are not reversible.\n\n\n  Architecture and Design: Implement password aging functionality that requires passwords\n  be changed after a certain point.\n\n\n  Architecture and Design: Use a mechanism for determining the strength of a password\n  and notify the user of weak password use.\n\n\n  Architecture and Design: Inform the user of why password protections are in place,\n  how they work to protect data integrity, and why it is important to heed their warnings.'\nRelated_Attack_Patterns: \"16: \\n\\n49: \\n\\n509: \\n\\n55: \\n\\n555: \\n\\n560: \\n\\n561:\\\n  \\ \\n\\n565: \\n\\n600: \\n\\n652: \\n\\n653: \\n\\n70: \"\n",
  "ID: '31'\nName: 'Path Traversal: ''dir\\..\\..\\filename'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize 'dir\\..\\..\\filename'\n  (multiple internal backslash dot dot) sequences that can resolve to a location that\n  is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''dir\\..\\..\\filename'' manipulation is useful for bypassing some path traversal\n  protection schemes. Sometimes a program only removes one \"..\\\" sequence, so multiple\n  \"..\\\" can bypass that check. Alternately, this manipulation could be used to bypass\n  a check for \"..\\\" at the beginning of the pathname, moving up more than one directory\n  level.'\nApplicable_Platforms:\n  Operating_System: Windows\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0160: The administration function in Access Control Server\n  allows remote attackers to read HTML, Java class, and image files outside the web\n  root via a \"..\\..\" sequence in the URL to port 2002.'\n",
  "ID: '311'\nName: Missing Encryption of Sensitive Data\nDescription: The product does not encrypt sensitive or critical information before\n  storage or transmission.\nExtended_Description: The lack of proper data encryption passes up the guarantees\n  of confidentiality, integrity, and accountability that properly implemented encryption\n  conveys.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Operation: '\nDetection_Methods: 'Manual Analysis: The characterizaton of sensitive data often requires\n  domain-specific understanding, so manual methods are useful. However, manual efforts\n  might not achieve desired code coverage within limited time constraints. Black box\n  methods may produce artifacts (e.g. stored data or unencrypted network transfer)\n  that require manual evaluation.\n\n\n  Automated Analysis: Automated measurement of the entropy of an input/output source\n  may indicate the use or lack of encryption, but human analysis is still required\n  to distinguish intentionally-unencrypted data (e.g. metadata) from sensitive data.\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Requirements: Clearly specify which data or resources are\n  valuable enough that they should be protected by encryption. Require that any transmission\n  or storage of this data/resource should use well-vetted encryption algorithms.\n\n\n  Architecture and Design: Ensure that encryption is properly integrated into the\n  system design, including but not necessarily limited to:\n\n  Identify the separate needs and contexts for encryption:\n\n  Using threat modeling or other techniques, assume that data can be compromised through\n  a separate vulnerability or weakness, and determine where encryption will be most\n  effective. Ensure that data that should be private is not being inadvertently exposed\n  using weaknesses such as insecure permissions (CWE-732). [REF-7]\n\n\n  Architecture and Design: When there is a need to store or transmit sensitive data,\n  use strong, up-to-date cryptographic algorithms to encrypt that data. Select a well-vetted\n  algorithm that is currently considered to be strong by experts in the field, and\n  use well-tested implementations. As with all cryptographic mechanisms, the source\n  code should be available for analysis.\n\n  For example, US government systems require FIPS 140-2 certification.\n\n  Do not develop custom or private cryptographic algorithms. They will likely be exposed\n  to attacks that are well-understood by cryptographers. Reverse engineering techniques\n  are mature. If the algorithm can be compromised if attackers find out how it works,\n  then it is especially weak.\n\n  Periodically ensure that the cryptography has not become obsolete. Some older algorithms,\n  once thought to require a billion years of computing time, can now be broken in\n  days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were\n  once regarded as strong. [REF-267]\n\n\n  Architecture and Design: Compartmentalize the system to have \"safe\" areas where\n  trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside\n  of the trust boundary and always be careful when interfacing with a compartment\n  outside of the safe area.\n\n  Ensure that appropriate compartmentalization is built into the system design, and\n  the compartmentalization allows for and reinforces privilege separation functionality.\n  Architects and designers should rely on the principle of least privilege to decide\n  the appropriate time to use privileges and the time to drop privileges.\n\n\n  Implementation\n\n  Architecture and Design: When using industry-approved techniques, use them correctly.\n  Don''t cut corners by skipping resource-intensive steps (CWE-325). These steps are\n  often essential for preventing common attacks.\n\n\n  Implementation: Use naming conventions and strong types to make it easier to spot\n  when sensitive data is being used. When creating structures, objects, or other complex\n  entities, separate the sensitive and non-sensitive data as much as possible.'\nObserved_Examples: 'CVE-2009-2272: password and username stored in cleartext in a\n  cookie\n\n\n  CVE-2009-1466: password stored in cleartext in a file with insecure permissions\n\n\n  CVE-2009-0152: chat program disables SSL in some circumstances even when the user\n  says to use SSL.\n\n\n  CVE-2009-1603: Chain: product uses an incorrect public exponent when generating\n  an RSA key, which effectively disables the encryption\n\n\n  CVE-2009-0964: storage of unencrypted passwords in a database\n\n\n  CVE-2008-6157: storage of unencrypted passwords in a database\n\n\n  CVE-2008-6828: product stores a password in cleartext in memory\n\n\n  CVE-2008-1567: storage of a secret key in cleartext in a temporary file\n\n\n  CVE-2008-0174: SCADA product uses HTTP Basic Authentication, which is not encrypted\n\n\n  CVE-2007-5778: login credentials stored unencrypted in a registry key\n\n\n  CVE-2002-1949: Passwords transmitted in cleartext.\n\n\n  CVE-2008-4122: Chain: Use of HTTPS cookie without \"secure\" flag causes it to be\n  transmitted across unencrypted HTTP.\n\n\n  CVE-2008-3289: Product sends password hash in cleartext in violation of intended\n  policy.\n\n\n  CVE-2008-4390: Remote management feature sends sensitive information including passwords\n  in cleartext.\n\n\n  CVE-2007-5626: Backup routine sends password in cleartext in email.\n\n\n  CVE-2004-1852: Product transmits Blowfish encryption key in cleartext.\n\n\n  CVE-2008-0374: Printer sends configuration information, including administrative\n  password, in cleartext.\n\n\n  CVE-2007-4961: Chain: cleartext transmission of the MD5 hash of password enables\n  attacks against a server that is susceptible to replay (CWE-294).\n\n\n  CVE-2007-4786: Product sends passwords in cleartext to a log server.\n\n\n  CVE-2005-3140: Product sends file with cleartext passwords in e-mail message intended\n  for diagnostic purposes.'\nRelated_Attack_Patterns: \"157: \\n\\n158: \\n\\n204: \\n\\n31: \\n\\n37: \\n\\n383: \\n\\n384:\\\n  \\ \\n\\n385: \\n\\n386: \\n\\n387: \\n\\n388: \\n\\n477: \\n\\n609: \\n\\n65: \"\n",
  "ID: '312'\nName: Cleartext Storage of Sensitive Information\nDescription: The product stores sensitive information in cleartext within a resource\n  that might be accessible to another control sphere.\nExtended_Description: 'Because the information is stored in cleartext (i.e., unencrypted),\n  attackers could potentially read it. Even if the information is encoded in a way\n  that is not human-readable, certain techniques could determine which encoding is\n  being used, then decode the information.\n\n  When organizations adopt cloud services, it can be easier for attackers to access\n  the data from anywhere on the Internet.\n\n  In some systems/environments such as cloud, the use of \"double encryption\" (at both\n  the software and hardware layer) might be required, and the developer might be solely\n  responsible for both layers, instead of shared responsibility with the administrator\n  of the broader system/environment.'\nApplicable_Platforms:\n  Technology: Cloud Computing, ICS/OT, Mobile\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation, System Configuration, Operation: When storing\n  data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use\n  the provider''s controls to encrypt the data at rest. [REF-1297] [REF-1299] [REF-1301]'\nObserved_Examples: 'CVE-2022-30275: Remote Terminal Unit (RTU) uses a driver that\n  relies on a password stored in plaintext.\n\n\n  CVE-2009-2272: password and username stored in cleartext in a cookie\n\n\n  CVE-2009-1466: password stored in cleartext in a file with insecure permissions\n\n\n  CVE-2009-0152: chat program disables SSL in some circumstances even when the user\n  says to use SSL.\n\n\n  CVE-2009-1603: Chain: product uses an incorrect public exponent when generating\n  an RSA key, which effectively disables the encryption\n\n\n  CVE-2009-0964: storage of unencrypted passwords in a database\n\n\n  CVE-2008-6157: storage of unencrypted passwords in a database\n\n\n  CVE-2008-6828: product stores a password in cleartext in memory\n\n\n  CVE-2008-1567: storage of a secret key in cleartext in a temporary file\n\n\n  CVE-2008-0174: SCADA product uses HTTP Basic Authentication, which is not encrypted\n\n\n  CVE-2007-5778: login credentials stored unencrypted in a registry key\n\n\n  CVE-2001-1481: Plaintext credentials in world-readable file.\n\n\n  CVE-2005-1828: Password in cleartext in config file.\n\n\n  CVE-2005-2209: Password in cleartext in config file.\n\n\n  CVE-2002-1696: Decrypted copy of a message written to disk given a combination of\n  options and when user replies to an encrypted message.\n\n\n  CVE-2004-2397: Plaintext storage of private key and passphrase in log file when\n  user imports the key.\n\n\n  CVE-2002-1800: Admin password in plaintext in a cookie.\n\n\n  CVE-2001-1537: Default configuration has cleartext usernames/passwords in cookie.\n\n\n  CVE-2001-1536: Usernames/passwords in cleartext in cookies.\n\n\n  CVE-2005-2160: Authentication information stored in cleartext in a cookie.'\nRelated_Attack_Patterns: '37: '\n",
  "ID: '313'\nName: Cleartext Storage in a File or on Disk\nDescription: The product stores sensitive information in cleartext in a file, or on\n  disk.\nExtended_Description: The sensitive information could be read by attackers with access\n  to the file, or with physical or administrator access to the raw disk. Even if the\n  information is encoded in a way that is not human-readable, certain techniques could\n  determine which encoding is being used, then decode the information.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2001-1481: Cleartext credentials in world-readable file.\n\n\n  CVE-2005-1828: Password in cleartext in config file.\n\n\n  CVE-2005-2209: Password in cleartext in config file.\n\n\n  CVE-2002-1696: Decrypted copy of a message written to disk given a combination of\n  options and when user replies to an encrypted message.\n\n\n  CVE-2004-2397: Cleartext storage of private key and passphrase in log file when\n  user imports the key.'\n",
  "ID: '314'\nName: Cleartext Storage in the Registry\nDescription: The product stores sensitive information in cleartext in the registry.\nExtended_Description: Attackers can read the information by accessing the registry\n  key. Even if the information is encoded in a way that is not human-readable, certain\n  techniques could determine which encoding is being used, then decode the information.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nObserved_Examples: 'CVE-2005-2227: Cleartext passwords in registry key.'\nRelated_Attack_Patterns: '37: '\n",
  "ID: '315'\nName: Cleartext Storage of Sensitive Information in a Cookie\nDescription: The product stores sensitive information in cleartext in a cookie.\nExtended_Description: Attackers can use widely-available tools to view the cookie\n  and read the sensitive information. Even if the information is encoded in a way\n  that is not human-readable, certain techniques could determine which encoding is\n  being used, then decode the information.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2002-1800: Admin password in cleartext in a cookie.\n\n\n  CVE-2001-1537: Default configuration has cleartext usernames/passwords in cookie.\n\n\n  CVE-2001-1536: Usernames/passwords in cleartext in cookies.\n\n\n  CVE-2005-2160: Authentication information stored in cleartext in a cookie.'\nRelated_Attack_Patterns: \"31: \\n\\n37: \\n\\n39: \\n\\n74: \"\n",
  "ID: '316'\nName: Cleartext Storage of Sensitive Information in Memory\nDescription: The product stores sensitive information in cleartext in memory.\nExtended_Description: 'The sensitive memory might be saved to disk, stored in a core\n  dump, or remain uncleared if the product crashes, or if the programmer does not\n  properly clear the memory before freeing it.\n\n  It could be argued that such problems are usually only exploitable by those with\n  administrator privileges. However, swapping could cause the memory to be written\n  to disk and leave it accessible to physical attack afterwards. Core dump files might\n  have insecure permissions or be stored in archive files that are accessible to untrusted\n  people. Or, uncleared sensitive memory might be inadvertently exposed to attackers\n  due to another weakness.'\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nObserved_Examples: 'CVE-2001-1517: Sensitive authentication information in cleartext\n  in memory.\n\n\n  BID:10155: Sensitive authentication information in cleartext in memory.\n\n\n  CVE-2001-0984: Password protector leaves passwords in memory when window is minimized,\n  even when \"clear password when minimized\" is set.\n\n\n  CVE-2003-0291: SSH client does not clear credentials from memory.'\n",
  "ID: '317'\nName: Cleartext Storage of Sensitive Information in GUI\nDescription: The product stores sensitive information in cleartext within the GUI.\nExtended_Description: An attacker can often obtain data from a GUI, even if hidden,\n  by using an API to directly access GUI objects such as windows and menus. Even if\n  the information is encoded in a way that is not human-readable, certain techniques\n  could determine which encoding is being used, then decode the information.\nApplicable_Platforms:\n  Operating_System: Windows\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nObserved_Examples: 'CVE-2002-1848: Unencrypted passwords stored in GUI dialog may\n  allow local users to access the passwords.'\n",
  "ID: '318'\nName: Cleartext Storage of Sensitive Information in Executable\nDescription: The product stores sensitive information in cleartext in an executable.\nExtended_Description: Attackers can reverse engineer binary code to obtain secret\n  data. This is especially easy when the cleartext is plain ASCII. Even if the information\n  is encoded in a way that is not human-readable, certain techniques could determine\n  which encoding is being used, then decode the information.\nObserved_Examples: 'CVE-2005-1794: Product stores RSA private key in a DLL and uses\n  it to sign a certificate, allowing spoofing of servers and Adversary-in-the-Middle\n  (AITM) attacks.\n\n\n  CVE-2001-1527: administration passwords in cleartext in executable'\nRelated_Attack_Patterns: \"37: \\n\\n65: \"\n",
  "ID: '319'\nName: Cleartext Transmission of Sensitive Information\nDescription: The product transmits sensitive or security-critical data in cleartext\n  in a communication channel that can be sniffed by unauthorized actors.\nExtended_Description: 'Many communication channels can be \"sniffed\" (monitored) by\n  adversaries during data transmission. For example, in networking, packets can traverse\n  many intermediary nodes from the source to the destination, whether across the internet,\n  an internal network, the cloud, etc. Some actors might have privileged access to\n  a network interface or any link along the channel, such as a router, but they might\n  not be authorized to collect the underlying data. As a result, network traffic could\n  be sniffed by adversaries, spilling security-critical data.\n\n  Applicable communication channels are not limited to software products. Applicable\n  channels include hardware-specific technologies such as internal hardware networks\n  and external debug channels, supporting remote JTAG debugging. When mitigations\n  are not applied to combat adversaries within the product''s threat model, this weakness\n  significantly lowers the difficulty of exploitation by such adversaries.\n\n  When full communications are recorded or logged, such as with a packet dump, an\n  adversary could attempt to obtain the dump long after the transmission has occurred\n  and try to \"sniff\" the cleartext from the recorded communications in the dump itself.\n  Even if the information is encoded in a way that is not human-readable, certain\n  techniques could determine which encoding is being used, then decode the information.'\nApplicable_Platforms:\n  Technology: Cloud Computing, Mobile, ICS/OT, System on Chip, Test/Debug Hardware\nModes_Of_Introduction: \"Architecture and Design: OMISSION: This weakness is caused\\\n  \\ by missing a security tactic during the architecture and design phase.\\n\\nArchitecture\\\n  \\ and Design: For hardware, this may be introduced when design does not plan for\\\n  \\ an attacker having physical access while a legitimate user is remotely operating\\\n  \\ the device.\\n\\nOperation: \\n\\nSystem Configuration: \"\nDetection_Methods: 'Black Box: Use monitoring tools that examine the software''s process\n  as it interacts with the operating system and the network. This technique is useful\n  in cases when source code is unavailable, if the software was not developed by you,\n  or if you want to verify that the build phase did not introduce any new weaknesses.\n  Examples include debuggers that directly attach to the running process; system-call\n  tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors\n  such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process, trigger the feature that sends the data, and\n  look for the presence or absence of common cryptographic functions in the call tree.\n  Monitor the network and determine if the data packets contain readable commands.\n  Tools exist for detecting if certain encodings are in use. If the traffic contains\n  high entropy, this might indicate the usage of encryption.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Before transmitting, encrypt the\n  data using reliable, confidentiality-protecting cryptographic protocols.\n\n\n  Implementation: When using web applications with SSL, use SSL for the entire session\n  from login to logout, not just for the initial login page.\n\n\n  Implementation: When designing hardware platforms, ensure that approved encryption\n  algorithms (such as those recommended by NIST) protect paths from security critical\n  data to trusted user applications.\n\n\n  Testing: Use tools and techniques that require manual (human) analysis, such as\n  penetration testing, threat modeling, and interactive tools that allow the tester\n  to record and modify an active session. These may be more effective than strictly\n  automated techniques. This is especially the case with weaknesses that are related\n  to design and business rules.\n\n\n  Operation: Configure servers to use encrypted channels for communication, which\n  may include SSL or other secure protocols.'\nObserved_Examples: 'CVE-2022-29519: Programmable Logic Controller (PLC) sends sensitive\n  information in plaintext, including passwords and session tokens.\n\n\n  CVE-2022-30312: Building Controller uses a protocol that transmits authentication\n  credentials in plaintext.\n\n\n  CVE-2022-31204: Programmable Logic Controller (PLC) sends password in plaintext.\n\n\n  CVE-2002-1949: Passwords transmitted in cleartext.\n\n\n  CVE-2008-4122: Chain: Use of HTTPS cookie without \"secure\" flag causes it to be\n  transmitted across unencrypted HTTP.\n\n\n  CVE-2008-3289: Product sends password hash in cleartext in violation of intended\n  policy.\n\n\n  CVE-2008-4390: Remote management feature sends sensitive information including passwords\n  in cleartext.\n\n\n  CVE-2007-5626: Backup routine sends password in cleartext in email.\n\n\n  CVE-2004-1852: Product transmits Blowfish encryption key in cleartext.\n\n\n  CVE-2008-0374: Printer sends configuration information, including administrative\n  password, in cleartext.\n\n\n  CVE-2007-4961: Chain: cleartext transmission of the MD5 hash of password enables\n  attacks against a server that is susceptible to replay (CWE-294).\n\n\n  CVE-2007-4786: Product sends passwords in cleartext to a log server.\n\n\n  CVE-2005-3140: Product sends file with cleartext passwords in e-mail message intended\n  for diagnostic purposes.'\nRelated_Attack_Patterns: \"102: \\n\\n117: \\n\\n383: \\n\\n477: \\n\\n65: \"\n",
  "ID: '32'\nName: 'Path Traversal: ''...'' (Triple Dot)'\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize '...' (triple\n  dot) sequences that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''...'' manipulation is useful for bypassing some path traversal protection\n  schemes. On some Windows systems, it is equivalent to \"..\\..\" and might bypass checks\n  that assume only two dots are valid. Incomplete filtering, such as removal of \"./\"\n  sequences, can ultimately produce valid \"..\" sequences due to a collapse into unsafe\n  value (CWE-182).'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2001-0467: \"\\...\" in web server\n\n\n  CVE-2001-0615: \"...\" or \"....\" in chat server\n\n\n  CVE-2001-0963: \"...\" in cd command in FTP server\n\n\n  CVE-2001-1193: \"...\" in cd command in FTP server\n\n\n  CVE-2001-1131: \"...\" in cd command in FTP server\n\n\n  CVE-2001-0480: read of arbitrary files and directories using GET or CD with \"...\"\n  in Windows-based FTP server.\n\n\n  CVE-2002-0288: read files using \".\" and Unicode-encoded \"/\" or \"\\\" characters in\n  the URL.\n\n\n  CVE-2003-0313: Directory listing of web server using \"...\"\n\n\n  CVE-2005-1658: Triple dot'\n",
  "ID: '321'\nName: Use of Hard-coded Cryptographic Key\nDescription: The use of a hard-coded cryptographic key significantly increases the\n  possibility that encrypted data may be recovered.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Prevention schemes mirror that of\n  hard-coded password storage.'\nObserved_Examples: 'CVE-2022-29960: Engineering Workstation uses hard-coded cryptographic\n  keys that could allow for unathorized filesystem access and privilege escalation\n\n\n  CVE-2022-30271: Remote Terminal Unit (RTU) uses a hard-coded SSH private key that\n  is likely to be used by default.\n\n\n  CVE-2020-10884: WiFi router service has a hard-coded encryption key, allowing root\n  access\n\n\n  CVE-2014-2198: Communications / collaboration product has a hardcoded SSH private\n  key, allowing access to root account'\n",
  "ID: '322'\nName: Key Exchange without Entity Authentication\nDescription: The product performs a key exchange with an actor without verifying the\n  identity of that actor.\nExtended_Description: Performing a key exchange will preserve the integrity of the\n  information sent between two entities, but this will not guarantee that the entities\n  are who they claim they are. This may enable an attacker to impersonate an actor\n  by modifying traffic between the two entities.  Typically, this involves a victim\n  client that contacts a malicious server that is impersonating a trusted server.\n  If the client skips authentication or ignores an authentication failure, the malicious\n  server may request authentication information from the user. The malicious server\n  can then use this authentication information to log in to the trusted server using\n  the victim's credentials, sniff traffic between the victim and trusted server, etc.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nPotential_Mitigations: 'Architecture and Design: Ensure that proper authentication\n  is included in the system design.\n\n\n  Implementation: Understand and properly implement all checks necessary to ensure\n  the identity of entities involved in encrypted communications.'\n",
  "ID: '323'\nName: Reusing a Nonce, Key Pair in Encryption\nDescription: Nonces should be used for the present occasion and only once.\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nPotential_Mitigations: 'Implementation: Refuse to reuse nonce values.\n\n\n  Implementation: Use techniques such as requiring incrementing, time based and/or\n  challenge response to assure uniqueness of nonces.'\n",
  "ID: '324'\nName: Use of a Key Past its Expiration Date\nDescription: The product uses a cryptographic key or password past its expiration\n  date, which diminishes its safety significantly by increasing the timing window\n  for cracking attacks against that key.\nExtended_Description: While the expiration of keys does not necessarily ensure that\n  they are compromised, it is a significant concern that keys which remain in use\n  for prolonged periods of time have a decreasing probability of integrity. For this\n  reason, it is important to replace keys within a period of time proportional to\n  their strength.\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Adequate consideration should be\n  put in to the user interface in order to notify users previous to the key''s expiration,\n  to explain the importance of new key generation and to walk users through the process\n  as painlessly as possible.'\n",
  "ID: '325'\nName: Missing Cryptographic Step\nDescription: The product does not implement a required step in a cryptographic algorithm,\n  resulting in weaker encryption than advertised by the algorithm.\nModes_Of_Introduction: 'Implementation: Developers sometimes omit \"expensive\" (resource-intensive)\n  steps in order to improve performance, especially in devices with limited memory\n  or slower CPUs. This step may be taken under a mistaken impression that the step\n  is unnecessary for the cryptographic algorithm.\n\n\n  Requirements: This issue may happen when the requirements for the cryptographic\n  algorithm are not clearly stated.'\nObserved_Examples: 'CVE-2001-1585: Missing challenge-response step allows authentication\n  bypass using public key.'\nRelated_Attack_Patterns: '68: '\n",
  "ID: '326'\nName: Inadequate Encryption Strength\nDescription: The product stores or transmits sensitive data using an encryption scheme\n  that is theoretically sound, but is not strong enough for the level of protection\n  required.\nExtended_Description: A weak encryption scheme can be subjected to brute force attacks\n  that have a reasonable chance of succeeding using current attack methods and resources.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use an encryption scheme that is\n  currently considered to be strong by experts in the field.'\nObserved_Examples: 'CVE-2001-1546: Weak encryption\n\n\n  CVE-2004-2172: Weak encryption (chosen plaintext attack)\n\n\n  CVE-2002-1682: Weak encryption\n\n\n  CVE-2002-1697: Weak encryption produces same ciphertext from the same plaintext\n  blocks.\n\n\n  CVE-2002-1739: Weak encryption\n\n\n  CVE-2005-2281: Weak encryption scheme\n\n\n  CVE-2002-1872: Weak encryption (XOR)\n\n\n  CVE-2002-1910: Weak encryption (reversible algorithm).\n\n\n  CVE-2002-1946: Weak encryption (one-to-one mapping).\n\n\n  CVE-2002-1975: Encryption error uses fixed salt, simplifying brute force / dictionary\n  attacks (overlaps randomness).'\nRelated_Attack_Patterns: \"112: \\n\\n192: \\n\\n20: \"\n",
  "ID: '327'\nName: Use of a Broken or Risky Cryptographic Algorithm\nDescription: The product uses a broken or risky cryptographic algorithm or protocol.\nExtended_Description: 'Cryptographic algorithms are the methods by which data is scrambled\n  to prevent observation or influence by unauthorized actors. Insecure cryptography\n  can be exploited to expose sensitive information, modify data in unexpected ways,\n  spoof identities of other users or devices, or other impacts.\n\n  It is very difficult to produce a secure algorithm, and even high-profile algorithms\n  by accomplished cryptographic experts have been broken. Well-known techniques exist\n  to break or weaken various kinds of cryptography. Accordingly, there are a small\n  number of well-understood and heavily studied algorithms that should be used by\n  most products. Using a non-standard or known-insecure algorithm is dangerous because\n  a determined adversary may be able to break the algorithm and compromise whatever\n  data has been protected.\n\n  Since the state of cryptography advances so rapidly, it is common for an algorithm\n  to be considered \"unsafe\" even if it was once thought to be strong. This can happen\n  when new attacks are discovered, or if computing power increases so much that the\n  cryptographic algorithm no longer provides the amount of protection that was originally\n  thought.\n\n  For a number of reasons, this weakness is even more challenging to manage with hardware\n  deployment of cryptographic algorithms as opposed to software implementation. First,\n  if a flaw is discovered with hardware-implemented cryptography, the flaw cannot\n  be fixed in most cases without a recall of the product, because hardware is not\n  easily replaceable like software. Second, because the hardware product is expected\n  to work for years, the adversary''s computing power will only increase over time.'\nApplicable_Platforms:\n  Language: Verilog, VHDL\n  Technology: ICS/OT\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: With hardware, the Architecture or Design Phase might start with\n  compliant cryptography, but it is replaced with a non-compliant crypto during the\n  later Implementation phase due to implementation constraints (e.g., not enough entropy\n  to make it function properly, or not enough silicon real estate available to implement).\n  Or, in rare cases (especially for long projects that span over years), the Architecture\n  specifications might start with cryptography that was originally compliant at the\n  time the Architectural specs were written, but over the time it became non-compliant\n  due to progress made in attacking the crypto.'\nDetection_Methods: 'Automated Analysis: Automated methods may be useful for recognizing\n  commonly-used libraries or features that have become obsolete.\n\n  False negatives may occur if the tool is not aware of the cryptographic libraries\n  in use, or if custom cryptography is being used.\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: When there is a need to store or\n  transmit sensitive data, use strong, up-to-date cryptographic algorithms to encrypt\n  that data. Select a well-vetted algorithm that is currently considered to be strong\n  by experts in the field, and use well-tested implementations. As with all cryptographic\n  mechanisms, the source code should be available for analysis.\n\n  For example, US government systems require FIPS 140-2 certification [REF-1192].\n\n  Do not develop custom or private cryptographic algorithms. They will likely be exposed\n  to attacks that are well-understood by cryptographers. Reverse engineering techniques\n  are mature. If the algorithm can be compromised if attackers find out how it works,\n  then it is especially weak.\n\n  Periodically ensure that the cryptography has not become obsolete. Some older algorithms,\n  once thought to require a billion years of computing time, can now be broken in\n  days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were\n  once regarded as strong. [REF-267]\n\n\n  Architecture and Design: Ensure that the design allows one cryptographic algorithm\n  to be replaced with another in the next generation or version. Where possible, use\n  wrappers to make the interfaces uniform. This will make it easier to upgrade to\n  stronger algorithms. With hardware, design the product at the Intellectual Property\n  (IP) level so that one cryptographic algorithm can be replaced with another in the\n  next generation of the hardware product.\n\n\n  Architecture and Design: Carefully manage and protect cryptographic keys (see CWE-320).\n  If the keys can be guessed or stolen, then the strength of the cryptography itself\n  is irrelevant.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Industry-standard implementations will save development time and may be more likely\n  to avoid errors that can occur during implementation of cryptographic algorithms.\n  Consider the ESAPI Encryption feature.\n\n\n  Implementation\n\n  Architecture and Design: When using industry-approved techniques, use them correctly.\n  Don''t cut corners by skipping resource-intensive steps (CWE-325). These steps are\n  often essential for preventing common attacks.'\nObserved_Examples: 'CVE-2022-30273: SCADA-based protocol supports a legacy encryption\n  mode that uses Tiny Encryption Algorithm (TEA) in ECB mode, which leaks patterns\n  in messages and cannot protect integrity\n\n\n  CVE-2022-30320: Programmable Logic Controller (PLC) uses a protocol with a cryptographically\n  insecure hashing algorithm for passwords.\n\n\n  CVE-2008-3775: Product uses \"ROT-25\" to obfuscate the password in the registry.\n\n\n  CVE-2007-4150: product only uses \"XOR\" to obfuscate sensitive data\n\n\n  CVE-2007-5460: product only uses \"XOR\" and a fixed key to obfuscate sensitive data\n\n\n  CVE-2005-4860: Product substitutes characters with other characters in a fixed way,\n  and also leaves certain input characters unchanged.\n\n\n  CVE-2002-2058: Attackers can infer private IP addresses by dividing each octet by\n  the MD5 hash of ''20''.\n\n\n  CVE-2008-3188: Product uses DES when MD5 has been specified in the configuration,\n  resulting in weaker-than-expected password hashes.\n\n\n  CVE-2005-2946: Default configuration of product uses MD5 instead of stronger algorithms\n  that are available, simplifying forgery of certificates.\n\n\n  CVE-2007-6013: Product uses the hash of a hash for authentication, allowing attackers\n  to gain privileges if they can obtain the original hash.'\nRelated_Attack_Patterns: \"20: \\n\\n459: \\n\\n473: \\n\\n475: \\n\\n608: \\n\\n614: \\n\\n97: \"\n",
  "ID: '328'\nName: Use of Weak Hash\nDescription: The product uses an algorithm that produces a digest (output value) that\n  does not meet security expectations for a hash function that allows an adversary\n  to reasonably determine the original input (preimage attack), find another input\n  that can produce the same hash (2nd preimage attack), or find multiple inputs that\n  evaluate to the same hash (birthday attack).\nExtended_Description: 'A hash function is defined as an algorithm that maps arbitrarily\n  sized data into a fixed-sized digest (output) such that the following properties\n  hold:\n\n  Building on this definition, a cryptographic hash function must also ensure that\n  a malicious actor cannot leverage the hash function to have a reasonable chance\n  of success at determining any of the following:\n\n  What is regarded as \"reasonable\" varies by context and threat model, but in general,\n  \"reasonable\" could cover any attack that is more efficient than brute force (i.e.,\n  on average, attempting half of all possible combinations). Note that some attacks\n  might be more efficient than brute force but are still not regarded as achievable\n  in the real world.\n\n  Any algorithm does not meet the above conditions will generally be considered weak\n  for general use in hashing.\n\n  In addition to algorithmic weaknesses, a hash function can be made weak by using\n  the hash in a security context that breaks its security guarantees. For example,\n  using a hash function without a salt for storing passwords (that are sufficiently\n  short) could enable an adversary to create a \"rainbow table\" [REF-637] to recover\n  the password under certain conditions; this attack works against such hash functions\n  as MD5, SHA-1, and SHA-2.'\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use an adaptive hash function that\n  can be configured to change the amount of computational effort needed to compute\n  the hash, such as the number of iterations (\"stretching\") or the amount of memory\n  required. Some hash functions perform salting automatically. These functions can\n  significantly increase the overhead for a brute force attack compared to intentionally-fast\n  functions such as MD5. For example, rainbow table attacks can become infeasible\n  due to the high computing overhead. Finally, since computing power gets faster and\n  cheaper over time, the technique can be reconfigured to increase the workload without\n  forcing an entire replacement of the algorithm in use.\n\n  Some hash functions that have one or more of these desired properties include bcrypt\n  [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate\n  about which of these is the most effective, they are all stronger than using salts\n  with hash functions with very little computing overhead.\n\n  Note that using these functions can have an impact on performance, so they require\n  special consideration to avoid denial-of-service attacks. However, their configurability\n  provides finer control over how much CPU and memory is used, so it could be adjusted\n  to suit the environment''s needs.'\nObserved_Examples: 'CVE-2022-30320: Programmable Logic Controller (PLC) uses a protocol\n  with a cryptographically insecure hashing algorithm for passwords.\n\n\n  CVE-2005-4900: SHA-1 algorithm is not collision-resistant.\n\n\n  CVE-2020-25685: DNS product uses a weak hash (CRC32 or SHA-1) of the query name,\n  allowing attacker to forge responses by computing domain names with the same hash.\n\n\n  CVE-2012-6707: blogging product uses MD5-based algorithm for passwords.\n\n\n  CVE-2019-14855: forging of certificate signatures using SHA-1 collisions.\n\n\n  CVE-2017-15999: mobile app for backup sends SHA-1 hash of password in cleartext.\n\n\n  CVE-2006-4068: Hard-coded hashed values for username and password contained in client-side\n  script, allowing brute-force offline attacks.'\nRelated_Attack_Patterns: \"461: \\n\\n68: \"\n",
  "ID: '329'\nName: Generation of Predictable IV with CBC Mode\nDescription: The product generates and uses a predictable initialization Vector (IV)\n  with Cipher Block Chaining (CBC) Mode, which causes algorithms to be susceptible\n  to dictionary attacks when they are encrypted under the same key.\nExtended_Description: \"CBC mode eliminates a weakness of Electronic Code\\n\\t   Book\\\n  \\ (ECB) mode by allowing identical plaintext blocks to\\n\\t   be encrypted to different\\\n  \\ ciphertext blocks. This is\\n\\t   possible by the XOR-ing of an IV with the initial\\\n  \\ plaintext\\n\\t   block so that every plaintext block in the chain is XOR'd\\n\\t\\\n  \\   with a different value before encryption. If IVs are\\n\\t   reused, then identical\\\n  \\ plaintexts would be encrypted to\\n\\t   identical ciphertexts. However, even if\\\n  \\ IVs are not\\n\\t   identical but are predictable, then they still break the\\n\\t\\\n  \\   security of CBC mode against Chosen Plaintext Attacks\\n\\t   (CPA).\"\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Implementation: Developers might dismiss the importance of\n  an unpredictable IV and choose an easier implementation to save effort, weakening\n  the scheme in the process.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: NIST recommends two methods of generating\n  unpredictable IVs for CBC mode [REF-1172]. The first is to generate the IV randomly.\n  The second method is to encrypt a nonce with the same key and cipher to be used\n  to encrypt the plaintext. In this case the nonce must be unique but can be predictable,\n  since the block cipher will act as a pseudo random permutation.'\nObserved_Examples: 'CVE-2020-5408: encryption functionality in an authentication framework\n  uses a fixed null IV with CBC mode, allowing attackers to decrypt traffic in applications\n  that use this functionality\n\n\n  CVE-2017-17704: messages for a door-unlocking product use a fixed IV in CBC mode,\n  which is the same after each restart\n\n\n  CVE-2017-11133: application uses AES in CBC mode, but the pseudo-random secret and\n  IV are generated using math.random, which is not cryptographically strong.\n\n\n  CVE-2007-3528: Blowfish-CBC implementation constructs an IV where each byte is calculated\n  modulo 8 instead of modulo 256, resulting in less than 12 bits for the effective\n  IV length, and less than 4096 possible IV values.\n\n\n  CVE-2011-3389: BEAST attack in SSL 3.0 / TLS 1.0. In CBC mode, chained initialization\n  vectors are non-random, allowing decryption of HTTPS traffic using a chosen plaintext\n  attack.'\n",
  "ID: '33'\nName: 'Path Traversal: ''....'' (Multiple Dot)'\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize '....' (multiple\n  dot) sequences that can resolve to a location that is outside of that directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''....'' manipulation is useful for bypassing some path traversal protection\n  schemes. On some Windows systems, it is equivalent to \"..\\..\\..\" and might bypass\n  checks that assume only two dots are valid. Incomplete filtering, such as removal\n  of \"./\" sequences, can ultimately produce valid \"..\" sequences due to a collapse\n  into unsafe value (CWE-182).'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-0240: read files via \"/........../\" in URL\n\n\n  CVE-2000-0773: read files via \"....\" in web server\n\n\n  CVE-1999-1082: read files via \"......\" in web server (doubled triple dot?)\n\n\n  CVE-2004-2121: read files via \"......\" in web server (doubled triple dot?)\n\n\n  CVE-2001-0491: multiple attacks using \"..\", \"...\", and \"....\" in different commands\n\n\n  CVE-2001-0615: \"...\" or \"....\" in chat server'\n",
  "ID: '330'\nName: Use of Insufficiently Random Values\nDescription: The product uses insufficiently random numbers or values in a security\n  context that depends on unpredictable numbers.\nExtended_Description: When product generates predictable values in a context requiring\n  unpredictability, it may be possible for an attacker to guess the next value that\n  will be generated, and use this guess to impersonate another user or access sensitive\n  information.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Black Box: Use monitoring tools that examine the software''s process\n  as it interacts with the operating system and the network. This technique is useful\n  in cases when source code is unavailable, if the software was not developed by you,\n  or if you want to verify that the build phase did not introduce any new weaknesses.\n  Examples include debuggers that directly attach to the running process; system-call\n  tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors\n  such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and look for library functions that indicate when\n  randomness is being used. Run the process multiple times to see if the seed changes.\n  Look for accesses of devices or equivalent resources that are commonly used for\n  strong (or weak) randomness, such as /dev/urandom on Linux. Look for library or\n  system calls that access predictable information such as process IDs and system\n  time.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use a well-vetted algorithm that\n  is currently considered to be strong by experts in the field, and select well-tested\n  implementations with adequate length seeds.\n\n  In general, if a pseudo-random number generator is not advertised as being cryptographically\n  secure, then it is probably a statistical PRNG and should not be used in security-sensitive\n  contexts.\n\n  Pseudo-random number generators can produce predictable numbers if the generator\n  is known and the seed can be guessed. A 256-bit seed is a good starting point for\n  producing a \"random enough\" number.\n\n\n  Implementation: Consider a PRNG that re-seeds itself as needed from high quality\n  pseudo-random output sources, such as hardware devices.\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n\n  Testing: Use tools and techniques that require manual (human) analysis, such as\n  penetration testing, threat modeling, and interactive tools that allow the tester\n  to record and modify an active session. These may be more effective than strictly\n  automated techniques. This is especially the case with weaknesses that are related\n  to design and business rules.'\nObserved_Examples: \"CVE-2020-7010: Cloud application on Kubernetes generates passwords\\\n  \\ using a weak random number generator based on deployment time.\\n\\nCVE-2009-3278:\\\n  \\ Crypto product uses rand() library function to generate a recovery key, making\\\n  \\ it easier to conduct brute force attacks.\\n\\nCVE-2009-3238: Random number generator\\\n  \\ can repeatedly generate the same value.\\n\\nCVE-2009-2367: Web application generates\\\n  \\ predictable session IDs, allowing session hijacking.\\n\\nCVE-2009-2158: Password\\\n  \\ recovery utility generates a relatively small number of random passwords, simplifying\\\n  \\ brute force attacks.\\n\\nCVE-2009-0255: Cryptographic key created with a seed based\\\n  \\ on the system time.\\n\\nCVE-2008-5162: Kernel function does not have a good entropy\\\n  \\ source just after boot.\\n\\nCVE-2008-4905: Blogging software uses a hard-coded\\\n  \\ salt when calculating a password hash.\\n\\nCVE-2008-4929: Bulletin board application\\\n  \\ uses insufficiently random names for uploaded files, allowing other users to access\\\n  \\ private files.\\n\\nCVE-2008-3612: Handheld device uses predictable TCP sequence\\\n  \\ numbers, allowing spoofing or hijacking of TCP connections.\\n\\nCVE-2008-2433:\\\n  \\ Web management console generates session IDs based on the login time, making it\\\n  \\ easier to conduct session hijacking.\\n\\nCVE-2008-0166: SSL library uses a weak\\\n  \\ random number generator that only generates 65,536 unique keys.\\n\\nCVE-2008-2108:\\\n  \\ Chain: insufficient precision causes extra zero bits to be assigned, reducing\\\n  \\ entropy for an API function that generates random numbers.\\n\\nCVE-2008-2108: Chain:\\\n  \\ insufficient precision (CWE-1339) in\\n\\t     random-number generator causes some\\\n  \\ zero bits to be reliably\\n\\t     generated, reducing the amount of entropy (CWE-331)\\n\\\n  \\nCVE-2008-2020: CAPTCHA implementation does not produce enough different images,\\\n  \\ allowing bypass using a database of all possible checksums.\\n\\nCVE-2008-0087:\\\n  \\ DNS client uses predictable DNS transaction IDs, allowing DNS spoofing.\\n\\nCVE-2008-0141:\\\n  \\ Application generates passwords that are based on the time of day.\"\nRelated_Attack_Patterns: \"112: \\n\\n485: \\n\\n59: \"\n",
  "ID: '331'\nName: Insufficient Entropy\nDescription: The product uses an algorithm or scheme that produces insufficient entropy,\n  leaving patterns or clusters of values that are more likely to occur than others.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Implementation: Determine the necessary entropy to adequately\n  provide for randomness and predictability. This can be achieved by increasing the\n  number of bits of objects such as keys and seeds.'\nObserved_Examples: \"CVE-2001-0950: Insufficiently random data used to generate session\\\n  \\ tokens using C rand(). Also, for certificate/key generation, uses a source that\\\n  \\ does not block when entropy is low.\\n\\nCVE-2008-2108: Chain: insufficient precision\\\n  \\ (CWE-1339) in\\n\\t     random-number generator causes some zero bits to be reliably\\n\\\n  \\t     generated, reducing the amount of entropy (CWE-331)\"\nRelated_Attack_Patterns: '59: '\n",
  "ID: '332'\nName: Insufficient Entropy in PRNG\nDescription: The lack of entropy available for, or used by, a Pseudo-Random Number\n  Generator (PRNG) can be a stability and security threat.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n\n  Implementation: Consider a PRNG that re-seeds itself as needed from high-quality\n  pseudo-random output, such as hardware devices.\n\n\n  Architecture and Design: When deciding which PRNG to use, look at its sources of\n  entropy. Depending on what your security needs are, you may need to use a random\n  number generator that always uses strong random data -- i.e., a random number generator\n  that attempts to be strong but will fail in a weak way or will always provide some\n  middle ground of protection through techniques like re-seeding. Generally, something\n  that always provides a predictable amount of strength is preferable.'\nObserved_Examples: 'CVE-2019-1715: security product has insufficient entropy in the\n  DRBG, allowing collisions and private key discovery'\n",
  "ID: '333'\nName: Improper Handling of Insufficient Entropy in TRNG\nDescription: True random number generators (TRNG) generally have a limited source\n  of entropy and therefore can fail or block.\nExtended_Description: The rate at which true random numbers can be generated is limited.\n  It is important that one uses them only when they are needed for security.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Implementation: Rather than failing on a lack of random numbers,\n  it is often preferable to wait for more numbers to be created.'\n",
  "ID: '334'\nName: Small Space of Random Values\nDescription: The number of possible random values is smaller than needed by the product,\n  making it more susceptible to brute force attacks.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").'\nObserved_Examples: 'CVE-2002-0583: Product uses 5 alphanumeric characters for filenames\n  of expense claim reports, stored under web root.\n\n\n  CVE-2002-0903: Product uses small number of random numbers for a code to approve\n  an action, and also uses predictable new user IDs, allowing attackers to hijack\n  new accounts.\n\n\n  CVE-2003-1230: SYN cookies implementation only uses 32-bit keys, making it easier\n  to brute force ISN.\n\n\n  CVE-2004-0230: Complex predictability / randomness (reduced space).'\n",
  "ID: '335'\nName: Incorrect Usage of Seeds in Pseudo-Random Number Generator (PRNG)\nDescription: The product uses a Pseudo-Random Number Generator (PRNG) but does not\n  correctly manage seeds.\nExtended_Description: \"PRNGs are deterministic and, while their output appears\\n\\t\\\n  \\t   random, they cannot actually create entropy. They rely on\\n\\t\\t   cryptographically\\\n  \\ secure and unique seeds for entropy so\\n\\t\\t   proper seeding is critical to the\\\n  \\ secure operation of the\\n\\t\\t   PRNG.\\nManagement of seeds could be broken down\\\n  \\ into two main areas:\\nPRNGs require a seed as input to generate a stream of\\n\\t\\\n  \\t\\t   numbers that are functionally indistinguishable from\\n\\t\\t\\t   random numbers.\\\n  \\  While the output is, in many cases,\\n\\t\\t\\t   sufficient for cryptographic uses,\\\n  \\ the output of any\\n\\t\\t\\t   PRNG is directly determined by the seed provided as\\n\\\n  \\t\\t\\t   input. If the seed can be ascertained by a third party,\\n\\t\\t\\t   the entire\\\n  \\ output of the PRNG can be made known to\\n\\t\\t\\t   them. As such, the seed should\\\n  \\ be kept secret and\\n\\t\\t\\t   should ideally not be able to be guessed. For example,\\n\\\n  \\t\\t\\t   the current time may be a poor seed. Knowing the\\n\\t\\t\\t   approximate\\\n  \\ time the PRNG was seeded greatly reduces\\n\\t\\t\\t   the possible key space.\\nSeeds\\\n  \\ do not necessarily need to be unique, but reusing seeds may open up attacks if\\\n  \\ the seed is discovered.\"\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: \"CVE-2020-7010: Cloud application on Kubernetes generates passwords\\\n  \\ using a weak random number generator based on deployment time.\\n\\nCVE-2019-11495:\\\n  \\ server uses erlang:now() to seed the PRNG, which\\n\\t\\t\\t results in a small search\\\n  \\ space for potential random\\n\\t\\t\\t seeds\\n\\nCVE-2018-12520: Product's PRNG is\\\n  \\ not seeded for the generation of session IDs\\n\\nCVE-2016-10180: Router's PIN generation\\\n  \\ is based on rand(time(0)) seeding.\"\n",
  "ID: '336'\nName: Same Seed in Pseudo-Random Number Generator (PRNG)\nDescription: A Pseudo-Random Number Generator (PRNG) uses the same seed each time\n  the product is initialized.\nExtended_Description: Given the deterministic nature of PRNGs, using the same seed\n  for each initialization will lead to the same output in the same order. If an attacker\n  can guess (or knows) the seed, then the attacker may be able to determine the random\n  numbers that will be produced from the PRNG.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Do not reuse PRNG seeds. Consider\n  a PRNG that periodically re-seeds itself as needed from a high quality pseudo-random\n  output, such as hardware devices.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.'\n",
  "ID: '337'\nName: Predictable Seed in Pseudo-Random Number Generator (PRNG)\nDescription: A Pseudo-Random Number Generator (PRNG) is initialized from a predictable\n  seed, such as the process ID or system time.\nExtended_Description: The use of predictable seeds significantly reduces the number\n  of possible seeds that an attacker would need to test in order to predict which\n  random numbers will be generated by the PRNG.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Use non-predictable inputs for seed generation.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.\n\n\n  Implementation: Use a PRNG that periodically re-seeds itself using input from high-quality\n  sources, such as hardware devices with high entropy. However, do not re-seed too\n  frequently, or else the entropy source might block.'\nObserved_Examples: \"CVE-2020-7010: Cloud application on Kubernetes generates passwords\\\n  \\ using a weak random number generator based on deployment time.\\n\\nCVE-2019-11495:\\\n  \\ server uses erlang:now() to seed the PRNG, which\\n\\t\\t\\t results in a small search\\\n  \\ space for potential random\\n\\t\\t\\t seeds\\n\\nCVE-2008-0166: The removal of a couple\\\n  \\ lines of code caused Debian's OpenSSL Package to only use the current process\\\n  \\ ID for seeding a PRNG\\n\\nCVE-2016-10180: Router's PIN generation is based on rand(time(0))\\\n  \\ seeding.\\n\\nCVE-2018-9057: cloud provider product uses a non-cryptographically\\\n  \\ secure PRNG and seeds it with the current time\"\n",
  "ID: '338'\nName: Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG)\nDescription: The product uses a Pseudo-Random Number Generator (PRNG) in a security\n  context, but the PRNG's algorithm is not cryptographically strong.\nExtended_Description: 'When a non-cryptographic PRNG is used in a cryptographic context,\n  it can expose the cryptography to certain types of attacks.\n\n  Often a pseudo-random number generator (PRNG) is not designed for cryptography.\n  Sometimes a mediocre source of randomness is sufficient or preferable for algorithms\n  that use random numbers. Weak generators generally take less processing power and/or\n  do not use the precious, finite, entropy sources on a system. While such PRNGs might\n  have very useful features, these same features could be used to break the cryptography.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use functions or hardware which use a hardware-based\n  random number generation for all crypto. This is the recommended solution. Use CyptGenRandom\n  on Windows, or hw_rand() on Linux.'\nObserved_Examples: 'CVE-2009-3278: Crypto product uses rand() library function to\n  generate a recovery key, making it easier to conduct brute force attacks.\n\n\n  CVE-2009-3238: Random number generator can repeatedly generate the same value.\n\n\n  CVE-2009-2367: Web application generates predictable session IDs, allowing session\n  hijacking.\n\n\n  CVE-2008-0166: SSL library uses a weak random number generator that only generates\n  65,536 unique keys.'\n",
  "ID: '339'\nName: Small Seed Space in PRNG\nDescription: A Pseudo-Random Number Generator (PRNG) uses a relatively small seed\n  space, which makes it more susceptible to brute force attacks.\nExtended_Description: PRNGs are entirely deterministic once seeded, so it should be\n  extremely difficult to guess the seed. If an attacker can collect the outputs of\n  a PRNG and then brute force the seed by trying every possibility to see which seed\n  matches the observed output, then the attacker will know the output of any subsequent\n  calls to the PRNG. A small seed space implies that the attacker will have far fewer\n  possible values to try to exhaust all possibilities.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Use well vetted pseudo-random number\n  generating algorithms with adequate length seeds. Pseudo-random number generators\n  can produce predictable numbers if the generator is known and the seed can be guessed.\n  A 256-bit seed is a good starting point for producing a \"random enough\" number.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.'\nObserved_Examples: 'CVE-2019-10908: product generates passwords via org.apache.commons.lang.RandomStringUtils,\n  which uses java.util.Random internally. This PRNG has only a 48-bit seed.'\n",
  "ID: '34'\nName: 'Path Traversal: ''....//'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize '....//' (doubled\n  dot dot slash) sequences that can resolve to a location that is outside of that\n  directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''....//'' manipulation is useful for bypassing some path traversal protection\n  schemes. If \"../\" is filtered in a sequential fashion, as done by some regular expression\n  engines, then \"....//\" can collapse into the \"../\" unsafe value (CWE-182). It could\n  also be useful when \"..\" is removed, if the operating system treats \"//\" and \"/\"\n  as equivalent.'\nDetection_Methods: 'Automated Static Analysis - Source Code: According to SOAR, the\n  following detection techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2004-1670: Mail server allows remote attackers to create arbitrary\n  directories via a \"..\" or rename arbitrary files via a \"....//\" in user supplied\n  parameters.'\n",
  "ID: '340'\nName: Generation of Predictable Numbers or Identifiers\nDescription: The product uses a scheme that generates numbers or identifiers that\n  are more predictable than required.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '341'\nName: Predictable from Observable State\nDescription: A number or object is predictable based on observations that the attacker\n  can make about the state of the system or network, such as time, process ID, etc.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Implementation: Increase the entropy used to seed a PRNG.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n\n  Implementation: Use a PRNG that periodically re-seeds itself using input from high-quality\n  sources, such as hardware devices with high entropy. However, do not re-seed too\n  frequently, or else the entropy source might block.'\nObserved_Examples: 'CVE-2002-0389: Mail server stores private mail messages with predictable\n  filenames in a world-executable directory, which allows local users to read private\n  mailing list archives.\n\n\n  CVE-2001-1141: PRNG allows attackers to use the output of small PRNG requests to\n  determine the internal state information, which could be used by attackers to predict\n  future pseudo-random numbers.\n\n\n  CVE-2000-0335: DNS resolver library uses predictable IDs, which allows a local attacker\n  to spoof DNS query results.\n\n\n  CVE-2005-1636: MFV. predictable filename and insecure permissions allows file modification\n  to execute SQL queries.'\n",
  "ID: '342'\nName: Predictable Exact Value from Previous Values\nDescription: An exact value or random number can be precisely predicted by observing\n  previous values.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Increase the entropy used to seed a PRNG.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n\n  Implementation: Use a PRNG that periodically re-seeds itself using input from high-quality\n  sources, such as hardware devices with high entropy. However, do not re-seed too\n  frequently, or else the entropy source might block.'\nObserved_Examples: 'CVE-2002-1463: Firewall generates easily predictable initial sequence\n  numbers (ISN), which allows remote attackers to spoof connections.\n\n\n  CVE-1999-0074: Listening TCP ports are sequentially allocated, allowing spoofing\n  attacks.\n\n\n  CVE-1999-0077: Predictable TCP sequence numbers allow spoofing.\n\n\n  CVE-2000-0335: DNS resolver uses predictable IDs, allowing a local user to spoof\n  DNS query results.'\n",
  "ID: '343'\nName: Predictable Value Range from Previous Values\nDescription: The product's random number generator produces a series of values which,\n  when observed, can be used to infer a relatively small range of possibilities for\n  the next value that could be generated.\nExtended_Description: The output of a random number generator should not be predictable\n  based on observations of previous values. In some cases, an attacker cannot predict\n  the exact value that will be produced next, but can narrow down the possibilities\n  significantly. This reduces the amount of effort to perform a brute force attack.\n  For example, suppose the product generates random numbers between 1 and 100, but\n  it always produces a larger value until it reaches 100. If the generator produces\n  an 80, then the attacker knows that the next value will be somewhere between 81\n  and 100. Instead of 100 possibilities, the attacker only needs to consider 20.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Increase the entropy used to seed a PRNG.\n\n\n  Architecture and Design\n\n  Requirements: Use products or modules that conform to FIPS 140-2 [REF-267] to avoid\n  obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n\n  Implementation: Use a PRNG that periodically re-seeds itself using input from high-quality\n  sources, such as hardware devices with high entropy. However, do not re-seed too\n  frequently, or else the entropy source might block.'\n",
  "ID: '344'\nName: Use of Invariant Value in Dynamically Changing Context\nDescription: The product uses a constant value, name, or reference, but this value\n  can (or should) vary across different environments.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2002-0980: Component for web browser writes an error message\n  to a known location, which can then be referenced by attackers to process HTML/script\n  in a less restrictive context'\n",
  "ID: '345'\nName: Insufficient Verification of Data Authenticity\nDescription: The product does not sufficiently verify the origin or authenticity of\n  data, in a way that causes it to accept invalid data.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2022-30260: Distributed Control System (DCS) does not sign\n  firmware images and only relies on insecure checksums for integrity checks\n\n\n  CVE-2022-30267: Distributed Control System (DCS) does not sign firmware images and\n  only relies on insecure checksums for integrity checks\n\n\n  CVE-2022-30272: Remote Terminal Unit (RTU) does not use signatures for firmware\n  images and relies on insecure checksums'\nRelated_Attack_Patterns: \"111: \\n\\n141: \\n\\n142: \\n\\n148: \\n\\n218: \\n\\n384: \\n\\n385:\\\n  \\ \\n\\n386: \\n\\n387: \\n\\n388: \\n\\n665: \\n\\n701: \"\n",
  "ID: '346'\nName: Origin Validation Error\nDescription: The product does not properly verify that the source of data or communication\n  is valid.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nObserved_Examples: 'CVE-2000-1218: DNS server can accept DNS updates from hosts that\n  it did not query, leading to cache poisoning\n\n\n  CVE-2005-0877: DNS server can accept DNS updates from hosts that it did not query,\n  leading to cache poisoning\n\n\n  CVE-2001-1452: DNS server caches glue records received from non-delegated name servers\n\n\n  CVE-2005-2188: user ID obtained from untrusted source (URL)\n\n\n  CVE-2003-0174: LDAP service does not verify if a particular attribute was set by\n  the LDAP server\n\n\n  CVE-1999-1549: product does not sufficiently distinguish external HTML from internal,\n  potentially dangerous HTML, allowing bypass using special strings in the page title.\n  Overlaps special elements.\n\n\n  CVE-2003-0981: product records the reverse DNS name of a visitor in the logs, allowing\n  spoofing and resultant XSS.'\nRelated_Attack_Patterns: \"111: \\n\\n141: \\n\\n142: \\n\\n160: \\n\\n21: \\n\\n384: \\n\\n385:\\\n  \\ \\n\\n386: \\n\\n387: \\n\\n388: \\n\\n510: \\n\\n59: \\n\\n60: \\n\\n75: \\n\\n76: \\n\\n89: \"\n",
  "ID: '347'\nName: Improper Verification of Cryptographic Signature\nDescription: The product does not verify, or incorrectly verifies, the cryptographic\n  signature for data.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2002-1796: Does not properly verify signatures for \"trusted\"\n  entities.\n\n\n  CVE-2005-2181: Insufficient verification allows spoofing.\n\n\n  CVE-2005-2182: Insufficient verification allows spoofing.\n\n\n  CVE-2002-1706: Accepts a configuration file without a Message Integrity Check (MIC)\n  signature.'\nRelated_Attack_Patterns: \"463: \\n\\n475: \"\n",
  "ID: '348'\nName: Use of Less Trusted Source\nDescription: The product has two different sources of the same data or information,\n  but it uses the source that has less support for verification, is less trusted,\n  or is less resistant to attack.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2001-0860: Product uses IP address provided by a client, instead\n  of obtaining it from the packet headers, allowing easier spoofing.\n\n\n  CVE-2004-1950: Web product uses the IP address in the X-Forwarded-For HTTP header\n  instead of a server variable that uses the connecting IP address, allowing filter\n  bypass.\n\n\n  BID:15326: Similar to CVE-2004-1950\n\n\n  CVE-2001-0908: Product logs IP address specified by the client instead of obtaining\n  it from the packet headers, allowing information hiding.\n\n\n  CVE-2006-1126: PHP application uses IP address from X-Forwarded-For HTTP header,\n  instead of REMOTE_ADDR.'\nRelated_Attack_Patterns: \"141: \\n\\n142: \\n\\n73: \\n\\n76: \\n\\n85: \"\n",
  "ID: '349'\nName: Acceptance of Extraneous Untrusted Data With Trusted Data\nDescription: The product, when processing trusted data, accepts any untrusted data\n  that is also included with the trusted data, treating the untrusted data as if it\n  were trusted.\nObserved_Examples: 'CVE-2002-0018: Does not verify that trusted entity is authoritative\n  for all entities in its response.\n\n\n  CVE-2006-5462: use of extra data in a signature allows certificate signature forging'\nRelated_Attack_Patterns: \"141: \\n\\n142: \\n\\n75: \"\n",
  "ID: '35'\nName: 'Path Traversal: ''.../...//'''\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize '.../...//' (doubled\n  triple dot slash) sequences that can resolve to a location that is outside of that\n  directory.\nExtended_Description: 'This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\n\n  The ''.../...//'' manipulation is useful for bypassing some path traversal protection\n  schemes. If \"../\" is filtered in a sequential fashion, as done by some regular expression\n  engines, then \".../...//\" can collapse into the \"../\" unsafe value (CWE-182). Removing\n  the first \"../\" yields \"....//\"; the second removal yields \"../\". Depending on the\n  algorithm, the product could be susceptible to CWE-34 but not CWE-35, or vice versa.'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2005-2169: chain: \".../...//\" bypasses protection mechanism\n  using regexp''s that remove \"../\" resulting in collapse into an unsafe value \"../\"\n  (CWE-182) and resultant path traversal.\n\n\n  CVE-2005-0202: \".../....///\" bypasses regexp''s that remove \"./\" and \"../\"'\n",
  "ID: '350'\nName: Reliance on Reverse DNS Resolution for a Security-Critical Action\nDescription: The product performs reverse DNS resolution on an IP address to obtain\n  the hostname and make a security decision, but it does not properly ensure that\n  the IP address is truly associated with the hostname.\nExtended_Description: 'Since DNS names can be easily spoofed or misreported, and it\n  may be difficult for the product to detect if a trusted DNS server has been compromised,\n  DNS names do not constitute a valid authentication mechanism.\n\n  When the product performs a reverse DNS resolution for an IP address, if an attacker\n  controls the DNS server for that IP address, then the attacker can cause the server\n  to return an arbitrary hostname. As a result, the attacker may be able to bypass\n  authentication, cause the wrong hostname to be recorded in log files to hide activities,\n  or perform other attacks.\n\n  Attackers can spoof DNS names by either (1) compromising a DNS server and modifying\n  its records (sometimes called DNS cache poisoning), or (2) having legitimate control\n  over a DNS server associated with their IP address.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use other means of identity verification\n  that cannot be simply spoofed. Possibilities include a username/password or certificate.\n\n\n  Implementation: Perform proper forward and reverse DNS lookups to detect DNS spoofing.'\nObserved_Examples: 'CVE-2001-1488: Does not do double-reverse lookup to prevent DNS\n  spoofing.\n\n\n  CVE-2001-1500: Does not verify reverse-resolved hostnames in DNS.\n\n\n  CVE-2000-1221: Authentication bypass using spoofed reverse-resolved DNS hostnames.\n\n\n  CVE-2002-0804: Authentication bypass using spoofed reverse-resolved DNS hostnames.\n\n\n  CVE-2001-1155: Filter does not properly check the result of a reverse DNS lookup,\n  which could allow remote attackers to bypass intended access restrictions via DNS\n  spoofing.\n\n\n  CVE-2004-0892: Reverse DNS lookup used to spoof trusted content in intermediary.\n\n\n  CVE-2003-0981: Product records the reverse DNS name of a visitor in the logs, allowing\n  spoofing and resultant XSS.'\nRelated_Attack_Patterns: \"142: \\n\\n275: \\n\\n73: \\n\\n89: \"\n",
  "ID: '351'\nName: Insufficient Type Distinction\nDescription: The product does not properly distinguish between different types of\n  elements in a way that leads to insecure behavior.\nObserved_Examples: 'CVE-2005-2260: Browser user interface does not distinguish between\n  user-initiated and synthetic events.\n\n\n  CVE-2005-2801: Product does not compare all required data in two separate elements,\n  causing it to think they are the same, leading to loss of ACLs. Similar to Same\n  Name error.'\n",
  "ID: '352'\nName: Cross-Site Request Forgery (CSRF)\nDescription: The web application does not, or can not, sufficiently verify whether\n  a well-formed, valid, consistent request was intentionally provided by the user\n  who submitted the request.\nExtended_Description: When a web server is designed to receive a request from a client\n  without any mechanism for verifying that it was intentionally sent, then it might\n  be possible for an attacker to trick a client into making an unintentional request\n  to the web server which will be treated as an authentic request. This can be done\n  via a URL, image load, XMLHttpRequest, etc. and can result in exposure of data or\n  unintended code execution.\nApplicable_Platforms:\n  Technology: Web Server\nAlternate_Terms: \"Session Riding: \\n\\nCross Site Reference Forgery: \\n\\nXSRF: \"\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Manual Analysis: This weakness can be detected using tools and\n  techniques that require manual (human) analysis, such as penetration testing, threat\n  modeling, and interactive tools that allow the tester to record and modify an active\n  session.\n\n  Specifically, manual analysis can be useful for finding this weakness, and for minimizing\n  false positives assuming an understanding of business logic. However, it might not\n  achieve desired code coverage within limited time constraints. For black-box analysis,\n  if credentials are not known for privileged accounts, then the most security-critical\n  portions of the application may not receive sufficient attention.\n\n  Consider using OWASP CSRFTester to identify potential issues and aid in manual analysis.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Automated Static Analysis: CSRF is currently difficult to detect reliably using\n  automated techniques. This is because each application has its own implicit security\n  policy that dictates which requests can be influenced by an outsider and automatically\n  performed on behalf of a user, versus which requests require strong confidence that\n  the user intends to make the request. For example, a keyword search of the public\n  portion of a web site is typically expected to be encoded within a link that can\n  be launched automatically when the user clicks on the link.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use a vetted library or framework\n  that does not allow this weakness to occur or provides constructs that make this\n  weakness easier to avoid.\n\n  For example, use anti-CSRF packages such as the OWASP CSRFGuard. [REF-330]\n\n  Another example is the ESAPI Session Management control, which includes a component\n  for CSRF. [REF-45]\n\n\n  Implementation: Ensure that the application is free of cross-site scripting issues\n  (CWE-79), because most CSRF defenses can be bypassed using attacker-controlled script.\n\n\n  Architecture and Design: Generate a unique nonce for each form, place the nonce\n  into the form, and verify the nonce upon receipt of the form. Be sure that the nonce\n  is not predictable (CWE-330). [REF-332]\n\n\n  Architecture and Design: Identify especially dangerous operations. When the user\n  performs a dangerous operation, send a separate confirmation request to ensure that\n  the user intended to perform that operation.\n\n\n  Architecture and Design: Use the \"double-submitted cookie\" method as described by\n  Felten and Zeller:\n\n  When a user visits a site, the site should generate a pseudorandom value and set\n  it as a cookie on the user''s machine. The site should require every form submission\n  to include this value as a form value and also as a cookie value. When a POST request\n  is sent to the site, the request should only be considered valid if the form value\n  and the cookie value are the same.\n\n  Because of the same-origin policy, an attacker cannot read or modify the value stored\n  in the cookie. To successfully submit a form on behalf of the user, the attacker\n  would have to correctly guess the pseudorandom value. If the pseudorandom value\n  is cryptographically strong, this will be prohibitively difficult.\n\n  This technique requires Javascript, so it may not work for browsers that have Javascript\n  disabled. [REF-331]\n\n\n  Architecture and Design: Do not use the GET method for any request that triggers\n  a state change.\n\n\n  Implementation: Check the HTTP Referer header to see if the request originated from\n  an expected page. This could break legitimate functionality, because users or proxies\n  may have disabled sending the Referer for privacy reasons.'\nObserved_Examples: 'CVE-2004-1703: Add user accounts via a URL in an img tag\n\n\n  CVE-2004-1995: Add user accounts via a URL in an img tag\n\n\n  CVE-2004-1967: Arbitrary code execution by specifying the code in a crafted img\n  tag or URL\n\n\n  CVE-2004-1842: Gain administrative privileges via a URL in an img tag\n\n\n  CVE-2005-1947: Delete a victim''s information via a URL or an img tag\n\n\n  CVE-2005-2059: Change another user''s settings via a URL or an img tag\n\n\n  CVE-2005-1674: Perform actions as administrator via a URL or an img tag\n\n\n  CVE-2009-3520: modify password for the administrator\n\n\n  CVE-2009-3022: CMS allows modification of configuration via CSRF attack against\n  the administrator\n\n\n  CVE-2009-3759: web interface allows password changes or stopping a virtual machine\n  via CSRF'\nRelated_Attack_Patterns: \"111: \\n\\n462: \\n\\n467: \\n\\n62: \"\n",
  "ID: '353'\nName: Missing Support for Integrity Check\nDescription: The product uses a transmission protocol that does not include a mechanism\n  for verifying the integrity of the data during transmission, such as a checksum.\nExtended_Description: If integrity check values or \"checksums\" are omitted from a\n  protocol, there is no way of determining if data has been corrupted in transmission.\n  The lack of checksum functionality in a protocol removes the first application-level\n  check of data that can be used. The end-to-end philosophy of checks states that\n  integrity checks should be performed at the lowest level that they can be completely\n  implemented. Excluding further sanity checks and input validation performed by applications,\n  the protocol's checksum is the most important level of checksum, since it can be\n  performed more completely than at any previous level and takes into account entire\n  messages, as opposed to single packets.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Add an appropriately sized checksum\n  to the protocol, ensuring that data received may be simply validated before it is\n  parsed and used.\n\n\n  Implementation: Ensure that the checksums present in the protocol design are properly\n  implemented and added to each message before it is sent.'\nRelated_Attack_Patterns: \"13: \\n\\n14: \\n\\n389: \\n\\n39: \\n\\n665: \\n\\n74: \\n\\n75: \"\n",
  "ID: '354'\nName: Improper Validation of Integrity Check Value\nDescription: The product does not validate or incorrectly validates the integrity\n  check values or \"checksums\" of a message. This may prevent it from detecting if\n  the data has been modified or corrupted in transmission.\nExtended_Description: Improper validation of checksums before use results in an unnecessary\n  risk that can easily be mitigated. The protocol specification describes the algorithm\n  used for calculating the checksum. It is then a simple matter of implementing the\n  calculation and verifying that the calculated checksum and the received checksum\n  match. Improper verification of the calculated checksum and the received checksum\n  can lead to far greater consequences.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Implementation: Ensure that the checksums present in messages\n  are properly checked in accordance with the protocol specification before they are\n  parsed and used.'\nRelated_Attack_Patterns: \"145: \\n\\n463: \\n\\n75: \"\n",
  "ID: '356'\nName: Product UI does not Warn User of Unsafe Actions\nDescription: The product's user interface does not warn the user before undertaking\n  an unsafe action on behalf of that user. This makes it easier for attackers to trick\n  users into inflicting damage to their system.\nExtended_Description: Product systems should warn users that a potentially dangerous\n  action may occur if the user proceeds. For example, if the user downloads a file\n  from an unknown source and attempts to execute the file on their machine, then the\n  application's GUI can indicate that the file is unsafe.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-1999-1055: Product does not warn user when document contains\n  certain dangerous functions or macros.\n\n\n  CVE-1999-0794: Product does not warn user when document contains certain dangerous\n  functions or macros.\n\n\n  CVE-2000-0277: Product does not warn user when document contains certain dangerous\n  functions or macros.\n\n\n  CVE-2000-0517: Product does not warn user about a certificate if it has already\n  been accepted for a different site. Possibly resultant.\n\n\n  CVE-2005-0602: File extractor does not warn user it setuid/setgid files could be\n  extracted. Overlaps privileges/permissions.\n\n\n  CVE-2000-0342: E-mail client allows bypass of warning for dangerous attachments\n  via a Windows .LNK file that refers to the attachment.'\n",
  "ID: '357'\nName: Insufficient UI Warning of Dangerous Operations\nDescription: The user interface provides a warning to a user regarding dangerous or\n  sensitive operations, but the warning is not noticeable enough to warrant attention.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2007-1099: User not sufficiently warned if host key mismatch\n  occurs'\n",
  "ID: '358'\nName: Improperly Implemented Security Check for Standard\nDescription: The product does not implement or incorrectly implements one or more\n  security-relevant checks as specified by the design of a standardized algorithm,\n  protocol, or technique.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: This is an implementation\\\n  \\ error, in which the algorithm/technique requires certain security-related behaviors\\\n  \\ or conditions that are not implemented or checked properly, thus causing a vulnerability.\"\nObserved_Examples: 'CVE-2002-0862: Browser does not verify Basic Constraints of a\n  certificate, even though it is required, allowing spoofing of trusted certificates.\n\n\n  CVE-2002-0970: Browser does not verify Basic Constraints of a certificate, even\n  though it is required, allowing spoofing of trusted certificates.\n\n\n  CVE-2002-1407: Browser does not verify Basic Constraints of a certificate, even\n  though it is required, allowing spoofing of trusted certificates.\n\n\n  CVE-2005-0198: Logic error prevents some required conditions from being enforced\n  during Challenge-Response Authentication Mechanism with MD5 (CRAM-MD5).\n\n\n  CVE-2004-2163: Shared secret not verified in a RADIUS response packet, allowing\n  authentication bypass by spoofing server replies.\n\n\n  CVE-2005-2181: Insufficient verification in VoIP implementation, in violation of\n  standard, allows spoofed messages.\n\n\n  CVE-2005-2182: Insufficient verification in VoIP implementation, in violation of\n  standard, allows spoofed messages.\n\n\n  CVE-2005-2298: Security check not applied to all components, allowing bypass.'\n",
  "ID: '359'\nName: Exposure of Private Personal Information to an Unauthorized Actor\nDescription: The product does not properly prevent a person's private, personal information\n  from being accessed by actors who either (1) are not explicitly authorized to access\n  the information or (2) do not have the implicit consent of the person about whom\n  the information is collected.\nExtended_Description: 'There are many types of sensitive information that products\n  must protect from attackers, including system data, communications, configuration,\n  business secrets, intellectual property, and an individual''s personal (private)\n  information.  Private personal information may include a password, phone number,\n  geographic location, personal messages, credit card number, etc.  Private information\n  is important to consider whether the person is a user of the product, or part of\n  a data set that is processed by the product.  An exposure of private information\n  does not necessarily prevent the product from working properly, and in fact the\n  exposure might be intended by the developer, e.g. as part of data sharing with other\n  organizations.  However, the exposure of personal private information can still\n  be undesirable or explicitly prohibited by law or regulation.\n\n  Some types of private information include:\n\n  Some of this information may be characterized as PII (Personally Identifiable Information),\n  Protected Health Information (PHI), etc. Categories of private information may overlap\n  or vary based on the intended usage or the policies and practices of a particular\n  industry.\n\n  Sometimes data that is not labeled as private can have a privacy implication in\n  a different context. For example, student identification numbers are usually not\n  considered private because there is no explicit and publicly-available mapping to\n  an individual student''s personal information. However, if a school generates identification\n  numbers based on student social security numbers, then the identification numbers\n  should be considered private.'\nApplicable_Platforms:\n  Technology: Mobile\nAlternate_Terms: \"Privacy violation: \\n\\nPrivacy leak: \\n\\nPrivacy leakage: \"\nModes_Of_Introduction: \"Architecture and Design: OMISSION: This weakness is caused\\\n  \\ by missing a security tactic during the architecture and design phase.\\n\\nImplementation:\\\n  \\ \\n\\nOperation: \"\nDetection_Methods: 'Architecture or Design Review: Private personal data can enter\n  a program in a variety of ways:\n\n  If the data is written to an external location - such as the console, file system,\n  or network - a privacy violation may occur.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Identify and consult all relevant regulations\n  for personal privacy.  An organization may be required to comply with certain federal\n  and state regulations, depending on its location, the type of business it conducts,\n  and the nature of any private data it handles.  Regulations may include Safe Harbor\n  Privacy Framework [REF-340], Gramm-Leach Bliley Act (GLBA) [REF-341], Health Insurance\n  Portability and Accountability Act (HIPAA) [REF-342], General Data Protection Regulation\n  (GDPR) [REF-1047], California Consumer Privacy Act (CCPA) [REF-1048], and others.\n\n\n  Architecture and Design: Carefully evaluate how secure design may interfere with\n  privacy, and vice versa.  Security and privacy concerns often seem to compete with\n  each other. From a security perspective, all important operations should be recorded\n  so that any anomalous activity can later be identified. However, when private data\n  is involved, this practice can in fact create risk. Although there are many ways\n  in which private data can be handled unsafely, a common risk stems from misplaced\n  trust. Programmers often trust the operating environment in which a program runs,\n  and therefore believe that it is acceptable store private information on the file\n  system, in the registry, or in other locally-controlled resources. However, even\n  if access to certain resources is restricted, this does not guarantee that the individuals\n  who do have access can be trusted.'\nRelated_Attack_Patterns: \"464: \\n\\n467: \\n\\n498: \\n\\n508: \"\n",
  "ID: '36'\nName: Absolute Path Traversal\nDescription: The product uses external input to construct a pathname that should be\n  within a restricted directory, but it does not properly neutralize absolute path\n  sequences such as \"/abs/path\" that can resolve to a location that is outside of\n  that directory.\nExtended_Description: This allows attackers to traverse the file system to access\n  files or directories that are outside of the restricted directory.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2022-31503: Python package constructs filenames using an unsafe\n  os.path.join call on untrusted input, allowing absolute path traversal because os.path.join\n  resets the pathname to an absolute path that is specified as part of the input.\n\n\n  CVE-2002-1345: Multiple FTP clients write arbitrary files via absolute paths in\n  server responses\n\n\n  CVE-2001-1269: ZIP file extractor allows full path\n\n\n  CVE-2002-1818: Path traversal using absolute pathname\n\n\n  CVE-2002-1913: Path traversal using absolute pathname\n\n\n  CVE-2005-2147: Path traversal using absolute pathname\n\n\n  CVE-2000-0614: Arbitrary files may be overwritten via compressed attachments that\n  specify absolute path names for the decompressed output.\n\n\n  CVE-1999-1263: Mail client allows remote attackers to overwrite arbitrary files\n  via an e-mail message containing a uuencoded attachment that specifies the full\n  pathname for the file to be modified.\n\n\n  CVE-2003-0753: Remote attackers can read arbitrary files via a full pathname to\n  the target file in config parameter.\n\n\n  CVE-2002-1525: Remote attackers can read arbitrary files via an absolute pathname.\n\n\n  CVE-2001-0038: Remote attackers can read arbitrary files by specifying the drive\n  letter in the requested URL.\n\n\n  CVE-2001-0255: FTP server allows remote attackers to list arbitrary directories\n  by using the \"ls\" command and including the drive letter name (e.g. C:) in the requested\n  pathname.\n\n\n  CVE-2001-0933: FTP server allows remote attackers to list the contents of arbitrary\n  drives via a ls command that includes the drive letter as an argument.\n\n\n  CVE-2002-0466: Server allows remote attackers to browse arbitrary directories via\n  a full pathname in the arguments to certain dynamic pages.\n\n\n  CVE-2002-1483: Remote attackers can read arbitrary files via an HTTP request whose\n  argument is a filename of the form \"C:\" (Drive letter), \"//absolute/path\", or \"..\"\n  .\n\n\n  CVE-2004-2488: FTP server read/access arbitrary files using \"C:\\\" filenames\n\n\n  CVE-2001-0687: FTP server allows a remote attacker to retrieve privileged web server\n  system information by specifying arbitrary paths in the UNC format (\\\\computername\\sharename).'\nRelated_Attack_Patterns: '597: '\n",
  "ID: '360'\nName: Trust of System Event Data\nDescription: Security based on event locations are insecure and can be spoofed.\nExtended_Description: Events are a messaging system which may provide control data\n  to programs listening for events. Events often do not have any type of authentication\n  framework to allow them to be verified from a trusted source. Any application, in\n  Windows, on a given desktop can send a message to any window on the same desktop.\n  There is no authentication framework for these messages. Therefore, any message\n  can be used to manipulate any process on the desktop if the process does not check\n  the validity and safeness of those messages.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Never trust or rely any of the information\n  in an Event for security.'\n",
  "ID: '362'\nName: Concurrent Execution using Shared Resource with Improper Synchronization ('Race\n  Condition')\nDescription: The product contains a code sequence that can run concurrently with other\n  code, and the code sequence requires temporary, exclusive access to a shared resource,\n  but a timing window exists in which the shared resource can be modified by another\n  code sequence that is operating concurrently.\nExtended_Description: 'This can have security implications when the expected synchronization\n  is in security-critical code, such as recording whether a user is authenticated\n  or modifying important state information that should not be influenced by an outsider.\n\n  A race condition occurs within concurrent environments, and is effectively a property\n  of a code sequence. Depending on the context, a code sequence may be in the form\n  of a function call, a small number of instructions, a series of program invocations,\n  etc.\n\n  A race condition violates these properties, which are closely related:\n\n  A race condition exists when an \"interfering code sequence\" can still access the\n  shared resource, violating exclusivity. Programmers may assume that certain code\n  sequences execute too quickly to be affected by an interfering code sequence; when\n  they are not, this violates atomicity. For example, the single \"x++\" statement may\n  appear atomic at the code layer, but it is actually non-atomic at the instruction\n  layer, since it involves a read (the original value of x), followed by a computation\n  (x+1), followed by a write (save the result to x).\n\n  The interfering code sequence could be \"trusted\" or \"untrusted.\" A trusted interfering\n  code sequence occurs within the product; it cannot be modified by the attacker,\n  and it can only be invoked indirectly. An untrusted interfering code sequence can\n  be authored directly by the attacker, and typically it is external to the vulnerable\n  product.'\nApplicable_Platforms:\n  Language: C, C++, Java\n  Technology: Mobile, ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Black Box: Black box methods may be able to identify evidence\n  of race conditions via methods such as multiple simultaneous connections, which\n  may cause the software to become instable or crash. However, race conditions with\n  very narrow timing windows would not be detectable.\n\n\n  White Box: Common idioms are detectable in white box analysis, such as time-of-check-time-of-use\n  (TOCTOU) file operations (CWE-367), or double-checked locking (CWE-609).\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n  Race conditions may be detected with a stress-test by calling the software simultaneously\n  from a large number of threads or processes, and look for evidence of any unexpected\n  behavior.\n\n  Insert breakpoints or delays in between relevant code statements to artificially\n  expand the race window so that it will be easier to detect.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: In languages that support it, use\n  synchronization primitives. Only wrap these around critical code to minimize the\n  impact on performance.\n\n\n  Architecture and Design: Use thread-safe capabilities such as the data access abstraction\n  in Spring.\n\n\n  Architecture and Design: Minimize the usage of shared resources in order to remove\n  as much complexity as possible from the control flow and to reduce the likelihood\n  of unexpected conditions occurring.\n\n  Additionally, this will minimize the amount of synchronization necessary and may\n  even help to reduce the likelihood of a denial of service where an attacker may\n  be able to repeatedly trigger a critical section (CWE-400).\n\n\n  Implementation: When using multithreading and operating on shared variables, only\n  use thread-safe functions.\n\n\n  Implementation: Use atomic operations on shared variables. Be wary of innocent-looking\n  constructs such as \"x++\". This may appear atomic at the code layer, but it is actually\n  non-atomic at the instruction layer, since it involves a read, followed by a computation,\n  followed by a write.\n\n\n  Implementation: Use a mutex if available, but be sure to avoid related weaknesses\n  such as CWE-412.\n\n\n  Implementation: Avoid double-checked locking (CWE-609) and other implementation\n  errors that arise when trying to avoid the overhead of synchronization.\n\n\n  Implementation: Disable interrupts or signals over critical parts of the code, but\n  also make sure that the code does not go into a large or infinite loop.\n\n\n  Implementation: Use the volatile type modifier for critical variables to avoid unexpected\n  compiler optimization or reordering. This does not necessarily solve the synchronization\n  problem, but it can help.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.'\nObserved_Examples: 'CVE-2022-29527: Go application for cloud management creates a\n  world-writable sudoers file that allows local attackers to inject sudo rules and\n  escalate privileges to root by winning a race condition.\n\n\n  CVE-2021-1782: Chain: improper locking (CWE-667) leads to race condition (CWE-362),\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-0920: Chain: mobile platform race condition (CWE-362) leading to use-after-free\n  (CWE-416), as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-6819: Chain: race condition (CWE-362) leads to use-after-free (CWE-416),\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2019-18827: chain: JTAG interface is not disabled (CWE-1191) during ROM code\n  execution, introducing a race condition (CWE-362) to extract encryption keys\n\n\n  CVE-2019-1161: Chain: race condition (CWE-362) in anti-malware product allows deletion\n  of files by creating a junction (CWE-1386) and using hard links during the time\n  window in which a temporary file is created and deleted.\n\n\n  CVE-2015-1743: TOCTOU in sandbox process allows installation of untrusted browser\n  add-ons by replacing a file after it has been verified, but before it is executed\n\n\n  CVE-2014-8273: Chain: chipset has a race condition (CWE-362) between when an interrupt\n  handler detects an attempt to write-enable the BIOS (in violation of the lock bit),\n  and when the handler resets the write-enable bit back to 0, allowing attackers to\n  issue BIOS writes during the timing window [REF-1237].\n\n\n  CVE-2008-5044: Race condition leading to a crash by calling a hook removal procedure\n  while other activities are occurring at the same time.\n\n\n  CVE-2008-2958: chain: time-of-check time-of-use (TOCTOU) race condition in program\n  allows bypass of protection mechanism that was designed to prevent symlink attacks.\n\n\n  CVE-2008-1570: chain: time-of-check time-of-use (TOCTOU) race condition in program\n  allows bypass of protection mechanism that was designed to prevent symlink attacks.\n\n\n  CVE-2008-0058: Unsynchronized caching operation enables a race condition that causes\n  messages to be sent to a deallocated object.\n\n\n  CVE-2008-0379: Race condition during initialization triggers a buffer overflow.\n\n\n  CVE-2007-6599: Daemon crash by quickly performing operations and undoing them, which\n  eventually leads to an operation that does not acquire a lock.\n\n\n  CVE-2007-6180: chain: race condition triggers NULL pointer dereference\n\n\n  CVE-2007-5794: Race condition in library function could cause data to be sent to\n  the wrong process.\n\n\n  CVE-2007-3970: Race condition in file parser leads to heap corruption.\n\n\n  CVE-2008-5021: chain: race condition allows attacker to access an object while it\n  is still being initialized, causing software to access uninitialized memory.\n\n\n  CVE-2009-4895: chain: race condition for an argument value, possibly resulting in\n  NULL dereference\n\n\n  CVE-2009-3547: chain: race condition might allow resource to be released before\n  operating on it, leading to NULL dereference\n\n\n  CVE-2006-5051: Chain: Signal handler contains too much functionality (CWE-828),\n  introducing a race condition (CWE-362) that leads to a double free (CWE-415).'\nRelated_Attack_Patterns: \"26: \\n\\n29: \"\n",
  "ID: '363'\nName: Race Condition Enabling Link Following\nDescription: The product checks the status of a file or directory before accessing\n  it, which produces a race condition in which the file can be replaced with a link\n  before the access is performed, causing the product to access the wrong file.\nExtended_Description: While developers might expect that there is a very narrow time\n  window between the time of check and time of use, there is still a race condition.\n  An attacker could cause the product to slow down (e.g. with memory consumption),\n  causing the time window to become larger. Alternately, in some situations, the attacker\n  could win the race by performing a large number of attacks.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nRelated_Attack_Patterns: '26: '\n",
  "ID: '364'\nName: Signal Handler Race Condition\nDescription: The product uses a signal handler that introduces a race condition.\nExtended_Description: 'Race conditions frequently occur in signal handlers, since\n  signal handlers support asynchronous actions. These race conditions have a variety\n  of root causes and symptoms. Attackers may be able to exploit a signal handler race\n  condition to cause the product state to be corrupted, possibly leading to a denial\n  of service or even code execution.\n\n  These issues occur when non-reentrant functions, or state-sensitive actions occur\n  in the signal handler, where they may be called at any time. These behaviors can\n  violate assumptions being made by the \"regular\" code that is interrupted, or by\n  other signal handlers that may also be invoked. If these functions are called at\n  an inopportune moment - such as while a non-reentrant function is already running\n  - memory corruption could occur that may be exploitable for code execution. Another\n  signal race condition commonly found occurs when free is called within a signal\n  handler, resulting in a double free and therefore a write-what-where condition.\n  Even if a given pointer is set to NULL after it has been freed, a race condition\n  still exists between the time the memory was freed and the pointer was set to NULL.\n  This is especially problematic if the same signal handler has been set for more\n  than one signal -- since it means that the signal handler itself may be reentered.\n\n  There are several known behaviors related to signal handlers that have received\n  the label of \"signal handler race condition\":\n\n  Signal handler vulnerabilities are often classified based on the absence of a specific\n  protection mechanism, although this style of classification is discouraged in CWE\n  because programmers often have a choice of several different mechanisms for addressing\n  the weakness. Such protection mechanisms may preserve exclusivity of access to the\n  shared resource, and behavioral atomicity for the relevant code:'\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n\n  Architecture and Design: Design signal handlers to only set flags, rather than perform\n  complex functionality. These flags can then be checked and acted upon within the\n  main program loop.\n\n\n  Implementation: Only use reentrant functions within signal handlers. Also, use validation\n  to ensure that state is consistent while performing asynchronous actions that affect\n  the state of execution.'\nObserved_Examples: 'CVE-1999-0035: Signal handler does not disable other signal handlers,\n  allowing it to be interrupted, causing other functionality to access files/etc.\n  with raised privileges\n\n\n  CVE-2001-0905: Attacker can send a signal while another signal handler is already\n  running, leading to crash or execution with root privileges\n\n\n  CVE-2001-1349: unsafe calls to library functions from signal handler\n\n\n  CVE-2004-0794: SIGURG can be used to remotely interrupt signal handler; other variants\n  exist\n\n\n  CVE-2004-2259: SIGCHLD signal to FTP server can cause crash under heavy load while\n  executing non-reentrant functions like malloc/free.'\n",
  "ID: '365'\nName: 'DEPRECATED: Race Condition in Switch'\nDescription: This entry has been deprecated. There are no documented cases in which\n  a switch's control expression is evaluated more than once.\nExtended_Description: It is likely that this entry was initially created based on\n  a misinterpretation of the original source material. The original source intended\n  to explain how switches could be unpredictable when using threads, if the control\n  expressions used data or variables that could change between execution of different\n  threads. That weakness is already covered by CWE-367. Despite the ambiguity in the\n  documentation for some languages and compilers, in practice, they all evaluate the\n  switch control expression only once. If future languages state that the code explicitly\n  evaluates the control expression more than once, then this would not be a weakness,\n  but the language performing as designed.\n",
  "ID: '366'\nName: Race Condition within a Thread\nDescription: If two threads of execution use a resource simultaneously, there exists\n  the possibility that resources may be used while invalid, in turn making the state\n  of execution undefined.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use locking functionality. This is\n  the recommended solution. Implement some form of locking mechanism around code which\n  alters or reads persistent data in a multithreaded environment.\n\n\n  Architecture and Design: Create resource-locking validation checks. If no inherent\n  locking mechanisms exist, use flags and signals to enforce your own blocking scheme\n  when resources are being used by other threads of execution.'\nRelated_Attack_Patterns: \"26: \\n\\n29: \"\n",
  "ID: '367'\nName: Time-of-check Time-of-use (TOCTOU) Race Condition\nDescription: The product checks the state of a resource before using that resource,\n  but the resource's state can change between the check and the use in a way that\n  invalidates the results of the check. This can cause the product to perform invalid\n  actions when the resource is in an unexpected state.\nExtended_Description: This weakness can be security-relevant when an attacker can\n  influence the state of the resource between check and use. This can happen with\n  shared resources such as files, memory, or even variables in multithreaded programs.\nAlternate_Terms: 'TOCTTOU: The TOCTTOU acronym expands to \"Time Of Check To Time Of\n  Use\".\n\n\n  TOCCTOU: The TOCCTOU acronym is most likely a typo of TOCTTOU, but it has been used\n  in some influential documents, so the typo is repeated fairly frequently.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: The most basic advice for TOCTOU vulnerabilities\n  is to not perform a check before the use. This does not resolve the underlying issue\n  of the execution of a function on a resource whose state and identity cannot be\n  assured, but it does help to limit the false sense of security given by the check.\n\n\n  Implementation: When the file being altered is owned by the current user and group,\n  set the effective gid and uid to that of the current user and group when executing\n  this statement.\n\n\n  Architecture and Design: Limit the interleaving of operations on files from multiple\n  processes.\n\n\n  Implementation\n\n  Architecture and Design: If you cannot perform operations atomically and you must\n  share access to the resource between multiple processes or threads, then try to\n  limit the amount of time (CPU cycles) between the check and use of the resource.\n  This will not fix the problem, but it could make it more difficult for an attack\n  to succeed.\n\n\n  Implementation: Recheck the resource after the use call to verify that the action\n  was taken appropriately.\n\n\n  Architecture and Design: Ensure that some environmental locking mechanism can be\n  used to protect resources effectively.\n\n\n  Implementation: Ensure that locking occurs before the check, as opposed to afterwards,\n  such that the resource, as checked, is the same as it is when in use.'\nObserved_Examples: 'CVE-2015-1743: TOCTOU in sandbox process allows installation of\n  untrusted browser add-ons by replacing a file after it has been verified, but before\n  it is executed\n\n\n  CVE-2003-0813: A multi-threaded race condition allows remote attackers to cause\n  a denial of service (crash or reboot) by causing two threads to process the same\n  RPC request, which causes one thread to use memory after it has been freed.\n\n\n  CVE-2004-0594: PHP flaw allows remote attackers to execute arbitrary code by aborting\n  execution before the initialization of key data structures is complete.\n\n\n  CVE-2008-2958: chain: time-of-check time-of-use (TOCTOU) race condition in program\n  allows bypass of protection mechanism that was designed to prevent symlink attacks.\n\n\n  CVE-2008-1570: chain: time-of-check time-of-use (TOCTOU) race condition in program\n  allows bypass of protection mechanism that was designed to prevent symlink attacks.'\nRelated_Attack_Patterns: \"27: \\n\\n29: \"\n",
  "ID: '368'\nName: Context Switching Race Condition\nDescription: A product performs a series of non-atomic actions to switch between contexts\n  that cross privilege or other security boundaries, but a race condition allows an\n  attacker to modify or misrepresent the product's behavior during the switch.\nExtended_Description: This is commonly seen in web browser vulnerabilities in which\n  the attacker can perform certain actions while the browser is transitioning from\n  a trusted to an untrusted domain, or vice versa, and the browser performs the actions\n  on one domain using the trust level and resources of the other domain.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2009-1837: Chain: race condition (CWE-362) from improper handling\n  of a page transition in web client while an applet is loading (CWE-368) leads to\n  use after free (CWE-416)\n\n\n  CVE-2004-2260: Browser updates address bar as soon as user clicks on a link instead\n  of when the page has loaded, allowing spoofing by redirecting to another page using\n  onUnload method. ** this is one example of the role of \"hooks\" and context switches,\n  and should be captured somehow - also a race condition of sorts **\n\n\n  CVE-2004-0191: XSS when web browser executes Javascript events in the context of\n  a new page while it''s being loaded, allowing interaction with previous page in\n  different domain.\n\n\n  CVE-2004-2491: Web browser fills in address bar of clicked-on link before page has\n  been loaded, and doesn''t update afterward.'\nRelated_Attack_Patterns: \"26: \\n\\n29: \"\n",
  "ID: '369'\nName: Divide By Zero\nDescription: The product divides a value by zero.\nExtended_Description: This weakness typically occurs when an unexpected value is provided\n  to the product, or if an error occurs that is not properly detected. It frequently\n  occurs in calculations involving physical dimensions such as size, length, width,\n  and height.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)\n\n\n  Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating large numbers\n  of diverse inputs - either randomly or algorithmically - and dynamically invoking\n  the code with those inputs. Even with random inputs, it is often capable of generating\n  unexpected results such as crashes, memory corruption, or resource consumption.\n  Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which\n  helps developers to diagnose the issues.'\nObserved_Examples: 'CVE-2007-3268: Invalid size value leads to divide by zero.\n\n\n  CVE-2007-2723: \"Empty\" content triggers divide by zero.\n\n\n  CVE-2007-2237: Height value of 0 triggers divide by zero.'\n",
  "ID: '37'\nName: 'Path Traversal: ''/absolute/pathname/here'''\nDescription: The product accepts input in the form of a slash absolute path ('/absolute/pathname/here')\n  without appropriate validation, which can allow an attacker to traverse the file\n  system to unintended locations or access arbitrary files.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-1345: Multiple FTP clients write arbitrary files via\n  absolute paths in server responses\n\n\n  CVE-2001-1269: ZIP file extractor allows full path\n\n\n  CVE-2002-1818: Path traversal using absolute pathname\n\n\n  CVE-2002-1913: Path traversal using absolute pathname\n\n\n  CVE-2005-2147: Path traversal using absolute pathname\n\n\n  CVE-2000-0614: Arbitrary files may be overwritten via compressed attachments that\n  specify absolute path names for the decompressed output.'\n",
  "ID: '370'\nName: Missing Check for Certificate Revocation after Initial Check\nDescription: The product does not check the revocation status of a certificate after\n  its initial revocation check, which can cause the product to perform privileged\n  actions even after the certificate is revoked at a later time.\nExtended_Description: If the revocation status of a certificate is not checked before\n  each action that requires privileges, the system may be subject to a race condition.\n  If a certificate is revoked after the initial check, all subsequent actions taken\n  with the owner of the revoked certificate will lose all benefits guaranteed by the\n  certificate. In fact, it is almost certain that the use of a revoked certificate\n  indicates malicious activity.\nPotential_Mitigations: 'Architecture and Design: Ensure that certificates are checked\n  for revoked status before each use of a protected resource. If the certificate is\n  checked before each access of a protected resource, the delay subject to a possible\n  race condition becomes almost negligible and significantly reduces the risk associated\n  with this issue.'\nRelated_Attack_Patterns: \"26: \\n\\n29: \"\n",
  "ID: '372'\nName: Incomplete Internal State Distinction\nDescription: The product does not properly determine which state it is in, causing\n  it to assume it is in state X when in fact it is in state Y, causing it to perform\n  incorrect operations in a security-relevant manner.\nRelated_Attack_Patterns: \"140: \\n\\n74: \"\n",
  "ID: '373'\nName: 'DEPRECATED: State Synchronization Error'\nDescription: This entry was deprecated because it overlapped the same concepts as\n  race condition (CWE-362) and Improper Synchronization (CWE-662).\n",
  "ID: '374'\nName: Passing Mutable Objects to an Untrusted Method\nDescription: The product sends non-cloned mutable data as an argument to a method\n  or function.\nExtended_Description: The function or method that has been called can alter or delete\n  the mutable data. This could violate assumptions that the calling function has made\n  about its state. In situations where unknown code is called with references to mutable\n  data, this external code could make changes to the data sent. If this data was not\n  previously cloned, the modified data might not be valid in the context of execution.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nPotential_Mitigations: 'Implementation: Pass in data which should not be altered as\n  constant or immutable.\n\n\n  Implementation: Clone all mutable data before passing it into an external function\n  . This is the preferred mitigation. This way, regardless of what changes are made\n  to the data, a valid copy is retained for use by the class.'\n",
  "ID: '375'\nName: Returning a Mutable Object to an Untrusted Caller\nDescription: Sending non-cloned mutable data as a return value may result in that\n  data being altered or deleted by the calling function.\nExtended_Description: In situations where functions return references to mutable data,\n  it is possible that the external code which called the function may make changes\n  to the data sent. If this data was not previously cloned, the class will then be\n  using modified data which may violate assumptions about its internal state.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nPotential_Mitigations: 'Implementation: Declare returned data which should not be\n  altered as constant or immutable.\n\n\n  Implementation: Clone all mutable data before returning references to it. This is\n  the preferred mitigation. This way, regardless of what changes are made to the data,\n  a valid copy is retained for use by the class.'\n",
  "ID: '377'\nName: Insecure Temporary File\nDescription: Creating and using insecure temporary files can leave application and\n  system data vulnerable to attack.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nRelated_Attack_Patterns: \"149: \\n\\n155: \"\n",
  "ID: '378'\nName: Creation of Temporary File With Insecure Permissions\nDescription: Opening temporary files without appropriate measures or controls can\n  leave the file, its contents and any function that it impacts vulnerable to attack.\nPotential_Mitigations: 'Requirements: Many contemporary languages have functions which\n  properly handle this condition. Older C temp file functions are especially susceptible.\n\n\n  Implementation: Ensure that you use proper file permissions. This can be achieved\n  by using a safe temp file function. Temporary files should be writable and readable\n  only by the process that owns the file.\n\n\n  Implementation: Randomize temporary file names. This can also be achieved by using\n  a safe temp-file function. This will ensure that temporary files will not be created\n  in predictable places.'\n",
  "ID: '379'\nName: Creation of Temporary File in Directory with Insecure Permissions\nDescription: The product creates a temporary file in a directory whose permissions\n  allow unintended actors to determine the file's existence or otherwise access that\n  file.\nExtended_Description: On some operating systems, the fact that the temporary file\n  exists may be apparent to any user with sufficient privileges to access that directory.\n  Since the file is visible, the application that is using the temporary file could\n  be known. If one has access to list the processes on the system, the attacker has\n  gained information about what the user is doing at that time. By correlating this\n  with the applications the user is running, an attacker could potentially discover\n  what a user's actions are. From this, higher levels of security could be breached.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Many contemporary languages have functions which\n  properly handle this condition. Older C temp file functions are especially susceptible.\n\n\n  Implementation: Try to store sensitive tempfiles in a directory which is not world\n  readable -- i.e., per-user directories.\n\n\n  Implementation: Avoid using vulnerable temp file functions.'\n",
  "ID: '38'\nName: 'Path Traversal: ''\\absolute\\pathname\\here'''\nDescription: The product accepts input in the form of a backslash absolute path ('\\absolute\\pathname\\here')\n  without appropriate validation, which can allow an attacker to traverse the file\n  system to unintended locations or access arbitrary files.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-1999-1263: Mail client allows remote attackers to overwrite\n  arbitrary files via an e-mail message containing a uuencoded attachment that specifies\n  the full pathname for the file to be modified.\n\n\n  CVE-2003-0753: Remote attackers can read arbitrary files via a full pathname to\n  the target file in config parameter.\n\n\n  CVE-2002-1525: Remote attackers can read arbitrary files via an absolute pathname.'\n",
  "ID: '382'\nName: 'J2EE Bad Practices: Use of System.exit()'\nDescription: A J2EE application uses System.exit(), which also shuts down its container.\nExtended_Description: It is never a good idea for a web application to attempt to\n  shut down the application container. Access to a function that can shut down the\n  application is an avenue for Denial of Service (DoS) attacks.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: 'Implementation: A call to System.exit() is probably part of\n  leftover debug code or code imported from a non-J2EE application.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: The shutdown function should be a\n  privileged function available only to a properly authorized administrative user\n\n\n  Implementation: Web applications should not call methods that cause the virtual\n  machine to exit, such as System.exit()\n\n\n  Implementation: Web applications should also not throw any Throwables to the application\n  server as this may adversely affect the container.\n\n\n  Implementation: Non-web applications may have a main() method that contains a System.exit(),\n  but generally should not call System.exit() from other locations in the code'\n",
  "ID: '383'\nName: 'J2EE Bad Practices: Direct Use of Threads'\nDescription: Thread management in a Web application is forbidden in some circumstances\n  and is always highly error prone.\nExtended_Description: Thread management in a web application is forbidden by the J2EE\n  standard in some circumstances and is always highly error prone. Managing threads\n  is difficult and is likely to interfere in unpredictable ways with the behavior\n  of the application container. Even without interfering with the container, thread\n  management usually leads to bugs that are hard to detect and diagnose like deadlock,\n  race conditions, and other synchronization errors.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: For EJB, use framework approaches\n  for parallel execution, instead of using threads.'\n",
  "ID: '384'\nName: Session Fixation\nDescription: Authenticating a user, or otherwise establishing a new user session,\n  without invalidating any existing session identifier gives an attacker the opportunity\n  to steal authenticated sessions.\nExtended_Description: 'Such a scenario is commonly observed when:'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Invalidate any existing session identifiers\n  prior to authorizing a new user session.\n\n\n  Architecture and Design: For platforms such as ASP that do not generate new values\n  for sessionid cookies, utilize a secondary cookie. In this approach, set a secondary\n  cookie on the user''s browser to a random value and set a session variable to the\n  same value. If the session variable and the cookie value ever don''t match, invalidate\n  the session, and force the user to log on again.'\nRelated_Attack_Patterns: \"196: \\n\\n21: \\n\\n31: \\n\\n39: \\n\\n59: \\n\\n60: \\n\\n61: \"\n",
  "ID: '385'\nName: Covert Timing Channel\nDescription: Covert timing channels convey information by modulating some aspect of\n  system behavior over time, so that the program receiving the information can observe\n  system behavior and infer protected information.\nExtended_Description: 'In some instances, knowing when data is transmitted between\n  parties can provide a malicious user with privileged information. Also, externally\n  monitoring the timing of operations can potentially reveal sensitive data. For example,\n  a cryptographic operation can expose its internal state if the time it takes to\n  perform the operation varies, based on the state.\n\n  Covert channels are frequently classified as either storage or timing channels.\n  Some examples of covert timing channels are the system''s paging rate, the time\n  a certain transaction requires to execute, and the time it takes to gain access\n  to a shared bus.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Whenever possible, specify implementation\n  strategies that do not introduce time variances in operations.\n\n\n  Implementation: Often one can artificially manipulate the time which operations\n  take or -- when operations occur -- can remove information from the attacker.\n\n\n  Implementation: It is reasonable to add artificial or random delays so that the\n  amount of CPU time consumed is independent of the action being taken by the application.'\nRelated_Attack_Patterns: '462: '\n",
  "ID: '386'\nName: Symbolic Name not Mapping to Correct Object\nDescription: A constant symbolic reference to an object is used, even though the reference\n  can resolve to a different object over time.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '39'\nName: 'Path Traversal: ''C:dirname'''\nDescription: The product accepts input that contains a drive letter or Windows volume\n  letter ('C:dirname') that potentially redirects access to an unintended location\n  or arbitrary file.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2001-0038: Remote attackers can read arbitrary files by specifying\n  the drive letter in the requested URL.\n\n\n  CVE-2001-0255: FTP server allows remote attackers to list arbitrary directories\n  by using the \"ls\" command and including the drive letter name (e.g. C:) in the requested\n  pathname.\n\n\n  CVE-2001-0687: FTP server allows a remote attacker to retrieve privileged system\n  information by specifying arbitrary paths.\n\n\n  CVE-2001-0933: FTP server allows remote attackers to list the contents of arbitrary\n  drives via a ls command that includes the drive letter as an argument.\n\n\n  CVE-2002-0466: Server allows remote attackers to browse arbitrary directories via\n  a full pathname in the arguments to certain dynamic pages.\n\n\n  CVE-2002-1483: Remote attackers can read arbitrary files via an HTTP request whose\n  argument is a filename of the form \"C:\" (Drive letter), \"//absolute/path\", or \"..\"\n  .\n\n\n  CVE-2004-2488: FTP server read/access arbitrary files using \"C:\\\" filenames'\n",
  "ID: '390'\nName: Detection of Error Condition Without Action\nDescription: The product detects a specific error, but takes no actions to handle\n  the error.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Properly handle each exception. This is the\n  recommended solution. Ensure that all exceptions are handled in such a way that\n  you can be sure of the state of your system at any given moment.\n\n\n  Implementation: If a function returns an error, it is important to either fix the\n  problem and try again, alert the user that an error has happened and let the program\n  continue, or alert the user and close and cleanup the program.\n\n\n  Testing: Subject the product to extensive testing to discover some of the possible\n  instances of where/how errors or return values are not handled. Consider testing\n  techniques such as ad hoc, equivalence partitioning, robustness and fault tolerance,\n  mutation, and fuzzing.'\n",
  "ID: '391'\nName: Unchecked Error Condition\nDescription: '[PLANNED FOR DEPRECATION. SEE MAINTENANCE NOTES AND CONSIDER CWE-252,\n  CWE-248, OR CWE-1069.] Ignoring exceptions and other error conditions may allow\n  an attacker to induce unexpected behavior unnoticed.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: The choice between a language which has named\n  or unnamed exceptions needs to be done. While unnamed exceptions exacerbate the\n  chance of not properly dealing with an exception, named exceptions suffer from the\n  up call version of the weak base class problem.\n\n\n  Requirements: A language can be used which requires, at compile time, to catch all\n  serious exceptions. However, one must make sure to use the most current version\n  of the API as new exceptions could be added.\n\n\n  Implementation: Catch all relevant exceptions. This is the recommended solution.\n  Ensure that all exceptions are handled in such a way that you can be sure of the\n  state of your system at any given moment.'\n",
  "ID: '392'\nName: Missing Report of Error Condition\nDescription: The product encounters an error but does not provide a status code or\n  return value to indicate that an error has occurred.\nObserved_Examples: 'CVE-2004-0063: Function returns \"OK\" even if another function\n  returns a different status code than expected, leading to accepting an invalid PIN\n  number.\n\n\n  CVE-2002-1446: Error checking routine in PKCS#11 library returns \"OK\" status even\n  when invalid signature is detected, allowing spoofed messages.\n\n\n  CVE-2002-0499: Kernel function truncates long pathnames without generating an error,\n  leading to operation on wrong directory.\n\n\n  CVE-2005-2459: Function returns non-error value when a particular erroneous condition\n  is encountered, leading to resultant NULL dereference.'\n",
  "ID: '393'\nName: Return of Wrong Status Code\nDescription: A function or operation returns an incorrect return value or status code\n  that does not indicate an error, but causes the product to modify its behavior based\n  on the incorrect result.\nExtended_Description: This can lead to unpredictable behavior. If the function is\n  used to make security-critical decisions or provide security-critical information,\n  then the wrong status code can cause the product to assume that an action is safe,\n  even when it is not.\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nObserved_Examples: 'CVE-2003-1132: DNS server returns wrong response code for non-existent\n  AAAA record, which effectively says that the domain is inaccessible.\n\n\n  CVE-2001-1509: Hardware-specific implementation of system call causes incorrect\n  results from geteuid.\n\n\n  CVE-2001-1559: System call returns wrong value, leading to a resultant NULL dereference.\n\n\n  CVE-2014-1266: chain: incorrect \"goto\" in Apple SSL product bypasses certificate\n  validation, allowing Adversary-in-the-Middle (AITM) attack (Apple \"goto fail\" bug).\n  CWE-705 (Incorrect Control Flow Scoping) -> CWE-561 (Dead Code) -> CWE-295 (Improper\n  Certificate Validation) -> CWE-393 (Return of Wrong Status Code) -> CWE-300 (Channel\n  Accessible by Non-Endpoint).'\n",
  "ID: '394'\nName: Unexpected Status Code or Return Value\nDescription: The product does not properly check when a function or operation returns\n  a value that is legitimate for the function, but is not expected by the product.\nObserved_Examples: 'CVE-2004-1395: Certain packets (zero byte and other lengths) cause\n  a recvfrom call to produce an unexpected return code that causes a server''s listening\n  loop to exit.\n\n\n  CVE-2002-2124: Unchecked return code from recv() leads to infinite loop.\n\n\n  CVE-2005-2553: Kernel function does not properly handle when a null is returned\n  by a function call, causing it to call another function that it shouldn''t.\n\n\n  CVE-2005-1858: Memory not properly cleared when read() function call returns fewer\n  bytes than expected.\n\n\n  CVE-2000-0536: Bypass access restrictions when connecting from IP whose DNS reverse\n  lookup does not return a hostname.\n\n\n  CVE-2001-0910: Bypass access restrictions when connecting from IP whose DNS reverse\n  lookup does not return a hostname.\n\n\n  CVE-2004-2371: Game server doesn''t check return values for functions that handle\n  text strings and associated size values.\n\n\n  CVE-2005-1267: Resultant infinite loop when function call returns -1 value.'\n",
  "ID: '395'\nName: Use of NullPointerException Catch to Detect NULL Pointer Dereference\nDescription: Catching NullPointerException should not be used as an alternative to\n  programmatic checks to prevent dereferencing a null pointer.\nExtended_Description: 'Programmers typically catch NullPointerException under three\n  circumstances:\n\n  Of these three circumstances, only the last is acceptable.'\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Do not extensively rely on catching exceptions (especially for validating\n  user input) to handle errors. Handling exceptions can decrease the performance of\n  an application.'\n",
  "ID: '396'\nName: Declaration of Catch for Generic Exception\nDescription: Catching overly broad exceptions promotes complex error handling code\n  that is more likely to contain security vulnerabilities.\nExtended_Description: Multiple catch blocks can get ugly and repetitive, but \"condensing\"\n  catch blocks by catching a high-level class like Exception can obscure exceptions\n  that deserve special treatment or that should not be caught at this point in the\n  program. Catching an overly broad exception essentially defeats the purpose of a\n  language's typed exceptions, and can become particularly dangerous if the program\n  grows and begins to throw new types of exceptions. The new exception types will\n  not receive any attention.\nApplicable_Platforms:\n  Language: C++, Java, C#, Python\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '397'\nName: Declaration of Throws for Generic Exception\nDescription: Throwing overly broad exceptions promotes complex error handling code\n  that is more likely to contain security vulnerabilities.\nExtended_Description: Declaring a method to throw Exception or Throwable makes it\n  difficult for callers to perform proper error handling and error recovery. Java's\n  exception mechanism, for example, is set up to make it easy for callers to anticipate\n  what can go wrong and write code to handle each specific exceptional circumstance.\n  Declaring that a method throws a generic form of exception defeats this system.\nApplicable_Platforms:\n  Language: C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '40'\nName: 'Path Traversal: ''\\\\UNC\\share\\name\\'' (Windows UNC Share)'\nDescription: The product accepts input that identifies a Windows UNC share ('\\\\UNC\\share\\name')\n  that potentially redirects access to an unintended location or arbitrary file.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2001-0687: FTP server allows a remote attacker to retrieve\n  privileged web server system information by specifying arbitrary paths in the UNC\n  format (\\\\computername\\sharename).'\n",
  "ID: '400'\nName: Uncontrolled Resource Consumption\nDescription: The product does not properly control the allocation and maintenance\n  of a limited resource, thereby enabling an actor to influence the amount of resources\n  consumed, eventually leading to the exhaustion of available resources.\nExtended_Description: 'Limited resources include memory, file system storage, database\n  connection pool entries, and CPU. If an attacker can trigger the allocation of these\n  limited resources, but the number or size of the resources is not controlled, then\n  the attacker could cause a denial of service that consumes all available resources.\n  This would prevent valid users from accessing the product, and it could potentially\n  have an impact on the surrounding environment. For example, a memory exhaustion\n  attack against an application could slow down the application as well as its host\n  operating system.\n\n  There are at least three distinct scenarios which can commonly lead to resource\n  exhaustion:\n\n  Resource exhaustion problems are often result due to an incorrect implementation\n  of the following situations:'\nModes_Of_Introduction: \"Operation: \\n\\nArchitecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis typically\n  has limited utility in recognizing resource exhaustion problems, except for program-independent\n  system resources such as files, sockets, and processes. For system resources, automated\n  static analysis may be able to detect circumstances in which resources are not released\n  after they have expired. Automated analysis of configuration files may be able to\n  detect settings that do not specify a maximum value.\n\n  Automated static analysis tools will not be appropriate for detecting exhaustion\n  of custom resources, such as an intended security policy in which a bulletin board\n  user is only allowed to make a limited number of posts per day.\n\n\n  Automated Dynamic Analysis: Certain automated dynamic analysis techniques may be\n  effective in spotting resource exhaustion problems, especially with resources such\n  as processes, memory, and connections. The technique may involve generating a large\n  number of requests to the product within a short time frame.\n\n\n  Fuzzing: While fuzzing is typically geared toward finding low-level implementation\n  bugs, it can inadvertently find resource exhaustion problems. This can occur when\n  the fuzzer generates a large number of test cases but does not restart the targeted\n  product in between test cases. If an individual test case produces a crash, but\n  it does not do so reliably, then an inability to handle resource exhaustion may\n  be the cause.'\nPotential_Mitigations: 'Architecture and Design: Design throttling mechanisms into\n  the system architecture. The best protection is to limit the amount of resources\n  that an unauthorized user can cause to be expended. A strong authentication and\n  access control model will help prevent such attacks from occurring in the first\n  place. The login application should be protected against DoS attacks as much as\n  possible. Limiting the database access, perhaps by caching result sets, can help\n  minimize the resources expended. To further limit the potential for a DoS attack,\n  consider tracking the rate of requests received from users and blocking requests\n  that exceed a defined rate threshold.\n\n\n  Architecture and Design: Mitigation of resource exhaustion attacks requires that\n  the target system either:\n\n  The first of these solutions is an issue in itself though, since it may allow attackers\n  to prevent the use of the system by a particular valid user. If the attacker impersonates\n  the valid user, they may be able to prevent the user from accessing the server in\n  question.\n\n  The second solution is simply difficult to effectively institute -- and even when\n  properly done, it does not provide a full solution. It simply makes the attack require\n  more resources on the part of the attacker.\n\n\n  Architecture and Design: Ensure that protocols have specific limits of scale placed\n  on them.\n\n\n  Implementation: Ensure that all failures in resource allocation place the system\n  into a safe posture.'\nObserved_Examples: 'CVE-2022-21668: Chain: Python library does not limit the resources\n  used to process images that specify a very large number of bands (CWE-1284), leading\n  to excessive memory consumption (CWE-789) or an integer overflow (CWE-190).\n\n\n  CVE-2020-7218: Go-based workload orchestrator does not limit resource usage with\n  unauthenticated connections, allowing a DoS by flooding the service\n\n\n  CVE-2020-3566: Resource exhaustion in distributed OS because of \"insufficient\" IGMP\n  queue management, as exploited in the wild per CISA KEV.\n\n\n  CVE-2009-2874: Product allows attackers to cause a crash via a large number of connections.\n\n\n  CVE-2009-1928: Malformed request triggers uncontrolled recursion, leading to stack\n  exhaustion.\n\n\n  CVE-2009-2858: Chain: memory leak (CWE-404) leads to resource exhaustion.\n\n\n  CVE-2009-2726: Driver does not use a maximum width when invoking sscanf style functions,\n  causing stack consumption.\n\n\n  CVE-2009-2540: Large integer value for a length property in an object causes a large\n  amount of memory allocation.\n\n\n  CVE-2009-2299: Web application firewall consumes excessive memory when an HTTP request\n  contains a large Content-Length value but no POST data.\n\n\n  CVE-2009-2054: Product allows exhaustion of file descriptors when processing a large\n  number of TCP packets.\n\n\n  CVE-2008-5180: Communication product allows memory consumption with a large number\n  of SIP requests, which cause many sessions to be created.\n\n\n  CVE-2008-2121: TCP implementation allows attackers to consume CPU and prevent new\n  connections using a TCP SYN flood attack.\n\n\n  CVE-2008-2122: Port scan triggers CPU consumption with processes that attempt to\n  read data from closed sockets.\n\n\n  CVE-2008-1700: Product allows attackers to cause a denial of service via a large\n  number of directives, each of which opens a separate window.\n\n\n  CVE-2007-4103: Product allows resource exhaustion via a large number of calls that\n  do not complete a 3-way handshake.\n\n\n  CVE-2006-1173: Mail server does not properly handle deeply nested multipart MIME\n  messages, leading to stack exhaustion.\n\n\n  CVE-2007-0897: Chain: anti-virus product encounters a malformed file but returns\n  from a function without closing a file descriptor (CWE-775) leading to file descriptor\n  consumption (CWE-400) and failed scans.'\nRelated_Attack_Patterns: \"147: \\n\\n227: \\n\\n492: \"\n",
  "ID: '401'\nName: Missing Release of Memory after Effective Lifetime\nDescription: The product does not sufficiently track and release allocated memory\n  after it has been used, which slowly consumes remaining memory.\nExtended_Description: This is often triggered by improper handling of malformed data\n  or unexpectedly interrupted sessions.  In some languages, developers are responsible\n  for tracking memory allocation and releasing the memory.  If there are no more pointers\n  or references to the memory, then it can no longer be tracked and identified for\n  release.\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: 'Implementation: Memory leaks have two common and sometimes\n  overlapping causes:'\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Choose a language or tool that provides automatic\n  memory management, or makes manual memory management less error-prone.\n\n  For example, glibc in Linux provides protection against free of invalid pointers.\n\n  When using Xcode to target OS X or iOS, enable automatic reference counting (ARC)\n  [REF-391].\n\n  To help correctly and consistently manage memory when programming in C++, consider\n  using a smart pointer class such as std::auto_ptr (defined by ISO/IEC ISO/IEC 14882:2003),\n  std::shared_ptr and std::unique_ptr (specified by an upcoming revision of the C++\n  standard, informally referred to as C++ 1x), or equivalent solutions such as Boost.\n\n\n  Architecture and Design: Use an abstraction library to abstract away risky APIs.\n  Not a complete solution.\n\n\n  Architecture and Design\n\n  Build and Compilation: The Boehm-Demers-Weiser Garbage Collector or valgrind can\n  be used to detect leaks in code.'\nObserved_Examples: 'CVE-2005-3119: Memory leak because function does not free() an\n  element of a data structure.\n\n\n  CVE-2004-0427: Memory leak when counter variable is not decremented.\n\n\n  CVE-2002-0574: chain: reference count is not decremented, leading to memory leak\n  in OS by sending ICMP packets.\n\n\n  CVE-2005-3181: Kernel uses wrong function to release a data structure, preventing\n  data from being properly tracked by other code.\n\n\n  CVE-2004-0222: Memory leak via unknown manipulations as part of protocol test suite.\n\n\n  CVE-2001-0136: Memory leak via a series of the same command.'\n",
  "ID: '402'\nName: Transmission of Private Resources into a New Sphere ('Resource Leak')\nDescription: The product makes resources available to untrusted parties when those\n  resources are only intended to be accessed by the product.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '403'\nName: Exposure of File Descriptor to Unintended Control Sphere ('File Descriptor Leak')\nDescription: A process does not close sensitive file descriptors before invoking a\n  child process, which allows the child to perform unauthorized I/O operations using\n  those descriptors.\nExtended_Description: When a new process is forked or executed, the child process\n  inherits any open file descriptors. When the child process has fewer privileges\n  than the parent process, this might introduce a vulnerability if the child process\n  can access the file descriptor but does not have the privileges to access the associated\n  file.\nApplicable_Platforms:\n  Operating_System: Unix\nAlternate_Terms: 'File descriptor leak: While this issue is frequently called a file\n  descriptor leak, the \"leak\" term is often used in two different ways - exposure\n  of a resource, or consumption of a resource. Use of this term could cause confusion.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2003-0740: Server leaks a privileged file descriptor, allowing\n  the server to be hijacked.\n\n\n  CVE-2004-1033: File descriptor leak allows read of restricted files.\n\n\n  CVE-2000-0094: Access to restricted resource using modified file descriptor for\n  stderr.\n\n\n  CVE-2002-0638: Open file descriptor used as alternate channel in complex race condition.\n\n\n  CVE-2003-0489: Program does not fully drop privileges after creating a file descriptor,\n  which allows access to the descriptor via a separate vulnerability.\n\n\n  CVE-2003-0937: User bypasses restrictions by obtaining a file descriptor then calling\n  setuid program, which does not close the descriptor.\n\n\n  CVE-2004-2215: Terminal manager does not properly close file descriptors, allowing\n  attackers to access terminals of other users.\n\n\n  CVE-2006-5397: Module opens a file for reading twice, allowing attackers to read\n  files.'\n",
  "ID: '404'\nName: Improper Resource Shutdown or Release\nDescription: The product does not release or incorrectly releases a resource before\n  it is made available for re-use.\nExtended_Description: When a resource is created or allocated, the developer is responsible\n  for properly releasing the resource as well as accounting for all potential paths\n  of expiration or invalidation, such as a set period of time or revocation.\nDetection_Methods: 'Automated Dynamic Analysis: This weakness can be detected using\n  dynamic tools and techniques that interact with the software using large test suites\n  with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and\n  fault injection. The software''s operation may slow down, but it should not become\n  unstable, crash, or generate incorrect results.\n\n  Resource clean up errors might be detected with a stress-test by calling the software\n  simultaneously from a large number of threads or processes, and look for evidence\n  of any unexpected behavior. The software''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.\n\n\n  Manual Dynamic Analysis: Identify error conditions that are not likely to occur\n  during normal usage and trigger them. For example, run the product under low memory\n  conditions, run with insufficient privileges or permissions, interrupt a transaction\n  before it is completed, or disable connectivity to basic network services such as\n  DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled\n  exception or similar error that was discovered and handled by the application''s\n  environment, it may still indicate unexpected conditions that were not handled by\n  the application itself.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, languages such as Java, Ruby, and Lisp perform automatic garbage collection\n  that releases memory for objects that have been deallocated.\n\n\n  Implementation: It is good practice to be responsible for freeing all resources\n  you allocate and to be consistent with how and where you free memory in a function.\n  If you allocate memory that you intend to free upon completion of the function,\n  you must be sure to free the memory at all exit points for that function including\n  error conditions.\n\n\n  Implementation: Memory should be allocated/freed using matching functions such as\n  malloc/free, new/delete, and new[]/delete[].\n\n\n  Implementation: When releasing a complex object or structure, ensure that you properly\n  dispose of all of its member components, not just the object itself.'\nObserved_Examples: 'CVE-1999-1127: Does not shut down named pipe connections if malformed\n  data is sent.\n\n\n  CVE-2001-0830: Sockets not properly closed when attacker repeatedly connects and\n  disconnects from server.\n\n\n  CVE-2002-1372: Return values of file/socket operations not checked, allowing resultant\n  consumption of file descriptors.'\nRelated_Attack_Patterns: \"125: \\n\\n130: \\n\\n131: \\n\\n494: \\n\\n495: \\n\\n496: \\n\\n666: \"\n",
  "ID: '405'\nName: Asymmetric Resource Consumption (Amplification)\nDescription: The product does not properly control situations in which an adversary\n  can cause the product to consume or produce excessive resources without requiring\n  the adversary to invest equivalent work or otherwise prove authorization, i.e.,\n  the adversary's influence is \"asymmetric.\"\nExtended_Description: This can lead to poor performance due to \"amplification\" of\n  resource consumption, typically in a non-linear fashion.  This situation is worsened\n  if the product allows malicious users or attackers to consume more resources than\n  their access level permits.\nApplicable_Platforms:\n  Technology: Client Server\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: An application must make resources\n  available to a client commensurate with the client''s access level.\n\n\n  Architecture and Design: An application must, at all times, keep track of allocated\n  resources and meter their usage appropriately.\n\n\n  System Configuration: Consider disabling resource-intensive algorithms on the server\n  side, such as Diffie-Hellman key exchange.'\nObserved_Examples: 'CVE-1999-0513: Classic \"Smurf\" attack, using spoofed ICMP packets\n  to broadcast addresses.\n\n\n  CVE-2003-1564: Parsing library allows XML bomb\n\n\n  CVE-2004-2458: Tool creates directories before authenticating user.\n\n\n  CVE-2020-10735: Python has \"quadratic complexity\" issue when converting string to\n  int with many digits in unexpected bases\n\n\n  CVE-2020-5243: server allows ReDOS with crafted User-Agent strings, due to overlapping\n  capture groups that cause excessive backtracking.\n\n\n  CVE-2013-5211: composite: NTP feature generates large responses (high amplification\n  factor) with spoofed UDP source addresses.\n\n\n  CVE-2002-20001: Diffie-Hellman (DHE) Key Agreement Protocol allows attackers to\n  send arbitrary numbers that are not public keys, which causes the server to perform\n  expensive, unnecessary computation of modular exponentiation.\n\n\n  CVE-2022-40735: The Diffie-Hellman Key Agreement Protocol allows use of long exponents,\n  which are more computationally expensive than using certain \"short exponents\" with\n  particular properties.'\n",
  "ID: '406'\nName: Insufficient Control of Network Message Volume (Network Amplification)\nDescription: The product does not sufficiently monitor or control transmitted network\n  traffic volume, so that an actor can cause the product to transmit more traffic\n  than should be allowed for that actor.\nExtended_Description: In the absence of a policy to restrict asymmetric resource consumption,\n  the application or system cannot distinguish between legitimate transmissions and\n  traffic intended to serve as an amplifying attack on target systems. Systems can\n  often be configured to restrict the amount of traffic sent out on behalf of a client,\n  based on the client's origin or access level. This is usually defined in a resource\n  allocation policy. In the absence of a mechanism to keep track of transmissions,\n  the system or application can be easily abused to transmit asymmetrically greater\n  traffic than the request or client should be permitted to.\nModes_Of_Introduction: \"Operation: \\n\\nArchitecture and Design: If the application\\\n  \\ uses UDP, then it could potentially be subject to spoofing attacks that use the\\\n  \\ inherent weaknesses of UDP to perform traffic amplification, although this problem\\\n  \\ can exist in other protocols or contexts.\\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: An application must make network\n  resources available to a client commensurate with the client''s access level.\n\n\n  Policy: Define a clear policy for network resource allocation and consumption.\n\n\n  Implementation: An application must, at all times, keep track of network resources\n  and meter their usage appropriately.'\nObserved_Examples: 'CVE-1999-0513: Classic \"Smurf\" attack, using spoofed ICMP packets\n  to broadcast addresses.\n\n\n  CVE-1999-1379: DNS query with spoofed source address causes more traffic to be returned\n  to spoofed address than was sent by the attacker.\n\n\n  CVE-2000-0041: Large datagrams are sent in response to malformed datagrams.\n\n\n  CVE-1999-1066: Game server sends a large amount.\n\n\n  CVE-2013-5211: composite: NTP feature generates large responses (high amplification\n  factor) with spoofed UDP source addresses.'\n",
  "ID: '407'\nName: Inefficient Algorithmic Complexity\nDescription: An algorithm in a product has an inefficient worst-case computational\n  complexity that may be detrimental to system performance and can be triggered by\n  an attacker, typically using crafted manipulations that ensure that the worst case\n  is being reached.\nAlternate_Terms: 'Quadratic Complexity: Used when the algorithmic complexity is related\n  to the square of the number of inputs (N^2)'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2021-32617: C++ library for image metadata has \"quadratic\n  complexity\" issue with unnecessarily repetitive parsing each time an invalid character\n  is encountered\n\n\n  CVE-2020-10735: Python has \"quadratic complexity\" issue when converting string to\n  int with many digits in unexpected bases\n\n\n  CVE-2020-5243: server allows ReDOS with crafted User-Agent strings, due to overlapping\n  capture groups that cause excessive backtracking.\n\n\n  CVE-2014-1474: Perl-based email address parser has \"quadratic complexity\" issue\n  via a string that does not contain a valid address\n\n\n  CVE-2003-0244: CPU consumption via inputs that cause many hash table collisions.\n\n\n  CVE-2003-0364: CPU consumption via inputs that cause many hash table collisions.\n\n\n  CVE-2002-1203: Product performs unnecessary processing before dropping an invalid\n  packet.\n\n\n  CVE-2001-1501: CPU and memory consumption using many wildcards.\n\n\n  CVE-2004-2527: Product allows attackers to cause multiple copies of a program to\n  be loaded more quickly than the program can detect that other copies are running,\n  then exit. This type of error should probably have its own category, where teardown\n  takes more time than initialization.\n\n\n  CVE-2006-6931: Network monitoring system allows remote attackers to cause a denial\n  of service (CPU consumption and detection outage) via crafted network traffic, aka\n  a \"backtracking attack.\"\n\n\n  CVE-2006-3380: Wiki allows remote attackers to cause a denial of service (CPU consumption)\n  by performing a diff between large, crafted pages that trigger the worst case algorithmic\n  complexity.\n\n\n  CVE-2006-3379: Wiki allows remote attackers to cause a denial of service (CPU consumption)\n  by performing a diff between large, crafted pages that trigger the worst case algorithmic\n  complexity.\n\n\n  CVE-2005-2506: OS allows attackers to cause a denial of service (CPU consumption)\n  via crafted Gregorian dates.\n\n\n  CVE-2005-1792: Memory leak by performing actions faster than the software can clear\n  them.'\n",
  "ID: '408'\nName: 'Incorrect Behavior Order: Early Amplification'\nDescription: The product allows an entity to perform a legitimate but expensive operation\n  before authentication or authorization has taken place.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2004-2458: Tool creates directories before authenticating\n  user.'\n",
  "ID: '409'\nName: Improper Handling of Highly Compressed Data (Data Amplification)\nDescription: The product does not handle or incorrectly handles a compressed input\n  with a very high compression ratio that produces a large output.\nExtended_Description: An example of data amplification is a \"decompression bomb,\"\n  a small ZIP file that can produce a large amount of data when it is decompressed.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2009-1955: XML bomb in web server module\n\n\n  CVE-2003-1564: Parsing library allows XML bomb'\n",
  "ID: '41'\nName: Improper Resolution of Path Equivalence\nDescription: The product is vulnerable to file system contents disclosure through\n  path equivalence. Path equivalence involves the use of special characters in file\n  and directory names. The associated manipulations are intended to generate multiple\n  names for the same object.\nExtended_Description: Path equivalence is usually employed in order to circumvent\n  access controls expressed using an incomplete set of file name or file path representations.\n  This is different from path traversal, wherein the manipulations are performed to\n  generate a name for a different object.\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2000-1114: Source code disclosure using trailing dot\n\n\n  CVE-2002-1986: Source code disclosure using trailing dot\n\n\n  CVE-2004-2213: Source code disclosure using trailing dot or trailing encoding space\n  \"%20\"\n\n\n  CVE-2005-3293: Source code disclosure using trailing dot\n\n\n  CVE-2004-0061: Bypass directory access restrictions using trailing dot in URL\n\n\n  CVE-2000-1133: Bypass directory access restrictions using trailing dot in URL\n\n\n  CVE-2001-1386: Bypass check for \".lnk\" extension using \".lnk.\"\n\n\n  CVE-2001-0693: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2001-0778: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2001-1248: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2004-0280: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2005-0622: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2005-1656: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2002-1603: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2001-0054: Multi-Factor Vulnerability (MVF). directory traversal and other issues\n  in FTP server using Web encodings such as \"%20\"; certain manipulations have unusual\n  side effects.\n\n\n  CVE-2002-1451: Trailing space (\"+\" in query string) leads to source code disclosure.\n\n\n  CVE-2000-0293: Filenames with spaces allow arbitrary file deletion when the product\n  does not properly quote them; some overlap with path traversal.\n\n\n  CVE-2001-1567: \"+\" characters in query string converted to spaces before sensitive\n  file/extension (internal space), leading to bypass of access restrictions to the\n  file.\n\n\n  CVE-2002-0253: Overlaps infoleak\n\n\n  CVE-2001-0446: Application server allows remote attackers to read source code for\n  .jsp files by appending a / to the requested URL.\n\n\n  CVE-2004-0334: Bypass Basic Authentication for files using trailing \"/\"\n\n\n  CVE-2001-0893: Read sensitive files with trailing \"/\"\n\n\n  CVE-2001-0892: Web server allows remote attackers to view sensitive files under\n  the document root (such as .htpasswd) via a GET request with a trailing /.\n\n\n  CVE-2004-1814: Directory traversal vulnerability in server allows remote attackers\n  to read protected files via .. (dot dot) sequences in an HTTP request.\n\n\n  BID:3518: Source code disclosure\n\n\n  CVE-2002-1483: Read files with full pathname using multiple internal slash.\n\n\n  CVE-1999-1456: Server allows remote attackers to read arbitrary files via a GET\n  request with more than one leading / (slash) character in the filename.\n\n\n  CVE-2004-0578: Server allows remote attackers to read arbitrary files via leading\n  slash (//) characters in a URL request.\n\n\n  CVE-2002-0275: Server allows remote attackers to bypass authentication and read\n  restricted files via an extra / (slash) in the requested URL.\n\n\n  CVE-2004-1032: Product allows local users to delete arbitrary files or create arbitrary\n  empty files via a target filename with a large number of leading slash (/) characters.\n\n\n  CVE-2002-1238: Server allows remote attackers to bypass access restrictions for\n  files via an HTTP request with a sequence of multiple / (slash) characters such\n  as http://www.example.com///file/.\n\n\n  CVE-2004-1878: Product allows remote attackers to bypass authentication, obtain\n  sensitive information, or gain access via a direct request to admin/user.pl preceded\n  by // (double leading slash).\n\n\n  CVE-2005-1365: Server allows remote attackers to execute arbitrary commands via\n  a URL with multiple leading \"/\" (slash) characters and \"..\" sequences.\n\n\n  CVE-2000-1050: Access directory using multiple leading slash.\n\n\n  CVE-2001-1072: Bypass access restrictions via multiple leading slash, which causes\n  a regular expression to fail.\n\n\n  CVE-2004-0235: Archive extracts to arbitrary files using multiple leading slash\n  in filenames in the archive.\n\n\n  CVE-2002-1078: Directory listings in web server using multiple trailing slash\n\n\n  CVE-2004-0847: ASP.NET allows remote attackers to bypass authentication for .aspx\n  files in restricted directories via a request containing a (1) \"\\\" (backslash) or\n  (2) \"%5C\" (encoded backslash), aka \"Path Validation Vulnerability.\"\n\n\n  CVE-2000-0004: Server allows remote attackers to read source code for executable\n  files by inserting a . (dot) into the URL.\n\n\n  CVE-2002-0304: Server allows remote attackers to read password-protected files via\n  a /./ in the HTTP request.\n\n\n  BID:6042: Input Validation error\n\n\n  CVE-1999-1083: Possibly (could be a cleansing error)\n\n\n  CVE-2004-0815: \"/./////etc\" cleansed to \".///etc\" then \"/etc\"\n\n\n  CVE-2002-0112: Server allows remote attackers to view password protected files via\n  /./ in the URL.\n\n\n  CVE-2004-0696: List directories using desired path and \"*\"\n\n\n  CVE-2002-0433: List files in web server using \"*.ext\"\n\n\n  CVE-2001-1152: Proxy allows remote attackers to bypass denylist restrictions and\n  connect to unauthorized web servers by modifying the requested URL, including (1)\n  a // (double slash), (2) a /SUBDIR/.. where the desired file is in the parentdir,\n  (3) a /./, or (4) URL-encoded characters.\n\n\n  CVE-2000-0191: application check access for restricted URL before canonicalization\n\n\n  CVE-2005-1366: CGI source disclosure using \"dirname/../cgi-bin\"\n\n\n  CVE-1999-0012: Multiple web servers allow restriction bypass using 8.3 names instead\n  of long names\n\n\n  CVE-2001-0795: Source code disclosure using 8.3 file name.\n\n\n  CVE-2005-0471: Multi-Factor Vulnerability. Product generates temporary filenames\n  using long filenames, which become predictable in 8.3 format.'\nRelated_Attack_Patterns: '3: '\n",
  "ID: '410'\nName: Insufficient Resource Pool\nDescription: The product's resource pool is not large enough to handle peak demand,\n  which allows an attacker to prevent others from accessing the resource by using\n  a (relatively) large number of requests for resources.\nExtended_Description: Frequently the consequence is a \"flood\" of connection or sessions.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Do not perform resource-intensive\n  transactions for unauthenticated users and/or invalid requests.\n\n\n  Architecture and Design: Consider implementing a velocity check mechanism which\n  would detect abusive behavior.\n\n\n  Operation: Consider load balancing as an option to handle heavy loads.\n\n\n  Implementation: Make sure that resource handles are properly closed when no longer\n  needed.\n\n\n  Architecture and Design: Identify the system''s resource intensive operations and\n  consider protecting them from abuse (e.g. malicious automated script which runs\n  the resources out).'\nObserved_Examples: 'CVE-1999-1363: Large number of locks on file exhausts the pool\n  and causes crash.\n\n\n  CVE-2001-1340: Product supports only one connection and does not disconnect a user\n  who does not provide credentials.\n\n\n  CVE-2002-0406: Large number of connections without providing credentials allows\n  connection exhaustion.'\n",
  "ID: '412'\nName: Unrestricted Externally Accessible Lock\nDescription: The product properly checks for the existence of a lock, but the lock\n  can be externally controlled or influenced by an actor that is outside of the intended\n  sphere of control.\nExtended_Description: This prevents the product from acting on associated resources\n  or performing other behaviors that are controlled by the presence of the lock. Relevant\n  locks might include an exclusive lock or mutex, or modifying a shared resource that\n  is treated as a lock. If the lock can be held for an indefinite period of time,\n  then the denial of service could be permanent.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'White Box: Automated code analysis techniques might not be able\n  to reliably detect this weakness, since the application''s behavior and general\n  security model dictate which resource locks are critical. Interpretation of the\n  weakness might require knowledge of the environment, e.g. if the existence of a\n  file is used as a lock, but the file is created in a world-writable directory.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Use any access control that is offered by the functionality that\n  is offering the lock.\n\n\n  Architecture and Design\n\n  Implementation: Use unpredictable names or identifiers for the locks. This might\n  not always be possible or feasible.\n\n\n  Architecture and Design: Consider modifying your code to use non-blocking synchronization\n  methods.'\nObserved_Examples: 'CVE-2001-0682: Program can not execute when attacker obtains a\n  mutex.\n\n\n  CVE-2002-1914: Program can not execute when attacker obtains a lock on a critical\n  output file.\n\n\n  CVE-2002-1915: Program can not execute when attacker obtains a lock on a critical\n  output file.\n\n\n  CVE-2002-0051: Critical file can be opened with exclusive read access by user, preventing\n  application of security policy. Possibly related to improper permissions, large-window\n  race condition.\n\n\n  CVE-2000-0338: Chain: predictable file names used for locking, allowing attacker\n  to create the lock beforehand. Resultant from permissions and randomness.\n\n\n  CVE-2000-1198: Chain: Lock files with predictable names. Resultant from randomness.\n\n\n  CVE-2002-1869: Product does not check if it can write to a log file, allowing attackers\n  to avoid logging by accessing the file using an exclusive lock. Overlaps unchecked\n  error condition. This is not quite CWE-412, but close.'\nRelated_Attack_Patterns: '25: '\n",
  "ID: '413'\nName: Improper Resource Locking\nDescription: The product does not lock or does not correctly lock a resource when\n  the product must have exclusive access to the resource.\nExtended_Description: When a resource is not properly locked, an attacker could modify\n  the resource while it is being operated on by the product. This might violate the\n  product's assumption that the resource will not change, potentially leading to unexpected\n  behaviors.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use a non-conflicting privilege scheme.\n\n\n  Architecture and Design\n\n  Implementation: Use synchronization when locking a resource.'\n",
  "ID: '414'\nName: Missing Lock Check\nDescription: A product does not check to see if a lock is present before performing\n  sensitive operations on a resource.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Implement a reliable lock mechanism.'\nObserved_Examples: 'CVE-2004-1056: Product does not properly check if a lock is present,\n  allowing other attackers to access functionality.'\n",
  "ID: '415'\nName: Double Free\nDescription: The product calls free() twice on the same memory address, potentially\n  leading to modification of unexpected memory locations.\nExtended_Description: When a program calls free() twice with the same argument, the\n  program's memory management data structures become corrupted. This corruption can\n  cause the program to crash or, in some circumstances, cause two later calls to malloc()\n  to return the same pointer. If malloc() returns the same value twice and the program\n  later gives the attacker control over the data that is written into this doubly-allocated\n  memory, the program becomes vulnerable to a buffer overflow attack.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Choose a language that provides automatic\n  memory management.\n\n\n  Implementation: Ensure that each allocation is freed only once. After freeing a\n  chunk, set the pointer to NULL to ensure the pointer cannot be freed again. In complicated\n  error conditions, be sure that clean-up routines respect the state of allocation\n  properly. If the language is object oriented, ensure that object destructors delete\n  each chunk of memory only once.\n\n\n  Implementation: Use a static analysis tool to find double free instances.'\nObserved_Examples: 'CVE-2006-5051: Chain: Signal handler contains too much functionality\n  (CWE-828), introducing a race condition (CWE-362) that leads to a double free (CWE-415).\n\n\n  CVE-2004-0642: Double free resultant from certain error conditions.\n\n\n  CVE-2004-0772: Double free resultant from certain error conditions.\n\n\n  CVE-2005-1689: Double free resultant from certain error conditions.\n\n\n  CVE-2003-0545: Double free from invalid ASN.1 encoding.\n\n\n  CVE-2003-1048: Double free from malformed GIF.\n\n\n  CVE-2005-0891: Double free from malformed GIF.\n\n\n  CVE-2002-0059: Double free from malformed compressed data.'\n",
  "ID: '416'\nName: Use After Free\nDescription: Referencing memory after it has been freed can cause a program to crash,\n  use unexpected values, or execute code.\nExtended_Description: 'The use of previously-freed memory can have any number of adverse\n  consequences, ranging from the corruption of valid data to the execution of arbitrary\n  code, depending on the instantiation and timing of the flaw. The simplest way data\n  corruption may occur involves the system''s reuse of the freed memory. Use-after-free\n  errors have two common and sometimes overlapping causes:\n\n  In this scenario, the memory in question is allocated to another pointer validly\n  at some point after it has been freed. The original pointer to the freed memory\n  is used again and points to somewhere within the new allocation. As the data is\n  changed, it corrupts the validly used memory; this induces undefined behavior in\n  the process.\n\n  If the newly allocated data happens to hold a class, in C++ for example, various\n  function pointers may be scattered within the heap data. If one of these function\n  pointers is overwritten with an address to valid shellcode, execution of arbitrary\n  code can be achieved.'\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: \"Dangling pointer: \\n\\nUse-After-Free: \"\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Choose a language that provides automatic\n  memory management.\n\n\n  Implementation: When freeing pointers, be sure to set them to NULL once they are\n  freed. However, the utilization of multiple or complex data structures may lower\n  the usefulness of this strategy.'\nObserved_Examples: 'CVE-2021-0920: Chain: mobile platform race condition (CWE-362)\n  leading to use-after-free (CWE-416), as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-6819: Chain: race condition (CWE-362) leads to use-after-free (CWE-416),\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2010-4168: Use-after-free triggered by closing a connection while data is still\n  being transmitted.\n\n\n  CVE-2010-2941: Improper allocation for invalid data leads to use-after-free.\n\n\n  CVE-2010-2547: certificate with a large number of Subject Alternate Names not properly\n  handled in realloc, leading to use-after-free\n\n\n  CVE-2010-1772: Timers are not disabled when a related object is deleted\n\n\n  CVE-2010-1437: Access to a \"dead\" object that is being cleaned up\n\n\n  CVE-2010-1208: object is deleted even with a non-zero reference count, and later\n  accessed\n\n\n  CVE-2010-0629: use-after-free involving request containing an invalid version number\n\n\n  CVE-2010-0378: unload of an object that is currently being accessed by other functionality\n\n\n  CVE-2010-0302: incorrectly tracking a reference count leads to use-after-free\n\n\n  CVE-2010-0249: use-after-free related to use of uninitialized memory\n\n\n  CVE-2010-0050: HTML document with incorrectly-nested tags\n\n\n  CVE-2009-3658: Use after free in ActiveX object by providing a malformed argument\n  to a method\n\n\n  CVE-2009-3616: use-after-free by disconnecting during data transfer, or a message\n  containing incorrect data types\n\n\n  CVE-2009-3553: disconnect during a large data transfer causes incorrect reference\n  count, leading to use-after-free\n\n\n  CVE-2009-2416: use-after-free found by fuzzing\n\n\n  CVE-2009-1837: Chain: race condition (CWE-362) from improper handling of a page\n  transition in web client while an applet is loading (CWE-368) leads to use after\n  free (CWE-416)\n\n\n  CVE-2009-0749: realloc generates new buffer and pointer, but previous pointer is\n  still retained, leading to use after free\n\n\n  CVE-2010-3328: Use-after-free in web browser, probably resultant from not initializing\n  memory.\n\n\n  CVE-2008-5038: use-after-free when one thread accessed memory that was freed by\n  another thread\n\n\n  CVE-2008-0077: assignment of malformed values to certain properties triggers use\n  after free\n\n\n  CVE-2006-4434: mail server does not properly handle a long header.\n\n\n  CVE-2010-2753: chain: integer overflow leads to use-after-free\n\n\n  CVE-2006-4997: freed pointer dereference'\n",
  "ID: '419'\nName: Unprotected Primary Channel\nDescription: The product uses a primary channel for administration or restricted functionality,\n  but it does not properly protect the channel.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Do not expose administrative functionnality\n  on the user UI.\n\n\n  Architecture and Design: Protect the administrative/restricted functionality with\n  a strong authentication mechanism.'\nRelated_Attack_Patterns: '383: '\n",
  "ID: '42'\nName: 'Path Equivalence: ''filename.'' (Trailing Dot)'\nDescription: The product accepts path input in the form of trailing dot ('filedir.')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nObserved_Examples: 'CVE-2000-1114: Source code disclosure using trailing dot\n\n\n  CVE-2002-1986: Source code disclosure using trailing dot\n\n\n  CVE-2004-2213: Source code disclosure using trailing dot\n\n\n  CVE-2005-3293: Source code disclosure using trailing dot\n\n\n  CVE-2004-0061: Bypass directory access restrictions using trailing dot in URL\n\n\n  CVE-2000-1133: Bypass directory access restrictions using trailing dot in URL\n\n\n  CVE-2001-1386: Bypass check for \".lnk\" extension using \".lnk.\"'\n",
  "ID: '420'\nName: Unprotected Alternate Channel\nDescription: The product protects a primary channel, but it does not use the same\n  level of protection for an alternate channel.\nModes_Of_Introduction: \"Architecture and Design: OMISSION: This weakness is caused\\\n  \\ by missing a security tactic during the architecture and design phase.\\n\\nImplementation:\\\n  \\ \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Identify all alternate channels and\n  use the same protection mechanisms that are used for the primary channels.'\nObserved_Examples: 'CVE-2002-0567: DB server assumes that local clients have performed\n  authentication, allowing attacker to directly connect to a process to load libraries\n  and execute commands; a socket interface also exists (another alternate channel),\n  so attack can be remote.\n\n\n  CVE-2002-1578: Product does not restrict access to underlying database, so attacker\n  can bypass restrictions by directly querying the database.\n\n\n  CVE-2003-1035: User can avoid lockouts by using an API instead of the GUI to conduct\n  brute force password guessing.\n\n\n  CVE-2002-1863: FTP service can not be disabled even when other access controls would\n  require it.\n\n\n  CVE-2002-0066: Windows named pipe created without authentication/access control,\n  allowing configuration modification.\n\n\n  CVE-2004-1461: Router management interface spawns a separate TCP connection after\n  authentication, allowing hijacking by attacker coming from the same IP address.'\n",
  "ID: '421'\nName: Race Condition During Access to Alternate Channel\nDescription: The product opens an alternate channel to communicate with an authorized\n  user, but the channel is accessible to other actors.\nExtended_Description: This creates a race condition that allows an attacker to access\n  the channel before the authorized user does.\nObserved_Examples: 'CVE-1999-0351: FTP \"Pizza Thief\" vulnerability. Attacker can connect\n  to a port that was intended for use by another client.\n\n\n  CVE-2003-0230: Product creates Windows named pipe during authentication that another\n  attacker can hijack by connecting to it.'\n",
  "ID: '422'\nName: Unprotected Windows Messaging Channel ('Shatter')\nDescription: The product does not properly verify the source of a message in the Windows\n  Messaging System while running at elevated privileges, creating an alternate channel\n  through which an attacker can directly send a message to the product.\nPotential_Mitigations: 'Architecture and Design: Always verify and authenticate the\n  source of the message.'\nObserved_Examples: 'CVE-2002-0971: Bypass GUI and access restricted dialog box.\n\n\n  CVE-2002-1230: Gain privileges via Windows message.\n\n\n  CVE-2003-0350: A control allows a change to a pointer for a callback function using\n  Windows message.\n\n\n  CVE-2003-0908: Product launches Help functionality while running with raised privileges,\n  allowing command execution using Windows message to access \"open file\" dialog.\n\n\n  CVE-2004-0213: Attacker uses Shatter attack to bypass GUI-enforced protection for\n  CVE-2003-0908.\n\n\n  CVE-2004-0207: User can call certain API functions to modify certain properties\n  of privileged programs.'\n",
  "ID: '423'\nName: 'DEPRECATED: Proxied Trusted Channel'\nDescription: This entry has been deprecated because it was a duplicate of CWE-441.\n  All content has been transferred to CWE-441.\n",
  "ID: '424'\nName: Improper Protection of Alternate Path\nDescription: The product does not sufficiently protect all possible paths that a user\n  can take to access restricted functionality or resources.\nPotential_Mitigations: 'Architecture and Design: Deploy different layers of protection\n  to implement security in depth.'\nRelated_Attack_Patterns: \"127: \\n\\n554: \"\n",
  "ID: '425'\nName: Direct Request ('Forced Browsing')\nDescription: The web application does not adequately enforce appropriate authorization\n  on all restricted URLs, scripts, or files.\nExtended_Description: Web applications susceptible to direct request attacks often\n  make the false assumption that such resources can only be reached through a given\n  navigation path and so only apply authorization at certain points in the path.\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: 'forced browsing: The \"forced browsing\" term could be misinterpreted\n  to include weaknesses such as CSRF or XSS, so its use is discouraged.'\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation: Apply appropriate access control authorizations for each access to all\n  restricted URLs, scripts or files.\n\n\n  Architecture and Design: Consider using MVC based frameworks such as Struts.'\nObserved_Examples: 'CVE-2022-29238: Access-control setting in web-based document collaboration\n  tool is not properly implemented by the code, which prevents listing hidden directories\n  but does not prevent direct requests to files in those directories.\n\n\n  CVE-2022-23607: Python-based HTTP library did not scope cookies to a particular\n  domain such that \"supercookies\" could be sent to any domain on redirect.\n\n\n  CVE-2004-2144: Bypass authentication via direct request.\n\n\n  CVE-2005-1892: Infinite loop or infoleak triggered by direct requests.\n\n\n  CVE-2004-2257: Bypass auth/auth via direct request.\n\n\n  CVE-2005-1688: Direct request leads to infoleak by error.\n\n\n  CVE-2005-1697: Direct request leads to infoleak by error.\n\n\n  CVE-2005-1698: Direct request leads to infoleak by error.\n\n\n  CVE-2005-1685: Authentication bypass via direct request.\n\n\n  CVE-2005-1827: Authentication bypass via direct request.\n\n\n  CVE-2005-1654: Authorization bypass using direct request.\n\n\n  CVE-2005-1668: Access privileged functionality using direct request.\n\n\n  CVE-2002-1798: Upload arbitrary files via direct request.'\nRelated_Attack_Patterns: \"127: \\n\\n143: \\n\\n144: \\n\\n668: \\n\\n87: \"\n",
  "ID: '426'\nName: Untrusted Search Path\nDescription: The product searches for critical resources using an externally-supplied\n  search path that can point to resources that are not under the product's direct\n  control.\nExtended_Description: 'This might allow attackers to execute their own programs, access\n  unauthorized data files, or modify configuration in unexpected ways. If the product\n  uses a search path to locate critical resources such as programs, then an attacker\n  could modify that search path to point to a malicious program, which the targeted\n  product would then execute. The problem extends to any type of critical resource\n  that the product trusts.\n\n  Some of the most common variants of untrusted search path are:'\nDetection_Methods: 'Black Box: Use monitoring tools that examine the software''s process\n  as it interacts with the operating system and the network. This technique is useful\n  in cases when source code is unavailable, if the software was not developed by you,\n  or if you want to verify that the build phase did not introduce any new weaknesses.\n  Examples include debuggers that directly attach to the running process; system-call\n  tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors\n  such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and look for library functions and system calls\n  that suggest when a search path is being used. One pattern is when the program performs\n  multiple accesses of the same file but in different directories, with repeated failures\n  until the proper filename is found. Library calls such as getenv() or their equivalent\n  can be checked to see if any path-related variables are being accessed.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)\n\n\n  Manual Analysis: Use tools and techniques that require manual (human) analysis,\n  such as penetration testing, threat modeling, and interactive tools that allow the\n  tester to record and modify an active session. These may be more effective than\n  strictly automated techniques. This is especially the case with weaknesses that\n  are related to design and business rules.'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Hard-code the search path to a set of known-safe values (such as\n  system directories), or only allow them to be specified by the administrator in\n  a configuration file. Do not allow these settings to be modified by an external\n  party. Be careful to avoid related weaknesses such as CWE-426 and CWE-428.\n\n\n  Implementation: When invoking other programs, specify those programs using fully-qualified\n  pathnames. While this is an effective approach, code that uses fully-qualified pathnames\n  might not be portable to other systems that do not use the same pathnames. The portability\n  can be improved by locating the full-qualified paths in a centralized, easily-modifiable\n  location within the source code, and having the code refer to these paths.\n\n\n  Implementation: Remove or restrict all environment settings before invoking other\n  programs. This includes the PATH environment variable, LD_LIBRARY_PATH, and other\n  settings that identify the location of code libraries, and any application-specific\n  search paths.\n\n\n  Implementation: Check your search path before use and remove any elements that are\n  likely to be unsafe, such as the current working directory or a temporary files\n  directory.\n\n\n  Implementation: Use other functions that require explicit paths. Making use of any\n  of the other readily available functions that require explicit paths is a safe way\n  to avoid this problem. For example, system() in C does not require a full path since\n  the shell can take care of it, while execl() and execv() require a full path.'\nObserved_Examples: 'CVE-1999-1120: Application relies on its PATH environment variable\n  to find and execute program.\n\n\n  CVE-2008-1810: Database application relies on its PATH environment variable to find\n  and execute program.\n\n\n  CVE-2007-2027: Chain: untrusted search path enabling resultant format string by\n  loading malicious internationalization messages.\n\n\n  CVE-2008-3485: Untrusted search path using malicious .EXE in Windows environment.\n\n\n  CVE-2008-2613: setuid program allows compromise using path that finds and loads\n  a malicious library.\n\n\n  CVE-2008-1319: Server allows client to specify the search path, which can be modified\n  to point to a program that the client has uploaded.'\nRelated_Attack_Patterns: '38: '\n",
  "ID: '427'\nName: Uncontrolled Search Path Element\nDescription: The product uses a fixed or controlled search path to find resources,\n  but one or more locations in that path can be under the control of unintended actors.\nExtended_Description: 'Although this weakness can occur with any type of resource,\n  it is frequently introduced when a product uses a directory search path to find\n  executables or code libraries, but the path contains a directory that can be modified\n  by an attacker, such as \"/tmp\" or the current working directory.\n\n  In Windows-based systems, when the LoadLibrary or LoadLibraryEx function is called\n  with a DLL name that does not contain a fully qualified path, the function follows\n  a search order that includes two path elements that might be uncontrolled:\n\n  In some cases, the attack can be conducted remotely, such as when SMB or WebDAV\n  network shares are used.\n\n  One or more locations in that path could include the Windows drive root or its subdirectories.\n  This often exists in Linux-based code assuming the controlled nature of the root\n  directory (/) or its subdirectories (/etc, etc), or a code that recursively accesses\n  the parent directory.  In Windows, the drive root and some of its subdirectories\n  have weak permissions by default, which makes them uncontrolled.\n\n  In some Unix-based systems, a PATH might be created that contains an empty element,\n  e.g. by splicing an empty variable into the PATH. This empty element can be interpreted\n  as equivalent to the current working directory, which might be an untrusted search\n  element.\n\n  In software package management frameworks (e.g., npm, RubyGems, or PyPi), the framework\n  may identify dependencies on third-party libraries or other packages, then consult\n  a repository that contains the desired package. The framework may search a public\n  repository before a private repository. This could be exploited by attackers by\n  placing a malicious package in the public repository that has the same name as a\n  package from the private repository. The search path might not be directly under\n  control of the developer relying on the framework, but this search order effectively\n  contains an untrusted element.'\nAlternate_Terms: 'DLL preloading: This term is one of several that are used to describe\n  exploitation of untrusted search path elements in Windows systems, which received\n  wide attention in August 2010. From a weakness perspective, the term is imprecise\n  because it can apply to both CWE-426 and CWE-427.\n\n\n  Binary planting: This term is one of several that are used to describe exploitation\n  of untrusted search path elements in Windows systems, which received wide attention\n  in August 2010. From a weakness perspective, the term is imprecise because it can\n  apply to both CWE-426 and CWE-427.\n\n\n  Insecure library loading: This term is one of several that are used to describe\n  exploitation of untrusted search path elements in Windows systems, which received\n  wide attention in August 2010. From a weakness perspective, the term is imprecise\n  because it can apply to both CWE-426 and CWE-427.\n\n\n  Dependency confusion: As of February 2021, this term is used to describe CWE-427\n  in the context of managing installation of software package dependencies, in which\n  attackers release packages on public sites where the names are the same as package\n  names used by private repositories, and the search for the dependent package tries\n  the public site first, downloading untrusted code. It may also be referred to as\n  a \"substitution attack.\"'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Hard-code the search path to a set of known-safe values (such as\n  system directories), or only allow them to be specified by the administrator in\n  a configuration file. Do not allow these settings to be modified by an external\n  party. Be careful to avoid related weaknesses such as CWE-426 and CWE-428.\n\n\n  Implementation: When invoking other programs, specify those programs using fully-qualified\n  pathnames. While this is an effective approach, code that uses fully-qualified pathnames\n  might not be portable to other systems that do not use the same pathnames. The portability\n  can be improved by locating the full-qualified paths in a centralized, easily-modifiable\n  location within the source code, and having the code refer to these paths.\n\n\n  Implementation: Remove or restrict all environment settings before invoking other\n  programs. This includes the PATH environment variable, LD_LIBRARY_PATH, and other\n  settings that identify the location of code libraries, and any application-specific\n  search paths.\n\n\n  Implementation: Check your search path before use and remove any elements that are\n  likely to be unsafe, such as the current working directory or a temporary files\n  directory. Since this is a denylist approach, it might not be a complete solution.\n\n\n  Implementation: Use other functions that require explicit paths. Making use of any\n  of the other readily available functions that require explicit paths is a safe way\n  to avoid this problem. For example, system() in C does not require a full path since\n  the shell can take care of finding the program using the PATH environment variable,\n  while execl() and execv() require a full path.'\nObserved_Examples: 'CVE-2022-4826: Go-based git extension on Windows can search for\n  and execute a malicious \"..exe\" in a repository because Go searches the current\n  working directory if git.exe is not found in the PATH\n\n\n  CVE-2020-26284: A Static Site Generator built in Go, when running on Windows, searches\n  the current working directory for a command, possibly allowing code execution using\n  a malicious .exe or .bat file with the name being searched\n\n\n  CVE-2022-24765: Windows-based fork of git creates a \".git\" folder in the C: drive,\n  allowing local attackers to create a .git folder with a malicious config file\n\n\n  CVE-2019-1552: SSL package searches under \"C:/usr/local\" for configuration files\n  and other critical data, but C:/usr/local might be world-writable.\n\n\n  CVE-2010-3402: \"DLL hijacking\" issue in document editor.\n\n\n  CVE-2010-3397: \"DLL hijacking\" issue in encryption software.\n\n\n  CVE-2010-3138: \"DLL hijacking\" issue in library used by multiple media players.\n\n\n  CVE-2010-3152: \"DLL hijacking\" issue in illustration program.\n\n\n  CVE-2010-3147: \"DLL hijacking\" issue in address book.\n\n\n  CVE-2010-3135: \"DLL hijacking\" issue in network monitoring software.\n\n\n  CVE-2010-3131: \"DLL hijacking\" issue in web browser.\n\n\n  CVE-2010-1795: \"DLL hijacking\" issue in music player/organizer.\n\n\n  CVE-2002-1576: Product uses the current working directory to find and execute a\n  program, which allows local users to gain privileges by creating a symlink that\n  points to a malicious version of the program.\n\n\n  CVE-1999-1461: Product trusts the PATH environmental variable to find and execute\n  a program, which allows local users to obtain root access by modifying the PATH\n  to point to a malicous version of that program.\n\n\n  CVE-1999-1318: Software uses a search path that includes the current working directory\n  (.), which allows local users to gain privileges via malicious programs.\n\n\n  CVE-2003-0579: Admin software trusts the user-supplied -uv.install command line\n  option to find and execute the uv.install program, which allows local users to gain\n  privileges by providing a pathname that is under control of the user.\n\n\n  CVE-2000-0854: When a document is opened, the directory of that document is first\n  used to locate DLLs , which could allow an attacker to execute arbitrary commands\n  by inserting malicious DLLs into the same directory as the document.\n\n\n  CVE-2001-0943: Database trusts the PATH environment variable to find and execute\n  programs, which allows local users to modify the PATH to point to malicious programs.\n\n\n  CVE-2001-0942: Database uses an environment variable to find and execute a program,\n  which allows local users to execute arbitrary programs by changing the environment\n  variable.\n\n\n  CVE-2001-0507: Server uses relative paths to find system files that will run in-process,\n  which allows local users to gain privileges via a malicious file.\n\n\n  CVE-2002-2017: Product allows local users to execute arbitrary code by setting an\n  environment variable to reference a malicious program.\n\n\n  CVE-1999-0690: Product includes the current directory in root''s PATH variable.\n\n\n  CVE-2001-0912: Error during packaging causes product to include a hard-coded, non-standard\n  directory in search path.\n\n\n  CVE-2001-0289: Product searches current working directory for configuration file.\n\n\n  CVE-2005-1705: Product searches current working directory for configuration file.\n\n\n  CVE-2005-1307: Product executable other program from current working directory.\n\n\n  CVE-2002-2040: Untrusted path.\n\n\n  CVE-2005-2072: Modification of trusted environment variable leads to untrusted path\n  vulnerability.\n\n\n  CVE-2005-1632: Product searches /tmp for modules before other paths.'\nRelated_Attack_Patterns: \"38: \\n\\n471: \"\n",
  "ID: '428'\nName: Unquoted Search Path or Element\nDescription: The product uses a search path that contains an unquoted element, in\n  which the element contains whitespace or other separators. This can cause the product\n  to access resources in a parent path.\nExtended_Description: If a malicious individual has access to the file system, it\n  is possible to elevate privileges by inserting such a file as \"C:\\Program.exe\" to\n  be run by a privileged program making use of WinExec.\nApplicable_Platforms:\n  Operating_System: Windows NT, macOS\nPotential_Mitigations: 'Implementation: Properly quote the full search path before\n  executing a program on the system.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2005-1185: Small handful of others. Program doesn''t quote\n  the \"C:\\Program Files\\\" path when calling a program to be executed - or any other\n  path with a directory or file whose name contains a space - so attacker can put\n  a malicious program.exe into C:.\n\n\n  CVE-2005-2938: CreateProcess() and CreateProcessAsUser() can be misused by applications\n  to allow \"program.exe\" style attacks in C:\n\n\n  CVE-2000-1128: Applies to \"Common Files\" folder, with a malicious common.exe, instead\n  of \"Program Files\"/program.exe.'\n",
  "ID: '43'\nName: 'Path Equivalence: ''filename....'' (Multiple Trailing Dot)'\nDescription: The product accepts path input in the form of multiple trailing dot ('filedir....')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nObserved_Examples: 'BUGTRAQ:20040205: Apache + Resin Reveals JSP Source Code ...\n\n\n  CVE-2004-0281: Multiple trailing dot allows directory listing'\n",
  "ID: '430'\nName: Deployment of Wrong Handler\nDescription: The wrong \"handler\" is assigned to process an object.\nExtended_Description: An example of deploying the wrong handler would be calling a\n  servlet to reveal source code of a .JSP file, or automatically \"determining\" type\n  of the object even if it is contradictory to an explicitly specified type.\nPotential_Mitigations: 'Architecture and Design: Perform a type check before interpreting\n  an object.\n\n\n  Architecture and Design: Reject any inconsistent types, such as a file with a .GIF\n  extension that appears to consist of PHP code.'\nObserved_Examples: 'CVE-2001-0004: Source code disclosure via manipulated file extension\n  that causes parsing by wrong DLL.\n\n\n  CVE-2002-0025: Web browser does not properly handle the Content-Type header field,\n  causing a different application to process the document.\n\n\n  CVE-2000-1052: Source code disclosure by directly invoking a servlet.\n\n\n  CVE-2002-1742: Arbitrary Perl functions can be loaded by calling a non-existent\n  function that activates a handler.'\nRelated_Attack_Patterns: '11: '\n",
  "ID: '431'\nName: Missing Handler\nDescription: A handler is not available or implemented.\nExtended_Description: When an exception is thrown and not caught, the process has\n  given up an opportunity to decide if a given failure or event is worth a change\n  in execution.\nPotential_Mitigations: 'Implementation: Handle all possible situations (e.g. error\n  condition).\n\n\n  Implementation: If an operation can throw an Exception, implement a handler for\n  that specific exception.'\n",
  "ID: '432'\nName: Dangerous Signal Handler not Disabled During Sensitive Operations\nDescription: The product uses a signal handler that shares state with other signal\n  handlers, but it does not properly mask or prevent those signal handlers from being\n  invoked while the original signal handler is still running.\nExtended_Description: During the execution of a signal handler, it can be interrupted\n  by another handler when a different signal is sent. If the two handlers share state\n  - such as global variables - then an attacker can corrupt the state by sending another\n  signal before the first handler has completed execution.\nPotential_Mitigations: 'Implementation: Turn off dangerous handlers when performing\n  sensitive operations.'\n",
  "ID: '433'\nName: Unparsed Raw Web Content Delivery\nDescription: The product stores raw content or supporting code under the web document\n  root with an extension that is not specifically handled by the server.\nExtended_Description: If code is stored in a file with an extension such as \".inc\"\n  or \".pl\", and the web server does not have a handler for that extension, then the\n  server will likely send the contents of the file directly to the requester without\n  the pre-processing that was expected. When that file contains sensitive information\n  such as database credentials, this may allow the attacker to compromise the application\n  or associated components.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Perform a type check before interpreting\n  files.\n\n\n  Architecture and Design: Do not store sensitive information in files which may be\n  misinterpreted.'\nObserved_Examples: 'CVE-2002-1886: \".inc\" file stored under web document root and\n  returned unparsed by the server\n\n\n  CVE-2002-2065: \".inc\" file stored under web document root and returned unparsed\n  by the server\n\n\n  CVE-2005-2029: \".inc\" file stored under web document root and returned unparsed\n  by the server\n\n\n  CVE-2001-0330: direct request to .pl file leaves it unparsed\n\n\n  CVE-2002-0614: .inc file\n\n\n  CVE-2004-2353: unparsed config.conf file\n\n\n  CVE-2007-3365: Chain: uppercase file extensions causes web server to return script\n  source code instead of executing the script.'\n",
  "ID: '434'\nName: Unrestricted Upload of File with Dangerous Type\nDescription: The product allows the attacker to upload or transfer files of dangerous\n  types that can be automatically processed within the product's environment.\nApplicable_Platforms:\n  Language: ASP.NET, PHP\n  Technology: Web Server\nAlternate_Terms: 'Unrestricted File Upload: Used in vulnerability databases and elsewhere,\n  but it is insufficiently precise. The phrase could be interpreted as the lack of\n  restrictions on the size or number of uploaded files, which is a resource consumption\n  issue.'\nModes_Of_Introduction: \"Implementation: \\n\\nArchitecture and Design: OMISSION: This\\\n  \\ weakness is caused by missing a security tactic during the architecture and design\\\n  \\ phase.\"\nDetection_Methods: 'Dynamic Analysis with Automated Results Interpretation: According\n  to SOAR, the following detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Generate a new, unique filename for\n  an uploaded file instead of using the user-supplied filename, so that no external\n  input is used at all.[REF-422] [REF-423]\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\n  Architecture and Design: Consider storing the uploaded files outside of the web\n  document root entirely. Then, use other mechanisms to deliver the files dynamically.\n  [REF-423]\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  For example, limiting filenames to alphanumeric characters can help to restrict\n  the introduction of unintended file extensions.\n\n\n  Architecture and Design: Define a very limited set of allowable extensions and only\n  generate filenames that end in these extensions. Consider the possibility of XSS\n  (CWE-79) before allowing .html or .htm file types.\n\n\n  Implementation: Ensure that only one extension is used in the filename. Some web\n  servers, including some versions of Apache, may process files based on inner extensions\n  so that \"filename.php.gif\" is fed to the PHP interpreter.[REF-422] [REF-423]\n\n\n  Implementation: When running on a web server that supports case-insensitive filenames,\n  perform case-insensitive evaluations of the extensions that are provided.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: Do not rely exclusively on sanity checks of file contents to ensure\n  that the file is of the expected type and size. It may be possible for an attacker\n  to hide code in some file segments that will still be executed by the server. For\n  example, GIF images may contain a free-form comments field.\n\n\n  Implementation: Do not rely exclusively on the MIME content type or filename attribute\n  when determining how to render a file. Validating the MIME content type and ensuring\n  that it matches the extension is only a partial solution.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.'\nObserved_Examples: 'CVE-2001-0901: Web-based mail product stores \".shtml\" attachments\n  that could contain SSI\n\n\n  CVE-2002-1841: PHP upload does not restrict file types\n\n\n  CVE-2005-1868: upload and execution of .php file\n\n\n  CVE-2005-1881: upload file with dangerous extension\n\n\n  CVE-2005-0254: program does not restrict file types\n\n\n  CVE-2004-2262: improper type checking of uploaded files\n\n\n  CVE-2006-4558: Double \"php\" extension leaves an active php extension in the generated\n  filename.\n\n\n  CVE-2006-6994: ASP program allows upload of .asp files by bypassing client-side\n  checks\n\n\n  CVE-2005-3288: ASP file upload\n\n\n  CVE-2006-2428: ASP file upload'\nRelated_Attack_Patterns: '1: '\n",
  "ID: '435'\nName: Improper Interaction Between Multiple Correctly-Behaving Entities\nDescription: An interaction error occurs when two entities have correct behavior when\n  running independently of each other, but when they are integrated as components\n  in a larger system or process, they introduce incorrect behaviors that may cause\n  resultant weaknesses.\nExtended_Description: When a system or process combines multiple independent components,\n  this often produces new, emergent behaviors at the system level.  However, if the\n  interactions between these components are not fully accounted for, some of the emergent\n  behaviors can be incorrect or even insecure.\nAlternate_Terms: \"Interaction Error: \\n\\nEmergent Fault: \"\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\n",
  "ID: '436'\nName: Interpretation Conflict\nDescription: Product A handles inputs or steps differently than Product B, which causes\n  A to perform incorrect actions based on its perception of B's state.\nExtended_Description: This is generally found in proxies, firewalls, anti-virus software,\n  and other intermediary devices that monitor, allow, deny, or modify traffic based\n  on how the client or server is expected to behave.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2005-1215: Bypass filters or poison web cache using requests\n  with multiple Content-Length headers, a non-standard behavior.\n\n\n  CVE-2002-0485: Anti-virus product allows bypass via Content-Type and Content-Disposition\n  headers that are mixed case, which are still processed by some clients.\n\n\n  CVE-2002-1978: FTP clients sending a command with \"PASV\" in the argument can cause\n  firewalls to misinterpret the server''s error as a valid response, allowing filter\n  bypass.\n\n\n  CVE-2002-1979: FTP clients sending a command with \"PASV\" in the argument can cause\n  firewalls to misinterpret the server''s error as a valid response, allowing filter\n  bypass.\n\n\n  CVE-2002-0637: Virus product bypass with spaces between MIME header fields and the\n  \":\" separator, a non-standard message that is accepted by some clients.\n\n\n  CVE-2002-1777: AV product detection bypass using inconsistency manipulation (file\n  extension in MIME Content-Type vs. Content-Disposition field).\n\n\n  CVE-2005-3310: CMS system allows uploads of files with GIF/JPG extensions, but if\n  they contain HTML, Internet Explorer renders them as HTML instead of images.\n\n\n  CVE-2005-4260: Interpretation conflict allows XSS via invalid \"<\" when a \">\" is\n  expected, which is treated as \">\" by many web browsers.\n\n\n  CVE-2005-4080: Interpretation conflict (non-standard behavior) enables XSS because\n  browser ignores invalid characters in the middle of tags.'\nRelated_Attack_Patterns: \"105: \\n\\n273: \\n\\n34: \"\n",
  "ID: '437'\nName: Incomplete Model of Endpoint Features\nDescription: A product acts as an intermediary or monitor between two or more endpoints,\n  but it does not have a complete model of an endpoint's features, behaviors, or state,\n  potentially causing the product to perform incorrect actions based on this incomplete\n  model.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '439'\nName: Behavioral Change in New Version or Environment\nDescription: A's behavior or functionality changes with a new version of A, or a new\n  environment, which is not known (or manageable) by B.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2002-1976: Linux kernel 2.2 and above allow promiscuous mode\n  using a different method than previous versions, and ifconfig is not aware of the\n  new method (alternate path property).\n\n\n  CVE-2005-1711: Product uses defunct method from another product that does not return\n  an error code and allows detection avoidance.\n\n\n  CVE-2003-0411: chain: Code was ported from a case-sensitive Unix platform to a case-insensitive\n  Windows platform where filetype handlers treat .jsp and .JSP as different extensions.\n  JSP source code may be read because .JSP defaults to the filetype \"text\".'\n",
  "ID: '44'\nName: 'Path Equivalence: ''file.name'' (Internal Dot)'\nDescription: The product accepts path input in the form of internal dot ('file.ordir')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\n",
  "ID: '440'\nName: Expected Behavior Violation\nDescription: A feature, API, or function does not perform according to its specification.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nObserved_Examples: 'CVE-2003-0187: Program uses large timeouts on \"undeserving\" to\n  compensate for inconsistency of support for linked lists.\n\n\n  CVE-2003-0465: \"strncpy\" in Linux kernel acts different than libc on x86, leading\n  to expected behavior difference - sort of a multiple interpretation error?\n\n\n  CVE-2005-3265: Buffer overflow in product stems the use of a third party library\n  function that is expected to have internal protection against overflows, but doesn''t.'\n",
  "ID: '441'\nName: Unintended Proxy or Intermediary ('Confused Deputy')\nDescription: The product receives a request, message, or directive from an upstream\n  component, but the product does not sufficiently preserve the original source of\n  the request before forwarding the request to an external actor that is outside of\n  the product's control sphere. This causes the product to appear to be the source\n  of the request, leading it to act as a proxy or other intermediary between the upstream\n  component and the external actor.\nExtended_Description: 'If an attacker cannot directly contact a target, but the product\n  has access to the target, then the attacker can send a request to the product and\n  have it be forwarded to the target. The request would appear to be coming from the\n  product''s system, not the attacker''s system. As a result, the attacker can bypass\n  access controls (such as firewalls) or hide the source of malicious requests, since\n  the requests would not be coming directly from the attacker.\n\n  Since proxy functionality and message-forwarding often serve a legitimate purpose,\n  this issue only becomes a vulnerability when:'\nAlternate_Terms: 'Confused Deputy: This weakness is sometimes referred to as the \"Confused\n  deputy\" problem, in which an attacker misused the authority of one victim (the \"confused\n  deputy\") when targeting another victim.'\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: \"Architecture and Design: Enforce the use of strong mutual\\\n  \\ authentication mechanism between the two parties.\\n\\nArchitecture and Design:\\\n  \\ Whenever a product is an intermediary or proxy for\\n                   transactions\\\n  \\ between two other components, the proxy core\\n                   should not drop\\\n  \\ the identity of the initiator of the\\n                   transaction. The immutability\\\n  \\ of the identity of the\\n                   initiator must be maintained and should\\\n  \\ be forwarded all the\\n                   way to the target.\"\nObserved_Examples: 'CVE-1999-0017: FTP bounce attack. The design of the protocol allows\n  an attacker to modify the PORT command to cause the FTP server to connect to other\n  machines besides the attacker''s.\n\n\n  CVE-1999-0168: RPC portmapper could redirect service requests from an attacker to\n  another entity, which thinks the requests came from the portmapper.\n\n\n  CVE-2005-0315: FTP server does not ensure that the IP address in a PORT command\n  is the same as the FTP user''s session, allowing port scanning by proxy.\n\n\n  CVE-2002-1484: Web server allows attackers to request a URL from another server,\n  including other ports, which allows proxied scanning.\n\n\n  CVE-2004-2061: CGI script accepts and retrieves incoming URLs.\n\n\n  CVE-2001-1484: Bounce attack allows access to TFTP from trusted side.\n\n\n  CVE-2010-1637: Web-based mail program allows internal network scanning using a modified\n  POP3 port number.\n\n\n  CVE-2009-0037: URL-downloading library automatically follows redirects to file://\n  and scp:// URLs'\nRelated_Attack_Patterns: \"219: \\n\\n465: \"\n",
  "ID: '443'\nName: 'DEPRECATED: HTTP response splitting'\nDescription: This weakness can be found at CWE-113.\n",
  "ID: '444'\nName: Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling')\nDescription: \"The product acts as an intermediary HTTP agent\\n         (such as a\\\n  \\ proxy or firewall) in the data flow between two\\n         entities such as a client\\\n  \\ and server, but it does not\\n         interpret malformed HTTP requests or responses\\\n  \\ in ways that\\n         are consistent with how the messages will be processed\\\n  \\ by\\n         those entities that are at the ultimate destination.\"\nExtended_Description: \"HTTP requests or responses (\\\"messages\\\") can be\\n\\t   malformed\\\n  \\ or unexpected in ways that cause web servers or\\n\\t   clients to interpret the\\\n  \\ messages in different ways than\\n\\t   intermediary HTTP agents such as load balancers,\\\n  \\ reverse\\n\\t   proxies, web caching proxies, application firewalls,\\n\\t   etc.\\\n  \\ For example, an adversary may be able to add duplicate\\n\\t   or different header\\\n  \\ fields that a client or server might\\n\\t   interpret as one set of messages, whereas\\\n  \\ the intermediary\\n\\t   might interpret the same sequence of bytes as a different\\n\\\n  \\t   set of messages. For example, discrepancies can arise in\\n\\t   how to handle\\\n  \\ duplicate headers like two Transfer-encoding\\n\\t   (TE) or two Content-length\\\n  \\ (CL), or the malicious HTTP\\n\\t   message will have different headers for TE and\\n\\\n  \\t   CL.\\nThe inconsistent parsing and interpretation of messages\\n\\t   can allow\\\n  \\ the adversary to \\\"smuggle\\\" a message to the\\n\\t   client/server without the\\\n  \\ intermediary being aware of it.\\nThis weakness is usually the result of the usage\\n\\\n  \\t   of outdated or incompatible HTTP protocol versions in the\\n\\t   HTTP agents.\"\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: \"HTTP Request Smuggling: \\n\\nHTTP Response Smuggling: \\n\\nHTTP Smuggling: \"\nPotential_Mitigations: 'Implementation: Use a web server that employs a strict HTTP\n  parsing procedure, such as Apache [REF-433].\n\n\n  Implementation: Use only SSL communication.\n\n\n  Implementation: Terminate the client session after each request.\n\n\n  System Configuration: Turn all pages to non-cacheable.'\nObserved_Examples: 'CVE-2022-24766: SSL/TLS-capable proxy allows HTTP smuggling when\n  used in tandem with HTTP/1.0 services, due to inconsistent interpretation and input\n  sanitization of HTTP messages within the body of another message\n\n\n  CVE-2021-37147: Chain: caching proxy server has improper input validation (CWE-20)\n  of headers, allowing HTTP response smuggling (CWE-444) using an \"LF line ending\"\n\n\n  CVE-2020-8287: Node.js platform allows request smuggling via two Transfer-Encoding\n  headers\n\n\n  CVE-2006-6276: Web servers allow request smuggling via inconsistent HTTP headers.\n\n\n  CVE-2005-2088: HTTP server allows request smuggling with both a \"Transfer-Encoding:\n  chunked\" header and a Content-Length header\n\n\n  CVE-2005-2089: HTTP server allows request smuggling with both a \"Transfer-Encoding:\n  chunked\" header and a Content-Length header'\nRelated_Attack_Patterns: \"273: \\n\\n33: \"\n",
  "ID: '446'\nName: UI Discrepancy for Security Feature\nDescription: The user interface does not correctly enable or configure a security\n  feature, but the interface provides feedback that causes the user to believe that\n  the feature is in a secure state.\nExtended_Description: When the user interface does not properly reflect what the user\n  asks of it, then it can lead the user into a false sense of security. For example,\n  the user might check a box to enable a security option to enable encrypted communications,\n  but the product does not actually enable the encryption. Alternately, the user might\n  provide a \"restrict ALL\" access control rule, but the product only implements \"restrict\n  SOME\".\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-1999-1446: UI inconsistency; visited URLs list not cleared\n  when \"Clear History\" option is selected.'\n",
  "ID: '447'\nName: Unimplemented or Unsupported Feature in UI\nDescription: A UI function for a security feature appears to be supported and gives\n  feedback to the user that suggests that it is supported, but the underlying functionality\n  is not implemented.\nPotential_Mitigations: 'Testing: Perform functionality testing before deploying the\n  application.'\nObserved_Examples: 'CVE-2000-0127: GUI configuration tool does not enable a security\n  option when a checkbox is selected, although that option is honored when manually\n  set in the configuration file.\n\n\n  CVE-2001-0863: Router does not implement a specific keyword when it is used in an\n  ACL, allowing filter bypass.\n\n\n  CVE-2001-0865: Router does not implement a specific keyword when it is used in an\n  ACL, allowing filter bypass.\n\n\n  CVE-2004-0979: Web browser does not properly modify security setting when the user\n  sets it.'\n",
  "ID: '448'\nName: Obsolete Feature in UI\nDescription: A UI function is obsolete and the product does not warn the user.\nPotential_Mitigations: 'Architecture and Design: Remove the obsolete feature from\n  the UI. Warn the user that the feature is no longer supported.'\n",
  "ID: '449'\nName: The UI Performs the Wrong Action\nDescription: The UI performs the wrong action with respect to the user's request.\nPotential_Mitigations: 'Testing: Perform extensive functionality testing of the UI.\n  The UI should behave as specified.'\nObserved_Examples: 'CVE-2001-1387: Network firewall accidentally implements one command\n  line option as if it were another, possibly leading to behavioral infoleak.\n\n\n  CVE-2001-0081: Command line option correctly suppresses a user prompt but does not\n  properly disable a feature, although when the product prompts the user, the feature\n  is properly disabled.\n\n\n  CVE-2002-1977: Product does not \"time out\" according to user specification, leaving\n  sensitive data available after it has expired.'\n",
  "ID: '45'\nName: 'Path Equivalence: ''file...name'' (Multiple Internal Dot)'\nDescription: The product accepts path input in the form of multiple internal dot ('file...dir')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\n",
  "ID: '450'\nName: Multiple Interpretations of UI Input\nDescription: The UI has multiple interpretations of user input but does not prompt\n  the user when it selects the less secure interpretation.\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\n",
  "ID: '451'\nName: User Interface (UI) Misrepresentation of Critical Information\nDescription: The user interface (UI) does not properly represent critical information\n  to the user, allowing the information - or its source - to be obscured or spoofed.\n  This is often a component in phishing attacks.\nExtended_Description: 'If an attacker can cause the UI to display erroneous data,\n  or to otherwise convince the user to display information that appears to come from\n  a trusted source, then the attacker could trick the user into performing the wrong\n  action. This is often a component in phishing attacks, but other kinds of problems\n  exist. For example, if the UI is used to monitor the security state of a system\n  or network, then omitting or obscuring an important indicator could prevent the\n  user from detecting and reacting to a security-critical event.\n\n  UI misrepresentation can take many forms:'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Perform data validation (e.g. syntax, length,\n  etc.) before interpreting the data.\n\n\n  Architecture and Design: Create a strategy for presenting information, and plan\n  for how to display unusual characters.'\nObserved_Examples: 'CVE-2004-2227: Web browser''s filename selection dialog only shows\n  the beginning portion of long filenames, which can trick users into launching executables\n  with dangerous extensions.\n\n\n  CVE-2001-0398: Attachment with many spaces in filename bypasses \"dangerous content\"\n  warning and uses different icon. Likely resultant.\n\n\n  CVE-2001-0643: Misrepresentation and equivalence issue.\n\n\n  CVE-2005-0593: Lock spoofing from several different weaknesses.\n\n\n  CVE-2004-1104: Incorrect indicator: web browser can be tricked into presenting the\n  wrong URL\n\n\n  CVE-2005-0143: Incorrect indicator: Lock icon displayed when an insecure page loads\n  a binary file loaded from a trusted site.\n\n\n  CVE-2005-0144: Incorrect indicator: Secure \"lock\" icon is presented for one channel,\n  while an insecure page is being simultaneously loaded in another channel.\n\n\n  CVE-2004-0761: Incorrect indicator: Certain redirect sequences cause security lock\n  icon to appear in web browser, even when page is not encrypted.\n\n\n  CVE-2004-2219: Incorrect indicator: Spoofing via multi-step attack that causes incorrect\n  information to be displayed in browser address bar.\n\n\n  CVE-2004-0537: Overlay: Wide \"favorites\" icon can overlay and obscure address bar\n\n\n  CVE-2005-2271: Visual distinction: Web browsers do not clearly associate a Javascript\n  dialog box with the web page that generated it, allowing spoof of the source of\n  the dialog. \"origin validation error\" of a sort?\n\n\n  CVE-2005-2272: Visual distinction: Web browsers do not clearly associate a Javascript\n  dialog box with the web page that generated it, allowing spoof of the source of\n  the dialog. \"origin validation error\" of a sort?\n\n\n  CVE-2005-2273: Visual distinction: Web browsers do not clearly associate a Javascript\n  dialog box with the web page that generated it, allowing spoof of the source of\n  the dialog. \"origin validation error\" of a sort?\n\n\n  CVE-2005-2274: Visual distinction: Web browsers do not clearly associate a Javascript\n  dialog box with the web page that generated it, allowing spoof of the source of\n  the dialog. \"origin validation error\" of a sort?\n\n\n  CVE-2001-1410: Visual distinction: Browser allows attackers to create chromeless\n  windows and spoof victim''s display using unprotected Javascript method.\n\n\n  CVE-2002-0197: Visual distinction: Chat client allows remote attackers to spoof\n  encrypted, trusted messages with lines that begin with a special sequence, which\n  makes the message appear legitimate.\n\n\n  CVE-2005-0831: Visual distinction: Product allows spoofing names of other users\n  by registering with a username containing hex-encoded characters.\n\n\n  CVE-2003-1025: Visual truncation: Special character in URL causes web browser to\n  truncate the user portion of the \"user@domain\" URL, hiding real domain in the address\n  bar.\n\n\n  CVE-2005-0243: Visual truncation: Chat client does not display long filenames in\n  file dialog boxes, allowing dangerous extensions via manipulations including (1)\n  many spaces and (2) multiple file extensions.\n\n\n  CVE-2005-1575: Visual truncation: Web browser file download type can be hidden using\n  whitespace.\n\n\n  CVE-2004-2530: Visual truncation: Visual truncation in chat client using whitespace\n  to hide dangerous file extension.\n\n\n  CVE-2005-0590: Visual truncation: Dialog box in web browser allows user to spoof\n  the hostname via a long \"user:pass\" sequence in the URL, which appears before the\n  real hostname.\n\n\n  CVE-2004-1451: Visual truncation: Null character in URL prevents entire URL from\n  being displayed in web browser.\n\n\n  CVE-2004-2258: Miscellaneous -- [step-based attack, GUI] -- Password-protected tab\n  can be bypassed by switching to another tab, then back to original tab.\n\n\n  CVE-2005-1678: Miscellaneous -- Dangerous file extensions not displayed.\n\n\n  CVE-2002-0722: Miscellaneous -- Web browser allows remote attackers to misrepresent\n  the source of a file in the File Download dialog box.'\nRelated_Attack_Patterns: \"154: \\n\\n163: \\n\\n164: \\n\\n173: \\n\\n98: \"\n",
  "ID: '453'\nName: Insecure Default Variable Initialization\nDescription: The product, by default, initializes an internal variable with an insecure\n  or less secure value than is possible.\nApplicable_Platforms:\n  Language: PHP\nPotential_Mitigations: 'System Configuration: Disable or change default settings when\n  they can be used to abuse the system. Since those default settings are shipped with\n  the product they are likely to be known by a potential attacker who is familiar\n  with the product. For instance, default credentials should be changed or the associated\n  accounts should be disabled.'\n",
  "ID: '454'\nName: External Initialization of Trusted Variables or Data Stores\nDescription: The product initializes critical internal variables or data stores using\n  inputs that can be modified by untrusted actors.\nExtended_Description: A product system should be reluctant to trust variables that\n  have been initialized outside of its trust boundary, especially if they are initialized\n  by users. The variables may have been initialized incorrectly. If an attacker can\n  initialize the variable, then they can influence what the vulnerable system will\n  do.\nApplicable_Platforms:\n  Language: PHP\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: A product system should be reluctant to trust\n  variables that have been initialized outside of its trust boundary. Ensure adequate\n  checking (e.g. input validation) is performed when relying on input from outside\n  a trust boundary.\n\n\n  Architecture and Design: Avoid any external control of variables. If necessary,\n  restrict the variables that can be modified using an allowlist, and use a different\n  namespace or naming convention if possible.'\nObserved_Examples: 'CVE-2000-0959: Does not clear dangerous environment variables,\n  enabling symlink attack.\n\n\n  CVE-2001-0033: Specify alternate configuration directory in environment variable,\n  enabling untrusted path.\n\n\n  CVE-2001-0872: Dangerous environment variable not cleansed.\n\n\n  CVE-2001-0084: Specify arbitrary modules using environment variable.'\n",
  "ID: '455'\nName: Non-exit on Failed Initialization\nDescription: The product does not exit or otherwise modify its operation when security-relevant\n  errors occur during initialization, such as when a configuration file has a format\n  error or a hardware security module (HSM) cannot be activated, which can cause the\n  product to execute in a less secure fashion than intended by the administrator.\nPotential_Mitigations: 'Implementation: Follow the principle of failing securely when\n  an error occurs. The system should enter a state where it is not vulnerable and\n  will not display sensitive error messages to a potential attacker.'\nObserved_Examples: 'CVE-2005-1345: Product does not trigger a fatal error if missing\n  or invalid ACLs are in a configuration file.'\n",
  "ID: '456'\nName: Missing Initialization of a Variable\nDescription: The product does not initialize critical variables, which causes the\n  execution environment to use unexpected values.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Check that critical variables are initialized.\n\n\n  Testing: Use a static analysis tool to spot non-initialized variables.'\nObserved_Examples: 'CVE-2020-6078: Chain: The return value of a function returning\n  a pointer is not checked for success (CWE-252) resulting in the later use of an\n  uninitialized variable (CWE-456) and a null pointer dereference (CWE-476)\n\n\n  CVE-2009-2692: Chain: Use of an unimplemented network socket operation pointing\n  to an uninitialized handler function (CWE-456) causes a crash because of a null\n  pointer dereference (CWE-476).\n\n\n  CVE-2020-20739: A variable that has its value set in a conditional statement is\n  sometimes used when the conditional fails, sometimes causing data leakage\n\n\n  CVE-2005-2978: Product uses uninitialized variables for size and index, leading\n  to resultant buffer overflow.\n\n\n  CVE-2005-2109: Internal variable in PHP application is not initialized, allowing\n  external modification.\n\n\n  CVE-2005-2193: Array variable not initialized in PHP application, leading to resultant\n  SQL injection.'\n",
  "ID: '457'\nName: Use of Uninitialized Variable\nDescription: The code uses a variable that has not been initialized, leading to unpredictable\n  or unintended results.\nExtended_Description: In some languages such as C and C++, stack variables are not\n  initialized by default. They generally contain junk data with the contents of stack\n  memory before the function was invoked. An attacker can sometimes control or read\n  these contents. In other languages or conditions, a variable that is not explicitly\n  initialized can be given a default value that has security implications, depending\n  on the logic of the program. The presence of an uninitialized variable can sometimes\n  indicate a typographic error in the code.\nApplicable_Platforms:\n  Language: C, C++, Perl, PHP\nModes_Of_Introduction: 'Implementation: In C, using an uninitialized char * in some\n  string libraries will return incorrect results, as the libraries expect the null\n  terminator to always be at the end of a string, even if the string is empty.'\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assign all variables to an initial value.\n\n\n  Build and Compilation: Most compilers will complain about the use of uninitialized\n  variables if warnings are turned on.\n\n\n  Implementation, Operation: When using a language that does not require explicit\n  declaration of variables, run or compile the software in a mode that reports undeclared\n  or unknown variables. This may indicate the presence of a typographic error in the\n  variable''s name.\n\n\n  Requirements: The choice could be made to use a language that is not susceptible\n  to these issues.\n\n\n  Architecture and Design: Mitigating technologies such as safe string libraries and\n  container abstractions could be introduced.'\nObserved_Examples: 'CVE-2019-15900: Chain: sscanf() call is used to check if a username\n  and group exists, but the return value of sscanf() call is not checked (CWE-252),\n  causing an uninitialized variable to be checked (CWE-457), returning success to\n  allow authorization bypass for executing a privileged (CWE-863).\n\n\n  CVE-2008-3688: Chain: A denial of service may be caused by an uninitialized variable\n  (CWE-457) allowing an infinite loop (CWE-835) resulting from a connection to an\n  unresponsive server.\n\n\n  CVE-2008-0081: Uninitialized variable leads to code execution in popular desktop\n  application.\n\n\n  CVE-2007-4682: Crafted input triggers dereference of an uninitialized object pointer.\n\n\n  CVE-2007-3468: Crafted audio file triggers crash when an uninitialized variable\n  is used.\n\n\n  CVE-2007-2728: Uninitialized random seed variable used.'\n",
  "ID: '458'\nName: 'DEPRECATED: Incorrect Initialization'\nDescription: This weakness has been deprecated because its name and description did\n  not match. The description duplicated CWE-454, while the name suggested a more abstract\n  initialization problem. Please refer to CWE-665 for the more abstract problem.\n",
  "ID: '459'\nName: Incomplete Cleanup\nDescription: The product does not properly \"clean up\" and remove temporary or supporting\n  resources after they have been used.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Temporary files and other supporting resources should be deleted/released\n  immediately after they are no longer needed.'\nObserved_Examples: 'CVE-2000-0552: World-readable temporary file not deleted after\n  use.\n\n\n  CVE-2005-2293: Temporary file not deleted after use, leaking database usernames\n  and passwords.\n\n\n  CVE-2002-0788: Interaction error creates a temporary file that can not be deleted\n  due to strong permissions.\n\n\n  CVE-2002-2066: Alternate data streams for NTFS files are not cleared when files\n  are wiped (alternate channel / infoleak).\n\n\n  CVE-2002-2067: Alternate data streams for NTFS files are not cleared when files\n  are wiped (alternate channel / infoleak).\n\n\n  CVE-2002-2068: Alternate data streams for NTFS files are not cleared when files\n  are wiped (alternate channel / infoleak).\n\n\n  CVE-2002-2069: Alternate data streams for NTFS files are not cleared when files\n  are wiped (alternate channel / infoleak).\n\n\n  CVE-2002-2070: Alternate data streams for NTFS files are not cleared when files\n  are wiped (alternate channel / infoleak).\n\n\n  CVE-2005-1744: Users not logged out when application is restarted after security-relevant\n  changes were made.'\n",
  "ID: '46'\nName: 'Path Equivalence: ''filename '' (Trailing Space)'\nDescription: The product accepts path input in the form of trailing space ('filedir\n  ') without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nObserved_Examples: 'CVE-2001-0693: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2001-0778: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2001-1248: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2004-0280: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2004-2213: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2005-0622: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2005-1656: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2002-1603: Source disclosure via trailing encoded space \"%20\"\n\n\n  CVE-2001-0054: Multi-Factor Vulnerability (MVF). directory traversal and other issues\n  in FTP server using Web encodings such as \"%20\"; certain manipulations have unusual\n  side effects.\n\n\n  CVE-2002-1451: Trailing space (\"+\" in query string) leads to source code disclosure.'\nRelated_Attack_Patterns: '649: '\n",
  "ID: '460'\nName: Improper Cleanup on Thrown Exception\nDescription: The product does not clean up its state or incorrectly cleans up its\n  state when an exception is thrown, leading to unexpected state or control flow.\nExtended_Description: Often, when functions or loops become complicated, some level\n  of resource cleanup is needed throughout execution. Exceptions can disturb the flow\n  of the code and prevent the necessary cleanup from happening.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: If one breaks from a loop or function by throwing\n  an exception, make sure that cleanup happens or that you should exit the program.\n  Use throwing exceptions sparsely.'\n",
  "ID: '462'\nName: Duplicate Key in Associative List (Alist)\nDescription: Duplicate keys in associative lists can lead to non-unique keys being\n  mistaken for an error.\nExtended_Description: A duplicate key entry -- if the alist is designed properly --\n  could be used as a constant time replace function. However, duplicate key entries\n  could be inserted by mistake. Because of this ambiguity, duplicate key entries in\n  an association list are not recommended and should not be allowed.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nPotential_Mitigations: 'Architecture and Design: Use a hash table instead of an alist.\n\n\n  Architecture and Design: Use an alist which checks the uniqueness of hash keys with\n  each entry before inserting the entry.'\n",
  "ID: '463'\nName: Deletion of Data Structure Sentinel\nDescription: The accidental deletion of a data-structure sentinel can cause serious\n  programming logic problems.\nExtended_Description: Often times data-structure sentinels are used to mark structure\n  of the data structure. A common example of this is the null character at the end\n  of strings. Another common example is linked lists which may contain a sentinel\n  to mark the end of the list. It is dangerous to allow this type of control data\n  to be easily accessible. Therefore, it is important to protect from the deletion\n  or modification outside of some wrapper interface which provides safety.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Architecture and Design: Use an abstraction library to abstract\n  away risky APIs. Not a complete solution.\n\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that automatically provide a protection mechanism that mitigates or eliminates buffer\n  overflows.\n\n  For example, certain compilers and extensions provide automatic buffer overflow\n  detection mechanisms that are built into the compiled code. Examples include the\n  Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard,\n  and ProPolice.\n\n\n  Operation: Use OS-level preventative functionality. Not a complete solution.'\n",
  "ID: '464'\nName: Addition of Data Structure Sentinel\nDescription: The accidental addition of a data-structure sentinel can cause serious\n  programming logic problems.\nExtended_Description: Data-structure sentinels are often used to mark the structure\n  of data. A common example of this is the null character at the end of strings or\n  a special sentinel to mark the end of a linked list. It is dangerous to allow this\n  type of control data to be easily accessible. Therefore, it is important to protect\n  from the addition or modification of sentinels.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Implementation\n\n  Architecture and Design: Encapsulate the user from interacting with data sentinels.\n  Validate user input to verify that sentinels are not present.\n\n\n  Implementation: Proper error checking can reduce the risk of inadvertently introducing\n  sentinel values into data. For example, if a parsing function fails or encounters\n  an error, it might return a value that is the same as the sentinel.\n\n\n  Architecture and Design: Use an abstraction library to abstract away risky APIs.\n  This is not a complete solution.\n\n\n  Operation: Use OS-level preventative functionality. This is not a complete solution.'\n",
  "ID: '466'\nName: Return of Pointer Value Outside of Expected Range\nDescription: A function can return a pointer to memory that is outside of the buffer\n  that the pointer is expected to reference.\nApplicable_Platforms:\n  Language: C, C++\n",
  "ID: '467'\nName: Use of sizeof() on a Pointer Type\nDescription: The code calls sizeof() on a malloced pointer type, which always returns\n  the wordsize/8. This can produce an unexpected result if the programmer intended\n  to determine how much memory has been allocated.\nExtended_Description: The use of sizeof() on a pointer can sometimes generate useful\n  information. An obvious case is to find out the wordsize on a platform. More often\n  than not, the appearance of sizeof(pointer) indicates a bug.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use expressions such as \"sizeof(*pointer)\"\n  instead of \"sizeof(pointer)\", unless you intend to run sizeof() on a pointer type\n  to gain some platform independence or if you are allocating a variable on the stack.'\n",
  "ID: '468'\nName: Incorrect Pointer Scaling\nDescription: In C and C++, one may often accidentally refer to the wrong memory due\n  to the semantics of when math operations are implicitly scaled.\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: 'Implementation: Programmers may try to index from a pointer\n  by adding a number of bytes. This is incorrect because C and C++ implicitly scale\n  the operand by the size of the data type.'\nPotential_Mitigations: 'Architecture and Design: Use a platform with high-level memory\n  abstractions.\n\n\n  Implementation: Always use array indexing instead of direct pointer manipulation.\n\n\n  Architecture and Design: Use technologies for preventing buffer overflows.'\n",
  "ID: '469'\nName: Use of Pointer Subtraction to Determine Size\nDescription: The product subtracts one pointer from another in order to determine\n  size, but this calculation can be incorrect if the pointers do not exist in the\n  same memory chunk.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Save an index variable. This is the recommended\n  solution. Rather than subtract pointers from one another, use an index variable\n  of the same size as the pointers in question. Use this variable to \"walk\" from one\n  pointer to the other and calculate the difference. Always validate this number.'\n",
  "ID: '47'\nName: 'Path Equivalence: '' filename'' (Leading Space)'\nDescription: The product accepts path input in the form of leading space (' filedir')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\n",
  "ID: '470'\nName: Use of Externally-Controlled Input to Select Classes or Code ('Unsafe Reflection')\nDescription: The product uses external input with reflection to select which classes\n  or code to use, but it does not sufficiently prevent the input from selecting improper\n  classes or code.\nExtended_Description: If the product uses external inputs to determine which class\n  to instantiate or which method to invoke, then an attacker could supply values to\n  select unexpected classes or methods. If this occurs, then the attacker could create\n  control flow paths that were not intended by the developer. These paths could bypass\n  authentication or access control checks, or otherwise cause the product to behave\n  in an unexpected manner. This situation becomes a doomsday scenario if the attacker\n  can upload files into a location that appears on the product's classpath (CWE-427)\n  or add new entries to the product's classpath (CWE-426). Under either of these conditions,\n  the attacker can use reflection to introduce new, malicious behavior into the product.\nApplicable_Platforms:\n  Language: Java, PHP, Interpreted\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Refactor your code to avoid using\n  reflection.\n\n\n  Architecture and Design: Do not use user-controlled inputs to select and load classes\n  or code.\n\n\n  Implementation: Apply strict input validation by using allowlists or indirect selection\n  to ensure that the user is only selecting allowable classes or code.'\nObserved_Examples: 'CVE-2004-2331: Database system allows attackers to bypass sandbox\n  restrictions by using the Reflection APi.'\nRelated_Attack_Patterns: '138: '\n",
  "ID: '471'\nName: Modification of Assumed-Immutable Data (MAID)\nDescription: The product does not properly protect an assumed-immutable element from\n  being modified by an attacker.\nExtended_Description: This occurs when a particular input is critical enough to the\n  functioning of the application that it should not be modifiable at all, but it is.\n  Certain resources are often assumed to be immutable when they are not, such as hidden\n  form fields in web applications, cookies, and reverse DNS lookups.\nModes_Of_Introduction: \"Implementation: \\n\\nArchitecture and Design: \"\nPotential_Mitigations: 'Architecture and Design\n\n  Operation\n\n  Implementation: When the data is stored or transmitted through untrusted sources\n  that could modify the data, implement integrity checks to detect unauthorized modification,\n  or store/transmit the data in a trusted location that is free from external influence.'\nObserved_Examples: 'CVE-2002-1757: Relies on $PHP_SELF variable for authentication.\n\n\n  CVE-2005-1905: Gain privileges by modifying assumed-immutable code addresses that\n  are accessed by a driver.'\nRelated_Attack_Patterns: \"384: \\n\\n385: \\n\\n386: \\n\\n387: \\n\\n388: \"\n",
  "ID: '472'\nName: External Control of Assumed-Immutable Web Parameter\nDescription: The web application does not sufficiently verify inputs that are assumed\n  to be immutable but are actually externally controllable, such as hidden form fields.\nExtended_Description: 'If a web product does not properly protect assumed-immutable\n  values from modification in hidden form fields, parameters, cookies, or URLs, this\n  can lead to modification of critical data. Web applications often mistakenly make\n  the assumption that data passed to the client in hidden fields or cookies is not\n  susceptible to tampering. Improper validation of data that are user-controllable\n  can lead to the application processing incorrect, and often malicious, input.\n\n  For example, custom cookies commonly store session data or persistent data across\n  sessions. This kind of session data is normally involved in security related decisions\n  on the server side, such as user authentication and access control. Thus, the cookies\n  might contain sensitive data such as user credentials and privileges. This is a\n  dangerous practice, as it can often lead to improper reliance on the value of the\n  client-provided cookie by the server side application.'\nModes_Of_Introduction: 'Implementation: OMISSION: This weakness is caused by missing\n  a security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180). Make sure that\n  the application does not decode the same input twice (CWE-174). Such errors could\n  be used to bypass allowlist validation schemes by introducing dangerous inputs after\n  they have been checked.'\nObserved_Examples: 'CVE-2002-0108: Forum product allows spoofed messages of other\n  users via hidden form fields for name and e-mail address.\n\n\n  CVE-2000-0253: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2000-0254: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2000-0926: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2000-0101: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2000-0102: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2000-0758: Allows admin access by modifying value of form field.\n\n\n  CVE-2002-1880: Read messages by modifying message ID parameter.\n\n\n  CVE-2000-1234: Send email to arbitrary users by modifying email parameter.\n\n\n  CVE-2005-1652: Authentication bypass by setting a parameter.\n\n\n  CVE-2005-1784: Product does not check authorization for configuration change admin\n  script, leading to password theft via modified e-mail address field.\n\n\n  CVE-2005-2314: Logic error leads to password disclosure.\n\n\n  CVE-2005-1682: Modification of message number parameter allows attackers to read\n  other people''s messages.'\nRelated_Attack_Patterns: \"146: \\n\\n226: \\n\\n31: \\n\\n39: \"\n",
  "ID: '473'\nName: PHP External Variable Modification\nDescription: A PHP application does not properly protect against the modification\n  of variables from external sources, such as query parameters or cookies. This can\n  expose the application to numerous weaknesses that would not exist otherwise.\nApplicable_Platforms:\n  Language: PHP\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Requirements, Implementation: Carefully identify which variables\n  can be controlled or influenced by an external user, and consider adopting a naming\n  convention to emphasize when externally modifiable variables are being used. An\n  application should be reluctant to trust variables that have been initialized outside\n  of its trust boundary. Ensure adequate checking is performed when relying on input\n  from outside a trust boundary. Do not allow your application to run with register_globals\n  enabled. If you implement a register_globals emulator, be extremely careful of variable\n  extraction, dynamic evaluation, and similar issues, since weaknesses in your emulation\n  could allow external variable modification to take place even without register_globals.'\nObserved_Examples: 'CVE-2000-0860: File upload allows arbitrary file read by setting\n  hidden form variables to match internal variable names.\n\n\n  CVE-2001-0854: Mistakenly trusts $PHP_SELF variable to determine if include script\n  was called by its parent.\n\n\n  CVE-2002-0764: PHP remote file inclusion by modified assumed-immutable variable.\n\n\n  CVE-2001-1025: Modify key variable when calling scripts that don''t load a library\n  that initializes it.\n\n\n  CVE-2003-0754: Authentication bypass by modifying array used for authentication.'\nRelated_Attack_Patterns: '77: '\n",
  "ID: '474'\nName: Use of Function with Inconsistent Implementations\nDescription: The code uses a function that has inconsistent implementations across\n  operating systems and versions.\nExtended_Description: 'The use of inconsistent implementations can cause changes in\n  behavior when the code is ported or built under a different environment than the\n  programmer expects, which can lead to security problems in some cases.\n\n  The implementation of many functions varies by platform, and at times, even by different\n  versions of the same platform. Implementation differences can include:'\nApplicable_Platforms:\n  Language: C, PHP\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Requirements: Do not accept inconsistent behavior from the API specifications when\n  the deviant behavior increase the risk level.'\n",
  "ID: '475'\nName: Undefined Behavior for Input to API\nDescription: The behavior of this function is undefined unless its control parameter\n  is set to a specific value.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '476'\nName: NULL Pointer Dereference\nDescription: A NULL pointer dereference occurs when the application dereferences a\n  pointer that it expects to be valid, but is NULL, typically causing a crash or exit.\nExtended_Description: NULL pointer dereference issues can occur through a number of\n  flaws, including race conditions, and simple programming omissions.\nApplicable_Platforms:\n  Language: C, C++, Java, C#, Go\nAlternate_Terms: \"NPD: \\n\\nnull deref: \\n\\nnil pointer dereference: used for access\\\n  \\ of nil in Go programs\"\nDetection_Methods: 'Automated Dynamic Analysis: This weakness can be detected using\n  dynamic tools and techniques that interact with the software using large test suites\n  with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and\n  fault injection. The software''s operation may slow down, but it should not become\n  unstable, crash, or generate incorrect results.\n\n\n  Manual Dynamic Analysis: Identify error conditions that are not likely to occur\n  during normal usage and trigger them. For example, run the program under low memory\n  conditions, run with insufficient privileges or permissions, interrupt a transaction\n  before it is completed, or disable connectivity to basic network services such as\n  DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled\n  exception or similar error that was discovered and handled by the application''s\n  environment, it may still indicate unexpected conditions that were not handled by\n  the application itself.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: If all pointers that could have been modified\n  are sanity-checked previous to use, nearly all NULL pointer dereferences can be\n  prevented.\n\n\n  Requirements: The choice could be made to use a language that is not susceptible\n  to these issues.\n\n\n  Implementation: Check the results of all functions that return a value and verify\n  that the value is non-null before acting upon it.\n\n\n  Architecture and Design: Identify all variables and data stores that receive information\n  from external sources, and apply input validation to make sure that they are only\n  initialized to expected values.\n\n\n  Implementation: Explicitly initialize all your variables and other data stores,\n  either during declaration or just before the first usage.\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.'\nObserved_Examples: 'CVE-2005-3274: race condition causes a table to be corrupted if\n  a timer activates while it is being modified, leading to resultant NULL dereference;\n  also involves locking.\n\n\n  CVE-2002-1912: large number of packets leads to NULL dereference\n\n\n  CVE-2005-0772: packet with invalid error status value triggers NULL dereference\n\n\n  CVE-2009-4895: Chain: race condition for an argument value, possibly resulting in\n  NULL dereference\n\n\n  CVE-2020-29652: ssh component for Go allows clients to cause a denial of service\n  (nil pointer dereference) against SSH servers.\n\n\n  CVE-2009-2692: Chain: Use of an unimplemented network socket operation pointing\n  to an uninitialized handler function (CWE-456) causes a crash because of a null\n  pointer dereference (CWE-476).\n\n\n  CVE-2009-3547: Chain: race condition might allow resource to be released before\n  operating on it, leading to NULL dereference\n\n\n  CVE-2009-3620: Chain: some unprivileged ioctls do not verify that a structure has\n  been initialized before invocation, leading to NULL dereference\n\n\n  CVE-2009-2698: Chain: IP and UDP layers each track the same value with different\n  mechanisms that can get out of sync, possibly resulting in a NULL dereference\n\n\n  CVE-2009-2692: Chain: uninitialized function pointers can be dereferenced allowing\n  code execution\n\n\n  CVE-2009-0949: Chain: improper initialization of memory can lead to NULL dereference\n\n\n  CVE-2008-3597: Chain: game server can access player data structures before initialization\n  has happened leading to NULL dereference\n\n\n  CVE-2020-6078: Chain: The return value of a function returning a pointer is not\n  checked for success (CWE-252) resulting in the later use of an uninitialized variable\n  (CWE-456) and a null pointer dereference (CWE-476)\n\n\n  CVE-2008-0062: Chain: a message having an unknown message type may cause a reference\n  to uninitialized memory resulting in a null pointer dereference (CWE-476) or dangling\n  pointer (CWE-825), possibly crashing the system or causing heap corruption.\n\n\n  CVE-2008-5183: Chain: unchecked return value can lead to NULL dereference\n\n\n  CVE-2004-0079: SSL software allows remote attackers to cause a denial of service\n  (crash) via a crafted SSL/TLS handshake that triggers a null dereference.\n\n\n  CVE-2004-0365: Network monitor allows remote attackers to cause a denial of service\n  (crash) via a malformed RADIUS packet that triggers a null dereference.\n\n\n  CVE-2003-1013: Network monitor allows remote attackers to cause a denial of service\n  (crash) via a malformed Q.931, which triggers a null dereference.\n\n\n  CVE-2003-1000: Chat client allows remote attackers to cause a denial of service\n  (crash) via a passive DCC request with an invalid ID number, which causes a null\n  dereference.\n\n\n  CVE-2004-0389: Server allows remote attackers to cause a denial of service (crash)\n  via malformed requests that trigger a null dereference.\n\n\n  CVE-2004-0119: OS allows remote attackers to cause a denial of service (crash from\n  null dereference) or execute arbitrary code via a crafted request during authentication\n  protocol selection.\n\n\n  CVE-2004-0458: Game allows remote attackers to cause a denial of service (server\n  crash) via a missing argument, which triggers a null pointer dereference.\n\n\n  CVE-2002-0401: Network monitor allows remote attackers to cause a denial of service\n  (crash) or execute arbitrary code via malformed packets that cause a NULL pointer\n  dereference.'\n",
  "ID: '477'\nName: Use of Obsolete Function\nDescription: The code uses deprecated or obsolete functions, which suggests that the\n  code has not been actively reviewed or maintained.\nExtended_Description: 'As programming languages evolve, functions occasionally become\n  obsolete due to:\n\n  Functions that are removed are usually replaced by newer counterparts that perform\n  the same task in some different and hopefully improved way.'\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: Refer to the documentation for the obsolete\n  function in order to determine why it is deprecated or obsolete and to learn about\n  alternative ways to achieve the same functionality.\n\n\n  Requirements: Consider seriously the security implications of using an obsolete\n  function. Consider using alternate functions.'\n",
  "ID: '478'\nName: Missing Default Case in Multiple Condition Expression\nDescription: The code does not have a default case in an expression with multiple\n  conditions, such as a switch statement.\nExtended_Description: If a multiple-condition expression (such as a switch in C) omits\n  the default case but does not consider or handle all possible values that could\n  occur, then this might lead to complex logical errors and resultant weaknesses.\n  Because of this, further decisions are made based on poor information, and cascading\n  failure results. This cascading failure may result in any number of security issues,\n  and constitutes a significant failure in the system.\nApplicable_Platforms:\n  Language: C, C++, Java, C#, Python, JavaScript\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Ensure that there are no cases unaccounted\n  for when adjusting program flow or values based on the value of a given variable.\n  In the case of switch style statements, the very simple act of creating a default\n  case can, if done correctly, mitigate this situation. Often however, the default\n  case is used simply to represent an assumed option, as opposed to working as a check\n  for invalid input. This is poor practice and in some cases is as bad as omitting\n  a default case entirely.'\n",
  "ID: '479'\nName: Signal Handler Use of a Non-reentrant Function\nDescription: The product defines a signal handler that calls a non-reentrant function.\nExtended_Description: 'Non-reentrant functions are functions that cannot safely be\n  called, interrupted, and then recalled before the first call has finished without\n  resulting in memory corruption. This can lead to an unexpected system state and\n  unpredictable results with a variety of potential consequences depending on context,\n  including denial of service and code execution.\n\n  Many functions are not reentrant, but some of them can result in the corruption\n  of memory if they are used in a signal handler. The function call syslog() is an\n  example of this. In order to perform its functionality, it allocates a small amount\n  of memory as \"scratch space.\" If syslog() is suspended by a signal call and the\n  signal handler calls syslog(), the memory used by both of these functions enters\n  an undefined, and possibly, exploitable state. Implementations of malloc() and free()\n  manage metadata in global structures in order to track which memory is allocated\n  versus which memory is available, but they are non-reentrant. Simultaneous calls\n  to these functions can cause corruption of the metadata.'\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Require languages or libraries that provide\n  reentrant functionality, or otherwise make it easier to avoid this weakness.\n\n\n  Architecture and Design: Design signal handlers to only set flags rather than perform\n  complex functionality.\n\n\n  Implementation: Ensure that non-reentrant functions are not found in signal handlers.\n\n\n  Implementation: Use sanity checks to reduce the timing window for exploitation of\n  race conditions. This is only a partial solution, since many attacks might fail,\n  but other attacks still might work within the narrower window, even accidentally.'\nObserved_Examples: 'CVE-2005-0893: signal handler calls function that ultimately uses\n  malloc()\n\n\n  CVE-2004-2259: SIGCHLD signal to FTP server can cause crash under heavy load while\n  executing non-reentrant functions like malloc/free.'\n",
  "ID: '48'\nName: 'Path Equivalence: ''file name'' (Internal Whitespace)'\nDescription: The product accepts path input in the form of internal space ('file(SPACE)name')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nObserved_Examples: 'CVE-2000-0293: Filenames with spaces allow arbitrary file deletion\n  when the product does not properly quote them; some overlap with path traversal.\n\n\n  CVE-2001-1567: \"+\" characters in query string converted to spaces before sensitive\n  file/extension (internal space), leading to bypass of access restrictions to the\n  file.'\n",
  "ID: '480'\nName: Use of Incorrect Operator\nDescription: The product accidentally uses the wrong operator, which changes the logic\n  in security-relevant ways.\nExtended_Description: These types of errors are generally the result of a typo by\n  the programmer.\nApplicable_Platforms:\n  Language: C, C++, Perl\nDetection_Methods: 'Automated Static Analysis: This weakness can be found easily using\n  static analysis. However in some cases an operator might appear to be incorrect,\n  but is actually correct and reflects unusual logic within the program.\n\n\n  Manual Static Analysis: This weakness can be found easily using static analysis.\n  However in some cases an operator might appear to be incorrect, but is actually\n  correct and reflects unusual logic within the program.'\nObserved_Examples: 'CVE-2021-3116: Chain: Python-based HTTP Proxy server uses the\n  wrong boolean operators (CWE-480) causing an  incorrect comparison (CWE-697) that\n  identifies an authN failure if all three conditions are met instead of only one,\n  allowing bypass of the proxy authentication (CWE-1390)'\n",
  "ID: '481'\nName: Assigning instead of Comparing\nDescription: The code uses an operator for assignment when the intention was to perform\n  a comparison.\nExtended_Description: In many languages the compare statement is very close in appearance\n  to the assignment statement and are often confused. This bug is generally the result\n  of a typo and usually causes obvious problems with program execution. If the comparison\n  is in an if statement, the if statement will usually evaluate the value of the right-hand\n  side of the predicate.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Testing: Many IDEs and static analysis products will detect\n  this problem.\n\n\n  Implementation: Place constants on the left. If one attempts to assign a constant\n  with a variable, the compiler will produce an error.'\n",
  "ID: '482'\nName: Comparing instead of Assigning\nDescription: The code uses an operator for comparison when the intention was to perform\n  an assignment.\nExtended_Description: In many languages, the compare statement is very close in appearance\n  to the assignment statement; they are often confused.\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: 'Implementation: This bug primarily originates from a typo.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Testing: Many IDEs and static analysis products will detect\n  this problem.'\n",
  "ID: '483'\nName: Incorrect Block Delimitation\nDescription: The code does not explicitly delimit a block that is intended to contain\n  2 or more statements, creating a logic error.\nExtended_Description: In some languages, braces (or other delimiters) are optional\n  for blocks. When the delimiter is omitted, it is possible to insert a logic error\n  in which a statement is thought to be in a block but is not. In some cases, the\n  logic error can have security implications.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Always use explicit block delimitation and\n  use static-analysis technologies to enforce this practice.'\nObserved_Examples: 'CVE-2014-1266: incorrect indentation of \"goto\" statement makes\n  it more difficult to detect an incorrect goto (Apple''s \"goto fail\")'\n",
  "ID: '484'\nName: Omitted Break Statement in Switch\nDescription: The product omits a break statement within a switch or similar construct,\n  causing code associated with multiple conditions to execute. This can cause problems\n  when the programmer only intended to execute code associated with one condition.\nExtended_Description: This can lead to critical code executing in situations where\n  it should not.\nApplicable_Platforms:\n  Language: C, C++, Java, C#, PHP\nDetection_Methods: 'White Box: Omission of a break statement might be intentional,\n  in order to support fallthrough. Automated detection methods might therefore be\n  erroneous. Semantic understanding of expected product behavior is required to interpret\n  whether the code is correct.\n\n\n  Black Box: Since this weakness is associated with a code construct, it would be\n  indistinguishable from other errors that produce the same behavior.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Omitting a break statement so that one may\n  fall through is often indistinguishable from an error, and therefore should be avoided.\n  If you need to use fall-through capabilities, make sure that you have clearly documented\n  this within the switch statement, and ensure that you have examined all the logical\n  possibilities.\n\n\n  Implementation: The functionality of omitting a break statement could be clarified\n  with an if statement. This method is much safer.'\n",
  "ID: '486'\nName: Comparison of Classes by Name\nDescription: The product compares classes by name, which can cause it to use the wrong\n  class when multiple classes can have the same name.\nExtended_Description: If the decision to trust the methods and data of an object is\n  based on the name of a class, it is possible for malicious users to send objects\n  of the same name as trusted classes and thereby gain the trust afforded to known\n  classes and types.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use class equivalency to determine type. Rather\n  than use the class name to determine if an object is of a given type, use the getClass()\n  method, and == operator.'\n",
  "ID: '487'\nName: Reliance on Package-level Scope\nDescription: Java packages are not inherently closed; therefore, relying on them for\n  code security is not a good practice.\nExtended_Description: The purpose of package scope is to prevent accidental access\n  by other parts of a program. This is an ease-of-software-development feature but\n  not a security feature.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Data should be private static and final whenever possible. This\n  will assure that your code is protected by instantiating early, preventing access\n  and tampering.'\n",
  "ID: '488'\nName: Exposure of Data Element to Wrong Session\nDescription: The product does not sufficiently enforce boundaries between the states\n  of different sessions, causing data to be provided to, or used by, the wrong session.\nExtended_Description: 'Data can \"bleed\" from one session to another through member\n  variables of singleton objects, such as Servlets, and objects from a shared pool.\n\n  In the case of Servlets, developers sometimes do not understand that, unless a Servlet\n  implements the SingleThreadModel interface, the Servlet is a singleton; there is\n  only one instance of the Servlet, and that single instance is used and re-used to\n  handle multiple requests that are processed simultaneously by different threads.\n  A common result is that developers use Servlet member fields in such a way that\n  one user may inadvertently see another user''s data. In other words, storing user\n  data in Servlet member fields introduces a data access race condition.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Protect the application''s sessions\n  from information leakage. Make sure that a session''s data is not used or visible\n  by other sessions.\n\n\n  Testing: Use a static analysis tool to scan the code for information leakage vulnerabilities\n  (e.g. Singleton Member Field).\n\n\n  Architecture and Design: In a multithreading environment, storing user data in Servlet\n  member fields introduces a data access race condition. Do not use member fields\n  to store information in the Servlet.'\nRelated_Attack_Patterns: \"59: \\n\\n60: \"\n",
  "ID: '489'\nName: Active Debug Code\nDescription: The product is deployed to unauthorized actors with debugging code still\n  enabled or active, which can create unintended entry points or expose sensitive\n  information.\nExtended_Description: A common development practice is to add \"back door\" code specifically\n  designed for debugging or testing purposes that is not intended to be shipped or\n  deployed with the product. These back door entry points create security risks because\n  they are not considered during design or testing and fall outside of the expected\n  operating conditions of the product.\nApplicable_Platforms:\n  Technology: ICS/OT\nAlternate_Terms: 'Leftover debug code: This term originates from Seven Pernicious\n  Kingdoms'\nModes_Of_Introduction: \"Implementation: In web-based applications, debug code is used\\\n  \\ to test and modify web application properties, configuration information, and\\\n  \\ functions. If a debug application is left on a production server, this oversight\\\n  \\ during the \\\"software process\\\" allows attackers access to debug functionality.\\n\\\n  \\nBuild and Compilation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Build and Compilation\n\n  Distribution: Remove debug code before deploying the application.'\nRelated_Attack_Patterns: \"121: \\n\\n661: \"\n",
  "ID: '49'\nName: 'Path Equivalence: ''filename/'' (Trailing Slash)'\nDescription: The product accepts path input in the form of trailing slash ('filedir/')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nObserved_Examples: 'CVE-2002-0253: Overlaps infoleak\n\n\n  CVE-2001-0446: Application server allows remote attackers to read source code for\n  .jsp files by appending a / to the requested URL.\n\n\n  CVE-2004-0334: Bypass Basic Authentication for files using trailing \"/\"\n\n\n  CVE-2001-0893: Read sensitive files with trailing \"/\"\n\n\n  CVE-2001-0892: Web server allows remote attackers to view sensitive files under\n  the document root (such as .htpasswd) via a GET request with a trailing /.\n\n\n  CVE-2004-1814: Directory traversal vulnerability in server allows remote attackers\n  to read protected files via .. (dot dot) sequences in an HTTP request.\n\n\n  BID:3518: Source code disclosure'\n",
  "ID: '491'\nName: Public cloneable() Method Without Final ('Object Hijack')\nDescription: A class has a cloneable() method that is not declared final, which allows\n  an object to be created without calling the constructor. This can cause the object\n  to be in an unexpected state.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Make the cloneable() method final.'\n",
  "ID: '492'\nName: Use of Inner Class Containing Sensitive Data\nDescription: Inner classes are translated into classes that are accessible at package\n  scope and may expose code that the programmer intended to keep private to attackers.\nExtended_Description: Inner classes quietly introduce several security concerns because\n  of the way they are translated into Java bytecode. In Java source code, it appears\n  that an inner class can be declared to be accessible only by the enclosing class,\n  but Java bytecode has no concept of an inner class, so the compiler must transform\n  an inner class declaration into a peer class with package level access to the original\n  outer class. More insidiously, since an inner class can access private fields in\n  its enclosing class, once an inner class becomes a peer class in bytecode, the compiler\n  converts private fields accessed by the inner class into protected fields.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Using sealed classes protects object-oriented\n  encapsulation paradigms and therefore protects code from being extended in unforeseen\n  ways.\n\n\n  Implementation: Inner Classes do not provide security. Warning: Never reduce the\n  security of the object from an outer class, going to an inner class. If an outer\n  class is final or private, ensure that its inner class is private as well.'\n",
  "ID: '493'\nName: Critical Public Variable Without Final Modifier\nDescription: The product has a critical public variable that is not final, which allows\n  the variable to be modified to contain unexpected values.\nExtended_Description: If a field is non-final and public, it can be changed once the\n  value is set by any function that has access to the class which contains the field.\n  This could lead to a vulnerability if other parts of the program make assumptions\n  about the contents of that field.\nApplicable_Platforms:\n  Language: Java, C++\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Declare all public fields as final when possible,\n  especially if it is used to maintain internal state of an Applet or of classes used\n  by an Applet. If a field must be public, then perform all appropriate sanity checks\n  before accessing the field from your code.'\n",
  "ID: '494'\nName: Download of Code Without Integrity Check\nDescription: The product downloads source code or an executable from a remote location\n  and executes the code without sufficiently verifying the origin and integrity of\n  the code.\nExtended_Description: An attacker can execute malicious code by compromising the host\n  server, performing DNS spoofing, or modifying the code in transit.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nDetection_Methods: 'Manual Analysis: This weakness can be detected using tools and\n  techniques that require manual (human) analysis, such as penetration testing, threat\n  modeling, and interactive tools that allow the tester to record and modify an active\n  session.\n\n  Specifically, manual static analysis is typically required to find the behavior\n  that triggers the download of code, and to determine whether integrity-checking\n  methods are in use.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Black Box: Use monitoring tools that examine the software''s process as it interacts\n  with the operating system and the network. This technique is useful in cases when\n  source code is unavailable, if the software was not developed by you, or if you\n  want to verify that the build phase did not introduce any new weaknesses. Examples\n  include debuggers that directly attach to the running process; system-call tracing\n  utilities such as truss (Solaris) and strace (Linux); system activity monitors such\n  as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and also sniff the network connection. Trigger\n  features related to product updates or plugin installation, which is likely to force\n  a code download. Monitor when files are downloaded and separately executed, or if\n  they are otherwise read back into the process. Look for evidence of cryptographic\n  library calls that use integrity checking.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Perform proper forward and reverse DNS lookups\n  to detect DNS spoofing.\n\n\n  Architecture and Design\n\n  Operation: Encrypt the code with a reliable encryption scheme before transmitting.\n\n  This will only be a partial solution, since it will not detect DNS spoofing and\n  it will not prevent your code from being modified on the hosting site.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Speficially, it may be helpful to use tools or frameworks to perform integrity checking\n  on the transmitted code.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.'\nObserved_Examples: 'CVE-2019-9534: Satellite phone does not validate its firmware\n  image.\n\n\n  CVE-2021-22909: Chain: router''s firmware update procedure uses curl with \"-k\" (insecure)\n  option that disables certificate validation (CWE-295), allowing adversary-in-the-middle\n  (AITM) compromise with a malicious firmware image (CWE-494).\n\n\n  CVE-2008-3438: OS does not verify authenticity of its own updates.\n\n\n  CVE-2008-3324: online poker client does not verify authenticity of its own updates.\n\n\n  CVE-2001-1125: anti-virus product does not verify automatic updates for itself.\n\n\n  CVE-2002-0671: VOIP phone downloads applications from web sites without verifying\n  integrity.'\nRelated_Attack_Patterns: \"184: \\n\\n185: \\n\\n186: \\n\\n187: \\n\\n533: \\n\\n538: \\n\\n657:\\\n  \\ \\n\\n662: \\n\\n691: \\n\\n692: \\n\\n693: \\n\\n695: \"\n",
  "ID: '495'\nName: Private Data Structure Returned From A Public Method\nDescription: The product has a method that is declared public, but returns a reference\n  to a private data structure, which could then be modified in unexpected ways.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Declare the method private.\n\n\n  Implementation: Clone the member data and keep an unmodified version of the data\n  private to the object.\n\n\n  Implementation: Use public setter methods that govern how a private member can be\n  modified.'\n",
  "ID: '496'\nName: Public Data Assigned to Private Array-Typed Field\nDescription: Assigning public data to a private array is equivalent to giving public\n  access to the array.\nApplicable_Platforms:\n  Language: C, C++, Java, C#\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Do not allow objects to modify private members\n  of a class.'\n",
  "ID: '497'\nName: Exposure of Sensitive System Information to an Unauthorized Control Sphere\nDescription: The product does not properly prevent sensitive system-level information\n  from being accessed by unauthorized actors who do not have the same level of access\n  to the underlying system as the product does.\nExtended_Description: 'Network-based products, such as web applications, often run\n  on top of an operating system or similar environment.  When the product communicates\n  with outside parties, details about the underlying system are expected to remain\n  hidden, such as path names for data files, other OS users, installed packages, the\n  application environment, etc. This system information may be provided by the product\n  itself, or buried within diagnostic or debugging messages. Debugging information\n  helps an adversary learn about the system and form an attack plan.\n\n  An information exposure occurs when system data or debugging information leaves\n  the program through an output stream or logging function that makes it accessible\n  to unauthorized parties. Using other weaknesses, an attacker could cause errors\n  to occur; the response to these errors can reveal detailed system information, along\n  with other impacts.  An attacker can use messages that reveal technologies, operating\n  systems, and product versions to tune the attack against known vulnerabilities in\n  these technologies. A product may use diagnostic methods that provide significant\n  implementation details such as stack traces as part of its error handling mechanism.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Production applications should never use methods that generate internal\n  details such as stack traces and error messages unless that information is directly\n  committed to a log that is not viewable by the end user. All error message text\n  should be HTML entity encoded before being written to the log file to protect against\n  potential cross-site scripting attacks against the viewer of the logs'\nRelated_Attack_Patterns: \"170: \\n\\n694: \"\n",
  "ID: '498'\nName: Cloneable Class Containing Sensitive Information\nDescription: The code contains a class with sensitive data, but the class is cloneable.\n  The data can then be accessed by cloning the class.\nExtended_Description: Cloneable classes are effectively open classes, since data cannot\n  be hidden in them. Classes that do not explicitly deny cloning can be cloned by\n  any other class without running the constructor.\nApplicable_Platforms:\n  Language: C++, Java, C#\nPotential_Mitigations: 'Implementation: If you do make your classes clonable, ensure\n  that your clone method is final and throw super.clone().'\n",
  "ID: '499'\nName: Serializable Class Containing Sensitive Data\nDescription: The code contains a class with sensitive data, but the class does not\n  explicitly deny serialization. The data can be accessed by serializing the class\n  through another class.\nExtended_Description: Serializable classes are effectively open classes since data\n  cannot be hidden in them. Classes that do not explicitly deny serialization can\n  be serialized by any other class, which can then in turn use the data stored inside\n  it.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: In Java, explicitly define final writeObject()\n  to prevent serialization. This is the recommended solution. Define the writeObject()\n  function to throw an exception explicitly denying serialization.\n\n\n  Implementation: Make sure to prevent serialization of your objects.'\n",
  "ID: '5'\nName: 'J2EE Misconfiguration: Data Transmission Without Encryption'\nDescription: Information sent over a network can be compromised while in transit.\n  An attacker may be able to read or modify the contents if the data are sent in plaintext\n  or are weakly encrypted.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'System Configuration: The product configuration should ensure\n  that SSL or an encryption mechanism of equivalent strength and vetted reputation\n  is used for all access-controlled pages.'\n",
  "ID: '50'\nName: 'Path Equivalence: ''//multiple/leading/slash'''\nDescription: The product accepts path input in the form of multiple leading slash\n  ('//multiple/leading/slash') without appropriate validation, which can lead to ambiguous\n  path resolution and allow an attacker to traverse the file system to unintended\n  locations or access arbitrary files.\nObserved_Examples: 'CVE-2002-1483: Read files with full pathname using multiple internal\n  slash.\n\n\n  CVE-1999-1456: Server allows remote attackers to read arbitrary files via a GET\n  request with more than one leading / (slash) character in the filename.\n\n\n  CVE-2004-0578: Server allows remote attackers to read arbitrary files via leading\n  slash (//) characters in a URL request.\n\n\n  CVE-2002-0275: Server allows remote attackers to bypass authentication and read\n  restricted files via an extra / (slash) in the requested URL.\n\n\n  CVE-2004-1032: Product allows local users to delete arbitrary files or create arbitrary\n  empty files via a target filename with a large number of leading slash (/) characters.\n\n\n  CVE-2002-1238: Server allows remote attackers to bypass access restrictions for\n  files via an HTTP request with a sequence of multiple / (slash) characters such\n  as http://www.example.com///file/.\n\n\n  CVE-2004-1878: Product allows remote attackers to bypass authentication, obtain\n  sensitive information, or gain access via a direct request to admin/user.pl preceded\n  by // (double leading slash).\n\n\n  CVE-2005-1365: Server allows remote attackers to execute arbitrary commands via\n  a URL with multiple leading \"/\" (slash) characters and \"..\" sequences.\n\n\n  CVE-2000-1050: Access directory using multiple leading slash.\n\n\n  CVE-2001-1072: Bypass access restrictions via multiple leading slash, which causes\n  a regular expression to fail.\n\n\n  CVE-2004-0235: Archive extracts to arbitrary files using multiple leading slash\n  in filenames in the archive.'\n",
  "ID: '500'\nName: Public Static Field Not Marked Final\nDescription: An object contains a public static field that is not marked final, which\n  might allow it to be modified in unexpected ways.\nExtended_Description: Public static variables can be read without an accessor and\n  changed without a mutator by any classes in the application.\nApplicable_Platforms:\n  Language: C++, Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Clearly identify the scope for all\n  critical data elements, including whether they should be regarded as static.\n\n\n  Implementation: Make any static fields private and constant.\n\n  A constant field is denoted by the keyword ''const'' in C/C++ and '' final'' in\n  Java'\n",
  "ID: '501'\nName: Trust Boundary Violation\nDescription: The product mixes trusted and untrusted data in the same data structure\n  or structured message.\nExtended_Description: A trust boundary can be thought of as line drawn through a program.\n  On one side of the line, data is untrusted. On the other side of the line, data\n  is assumed to be trustworthy. The purpose of validation logic is to allow data to\n  safely cross the trust boundary - to move from untrusted to trusted. A trust boundary\n  violation occurs when a program blurs the line between what is trusted and what\n  is untrusted. By combining trusted and untrusted data in the same data structure,\n  it becomes easier for programmers to mistakenly trust unvalidated data.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '502'\nName: Deserialization of Untrusted Data\nDescription: The product deserializes untrusted data without sufficiently verifying\n  that the resulting data will be valid.\nExtended_Description: 'It is often convenient to serialize objects for communication\n  or to save them for later use. However, deserialized data or code can often be modified\n  without using the provided accessor functions if it does not use cryptography to\n  protect itself. Furthermore, any cryptography would still be client-side security\n  -- which is a dangerous security assumption.\n\n  Data that is untrusted can not be trusted to be well-formed.\n\n  When developers place no restrictions on \"gadget chains,\" or series of instances\n  and method invocations that can self-execute during the deserialization process\n  (i.e., before the object is returned to the caller), it is sometimes possible for\n  attackers to leverage them to perform unauthorized actions, like generating a shell.'\nApplicable_Platforms:\n  Language: Java, Ruby, PHP, Python, JavaScript\n  Technology: ICS/OT\nAlternate_Terms: 'Marshaling, Unmarshaling: Marshaling and unmarshaling are effectively\n  synonyms for serialization and deserialization, respectively.\n\n\n  Pickling, Unpickling: In Python, the \"pickle\" functionality is used to perform serialization\n  and deserialization.\n\n\n  PHP Object Injection: Some PHP application researchers use this term when attacking\n  unsafe use of the unserialize() function; but it is also used for CWE-915.'\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: If available, use the signing/sealing features of the programming\n  language to assure that deserialized data has not been tainted. For example, a hash-based\n  message authentication code (HMAC) could be used to ensure that data has not been\n  modified.\n\n\n  Implementation: When deserializing data, populate a new object rather than just\n  deserializing. The result is that the data flows through safe input validation and\n  that the functions are safe.\n\n\n  Implementation: Explicitly define a final object() to prevent deserialization.\n\n\n  Architecture and Design\n\n  Implementation: Make fields transient to protect them from deserialization.\n\n  An attempt to serialize and then deserialize a class containing transient fields\n  will result in NULLs where the transient data should be. This is an excellent way\n  to prevent time, environment-based, or sensitive variables from being carried over\n  and used improperly.\n\n\n  Implementation: Avoid having unnecessary types or gadgets available that can be\n  leveraged for malicious ends. This limits the potential for unintended or unauthorized\n  types and gadgets to be leveraged by the attacker. Add only acceptable classes to\n  an allowlist. Note: new gadgets are constantly being discovered, so this alone is\n  not a sufficient mitigation.'\nObserved_Examples: 'CVE-2019-12799: chain: bypass of untrusted deserialization issue\n  (CWE-502) by using an assumed-trusted class (CWE-183)\n\n\n  CVE-2015-8103: Deserialization issue in commonly-used Java library allows remote\n  execution.\n\n\n  CVE-2015-4852: Deserialization issue in commonly-used Java library allows remote\n  execution.\n\n\n  CVE-2013-1465: Use of PHP unserialize function on untrusted input allows attacker\n  to modify application configuration.\n\n\n  CVE-2012-3527: Use of PHP unserialize function on untrusted input in content management\n  system might allow code execution.\n\n\n  CVE-2012-0911: Use of PHP unserialize function on untrusted input in content management\n  system allows code execution using a crafted cookie value.\n\n\n  CVE-2012-0911: Content management system written in PHP allows unserialize of arbitrary\n  objects, possibly allowing code execution.\n\n\n  CVE-2011-2520: Python script allows local users to execute code via pickled data.\n\n\n  CVE-2012-4406: Unsafe deserialization using pickle in a Python script.\n\n\n  CVE-2003-0791: Web browser allows execution of native methods via a crafted string\n  to a JavaScript function that deserializes the string.'\nRelated_Attack_Patterns: '586: '\n",
  "ID: '506'\nName: Embedded Malicious Code\nDescription: The product contains code that appears to be malicious in nature.\nExtended_Description: Malicious flaws have acquired colorful names, including Trojan\n  horse, trapdoor, timebomb, and logic-bomb. A developer might insert malicious code\n  with the intent to subvert the security of a product or its host system at some\n  time in the future. It generally refers to a program that performs a useful service\n  but exploits rights of the program's user in a way the user does not intend.\nModes_Of_Introduction: \"Implementation: \\n\\nBundling: \\n\\nDistribution: \\n\\nInstallation: \"\nDetection_Methods: 'Manual Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Testing: Remove the malicious code and start an effort to\n  ensure that no more malicious code exists. This may require a detailed review of\n  all code, as it is possible to hide a serious attack in only one or two lines of\n  code. These lines may be located almost anywhere in an application and may have\n  been intentionally obfuscated by the attacker.'\nRelated_Attack_Patterns: \"442: \\n\\n448: \\n\\n636: \"\n",
  "ID: '507'\nName: Trojan Horse\nDescription: The product appears to contain benign or useful functionality, but it\n  also contains code that is hidden from normal operation that violates the intended\n  security policy of the user or the system administrator.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Operation: Most antivirus software scans for Trojan Horses.\n\n\n  Installation: Verify the integrity of the product that is being installed.'\nRelated_Attack_Patterns: '698: '\n",
  "ID: '508'\nName: Non-Replicating Malicious Code\nDescription: Non-replicating malicious code only resides on the target system or product\n  that is attacked; it does not attempt to spread to other systems.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Operation: Antivirus software can help mitigate known malicious\n  code.\n\n\n  Installation: Verify the integrity of the software that is being installed.'\n",
  "ID: '509'\nName: Replicating Malicious Code (Virus or Worm)\nDescription: Replicating malicious code, including viruses and worms, will attempt\n  to attack other systems once it has successfully compromised the target system or\n  the product.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Operation: Antivirus software scans for viruses or worms.\n\n\n  Installation: Always verify the integrity of the software that is being installed.'\n",
  "ID: '51'\nName: 'Path Equivalence: ''/multiple//internal/slash'''\nDescription: The product accepts path input in the form of multiple internal slash\n  ('/multiple//internal/slash/') without appropriate validation, which can lead to\n  ambiguous path resolution and allow an attacker to traverse the file system to unintended\n  locations or access arbitrary files.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2002-1483: Read files with full pathname using multiple internal\n  slash.'\n",
  "ID: '510'\nName: Trapdoor\nDescription: A trapdoor is a hidden piece of code that responds to a special input,\n  allowing its user access to resources without passing through the normal security\n  enforcement mechanism.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Installation: Always verify the integrity of the software\n  that is being installed.\n\n\n  Testing: Identify and closely inspect the conditions for entering privileged areas\n  of the code, especially those related to authentication, process invocation, and\n  network communications.'\n",
  "ID: '511'\nName: Logic/Time Bomb\nDescription: The product contains code that is designed to disrupt the legitimate\n  operation of the product (or its environment) when a certain time passes, or when\n  a certain logical condition is met.\nExtended_Description: When the time bomb or logic bomb is detonated, it may perform\n  a denial of service such as crashing the system, deleting critical data, or degrading\n  system response time. This bomb might be placed within either a replicating or non-replicating\n  Trojan horse.\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Installation: Always verify the integrity of the product that\n  is being installed.\n\n\n  Testing: Conduct a code coverage analysis using live testing, then closely inspect\n  any code that is not covered.'\n",
  "ID: '512'\nName: Spyware\nDescription: The product collects personally identifiable information about a human\n  user or the user's activities, but the product accesses this information using other\n  resources besides itself, and it does not require that user's explicit approval\n  or direct input into the product.\nExtended_Description: '\"Spyware\" is a commonly used term with many definitions and\n  interpretations. In general, it is meant to refer to products that collect information\n  or install functionality that human users might not allow if they were fully aware\n  of the actions being taken by the software. For example, a user might expect that\n  tax software would collect a social security number and include it when filing a\n  tax return, but that same user would not expect gaming software to obtain the social\n  security number from that tax software''s data.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Operation: Use spyware detection and removal software.\n\n\n  Installation: Always verify the integrity of the product that is being installed.'\n",
  "ID: '514'\nName: Covert Channel\nDescription: A covert channel is a path that can be used to transfer information in\n  a way not intended by the system's designers.\nExtended_Description: Typically the system has not given authorization for the transmission\n  and has no knowledge of its occurrence.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nDetection_Methods: 'Architecture or Design Review: According to SOAR, the following\n  detection techniques may be useful:'\nRelated_Attack_Patterns: '463: '\n",
  "ID: '515'\nName: Covert Storage Channel\nDescription: A covert storage channel transfers information through the setting of\n  bits by one program and the reading of those bits by another. What distinguishes\n  this case from that of ordinary operation is that the bits are used to convey encoded\n  information.\nExtended_Description: Covert storage channels occur when out-of-band data is stored\n  in messages for the purpose of memory reuse. Covert channels are frequently classified\n  as either storage or timing channels. Examples would include using a file intended\n  to hold only audit information to convey user passwords--using the name of a file\n  or perhaps status bits associated with it that can be read by all users to signal\n  the contents of the file. Steganography, concealing information in such a manner\n  that no one but the intended recipient knows of the existence of the message, is\n  a good example of a covert storage channel.\nPotential_Mitigations: 'Implementation: Ensure that all reserved fields are set to\n  zero before messages are sent and that no unnecessary information is included.'\n",
  "ID: '516'\nName: 'DEPRECATED: Covert Timing Channel'\nDescription: This weakness can be found at CWE-385.\n",
  "ID: '52'\nName: 'Path Equivalence: ''/multiple/trailing/slash//'''\nDescription: The product accepts path input in the form of multiple trailing slash\n  ('/multiple/trailing/slash//') without appropriate validation, which can lead to\n  ambiguous path resolution and allow an attacker to traverse the file system to unintended\n  locations or access arbitrary files.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2002-1078: Directory listings in web server using multiple\n  trailing slash'\n",
  "ID: '520'\nName: '.NET Misconfiguration: Use of Impersonation'\nDescription: Allowing a .NET application to run at potentially escalated levels of\n  access to the underlying operating and file systems can be dangerous and result\n  in various forms of attacks.\nExtended_Description: .NET server applications can optionally execute using the identity\n  of the user authenticated to the client. The intention of this functionality is\n  to bypass authentication and access control checks within the .NET application code.\n  Authentication is done by the underlying web server (Microsoft Internet Information\n  Service IIS), which passes the authenticated token, or unauthenticated anonymous\n  token, to the .NET application. Using the token to impersonate the client, the application\n  then relies on the settings within the NTFS directories and files to control access.\n  Impersonation enables the application, on the server running the .NET application,\n  to both execute code and access resources in the context of the authenticated and\n  authorized user.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Operation: Run the application with limited privilege to the\n  underlying operating and file system.'\n",
  "ID: '521'\nName: Weak Password Requirements\nDescription: The product does not require that users should have strong passwords,\n  which makes it easier for attackers to compromise user accounts.\nExtended_Description: Authentication mechanisms often rely on a memorized secret (also\n  known as a password) to provide an assertion of identity for a user of a system.\n  It is therefore important that this password be of sufficient complexity and impractical\n  for an adversary to guess. The specific requirements around how complex a password\n  needs to be depends on the type of system being protected. Selecting the correct\n  password requirements and enforcing them through implementation are critical to\n  the overall success of the authentication mechanism.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: Not enforcing the password policy stated in a products design can\n  allow users to create passwords that do not provide the necessary level of protection.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: \"Architecture and Design: A product's design should require\\\n  \\ adherance to an appropriate password policy. Specific password requirements depend\\\n  \\ strongly on contextual factors, but it is recommended to contain the following\\\n  \\ attributes:\\nDepending on the threat model, the password policy may include several\\\n  \\ additional attributes.\\nSee NIST 800-63B [REF-1053] for further information on\\\n  \\ password requirements.\\n\\nArchitecture and Design: Consider a second\\n       \\\n  \\          authentication factor beyond the password, which prevents the\\n     \\\n  \\            password from being a single point of failure. See CWE-308 for\\n  \\\n  \\               further information.\\n\\nImplementation: Consider implementing a\\\n  \\ password complexity meter to inform users when a chosen password meets the required\\\n  \\ attributes.\"\nObserved_Examples: 'CVE-2020-4574: key server application does not require strong\n  passwords'\nRelated_Attack_Patterns: \"112: \\n\\n16: \\n\\n49: \\n\\n509: \\n\\n55: \\n\\n555: \\n\\n561:\\\n  \\ \\n\\n565: \\n\\n70: \"\n",
  "ID: '522'\nName: Insufficiently Protected Credentials\nDescription: The product transmits or stores authentication credentials, but it uses\n  an insecure method that is susceptible to unauthorized interception and/or retrieval.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use an appropriate security mechanism\n  to protect the credentials.\n\n\n  Architecture and Design: Make appropriate use of cryptography to protect the credentials.\n\n\n  Implementation: Use industry standards to protect the credentials (e.g. LDAP, keystore,\n  etc.).'\nObserved_Examples: 'CVE-2022-29959: Initialization file contains  credentials that\n  can be decoded using a \"simple string transformation\"\n\n\n  CVE-2022-35411: Python-based RPC framework enables pickle functionality by default,\n  allowing clients to unpickle untrusted data.\n\n\n  CVE-2022-29519: Programmable Logic Controller (PLC) sends sensitive information\n  in plaintext, including passwords and session tokens.\n\n\n  CVE-2022-30312: Building Controller uses a protocol that transmits authentication\n  credentials in plaintext.\n\n\n  CVE-2022-31204: Programmable Logic Controller (PLC) sends password in plaintext.\n\n\n  CVE-2022-30275: Remote Terminal Unit (RTU) uses a driver that relies on a password\n  stored in plaintext.\n\n\n  CVE-2007-0681: Web app allows remote attackers to change the passwords of arbitrary\n  users without providing the original password, and possibly perform other unauthorized\n  actions.\n\n\n  CVE-2000-0944: Web application password change utility doesn''t check the original\n  password.\n\n\n  CVE-2005-3435: product authentication succeeds if user-provided MD5 hash matches\n  the hash in its database; this can be subjected to replay attacks.\n\n\n  CVE-2005-0408: chain: product generates predictable MD5 hashes using a constant\n  value combined with username, allowing authentication bypass.'\nRelated_Attack_Patterns: \"102: \\n\\n474: \\n\\n50: \\n\\n509: \\n\\n551: \\n\\n555: \\n\\n560:\\\n  \\ \\n\\n561: \\n\\n600: \\n\\n644: \\n\\n645: \\n\\n652: \\n\\n653: \"\n",
  "ID: '523'\nName: Unprotected Transport of Credentials\nDescription: Login pages do not use adequate measures to protect the user name and\n  password while they are in transit from the client to the server.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Operation, System Configuration: Enforce SSL use for the login\n  page or any page used to transmit user credentials or other sensitive information.\n  Even if the entire site does not use SSL, it MUST use SSL for login. Additionally,\n  to help prevent phishing attacks, make sure that SSL serves the login page. SSL\n  allows the user to verify the identity of the server to which they are connecting.\n  If the SSL serves login page, the user can be certain they are talking to the proper\n  end system. A phishing attack would typically redirect a user to a site that does\n  not have a valid trusted server certificate issued from an authorized supplier.'\nRelated_Attack_Patterns: '102: '\n",
  "ID: '524'\nName: Use of Cache Containing Sensitive Information\nDescription: The code uses a cache that contains sensitive information, but the cache\n  can be read by an actor outside of the intended control sphere.\nExtended_Description: Applications may use caches to improve efficiency when communicating\n  with remote entities or performing intensive calculations.  A cache maintains a\n  pool of objects, threads, connections, pages, financial data, passwords, or other\n  resources to minimize the time it takes to initialize and access these resources.  If\n  the cache is accessible to unauthorized actors, attackers can read the cache and\n  obtain this sensitive information.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Protect information stored in cache.\n\n\n  Architecture and Design: Do not store unnecessarily sensitive information in the\n  cache.\n\n\n  Architecture and Design: Consider using encryption in the cache.'\nRelated_Attack_Patterns: '204: '\n",
  "ID: '525'\nName: Use of Web Browser Cache Containing Sensitive Information\nDescription: The web application does not use an appropriate caching policy that specifies\n  the extent to which each web page and associated form fields should be cached.\nPotential_Mitigations: 'Architecture and Design: Protect information stored in cache.\n\n\n  Architecture and Design\n\n  Implementation: Use a restrictive caching policy for forms and web pages that potentially\n  contain sensitive information.\n\n\n  Architecture and Design: Do not store unnecessarily sensitive information in the\n  cache.\n\n\n  Architecture and Design: Consider using encryption in the cache.'\nRelated_Attack_Patterns: '37: '\n",
  "ID: '526'\nName: Cleartext Storage of Sensitive Information in an Environment Variable\nDescription: The product uses an environment variable to store unencrypted sensitive\n  information.\nExtended_Description: Information stored in an environment variable can be accessible\n  by other processes with the execution context, including child processes that dependencies\n  are executed in, or serverless functions in cloud environments. An environment variable's\n  contents can also be inserted into messages, headers, log files, or other outputs.\n  Often these other dependencies have no need to use the environment variable in question.\n  A weakness that discloses environment variables could expose this information.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Encrypt information stored in the\n  environment variable to protect it from being exposed to an unauthorized user. If\n  encryption is not feasible or is considered too expensive for the business use of\n  the application, then consider using a properly protected configuration file instead\n  of an environment variable. It should be understood that unencrypted information\n  in a config file is also not guaranteed to be protected, but it is still a better\n  choice, because it reduces attack surface related to weaknesses such as CWE-214.\n  In some settings, vaults might be a feasible option for safer data transfer. Users\n  should be notified of the business choice made to not protect the sensitive information\n  through encryption.\n\n\n  Implementation: If the environment variable is not necessary for the desired behavior,\n  then remove it entirely, or clear it to an empty value.'\nObserved_Examples: 'CVE-2022-43691: CMS shows sensitive server-side information from\n  environment variables when run in Debug mode.\n\n\n  CVE-2022-27195: Plugin for an automation server inserts environment variable contents\n  into build XML files.\n\n\n  CVE-2022-25264: CI/CD tool logs environment variables related to passwords add Contribution\n  to content history.'\n",
  "ID: '527'\nName: Exposure of Version-Control Repository to an Unauthorized Control Sphere\nDescription: The product stores a CVS, git, or other repository in a directory, archive,\n  or other resource that is stored, transferred, or otherwise made accessible to unauthorized\n  actors.\nExtended_Description: Version control repositories such as CVS or git store version-specific\n  metadata and other details within subdirectories. If these subdirectories are stored\n  on a web server or added to an archive, then these could be used by an attacker.\n  This information may include usernames, filenames, path root, IP addresses, and\n  detailed \"diff\" data about how files have been changed - which could reveal source\n  code snippets that were never intended to be made public.\nModes_Of_Introduction: 'Operation: OMISSION: This weakness is caused by missing a\n  security tactic during the architecture and design phase.'\nPotential_Mitigations: 'Operation, Distribution, System Configuration: Recommendations\n  include removing any CVS directories and repositories from the production server,\n  disabling the use of remote CVS repositories, and ensuring that the latest CVS patches\n  and version updates have been performed.'\n",
  "ID: '528'\nName: Exposure of Core Dump File to an Unauthorized Control Sphere\nDescription: The product generates a core dump file in a directory, archive, or other\n  resource that is stored, transferred, or otherwise made accessible to unauthorized\n  actors.\nModes_Of_Introduction: 'Operation: OMISSION: This weakness is caused by missing a\n  security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'System Configuration: Protect the core dump files from unauthorized\n  access.'\n",
  "ID: '529'\nName: Exposure of Access Control List Files to an Unauthorized Control Sphere\nDescription: The product stores access control list files in a directory or other\n  container that is accessible to actors outside of the intended control sphere.\nExtended_Description: Exposure of these access control list files may give the attacker\n  information about the configuration of the site or system. This information may\n  then be used to bypass the intended security policy or identify trusted systems\n  from which an attack can be launched.\nModes_Of_Introduction: 'Operation: OMISSION: This weakness is caused by missing a\n  security tactic during the architecture and design phase.'\nPotential_Mitigations: 'System Configuration: Protect access control list files.'\n",
  "ID: '53'\nName: 'Path Equivalence: ''\\multiple\\\\internal\\backslash'''\nDescription: The product accepts path input in the form of multiple internal backslash\n  ('\\multiple\\trailing\\\\slash') without appropriate validation, which can lead to\n  ambiguous path resolution and allow an attacker to traverse the file system to unintended\n  locations or access arbitrary files.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\n",
  "ID: '530'\nName: Exposure of Backup File to an Unauthorized Control Sphere\nDescription: A backup file is stored in a directory or archive that is made accessible\n  to unauthorized actors.\nExtended_Description: Often, older backup files are renamed with an extension such\n  as .~bk to distinguish them from production files. The source code for old files\n  that have been renamed in this manner and left in the webroot can often be retrieved.\n  This renaming may have been performed automatically by the web server, or manually\n  by the administrator.\nModes_Of_Introduction: 'Operation: OMISSION: This weakness is caused by missing a\n  security tactic during the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Policy: Recommendations include implementing a security policy\n  within your organization that prohibits backing up web application source code in\n  the webroot.'\n",
  "ID: '531'\nName: Inclusion of Sensitive Information in Test Code\nDescription: Accessible test applications can pose a variety of security risks. Since\n  developers or administrators rarely consider that someone besides themselves would\n  even know about the existence of these applications, it is common for them to contain\n  sensitive information or functions.\nPotential_Mitigations: 'Distribution, Installation: Remove test code before deploying\n  the application into production.'\n",
  "ID: '532'\nName: Insertion of Sensitive Information into Log File\nDescription: Information written to log files can be of a sensitive nature and give\n  valuable guidance to an attacker or expose sensitive user information.\nExtended_Description: 'While logging all information may be helpful during development\n  stages, it is important that logging levels be set appropriately before a product\n  ships so that sensitive user data and system information are not accidentally exposed\n  to potential attackers.\n\n  Different log files may be produced and stored for:'\nModes_Of_Introduction: \"Architecture and Design: COMMISSION: This weakness refers\\\n  \\ to an incorrect design related to an architectural security tactic.\\n\\nImplementation:\\\n  \\ \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Consider seriously the sensitivity of the information written into\n  log files. Do not write secrets into the log files.\n\n\n  Distribution: Remove debug log files before deploying the application into production.\n\n\n  Operation: Protect log files against unauthorized read/write.\n\n\n  Implementation: Adjust configurations appropriately when software is transitioned\n  from a debug state to production.'\nObserved_Examples: 'CVE-2017-9615: verbose logging stores admin credentials in a world-readablelog\n  file\n\n\n  CVE-2018-1999036: SSH password for private key stored in build log'\nRelated_Attack_Patterns: '215: '\n",
  "ID: '533'\nName: 'DEPRECATED: Information Exposure Through Server Log Files'\nDescription: This entry has been deprecated because its abstraction was too low-level.  See\n  CWE-532.\n",
  "ID: '534'\nName: 'DEPRECATED: Information Exposure Through Debug Log Files'\nDescription: This entry has been deprecated because its abstraction was too low-level.  See\n  CWE-532.\n",
  "ID: '535'\nName: Exposure of Information Through Shell Error Message\nDescription: A command shell error message indicates that there exists an unhandled\n  exception in the web application code. In many cases, an attacker can leverage the\n  conditions that cause these errors in order to gain unauthorized access to the system.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '536'\nName: Servlet Runtime Error Message Containing Sensitive Information\nDescription: A servlet error message indicates that there exists an unhandled exception\n  in your web application code and may provide useful information to an attacker.\n",
  "ID: '537'\nName: Java Runtime Error Message Containing Sensitive Information\nDescription: In many cases, an attacker can leverage the conditions that cause unhandled\n  exception errors in order to gain unauthorized access to the system.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Do not expose sensitive error information\n  to the user.'\n",
  "ID: '538'\nName: Insertion of Sensitive Information into Externally-Accessible File or Directory\nDescription: The product places sensitive information into files or directories that\n  are accessible to actors who are allowed to have access to the files, but not to\n  the sensitive information.\nModes_Of_Introduction: 'Implementation: OMISSION: This weakness is caused by missing\n  a security tactic during the architecture and design phase.\n\n\n  Operation: OMISSION: This weakness is caused by missing a security tactic during\n  the architecture and design phase.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Operation\n\n  System Configuration: Do not expose file and directory information to the user.'\nRelated_Attack_Patterns: '95: '\n",
  "ID: '539'\nName: Use of Persistent Cookies Containing Sensitive Information\nDescription: The web application uses persistent cookies, but the cookies contain\n  sensitive information.\nExtended_Description: 'Cookies are small bits of data that are sent by the web application\n  but stored locally in the browser. This lets the application use the cookie to pass\n  information between pages and store variable information. The web application controls\n  what information is stored in a cookie and how it is used. Typical types of information\n  stored in cookies are session identifiers, personalization and customization information,\n  and in rare cases even usernames to enable automated logins. There are two different\n  types of cookies: session cookies and persistent cookies. Session cookies just live\n  in the browser''s memory and are not stored anywhere, but persistent cookies are\n  stored on the browser''s hard drive.   This can cause security and privacy issues\n  depending on the information stored in the cookie and how it is accessed.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Do not store sensitive information\n  in persistent cookies.'\nRelated_Attack_Patterns: \"21: \\n\\n31: \\n\\n39: \\n\\n59: \\n\\n60: \"\n",
  "ID: '54'\nName: 'Path Equivalence: ''filedir\\'' (Trailing Backslash)'\nDescription: The product accepts path input in the form of trailing backslash ('filedir\\')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2004-0847: ASP.NET allows remote attackers to bypass authentication\n  for .aspx files in restricted directories via a request containing a (1) \"\\\" (backslash)\n  or (2) \"%5C\" (encoded backslash), aka \"Path Validation Vulnerability.\"'\n",
  "ID: '540'\nName: Inclusion of Sensitive Information in Source Code\nDescription: Source code on a web server or repository often contains sensitive information\n  and should generally not be accessible to users.\nExtended_Description: There are situations where it is critical to remove source code\n  from an area or server. For example, obtaining Perl source code on a system allows\n  an attacker to understand the logic of the script and extract extremely useful information\n  such as code bugs or logins and passwords.\nPotential_Mitigations: 'Architecture and Design\n\n  System Configuration: Recommendations include removing this script from the web\n  server and moving it to a location not accessible from the Internet.'\n",
  "ID: '541'\nName: Inclusion of Sensitive Information in an Include File\nDescription: If an include file source is accessible, the file can contain usernames\n  and passwords, as well as sensitive information pertaining to the application and\n  system.\nPotential_Mitigations: 'Architecture and Design: Do not store sensitive information\n  in include files.\n\n\n  Architecture and Design\n\n  System Configuration: Protect include files from being exposed.'\n",
  "ID: '542'\nName: 'DEPRECATED: Information Exposure Through Cleanup Log Files'\nDescription: This entry has been deprecated because its abstraction was too low-level.  See\n  CWE-532.\n",
  "ID: '543'\nName: Use of Singleton Pattern Without Synchronization in a Multithreaded Context\nDescription: The product uses the singleton pattern when creating a resource within\n  a multithreaded environment.\nExtended_Description: The use of a singleton pattern may not be thread-safe.\nApplicable_Platforms:\n  Language: Java, C++\nPotential_Mitigations: 'Architecture and Design: Use the Thread-Specific Storage Pattern.\n  See References.\n\n\n  Implementation: Do not use member fields to store information in the Servlet. In\n  multithreading environments, storing user data in Servlet member fields introduces\n  a data access race condition.\n\n\n  Implementation: Avoid using the double-checked locking pattern in language versions\n  that cannot guarantee thread safety. This pattern may be used to avoid the overhead\n  of a synchronized call, but in certain versions of Java (for example), this has\n  been shown to be unsafe because it still introduces a race condition (CWE-209).'\n",
  "ID: '544'\nName: Missing Standardized Error Handling Mechanism\nDescription: The product does not use a standardized method for handling errors throughout\n  the code, which might introduce inconsistent error handling and resultant weaknesses.\nExtended_Description: If the product handles error messages individually, on a one-by-one\n  basis, this is likely to result in inconsistent error handling. The causes of errors\n  may be lost. Also, detailed information about the causes of an error may be unintentionally\n  returned to the user.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\nPotential_Mitigations: 'Architecture and Design: define a strategy for handling errors\n  of different severities, such as fatal errors versus basic log events. Use or create\n  built-in language features, or an external package, that provides an easy-to-use\n  API and define coding standards for the detection and handling of errors.'\n",
  "ID: '545'\nName: 'DEPRECATED: Use of Dynamic Class Loading'\nDescription: This weakness has been deprecated because it partially overlaps CWE-470,\n  it describes legitimate programmer behavior, and other portions will need to be\n  integrated into other entries.\n",
  "ID: '546'\nName: Suspicious Comment\nDescription: The code contains comments that suggest the presence of bugs, incomplete\n  functionality, or weaknesses.\nExtended_Description: Many suspicious comments, such as BUG, HACK, FIXME, LATER, LATER2,\n  TODO, in the code indicate missing security functionality and checking. Others indicate\n  code problems that programmers should fix, such as hard-coded variables, error handling,\n  not using stored procedures, and performance issues.\nPotential_Mitigations: 'Documentation: Remove comments that suggest the presence of\n  bugs, incomplete functionality, or weaknesses, before deploying the application.'\n",
  "ID: '547'\nName: Use of Hard-coded, Security-relevant Constants\nDescription: The product uses hard-coded constants instead of symbolic names for security-critical\n  values, which increases the likelihood of mistakes during code maintenance or security\n  policy change.\nExtended_Description: If the developer does not find all occurrences of the hard-coded\n  constants, an incorrect policy decision may be made if one of the constants is not\n  changed. Making changes to these values will require code changes that may be difficult\n  or impossible once the system is released to the field. In addition, these hard-coded\n  values may become available to attackers if the code is ever disclosed.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Avoid using hard-coded constants. Configuration\n  files offer a more flexible solution.'\n",
  "ID: '548'\nName: Exposure of Information Through Directory Listing\nDescription: A directory listing is inappropriately exposed, yielding potentially\n  sensitive information to attackers.\nExtended_Description: A directory listing provides an attacker with the complete index\n  of all the resources located inside of the directory. The specific risks and consequences\n  vary depending on which files are listed and accessible.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  System Configuration: Recommendations include restricting access to important directories\n  or files by adopting a need to know requirement for both the document and server\n  root, and turning off features such as Automatic Directory Listings that could expose\n  private files and provide information that could be utilized by an attacker when\n  formulating or conducting an attack.'\n",
  "ID: '549'\nName: Missing Password Field Masking\nDescription: The product does not mask passwords during entry, increasing the potential\n  for attackers to observe and capture passwords.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation, Requirements: Recommendations include requiring\n  all password fields in your web application be masked to prevent other users from\n  seeing this information.'\n",
  "ID: '55'\nName: 'Path Equivalence: ''/./'' (Single Dot Directory)'\nDescription: The product accepts path input in the form of single dot directory exploit\n  ('/./') without appropriate validation, which can lead to ambiguous path resolution\n  and allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2000-0004: Server allows remote attackers to read source code\n  for executable files by inserting a . (dot) into the URL.\n\n\n  CVE-2002-0304: Server allows remote attackers to read password-protected files via\n  a /./ in the HTTP request.\n\n\n  BID:6042: Input Validation error\n\n\n  CVE-1999-1083: Possibly (could be a cleansing error)\n\n\n  CVE-2004-0815: \"/./////etc\" cleansed to \".///etc\" then \"/etc\"\n\n\n  CVE-2002-0112: Server allows remote attackers to view password protected files via\n  /./ in the URL.'\n",
  "ID: '550'\nName: Server-generated Error Message Containing Sensitive Information\nDescription: Certain conditions, such as network failure, will cause a server error\n  message to be displayed.\nExtended_Description: While error messages in and of themselves are not dangerous,\n  per se, it is what an attacker can glean from them that might cause eventual problems.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design\n\n  System Configuration: Recommendations include designing and adding consistent error\n  handling mechanisms which are capable of handling any user input to your web application,\n  providing meaningful detail to end-users, and preventing error messages that might\n  provide information useful to an attacker from being displayed.'\n",
  "ID: '551'\nName: 'Incorrect Behavior Order: Authorization Before Parsing and Canonicalization'\nDescription: If a web server does not fully parse requested URLs before it examines\n  them for authorization, it may be possible for an attacker to bypass authorization\n  protection.\nExtended_Description: For instance, the character strings /./ and / both mean current\n  directory. If /SomeDirectory is a protected directory and an attacker requests /./SomeDirectory,\n  the attacker may be able to gain access to the resource if /./ is not converted\n  to / before the authorization check is performed.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: URL Inputs should be decoded and\n  canonicalized to the application''s current internal representation before being\n  validated and processed for authorization. Make sure that your application does\n  not decode the same input twice. Such errors could be used to bypass allowlist schemes\n  by introducing dangerous inputs after they have been checked.'\n",
  "ID: '552'\nName: Files or Directories Accessible to External Parties\nDescription: The product makes files or directories accessible to unauthorized actors,\n  even though they should not be.\nExtended_Description: 'Web servers, FTP servers, and similar servers may store a set\n  of files underneath a \"root\" directory that is accessible to the server''s users.  Applications\n  may store sensitive files underneath this root without also using access control\n  to limit which users may request those files, if any.  Alternately, an application\n  might package multiple files or directories into an archive file (e.g., ZIP or tar),\n  but the application might not exclude sensitive files that are underneath those\n  directories.\n\n  In cloud technologies and containers, this weakness might present itself in the\n  form of misconfigured storage accounts that can be read or written by a public or\n  anonymous user.'\nApplicable_Platforms:\n  Technology: Cloud Computing\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: OMISSION: This\\\n  \\ weakness is caused by missing a security tactic during the architecture and design\\\n  \\ phase.\\n\\nOperation: OMISSION: This weakness is caused by missing a security tactic\\\n  \\ during the architecture and design phase.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation, System Configuration, Operation: When storing\n  data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use\n  the provider''s controls to disable public access.'\nRelated_Attack_Patterns: \"150: \\n\\n639: \"\n",
  "ID: '553'\nName: Command Shell in Externally Accessible Directory\nDescription: A possible shell file exists in /cgi-bin/ or other accessible directories.\n  This is extremely dangerous and can be used by an attacker to execute commands on\n  the web server.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Installation, System Configuration: Remove any Shells accessible\n  under the web root folder and children directories.'\nRelated_Attack_Patterns: '650: '\n",
  "ID: '554'\nName: 'ASP.NET Misconfiguration: Not Using Input Validation Framework'\nDescription: The ASP.NET application does not use an input validation framework.\nApplicable_Platforms:\n  Language: ASP.NET\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Use the ASP.NET validation framework\n  to check all program input before it is processed by the application. Example uses\n  of the validation framework include checking to ensure that:'\n",
  "ID: '555'\nName: 'J2EE Misconfiguration: Plaintext Password in Configuration File'\nDescription: The J2EE application stores a plaintext password in a configuration file.\nExtended_Description: Storing a plaintext password in a configuration file allows\n  anyone who can read the file to access the password-protected resource, making it\n  an easy target for attackers.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Do not hardwire passwords into your\n  software.\n\n\n  Architecture and Design: Use industry standard libraries to encrypt passwords before\n  storage in configuration files.'\n",
  "ID: '556'\nName: 'ASP.NET Misconfiguration: Use of Identity Impersonation'\nDescription: Configuring an ASP.NET application to run with impersonated credentials\n  may give the application unnecessary privileges.\nExtended_Description: The use of impersonated credentials allows an ASP.NET application\n  to run with either the privileges of the client on whose behalf it is executing\n  or with arbitrary privileges granted in its configuration.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Use the least privilege principle.'\n",
  "ID: '558'\nName: Use of getlogin() in Multithreaded Application\nDescription: The product uses the getlogin() function in a multithreaded context,\n  potentially causing it to return incorrect values.\nExtended_Description: The getlogin() function returns a pointer to a string that contains\n  the name of the user associated with the calling process. The function is not reentrant,\n  meaning that if it is called from another process, the contents are not locked out\n  and the value of the string can be changed by another process. This makes it very\n  risky to use because the username can be changed by other processes, so the results\n  of the function cannot be trusted.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Architecture and Design: Using names for security purposes\n  is not advised. Names are easy to forge and can have overlapping user IDs, potentially\n  causing confusion or impersonation.\n\n\n  Implementation: Use getlogin_r() instead, which is reentrant, meaning that other\n  processes are locked out from changing the username.'\n",
  "ID: '56'\nName: 'Path Equivalence: ''filedir*'' (Wildcard)'\nDescription: The product accepts path input in the form of asterisk wildcard ('filedir*')\n  without appropriate validation, which can lead to ambiguous path resolution and\n  allow an attacker to traverse the file system to unintended locations or access\n  arbitrary files.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2004-0696: List directories using desired path and \"*\"\n\n\n  CVE-2002-0433: List files in web server using \"*.ext\"'\n",
  "ID: '560'\nName: Use of umask() with chmod-style Argument\nDescription: The product calls umask() with an incorrect argument that is specified\n  as if it is an argument to chmod().\nApplicable_Platforms:\n  Language: C\nPotential_Mitigations: 'Implementation: Use umask() with the correct argument.\n\n\n  Testing: If you suspect misuse of umask(), you can use grep to spot call instances\n  of umask().'\n",
  "ID: '561'\nName: Dead Code\nDescription: The product contains dead code, which can never be executed.\nExtended_Description: Dead code is code that can never be executed in a running program.\n  The surrounding code makes it impossible for a section of code to ever be executed.\nDetection_Methods: 'Architecture or Design Review: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:'\nPotential_Mitigations: 'Implementation: Remove dead code before deploying the application.\n\n\n  Testing: Use a static analysis tool to spot dead code.'\nObserved_Examples: 'CVE-2014-1266: chain: incorrect \"goto\" in Apple SSL product bypasses\n  certificate validation, allowing Adversary-in-the-Middle (AITM) attack (Apple \"goto\n  fail\" bug). CWE-705 (Incorrect Control Flow Scoping) -> CWE-561 (Dead Code) -> CWE-295\n  (Improper Certificate Validation) -> CWE-393 (Return of Wrong Status Code) -> CWE-300\n  (Channel Accessible by Non-Endpoint).'\n",
  "ID: '562'\nName: Return of Stack Variable Address\nDescription: A function returns the address of a stack variable, which will cause\n  unintended program behavior, typically in the form of a crash.\nExtended_Description: Because local variables are allocated on the stack, when a program\n  returns a pointer to a local variable, it is returning a stack address. A subsequent\n  function call is likely to re-use this same stack address, thereby overwriting the\n  value of the pointer, which no longer corresponds to the same variable since a function's\n  stack frame is invalidated when it returns. At best this will cause the value of\n  the pointer to change unexpectedly. In many cases it causes the program to crash\n  the next time the pointer is dereferenced.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Testing: Use static analysis tools to spot return of the address\n  of a stack variable.'\n",
  "ID: '563'\nName: Assignment to Variable without Use\nDescription: The variable's value is assigned but never used, making it a dead store.\nExtended_Description: After the assignment, the variable is either assigned another\n  value or goes out of scope. It is likely that the variable is simply vestigial,\n  but it is also possible that the unused variable points out a bug.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Remove unused variables from the code.'\n",
  "ID: '564'\nName: 'SQL Injection: Hibernate'\nDescription: Using Hibernate to execute a dynamic SQL statement built with user-controlled\n  input can allow an attacker to modify the statement's meaning or to execute arbitrary\n  SQL commands.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Requirements: A non-SQL style database which is not subject\n  to this flaw may be chosen.\n\n\n  Architecture and Design: Follow the principle of least privilege when creating user\n  accounts to a SQL database. Users should only have the minimum privileges necessary\n  to use their account. If the requirements of the system indicate that a user can\n  read and modify their own data, then limit their privileges so they cannot read/write\n  others'' data.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: Implement SQL strings using prepared statements that bind variables.\n  Prepared statements that do not bind variables can be vulnerable to attack.\n\n\n  Implementation: Use vigorous allowlist style checking on any user input that may\n  be used in a SQL command. Rather than escape meta-characters, it is safest to disallow\n  them entirely. Reason: Later use of data that have been entered in the database\n  may neglect to escape meta-characters before use. Narrowly define the set of safe\n  characters based on the expected value of the parameter in the request.'\nRelated_Attack_Patterns: '109: '\n",
  "ID: '565'\nName: Reliance on Cookies without Validation and Integrity Checking\nDescription: The product relies on the existence or values of cookies when performing\n  security-critical operations, but it does not properly ensure that the setting is\n  valid for the associated user.\nExtended_Description: Attackers can easily modify cookies, within the browser or by\n  implementing the client-side code outside of the browser. Reliance on cookies without\n  detailed validation and integrity checking can allow attackers to bypass authentication,\n  conduct injection attacks such as SQL injection and cross-site scripting, or otherwise\n  modify inputs in unexpected ways.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Avoid using cookie data for a security-related\n  decision.\n\n\n  Implementation: Perform thorough input validation (i.e.: server side validation)\n  on the cookie data if you''re going to use it for a security related decision.\n\n\n  Architecture and Design: Add integrity checks to detect tampering.\n\n\n  Architecture and Design: Protect critical cookies from replay attacks, since cross-site\n  scripting or other attacks may allow attackers to steal a strongly-encrypted cookie\n  that also passes integrity checks. This mitigation applies to cookies that should\n  only be valid during a single transaction or session. By enforcing timeouts, you\n  may limit the scope of an attack. As part of your integrity check, use an unpredictable,\n  server-side value that is not exposed to the client.'\nRelated_Attack_Patterns: \"226: \\n\\n31: \\n\\n39: \"\n",
  "ID: '566'\nName: Authorization Bypass Through User-Controlled SQL Primary Key\nDescription: The product uses a database table that includes records that should not\n  be accessible to an actor, but it executes a SQL statement with a primary key that\n  can be controlled by that actor.\nExtended_Description: 'When a user can set a primary key to any value, then the user\n  can modify the key to point to unauthorized records.\n\n  Database access control errors occur when:'\nApplicable_Platforms:\n  Technology: Database Server\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use a standard\n  input validation mechanism to validate all input for length, type, syntax, and business\n  rules before accepting the data. Use an \"accept known good\" validation strategy.\n\n\n  Implementation: Use a parameterized query AND make sure that the accepted values\n  conform to the business rules. Construct your SQL statement accordingly.'\n",
  "ID: '567'\nName: Unsynchronized Access to Shared Data in a Multithreaded Context\nDescription: The product does not properly synchronize shared data, such as static\n  variables across threads, which can lead to undefined behavior and unpredictable\n  data changes.\nExtended_Description: 'Within servlets, shared static variables are not protected\n  from concurrent access, but servlets are multithreaded. This is a typical programming\n  mistake in J2EE applications, since the multithreading is handled by the framework.\n  When a shared variable can be influenced by an attacker, one thread could wind up\n  modifying the variable to contain data that is not valid for a different thread\n  that is also using the data within the variable.\n\n  Note that this weakness is not unique to servlets.'\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Remove the use of static variables used between\n  servlets. If this cannot be avoided, use synchronized access for these variables.'\nRelated_Attack_Patterns: '25: '\n",
  "ID: '568'\nName: finalize() Method Without super.finalize()\nDescription: The product contains a finalize() method that does not call super.finalize().\nExtended_Description: The Java Language Specification states that it is a good practice\n  for a finalize() method to call super.finalize().\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Call the super.finalize() method.\n\n\n  Testing: Use static analysis tools to spot such issues in your code.'\n",
  "ID: '57'\nName: 'Path Equivalence: ''fakedir/../realdir/filename'''\nDescription: The product contains protection mechanisms to restrict access to 'realdir/filename',\n  but it constructs pathnames using external input in the form of 'fakedir/../realdir/filename'\n  that are not handled by those mechanisms. This allows attackers to perform unauthorized\n  actions against the targeted file.\nPotential_Mitigations: 'Implementation: Inputs should be decoded and canonicalized\n  to the application''s current internal representation before being validated (CWE-180).\n  Make sure that the application does not decode the same input twice (CWE-174). Such\n  errors could be used to bypass allowlist validation schemes by introducing dangerous\n  inputs after they have been checked.'\nObserved_Examples: 'CVE-2001-1152: Proxy allows remote attackers to bypass denylist\n  restrictions and connect to unauthorized web servers by modifying the requested\n  URL, including (1) a // (double slash), (2) a /SUBDIR/.. where the desired file\n  is in the parentdir, (3) a /./, or (4) URL-encoded characters.\n\n\n  CVE-2000-0191: application check access for restricted URL before canonicalization\n\n\n  CVE-2005-1366: CGI source disclosure using \"dirname/../cgi-bin\"'\n",
  "ID: '570'\nName: Expression is Always False\nDescription: The product contains an expression that will always evaluate to false.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Testing: Use Static Analysis tools to spot such conditions.'\n",
  "ID: '571'\nName: Expression is Always True\nDescription: The product contains an expression that will always evaluate to true.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Testing: Use Static Analysis tools to spot such conditions.'\n",
  "ID: '572'\nName: Call to Thread run() instead of start()\nDescription: The product calls a thread's run() method instead of calling start(),\n  which causes the code to run in the thread of the caller instead of the callee.\nExtended_Description: In most cases a direct call to a Thread object's run() method\n  is a bug. The programmer intended to begin a new thread of control, but accidentally\n  called run() instead of start(), so the run() method will execute in the caller's\n  thread of control.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use the start() method instead of the run()\n  method.'\n",
  "ID: '573'\nName: Improper Following of Specification by Caller\nDescription: The product does not follow or incorrectly follows the specifications\n  as required by the implementation language, environment, framework, protocol, or\n  platform.\nExtended_Description: When leveraging external functionality, such as an API, it is\n  important that the caller does so in accordance with the requirements of the external\n  functionality or else unintended behaviors may result, possibly leaving the system\n  vulnerable to any number of exploits.\nObserved_Examples: 'CVE-2006-7140: Crypto implementation removes padding when it shouldn''t,\n  allowing forged signatures\n\n\n  CVE-2006-4339: Crypto implementation removes padding when it shouldn''t, allowing\n  forged signatures'\n",
  "ID: '574'\nName: 'EJB Bad Practices: Use of Synchronization Primitives'\nDescription: The product violates the Enterprise JavaBeans (EJB) specification by\n  using thread synchronization primitives.\nExtended_Description: 'The Enterprise JavaBeans specification requires that every\n  bean provider follow a set of programming guidelines designed to ensure that the\n  bean will be portable and behave consistently in any EJB container. In this case,\n  the product violates the following EJB guideline: \"An enterprise bean must not use\n  thread synchronization primitives to synchronize execution of multiple instances.\"\n  The specification justifies this requirement in the following way: \"This rule is\n  required to ensure consistent runtime semantics because while some EJB containers\n  may use a single JVM to execute all enterprise bean''s instances, others may distribute\n  the instances across multiple JVMs.\"'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Do not use Synchronization Primitives when\n  writing EJBs.'\n",
  "ID: '575'\nName: 'EJB Bad Practices: Use of AWT Swing'\nDescription: The product violates the Enterprise JavaBeans (EJB) specification by\n  using AWT/Swing.\nExtended_Description: 'The Enterprise JavaBeans specification requires that every\n  bean provider follow a set of programming guidelines designed to ensure that the\n  bean will be portable and behave consistently in any EJB container. In this case,\n  the product violates the following EJB guideline: \"An enterprise bean must not use\n  the AWT functionality to attempt to output information to a display, or to input\n  information from a keyboard.\" The specification justifies this requirement in the\n  following way: \"Most servers do not allow direct interaction between an application\n  program and a keyboard/display attached to the server system.\"'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Architecture and Design: Do not use AWT/Swing when writing\n  EJBs.'\n",
  "ID: '576'\nName: 'EJB Bad Practices: Use of Java I/O'\nDescription: The product violates the Enterprise JavaBeans (EJB) specification by\n  using the java.io package.\nExtended_Description: 'The Enterprise JavaBeans specification requires that every\n  bean provider follow a set of programming guidelines designed to ensure that the\n  bean will be portable and behave consistently in any EJB container. In this case,\n  the product violates the following EJB guideline: \"An enterprise bean must not use\n  the java.io package to attempt to access files and directories in the file system.\"\n  The specification justifies this requirement in the following way: \"The file system\n  APIs are not well-suited for business components to access data. Business components\n  should use a resource manager API, such as JDBC, to store data.\"'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Do not use Java I/O when writing EJBs.'\n",
  "ID: '577'\nName: 'EJB Bad Practices: Use of Sockets'\nDescription: The product violates the Enterprise JavaBeans (EJB) specification by\n  using sockets.\nExtended_Description: 'The Enterprise JavaBeans specification requires that every\n  bean provider follow a set of programming guidelines designed to ensure that the\n  bean will be portable and behave consistently in any EJB container. In this case,\n  the product violates the following EJB guideline: \"An enterprise bean must not attempt\n  to listen on a socket, accept connections on a socket, or use a socket for multicast.\"\n  The specification justifies this requirement in the following way: \"The EJB architecture\n  allows an enterprise bean instance to be a network socket client, but it does not\n  allow it to be a network server. Allowing the instance to become a network server\n  would conflict with the basic function of the enterprise bean-- to serve the EJB\n  clients.\"'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Do not use Sockets when writing EJBs.'\n",
  "ID: '578'\nName: 'EJB Bad Practices: Use of Class Loader'\nDescription: The product violates the Enterprise JavaBeans (EJB) specification by\n  using the class loader.\nExtended_Description: 'The Enterprise JavaBeans specification requires that every\n  bean provider follow a set of programming guidelines designed to ensure that the\n  bean will be portable and behave consistently in any EJB container. In this case,\n  the product violates the following EJB guideline: \"The enterprise bean must not\n  attempt to create a class loader; obtain the current class loader; set the context\n  class loader; set security manager; create a new security manager; stop the JVM;\n  or change the input, output, and error streams.\" The specification justifies this\n  requirement in the following way: \"These functions are reserved for the EJB container.\n  Allowing the enterprise bean to use these functions could compromise security and\n  decrease the container''s ability to properly manage the runtime environment.\"'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: Do not use the Class Loader when writing EJBs.'\n",
  "ID: '579'\nName: 'J2EE Bad Practices: Non-serializable Object Stored in Session'\nDescription: The product stores a non-serializable object as an HttpSession attribute,\n  which can hurt reliability.\nExtended_Description: A J2EE application can make use of multiple JVMs in order to\n  improve application reliability and performance. In order to make the multiple JVMs\n  appear as a single application to the end user, the J2EE container can replicate\n  an HttpSession object across multiple JVMs so that if one JVM becomes unavailable\n  another can step in and take its place without disrupting the flow of the application.\n  This is only possible if all session data is serializable, allowing the session\n  to be duplicated between the JVMs.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: In order for session replication to work,\n  the values the product stores as attributes in the session must implement the Serializable\n  interface.'\n",
  "ID: '58'\nName: 'Path Equivalence: Windows 8.3 Filename'\nDescription: The product contains a protection mechanism that restricts access to\n  a long filename on a Windows operating system, but it does not properly restrict\n  access to the equivalent short \"8.3\" filename.\nExtended_Description: On later Windows operating systems, a file can have a \"long\n  name\" and a short name that is compatible with older Windows file systems, with\n  up to 8 characters in the filename and 3 characters for the extension. These \"8.3\"\n  filenames, therefore, act as an alternate name for files with long names, so they\n  are useful pathname equivalence manipulations.\nApplicable_Platforms:\n  Operating_System: Windows\nPotential_Mitigations: 'System Configuration: Disable Windows from supporting 8.3\n  filenames by editing the Windows registry. Preventing 8.3 filenames will not remove\n  previously generated 8.3 filenames.'\nObserved_Examples: 'CVE-1999-0012: Multiple web servers allow restriction bypass using\n  8.3 names instead of long names\n\n\n  CVE-2001-0795: Source code disclosure using 8.3 file name.\n\n\n  CVE-2005-0471: Multi-Factor Vulnerability. Product generates temporary filenames\n  using long filenames, which become predictable in 8.3 format.'\n",
  "ID: '580'\nName: clone() Method Without super.clone()\nDescription: The product contains a clone() method that does not call super.clone()\n  to obtain the new object.\nExtended_Description: All implementations of clone() should obtain the new object\n  by calling super.clone(). If a class does not follow this convention, a subclass's\n  clone() method will return an object of the wrong type.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Call super.clone() within your clone() method,\n  when obtaining a new object.\n\n\n  Implementation: In some cases, you can eliminate the clone method altogether and\n  use copy constructors.'\n",
  "ID: '581'\nName: 'Object Model Violation: Just One of Equals and Hashcode Defined'\nDescription: The product does not maintain equal hashcodes for equal objects.\nExtended_Description: Java objects are expected to obey a number of invariants related\n  to equality. One of these invariants is that equal objects must have equal hashcodes.\n  In other words, if a.equals(b) == true then a.hashCode() == b.hashCode().\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Both Equals() and Hashcode() should be defined.'\n",
  "ID: '582'\nName: Array Declared Public, Final, and Static\nDescription: The product declares an array public, final, and static, which is not\n  sufficient to prevent the array's contents from being modified.\nExtended_Description: Because arrays are mutable objects, the final constraint requires\n  that the array object itself be assigned only once, but makes no guarantees about\n  the values of the array elements. Since the array is public, a malicious program\n  can change the values stored in the array. As such, in most cases an array declared\n  public, final and static is a bug.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: In most situations the array should be made\n  private.'\n",
  "ID: '583'\nName: finalize() Method Declared Public\nDescription: The product violates secure coding principles for mobile code by declaring\n  a finalize() method public.\nExtended_Description: A product should never call finalize explicitly, except to call\n  super.finalize() inside an implementation of finalize(). In mobile code situations,\n  the otherwise error prone practice of manual garbage collection can become a security\n  threat if an attacker can maliciously invoke a finalize() method because it is declared\n  with public access.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: If you are using finalize() as it was designed,\n  there is no reason to declare finalize() with anything other than protected access.'\n",
  "ID: '584'\nName: Return Inside Finally Block\nDescription: The code has a return statement inside a finally block, which will cause\n  any thrown exception in the try block to be discarded.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Do not use a return statement inside the finally\n  block. The finally block should have \"cleanup\" code.'\n",
  "ID: '585'\nName: Empty Synchronized Block\nDescription: The product contains an empty synchronized block.\nExtended_Description: An empty synchronized block does not actually accomplish any\n  synchronization and may indicate a troubled section of code. An empty synchronized\n  block can occur because code no longer needed within the synchronized block is commented\n  out without removing the synchronized block.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: When you come across an empty synchronized\n  statement, or a synchronized statement in which the code has been commented out,\n  try to determine what the original intentions were and whether or not the synchronized\n  block is still necessary.'\n",
  "ID: '586'\nName: Explicit Call to Finalize()\nDescription: The product makes an explicit call to the finalize() method from outside\n  the finalizer.\nExtended_Description: 'While the Java Language Specification allows an object''s finalize()\n  method to be called from outside the finalizer, doing so is usually a bad idea.\n  For example, calling finalize() explicitly means that finalize() will be called\n  more than once: the first time will be the explicit call and the last time will\n  be the call that is made after the object is garbage collected.'\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation, Testing: Do not make explicit calls to finalize().\n  Use static analysis tools to spot such instances.'\n",
  "ID: '587'\nName: Assignment of a Fixed Address to a Pointer\nDescription: The product sets a pointer to a specific address other than NULL or 0.\nExtended_Description: Using a fixed address is not portable, because that address\n  will probably not be valid in all environments or platforms.\nApplicable_Platforms:\n  Language: C, C++, C#, Assembly\nPotential_Mitigations: 'Implementation: Never set a pointer to a fixed address.'\n",
  "ID: '588'\nName: Attempt to Access Child of a Non-structure Pointer\nDescription: Casting a non-structure type to a structure type and accessing a field\n  can lead to memory access errors or data corruption.\nPotential_Mitigations: 'Requirements: The choice could be made to use a language that\n  is not susceptible to these issues.\n\n\n  Implementation: Review of type casting operations can identify locations where incompatible\n  types are cast.'\n",
  "ID: '589'\nName: Call to Non-ubiquitous API\nDescription: The product uses an API function that does not exist on all versions\n  of the target platform. This could cause portability problems or inconsistencies\n  that allow denial of service or other consequences.\nExtended_Description: Some functions that offer security features supported by the\n  OS are not available on all versions of the OS in common use. Likewise, functions\n  are often deprecated or made obsolete for security reasons and should not be used.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Always test your code on any platform on which\n  it is targeted to run on.\n\n\n  Testing: Test your code on the newest and oldest platform on which it is targeted\n  to run on.\n\n\n  Testing: Develop a system to test for API functions that are not portable.'\nRelated_Attack_Patterns: '96: '\n",
  "ID: '59'\nName: Improper Link Resolution Before File Access ('Link Following')\nDescription: The product attempts to access a file based on the filename, but it does\n  not properly prevent that filename from identifying a link or shortcut that resolves\n  to an unintended resource.\nApplicable_Platforms:\n  Operating_System: Windows, Unix\nAlternate_Terms: 'insecure temporary file: Some people use the phrase \"insecure temporary\n  file\" when referring to a link following weakness, but other weaknesses can produce\n  insecure temporary files without any symlink involvement at all.\n\n\n  Zip Slip: \"Zip slip\" is an attack that uses file archives (e.g., ZIP, tar, rar,\n  etc.) that contain filenames with path traversal sequences that cause the files\n  to be written outside of the directory under which the archive is expected to be\n  extracted [REF-1282]. It is most commonly used for relative path traversal (CWE-23)\n  and link following (CWE-59).'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Follow the principle of least privilege\n  when assigning access rights to entities in a software system.\n\n  Denying access to a file can prevent an attacker from replacing that file with a\n  link to a sensitive file. Ensure good compartmentalization in the system to provide\n  protected areas that can be trusted.'\nObserved_Examples: 'CVE-1999-1386: Some versions of Perl follow symbolic links when\n  running with the -e option, which allows local users to overwrite arbitrary files\n  via a symlink attack.\n\n\n  CVE-2000-1178: Text editor follows symbolic links when creating a rescue copy during\n  an abnormal exit, which allows local users to overwrite the files of other users.\n\n\n  CVE-2004-0217: Antivirus update allows local users to create or append to arbitrary\n  files via a symlink attack on a logfile.\n\n\n  CVE-2003-0517: Symlink attack allows local users to overwrite files.\n\n\n  CVE-2004-0689: Window manager does not properly handle when certain symbolic links\n  point to \"stale\" locations, which could allow local users to create or truncate\n  arbitrary files.\n\n\n  CVE-2005-1879: Second-order symlink vulnerabilities\n\n\n  CVE-2005-1880: Second-order symlink vulnerabilities\n\n\n  CVE-2005-1916: Symlink in Python program\n\n\n  CVE-2000-0972: Setuid product allows file reading by replacing a file being edited\n  with a symlink to the targeted file, leaking the result in error messages when parsing\n  fails.\n\n\n  CVE-2005-0824: Signal causes a dump that follows symlinks.\n\n\n  CVE-2001-1494: Hard link attack, file overwrite; interesting because program checks\n  against soft links\n\n\n  CVE-2002-0793: Hard link and possibly symbolic link following vulnerabilities in\n  embedded operating system allow local users to overwrite arbitrary files.\n\n\n  CVE-2003-0578: Server creates hard links and unlinks files as root, which allows\n  local users to gain privileges by deleting and overwriting arbitrary files.\n\n\n  CVE-1999-0783: Operating system allows local users to conduct a denial of service\n  by creating a hard link from a device special file to a file on an NFS file system.\n\n\n  CVE-2004-1603: Web hosting manager follows hard links, which allows local users\n  to read or modify arbitrary files.\n\n\n  CVE-2004-1901: Package listing system allows local users to overwrite arbitrary\n  files via a hard link attack on the lockfiles.\n\n\n  CVE-2005-1111: Hard link race condition\n\n\n  CVE-2000-0342: Mail client allows remote attackers to bypass the user warning for\n  executable attachments such as .exe, .com, and .bat by using a .lnk file that refers\n  to the attachment, aka \"Stealth Attachment.\"\n\n\n  CVE-2001-1042: FTP server allows remote attackers to read arbitrary files and directories\n  by uploading a .lnk (link) file that points to the target file.\n\n\n  CVE-2001-1043: FTP server allows remote attackers to read arbitrary files and directories\n  by uploading a .lnk (link) file that points to the target file.\n\n\n  CVE-2005-0587: Browser allows remote malicious web sites to overwrite arbitrary\n  files by tricking the user into downloading a .LNK (link) file twice, which overwrites\n  the file that was referenced in the first .LNK file.\n\n\n  CVE-2001-1386: \".LNK.\" - .LNK with trailing dot\n\n\n  CVE-2003-1233: Rootkits can bypass file access restrictions to Windows kernel directories\n  using NtCreateSymbolicLinkObject function to create symbolic link\n\n\n  CVE-2002-0725: File system allows local attackers to hide file usage activities\n  via a hard link to the target file, which causes the link to be recorded in the\n  audit trail instead of the target file.\n\n\n  CVE-2003-0844: Web server plugin allows local users to overwrite arbitrary files\n  via a symlink attack on predictable temporary filenames.\n\n\n  CVE-2015-3629: A Libcontainer used in Docker Engine allows local users to escape\n  containerization and write to an arbitrary file on the host system via a symlink\n  attack in an image when respawning a container.\n\n\n  CVE-2021-21272: \"Zip Slip\" vulnerability in Go-based Open Container Initiative (OCI)\n  registries product allows writing arbitrary files outside intended directory via\n  symbolic links or hard links in a gzipped tarball.\n\n\n  CVE-2020-27833: \"Zip Slip\" vulnerability in container management product allows\n  writing arbitrary files outside intended directory via a container image (.tar format)\n  with filenames that are symbolic links that point to other files within the same\n  tar file; however, the files being pointed to can also be symbolic links to destinations\n  outside the intended directory, bypassing the initial check.'\nRelated_Attack_Patterns: \"132: \\n\\n17: \\n\\n35: \\n\\n76: \"\n",
  "ID: '590'\nName: Free of Memory not on the Heap\nDescription: The product calls free() on a pointer to memory that was not allocated\n  using associated heap allocation functions such as malloc(), calloc(), or realloc().\nExtended_Description: When free() is called on an invalid pointer, the program's memory\n  management data structures may become corrupted. This corruption can cause the program\n  to crash or, in some circumstances, an attacker may be able to cause free() to operate\n  on controllable memory locations to modify critical program variables or execute\n  code.\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Only free pointers that you have called malloc\n  on previously. This is the recommended solution. Keep track of which pointers point\n  at the beginning of valid chunks and free them only once.\n\n\n  Implementation: Before freeing a pointer, the programmer should make sure that the\n  pointer was previously allocated on the heap and that the memory belongs to the\n  programmer. Freeing an unallocated pointer will cause undefined behavior in the\n  program.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, glibc in Linux provides protection against free of invalid pointers.\n\n\n  Architecture and Design: Use a language that provides abstractions for memory allocation\n  and deallocation.\n\n\n  Testing: Use a tool that dynamically detects memory management problems, such as\n  valgrind.'\n",
  "ID: '591'\nName: Sensitive Data Storage in Improperly Locked Memory\nDescription: The product stores sensitive data in memory that is not locked, or that\n  has been incorrectly locked, which might cause the memory to be written to swap\n  files on disk by the virtual memory manager. This can make the data more accessible\n  to external actors.\nExtended_Description: On Windows systems the VirtualLock function can lock a page\n  of memory to ensure that it will remain present in memory and not be swapped to\n  disk. However, on older versions of Windows, such as 95, 98, or Me, the VirtualLock()\n  function is only a stub and provides no protection. On POSIX systems the mlock()\n  call ensures that a page will stay resident in memory but does not guarantee that\n  the page will not appear in the swap. Therefore, it is unsuitable for use as a protection\n  mechanism for sensitive data. Some platforms, in particular Linux, do make the guarantee\n  that the page will not be swapped, but this is non-standard and is not portable.\n  Calls to mlock() also require supervisor privilege. Return values for both of these\n  calls must be checked to ensure that the lock operation was actually successful.\nPotential_Mitigations: 'Architecture and Design: Identify data that needs to be protected\n  from swapping and choose platform-appropriate protection mechanisms.\n\n\n  Implementation: Check return values to ensure locking operations are successful.'\n",
  "ID: '592'\nName: 'DEPRECATED: Authentication Bypass Issues'\nDescription: This weakness has been deprecated because it covered redundant concepts\n  already described in CWE-287.\n",
  "ID: '593'\nName: 'Authentication Bypass: OpenSSL CTX Object Modified after SSL Objects are Created'\nDescription: The product modifies the SSL context after connection creation has begun.\nExtended_Description: If the program modifies the SSL_CTX object after creating SSL\n  objects from it, there is the possibility that older SSL objects created from the\n  original context could all be affected by that change.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Use a language or a library that\n  provides a cryptography framework at a higher level of abstraction.\n\n\n  Implementation: Most SSL_CTX functions have SSL counterparts that act on SSL-type\n  objects.\n\n\n  Implementation: Applications should set up an SSL_CTX completely, before creating\n  SSL objects from it.'\nRelated_Attack_Patterns: '94: '\n",
  "ID: '594'\nName: 'J2EE Framework: Saving Unserializable Objects to Disk'\nDescription: When the J2EE container attempts to write unserializable objects to disk\n  there is no guarantee that the process will complete successfully.\nExtended_Description: In heavy load conditions, most J2EE application frameworks flush\n  objects to disk to manage memory requirements of incoming requests. For example,\n  session scoped objects, and even application scoped objects, are written to disk\n  when required. While these application frameworks do the real work of writing objects\n  to disk, they do not enforce that those objects be serializable, thus leaving the\n  web application vulnerable to crashes induced by serialization failure. An attacker\n  may be able to mount a denial of service attack by sending enough requests to the\n  server to force the web application to save objects to disk.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: All objects that become part of session and application scope must\n  implement the java.io.Serializable interface to ensure serializability of containing\n  objects.'\n",
  "ID: '595'\nName: Comparison of Object References Instead of Object Contents\nDescription: The product compares object references instead of the contents of the\n  objects themselves, preventing it from detecting equivalent objects.\nExtended_Description: For example, in Java, comparing objects using == usually produces\n  deceptive results, since the == operator compares object references rather than\n  values; often, this means that using == for strings is actually comparing the strings'\n  references, not their values.\nApplicable_Platforms:\n  Language: Java, JavaScript, PHP\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: In Java, use the equals() method to compare\n  objects instead of the == operator. If using ==, it is important for performance\n  reasons that your objects are created by a static factory, not by a constructor.'\n",
  "ID: '596'\nName: 'DEPRECATED: Incorrect Semantic Object Comparison'\nDescription: This weakness has been deprecated.  It was poorly described and difficult\n  to distinguish from other entries.  It was also inappropriate to assign a separate\n  ID solely because of domain-specific considerations.  Its closest equivalent is\n  CWE-1023.\n",
  "ID: '597'\nName: Use of Wrong Operator in String Comparison\nDescription: The product uses the wrong operator when comparing a string, such as\n  using \"==\" when the .equals() method should be used instead.\nExtended_Description: In Java, using == or != to compare two strings for equality\n  actually compares two objects for equality rather than their string values for equality.\n  Chances are good that the two references will never be equal. While this weakness\n  often only affects program correctness, if the equality is used for a security decision,\n  the unintended comparison result could be leveraged to affect program security.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: '\n",
  "ID: '598'\nName: Use of GET Request Method With Sensitive Query Strings\nDescription: The web application uses the HTTP GET method to process a request and\n  includes sensitive information in the query string of that request.\nExtended_Description: The query string for the URL could be saved in the browser's\n  history, passed through Referers to other web sites, stored in web logs, or otherwise\n  recorded in other sources.  If the query string contains sensitive information such\n  as session identifiers, then attackers can use this information to launch further\n  attacks.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: When sensitive information is sent, use the\n  POST method (e.g. registration form).'\n",
  "ID: '599'\nName: Missing Validation of OpenSSL Certificate\nDescription: The product uses OpenSSL and trusts or uses a certificate without using\n  the SSL_get_verify_result() function to ensure that the certificate satisfies all\n  necessary security requirements.\nExtended_Description: This could allow an attacker to use an invalid certificate to\n  claim to be a trusted host, use expired certificates, or conduct other attacks that\n  could be detected if the certificate is properly validated.\nPotential_Mitigations: 'Architecture and Design: Ensure that proper authentication\n  is included in the system design.\n\n\n  Implementation: Understand and properly implement all checks necessary to ensure\n  the identity of entities involved in encrypted communications.'\n",
  "ID: '6'\nName: 'J2EE Misconfiguration: Insufficient Session-ID Length'\nDescription: The J2EE application is configured to use an insufficient session ID\n  length.\nExtended_Description: If an attacker can guess or steal a session ID, then they may\n  be able to take over the user's session (called session hijacking). The number of\n  possible session IDs increases with increased session ID length, making it more\n  difficult to guess or steal a session ID.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nPotential_Mitigations: 'Implementation: Session identifiers should be at least 128\n  bits long to prevent brute-force session guessing. A shorter session identifier\n  leaves the application open to brute-force session guessing attacks.\n\n\n  Implementation: A lower bound on the number of valid session identifiers that are\n  available to be guessed is the number of users that are active on a site at any\n  given moment. However, any users that abandon their sessions without logging out\n  will increase this number. (This is one of many good reasons to have a short inactive\n  session timeout.) With a 64 bit session identifier, assume 32 bits of entropy. For\n  a large web site, assume that the attacker can try 1,000 guesses per second and\n  that there are 10,000 valid session identifiers at any given moment. Given these\n  assumptions, the expected time for an attacker to successfully guess a valid session\n  identifier is less than 4 minutes. Now assume a 128 bit session identifier that\n  provides 64 bits of entropy. With a very large web site, an attacker might try 10,000\n  guesses per second with 100,000 valid session identifiers available to be guessed.\n  Given these assumptions, the expected time for an attacker to successfully guess\n  a valid session identifier is greater than 292 years.'\nRelated_Attack_Patterns: \"21: \\n\\n59: \"\n",
  "ID: '600'\nName: 'Uncaught Exception in Servlet '\nDescription: The Servlet does not catch all exceptions, which may reveal sensitive\n  debugging information.\nExtended_Description: When a Servlet throws an exception, the default error response\n  the Servlet container sends back to the user typically includes debugging information.\n  This information is of great value to an attacker. For example, a stack trace might\n  show the attacker a malformed SQL query string, the type of database being used,\n  and the version of the application container. This information enables the attacker\n  to target known vulnerabilities in these components.\nPotential_Mitigations: 'Implementation: Implement Exception blocks to handle all types\n  of Exceptions.'\n",
  "ID: '601'\nName: URL Redirection to Untrusted Site ('Open Redirect')\nDescription: A web application accepts a user-controlled input that specifies a link\n  to an external site, and uses that link in a Redirect. This simplifies phishing\n  attacks.\nExtended_Description: An http parameter may contain a URL value and could cause the\n  web application to redirect the request to the specified URL. By modifying the URL\n  value to a malicious site, an attacker may successfully launch a phishing scam and\n  steal user credentials. Because the server name in the modified link is identical\n  to the original site, phishing attempts have a more trustworthy appearance. Whether\n  this issue poses a vulnerability will be subject to the intended behavior of the\n  application. For example, a search engine might intentionally provide redirects\n  to arbitrary URLs.\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: \"Open Redirect: \\n\\nCross-site Redirect: \\n\\nCross-domain Redirect: \"\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nDetection_Methods: 'Manual Static Analysis: Since this weakness does not typically\n  appear frequently within a single software package, manual white box techniques\n  may be able to provide sufficient code coverage and reduction of false positives\n  if all potentially-vulnerable operations can be assessed within limited time constraints.\n\n\n  Automated Dynamic Analysis: Automated black box tools that supply URLs to every\n  input may be able to spot Location header modifications, but test case coverage\n  is a factor, and custom redirects may not be detected.\n\n\n  Automated Static Analysis: Automated static analysis tools may not be able to determine\n  whether input influences the beginning of a URL, which is important for reducing\n  false positives.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  Use a list of approved URLs or domains to be used for redirection.\n\n\n  Architecture and Design: Use an intermediate disclaimer page that provides the user\n  with a clear warning that they are leaving the current site. Implement a long timeout\n  before the redirect occurs, or force the user to click on the link. Be careful to\n  avoid XSS problems (CWE-79) when generating the disclaimer page.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n  For example, ID 1 could map to \"/login.asp\" and ID 2 could map to \"http://www.example.com/\".\n  Features such as the ESAPI AccessReferenceMap [REF-45] provide this capability.\n\n\n  Architecture and Design: Ensure that no externally-supplied requests are honored\n  by requiring that all redirect requests include a unique nonce generated by the\n  application [REF-483]. Be sure that the nonce is not predictable (CWE-330).\n\n\n  Architecture and Design\n\n  Implementation: Understand all the potential areas where untrusted inputs can enter\n  your software: parameters or arguments, cookies, anything read from the network,\n  environment variables, reverse DNS lookups, query results, request headers, URL\n  components, e-mail, files, filenames, databases, and any external systems that provide\n  data to the application. Remember that such inputs may be obtained indirectly through\n  API calls.\n\n  Many open redirect problems occur because the programmer assumed that certain inputs\n  could not be modified, such as cookies and hidden form fields.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.'\nObserved_Examples: 'CVE-2005-4206: URL parameter loads the URL into a frame and causes\n  it to appear to be part of a valid page.\n\n\n  CVE-2008-2951: An open redirect vulnerability in the search script in the software\n  allows remote attackers to redirect users to arbitrary web sites and conduct phishing\n  attacks via a URL as a parameter to the proper function.\n\n\n  CVE-2008-2052: Open redirect vulnerability in the software allows remote attackers\n  to redirect users to arbitrary web sites and conduct phishing attacks via a URL\n  in the proper parameter.\n\n\n  CVE-2020-11053: Chain: Go-based Oauth2 reverse proxy can send the authenticated\n  user to another site at the end of the authentication flow. A redirect URL with\n  HTML-encoded whitespace characters can bypass the validation (CWE-1289) to redirect\n  to a malicious site (CWE-601)'\nRelated_Attack_Patterns: '178: '\n",
  "ID: '602'\nName: Client-Side Enforcement of Server-Side Security\nDescription: The product is composed of a server that relies on the client to implement\n  a mechanism that is intended to protect the server.\nExtended_Description: When the server relies on protection mechanisms placed on the\n  client side, an attacker can modify the client-side behavior to bypass the protection\n  mechanisms, resulting in potentially unexpected interactions between the client\n  and server. The consequences will vary, depending on what the mechanisms are trying\n  to protect.\nApplicable_Platforms:\n  Technology: ICS/OT, Mobile\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Architecture and Design: Consider a product that consists of two or more processes\n  or nodes that must interact closely, such as a client/server model. If the product\n  uses protection schemes in the client in order to defend from attacks against the\n  server, and the server does not use the same schemes, then an attacker could modify\n  the client in a way that bypasses those schemes. This is a fundamental design flaw\n  that is primary to many weaknesses.'\nPotential_Mitigations: 'Architecture and Design: For any security checks that are\n  performed on the client side, ensure that these checks are duplicated on the server\n  side. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n  Even though client-side checks provide minimal benefits with respect to server-side\n  security, they are still useful. First, they can support intrusion detection. If\n  the server receives input that should have been rejected by the client, then it\n  may be an indication of an attack. Second, client-side error-checking can provide\n  helpful feedback to the user about the expectations for valid input. Third, there\n  may be a reduction in server-side processing time for accidental input errors, although\n  this is typically a small savings.\n\n\n  Architecture and Design: If some degree of trust is required between the two entities,\n  then use integrity checking and strong authentication to ensure that the inputs\n  are coming from a trusted source. Design the product so that this trust is managed\n  in a centralized fashion, especially if there are complex or numerous communication\n  channels, in order to reduce the risks that the implementer will mistakenly omit\n  a check in a single code path.\n\n\n  Testing: Use dynamic tools and techniques that interact with the software using\n  large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness\n  testing, and fault injection. The software''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.\n\n\n  Testing: Use tools and techniques that require manual (human) analysis, such as\n  penetration testing, threat modeling, and interactive tools that allow the tester\n  to record and modify an active session. These may be more effective than strictly\n  automated techniques. This is especially the case with weaknesses that are related\n  to design and business rules.'\nObserved_Examples: 'CVE-2022-33139: SCADA system only uses client-side authentication,\n  allowing adversaries to impersonate other users.\n\n\n  CVE-2006-6994: ASP program allows upload of .asp files by bypassing client-side\n  checks.\n\n\n  CVE-2007-0163: steganography products embed password information in the carrier\n  file, which can be extracted from a modified client.\n\n\n  CVE-2007-0164: steganography products embed password information in the carrier\n  file, which can be extracted from a modified client.\n\n\n  CVE-2007-0100: client allows server to modify client''s configuration and overwrite\n  arbitrary files.'\nRelated_Attack_Patterns: \"162: \\n\\n202: \\n\\n207: \\n\\n208: \\n\\n21: \\n\\n31: \\n\\n383:\\\n  \\ \\n\\n384: \\n\\n385: \\n\\n386: \\n\\n387: \\n\\n388: \"\n",
  "ID: '603'\nName: Use of Client-Side Authentication\nDescription: A client/server product performs authentication within client code but\n  not in server code, allowing server-side authentication to be bypassed via a modified\n  client that omits the authentication check.\nExtended_Description: Client-side authentication is extremely weak and may be breached\n  easily. Any attacker may read the source code and reverse-engineer the authentication\n  mechanism to access parts of the application which would otherwise be protected.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Do not rely on client side data.\n  Always perform server side authentication.'\nObserved_Examples: 'CVE-2022-33139: SCADA system only uses client-side authentication,\n  allowing adversaries to impersonate other users.\n\n\n  CVE-2006-0230: Client-side check for a password allows access to a server using\n  crafted XML requests from a modified client.'\n",
  "ID: '605'\nName: Multiple Binds to the Same Port\nDescription: When multiple sockets are allowed to bind to the same port, other services\n  on that port may be stolen or spoofed.\nExtended_Description: On most systems, a combination of setting the SO_REUSEADDR socket\n  option, and a call to bind() allows any process to bind to a port to which a previous\n  process has bound with INADDR_ANY. This allows a user to bind to the specific address\n  of a server bound to INADDR_ANY on an unprivileged port, and steal its UDP packets/TCP\n  connection.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Policy: Restrict server socket address to known local addresses.'\n",
  "ID: '606'\nName: Unchecked Input for Loop Condition\nDescription: The product does not properly check inputs that are used for loop conditions,\n  potentially leading to a denial of service or other consequences because of excessive\n  looping.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Do not use user-controlled data for loop conditions.\n\n\n  Implementation: Perform input validation.'\n",
  "ID: '607'\nName: Public Static Final Field References Mutable Object\nDescription: A public or protected static final field references a mutable object,\n  which allows the object to be changed by malicious code, or accidentally from another\n  package.\nApplicable_Platforms:\n  Language: Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Protect mutable objects by making them private.\n  Restrict access to the getter and setter as well.'\n",
  "ID: '608'\nName: 'Struts: Non-private Field in ActionForm Class'\nDescription: An ActionForm class contains a field that has not been declared private,\n  which can be accessed without using a setter or getter.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Make all fields private. Use getter to get\n  the value of the field. Setter should be used only by the framework; setting an\n  action form field from other actions is bad practice and should be avoided.'\n",
  "ID: '609'\nName: Double-Checked Locking\nDescription: The product uses double-checked locking to access a resource without\n  the overhead of explicit synchronization, but the locking is insufficient.\nExtended_Description: Double-checked locking refers to the situation where a programmer\n  checks to see if a resource has been initialized, grabs a lock, checks again to\n  see if the resource has been initialized, and then performs the initialization if\n  it has not occurred yet. This should not be done, as it is not guaranteed to work\n  in all languages and on all architectures. In summary, other threads may not be\n  operating inside the synchronous block and are not guaranteed to see the operations\n  execute in the same order as they would appear inside the synchronous block.\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: While double-checked locking can be achieved\n  in some languages, it is inherently flawed in Java before 1.5, and cannot be achieved\n  without compromising platform independence. Before Java 1.5, only use of the synchronized\n  keyword is known to work. Beginning in Java 1.5, use of the \"volatile\" keyword allows\n  double-checked locking to work successfully, although there is some debate as to\n  whether it achieves sufficient performance gains. See references.'\n",
  "ID: '61'\nName: UNIX Symbolic Link (Symlink) Following\nDescription: The product, when opening a file or directory, does not sufficiently\n  account for when the file is a symbolic link that resolves to a target outside of\n  the intended control sphere. This could allow an attacker to cause the product to\n  operate on unauthorized files.\nExtended_Description: A product that allows UNIX symbolic links (symlink) as part\n  of paths whether in internal code or through user input can allow an attacker to\n  spoof the symbolic link and traverse the file system to unintended locations or\n  access arbitrary files. The symbolic link can permit an attacker to read/write/corrupt\n  a file that they originally did not have permissions to access.\nAlternate_Terms: \"Symlink following: \\n\\nsymlink vulnerability: \"\nModes_Of_Introduction: 'Implementation: These are typically reported for temporary\n  files or privileged programs.'\nPotential_Mitigations: 'Implementation: Symbolic link attacks often occur when a program\n  creates a tmp directory that stores files/links. Access to the directory should\n  be restricted to the program as to prevent attackers from manipulating the files.\n\n\n  Architecture and Design: Follow the principle of least privilege when assigning\n  access rights to entities in a software system.\n\n  Denying access to a file can prevent an attacker from replacing that file with a\n  link to a sensitive file. Ensure good compartmentalization in the system to provide\n  protected areas that can be trusted.'\nObserved_Examples: 'CVE-1999-1386: Some versions of Perl follow symbolic links when\n  running with the -e option, which allows local users to overwrite arbitrary files\n  via a symlink attack.\n\n\n  CVE-2000-1178: Text editor follows symbolic links when creating a rescue copy during\n  an abnormal exit, which allows local users to overwrite the files of other users.\n\n\n  CVE-2004-0217: Antivirus update allows local users to create or append to arbitrary\n  files via a symlink attack on a logfile.\n\n\n  CVE-2003-0517: Symlink attack allows local users to overwrite files.\n\n\n  CVE-2004-0689: Possible interesting example\n\n\n  CVE-2005-1879: Second-order symlink vulnerabilities\n\n\n  CVE-2005-1880: Second-order symlink vulnerabilities\n\n\n  CVE-2005-1916: Symlink in Python program\n\n\n  CVE-2000-0972: Setuid product allows file reading by replacing a file being edited\n  with a symlink to the targeted file, leaking the result in error messages when parsing\n  fails.\n\n\n  CVE-2005-0824: Signal causes a dump that follows symlinks.\n\n\n  CVE-2015-3629: A Libcontainer used in Docker Engine allows local users to escape\n  containerization and write to an arbitrary file on the host system via a symlink\n  attack in an image when respawning a container.\n\n\n  CVE-2020-26277: In a MySQL database deployment tool, users may craft a maliciously\n  packaged tarball that contains symlinks to files external to the target and once\n  unpacked, will execute.\n\n\n  CVE-2021-21272: \"Zip Slip\" vulnerability in Go-based Open Container Initiative (OCI)\n  registries product allows writing arbitrary files outside intended directory via\n  symbolic links or hard links in a gzipped tarball.'\nRelated_Attack_Patterns: '27: '\n",
  "ID: '610'\nName: Externally Controlled Reference to a Resource in Another Sphere\nDescription: The product uses an externally controlled name or reference that resolves\n  to a resource that is outside of the intended control sphere.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nRelated_Attack_Patterns: '219: '\n",
  "ID: '611'\nName: Improper Restriction of XML External Entity Reference\nDescription: The product processes an XML document that can contain XML entities with\n  URIs that resolve to documents outside of the intended sphere of control, causing\n  the product to embed incorrect documents into its output.\nExtended_Description: 'XML documents optionally contain a Document Type Definition\n  (DTD), which, among other features, enables the definition of XML entities. It is\n  possible to define an entity by providing a substitution string in the form of a\n  URI. The XML parser can access the contents of this URI and embed these contents\n  back into the XML document for further processing.\n\n  By submitting an XML file that defines an external entity with a file:// URI, an\n  attacker can cause the processing application to read the contents of a local file.\n  For example, a URI such as \"file:///c:/winnt/win.ini\" designates (in Windows) the\n  file C:\\Winnt\\win.ini, or file:///etc/passwd designates the password file in Unix-based\n  systems. Using URIs with other schemes such as http://, the attacker can force the\n  application to make outgoing requests to servers that the attacker cannot reach\n  directly, which can be used to bypass firewall restrictions or hide the source of\n  attacks such as port scanning.\n\n  Once the content of the URI is read, it is fed back into the application that is\n  processing the XML. This application may echo back the data (e.g. in an error message),\n  thereby exposing the file contents.'\nApplicable_Platforms:\n  Language: XML\n  Technology: Web Based\nAlternate_Terms: 'XXE: An acronym used for the term \"XML eXternal Entities\"'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation, System Configuration: Many XML parsers and\n  validators can be configured to disable external entity expansion.'\nObserved_Examples: 'CVE-2005-1306: A browser control can allow remote attackers to\n  determine the existence of files via Javascript containing XML script.\n\n\n  CVE-2012-5656: XXE during SVG image conversion\n\n\n  CVE-2012-2239: XXE in PHP application allows reading the application''s configuration\n  file.\n\n\n  CVE-2012-3489: XXE in database server\n\n\n  CVE-2012-4399: XXE in rapid web application development framework allows reading\n  arbitrary files.\n\n\n  CVE-2012-3363: XXE via XML-RPC request.\n\n\n  CVE-2012-0037: XXE in office document product using RDF.\n\n\n  CVE-2011-4107: XXE in web-based administration tool for database.\n\n\n  CVE-2010-3322: XXE in product that performs large-scale data analysis.\n\n\n  CVE-2009-1699: XXE in XSL stylesheet functionality in a common library used by some\n  web browsers.'\nRelated_Attack_Patterns: '221: '\n",
  "ID: '612'\nName: Improper Authorization of Index Containing Sensitive Information\nDescription: The product creates a search index of private or sensitive documents,\n  but it does not properly limit index access to actors who are authorized to see\n  the original information.\nExtended_Description: Web sites and other document repositories may apply an indexing\n  routine against a group of private documents to facilitate search.  If the index's\n  results are available to parties who do not have access to the documents being indexed,\n  then attackers could obtain portions of the documents by conducting targeted searches\n  and reading the results.  The risk is especially dangerous if search results include\n  surrounding text that was not part of the search query. This issue can appear in\n  search engines that are not configured (or implemented) to ignore critical files\n  that should remain hidden; even without permissions to download these files directly,\n  the remote user could read them.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '613'\nName: Insufficient Session Expiration\nDescription: According to WASC, \"Insufficient Session Expiration is when a web site\n  permits an attacker to reuse old session credentials or session IDs for authorization.\"\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Set sessions/credentials expiration date.'\n",
  "ID: '614'\nName: Sensitive Cookie in HTTPS Session Without 'Secure' Attribute\nDescription: The Secure attribute for sensitive cookies in HTTPS sessions is not set,\n  which could cause the user agent to send those cookies in plaintext over an HTTP\n  session.\nApplicable_Platforms:\n  Technology: Web Based\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Always set the secure attribute when the cookie\n  should sent via HTTPS only.'\nObserved_Examples: 'CVE-2004-0462: A product does not set the Secure attribute for\n  sensitive cookies in HTTPS sessions, which could cause the user agent to send those\n  cookies in plaintext over an HTTP session with the product.\n\n\n  CVE-2008-3663: A product does not set the secure flag for the session cookie in\n  an https session, which can cause the cookie to be sent in http requests and make\n  it easier for remote attackers to capture this cookie.\n\n\n  CVE-2008-3662: A product does not set the secure flag for the session cookie in\n  an https session, which can cause the cookie to be sent in http requests and make\n  it easier for remote attackers to capture this cookie.\n\n\n  CVE-2008-0128: A product does not set the secure flag for a cookie in an https session,\n  which can cause the cookie to be sent in http requests and make it easier for remote\n  attackers to capture this cookie.'\nRelated_Attack_Patterns: '102: '\n",
  "ID: '615'\nName: Inclusion of Sensitive Information in Source Code Comments\nDescription: 'While adding general comments is very useful, some programmers tend\n  to leave important data, such as: filenames related to the web application, old\n  links or links which were not meant to be browsed by users, old code fragments,\n  etc.'\nExtended_Description: An attacker who finds these comments can map the application's\n  structure and files, expose hidden parts of the site, and study the fragments of\n  code to reverse engineer the application, which may help develop further attacks\n  against the site.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Distribution: Remove comments which have sensitive information\n  about the design/implementation of the application. Some of the comments may be\n  exposed to the user and affect the security posture of the application.'\nObserved_Examples: 'CVE-2007-6197: Version numbers and internal hostnames leaked in\n  HTML comments.\n\n\n  CVE-2007-4072: CMS places full pathname of server in HTML comment.\n\n\n  CVE-2009-2431: blog software leaks real username in HTML comment.'\n",
  "ID: '616'\nName: Incomplete Identification of Uploaded File Variables (PHP)\nDescription: The PHP application uses an old method for processing uploaded files\n  by referencing the four global variables that are set for each file (e.g. $varname,\n  $varname_size, $varname_name, $varname_type). These variables could be overwritten\n  by attackers, causing the application to process unauthorized files.\nExtended_Description: These global variables could be overwritten by POST requests,\n  cookies, or other methods of populating or overwriting these variables. This could\n  be used to read or process arbitrary files by providing values such as \"/etc/passwd\".\nApplicable_Platforms:\n  Language: PHP\nPotential_Mitigations: 'Architecture and Design: Use PHP 4 or later.\n\n\n  Architecture and Design: If you must support older PHP versions, write your own\n  version of is_uploaded_file() and run it against $HTTP_POST_FILES[''userfile'']))\n\n\n  Implementation: For later PHP versions, reference uploaded files using the $HTTP_POST_FILES\n  or $_FILES variables, and use is_uploaded_file() or move_uploaded_file() to ensure\n  that you are dealing with an uploaded file.'\nObserved_Examples: 'CVE-2002-1460: Forum does not properly verify whether a file was\n  uploaded or if the associated variables were set by POST, allowing remote attackers\n  to read arbitrary files.\n\n\n  CVE-2002-1759: Product doesn''t check if the variables for an upload were set by\n  uploading the file, or other methods such as $_POST.\n\n\n  CVE-2002-1710: Product does not distinguish uploaded file from other files.'\n",
  "ID: '617'\nName: Reachable Assertion\nDescription: The product contains an assert() or similar statement that can be triggered\n  by an attacker, which leads to an application exit or other behavior that is more\n  severe than necessary.\nExtended_Description: 'While assertion is good for catching logic errors and reducing\n  the chances of reaching more serious vulnerability conditions, it can still lead\n  to a denial of service.\n\n  For example, if a server handles multiple simultaneous connections, and an assert()\n  occurs in one single connection that causes all other connections to be dropped,\n  this is a reachable assertion that leads to a denial of service.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Make sensitive open/close operation non reachable\n  by directly user-controlled data (e.g. open/close resources)\n\n\n  Implementation: Perform input validation on user data.'\nObserved_Examples: 'CVE-2006-6767: FTP server allows remote attackers to cause a denial\n  of service (daemon abort) via crafted commands which trigger an assertion failure.\n\n\n  CVE-2006-6811: Chat client allows remote attackers to cause a denial of service\n  (crash) via a long message string when connecting to a server, which causes an assertion\n  failure.\n\n\n  CVE-2006-5779: Product allows remote attackers to cause a denial of service (daemon\n  crash) via LDAP BIND requests with long authcid names, which triggers an assertion\n  failure.\n\n\n  CVE-2006-4095: Product allows remote attackers to cause a denial of service (crash)\n  via certain queries, which cause an assertion failure.\n\n\n  CVE-2006-4574: Chain: security monitoring product has an off-by-one error that leads\n  to unexpected length values, triggering an assertion.'\n",
  "ID: '618'\nName: Exposed Unsafe ActiveX Method\nDescription: An ActiveX control is intended for use in a web browser, but it exposes\n  dangerous methods that perform actions that are outside of the browser's security\n  model (e.g. the zone or domain).\nExtended_Description: ActiveX controls can exercise far greater control over the operating\n  system than typical Java or javascript. Exposed methods can be subject to various\n  vulnerabilities, depending on the implemented behaviors of those methods, and whether\n  input validation is performed on the provided arguments. If there is no integrity\n  checking or origin validation, this method could be invoked by attackers.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: If you must expose a method, make sure to\n  perform input validation on all arguments, and protect against all possible vulnerabilities.\n\n\n  Architecture and Design: Use code signing, although this does not protect against\n  any weaknesses that are already in the control.\n\n\n  Architecture and Design\n\n  System Configuration: Where possible, avoid marking the control as safe for scripting.'\nObserved_Examples: 'CVE-2007-1120: download a file to arbitrary folders.\n\n\n  CVE-2006-6838: control downloads and executes a url in a parameter\n\n\n  CVE-2007-0321: resultant buffer overflow'\n",
  "ID: '619'\nName: Dangling Database Cursor ('Cursor Injection')\nDescription: If a database cursor is not closed properly, then it could become accessible\n  to other users while retaining the same privileges that were originally assigned,\n  leaving the cursor \"dangling.\"\nExtended_Description: For example, an improper dangling cursor could arise from unhandled\n  exceptions. The impact of the issue depends on the cursor's role, but SQL injection\n  attacks are commonly possible.\nApplicable_Platforms:\n  Language: SQL\nModes_Of_Introduction: 'Implementation: This issue is currently reported for unhandled\n  exceptions, but it is theoretically possible any time the programmer does not close\n  the cursor at the proper time.'\nPotential_Mitigations: 'Implementation: Close cursors immediately after access to\n  them is complete. Ensure that you close cursors if exceptions occur.'\n",
  "ID: '62'\nName: UNIX Hard Link\nDescription: The product, when opening a file or directory, does not sufficiently\n  account for when the name is associated with a hard link to a target that is outside\n  of the intended control sphere. This could allow an attacker to cause the product\n  to operate on unauthorized files.\nExtended_Description: Failure for a system to check for hard links can result in vulnerability\n  to different types of attacks. For example, an attacker can escalate their privileges\n  if a file used by a privileged program is replaced with a hard link to a sensitive\n  file (e.g. /etc/passwd). When the process opens the file, the attacker can assume\n  the privileges of that process.\nApplicable_Platforms:\n  Operating_System: Unix\nPotential_Mitigations: 'Architecture and Design: Follow the principle of least privilege\n  when assigning access rights to entities in a software system.\n\n  Denying access to a file can prevent an attacker from replacing that file with a\n  link to a sensitive file. Ensure good compartmentalization in the system to provide\n  protected areas that can be trusted.'\nObserved_Examples: 'CVE-2001-1494: Hard link attack, file overwrite; interesting because\n  program checks against soft links\n\n\n  CVE-2002-0793: Hard link and possibly symbolic link following vulnerabilities in\n  embedded operating system allow local users to overwrite arbitrary files.\n\n\n  CVE-2003-0578: Server creates hard links and unlinks files as root, which allows\n  local users to gain privileges by deleting and overwriting arbitrary files.\n\n\n  CVE-1999-0783: Operating system allows local users to conduct a denial of service\n  by creating a hard link from a device special file to a file on an NFS file system.\n\n\n  CVE-2004-1603: Web hosting manager follows hard links, which allows local users\n  to read or modify arbitrary files.\n\n\n  CVE-2004-1901: Package listing system allows local users to overwrite arbitrary\n  files via a hard link attack on the lockfiles.\n\n\n  CVE-2005-0342: The Finder in Mac OS X and earlier allows local users to overwrite\n  arbitrary files and gain privileges by creating a hard link from the .DS_Store file\n  to an arbitrary file.\n\n\n  CVE-2005-1111: Hard link race condition\n\n\n  CVE-2021-21272: \"Zip Slip\" vulnerability in Go-based Open Container Initiative (OCI)\n  registries product allows writing arbitrary files outside intended directory via\n  symbolic links or hard links in a gzipped tarball.\n\n\n  BUGTRAQ:20030203 ASA-0001: OpenBSD chpass/chfn/chsh file content leak'\n",
  "ID: '620'\nName: Unverified Password Change\nDescription: When setting a new password for a user, the product does not require\n  knowledge of the original password, or using another form of authentication.\nExtended_Description: This could be used by an attacker to change passwords for another\n  user, thus gaining the privileges associated with that user.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design: When prompting for a password change,\n  force the user to provide the original password in addition to the new password.\n\n\n  Architecture and Design: Do not use \"forgotten password\" functionality. But if you\n  must, ensure that you are only providing information to the actual user, e.g. by\n  using an email address or challenge question that the legitimate user already provided\n  in the past; do not allow the current user to change this identity information until\n  the correct password has been provided.'\nObserved_Examples: 'CVE-2007-0681: Web app allows remote attackers to change the passwords\n  of arbitrary users without providing the original password, and possibly perform\n  other unauthorized actions.\n\n\n  CVE-2000-0944: Web application password change utility doesn''t check the original\n  password.'\n",
  "ID: '621'\nName: Variable Extraction Error\nDescription: The product uses external input to determine the names of variables into\n  which information is extracted, without verifying that the names of the specified\n  variables are valid. This could cause the program to overwrite unintended variables.\nExtended_Description: 'For example, in PHP, extraction can be used to provide functionality\n  similar to register_globals, a dangerous functionality that is frequently disabled\n  in production systems. Calling extract() or import_request_variables() without the\n  proper arguments could allow arbitrary global variables to be overwritten, including\n  superglobals.\n\n  Similar functionality is possible in other interpreted languages, including custom\n  languages.'\nApplicable_Platforms:\n  Language: PHP\nPotential_Mitigations: 'Implementation: Use allowlists of variable names that can\n  be extracted.\n\n\n  Implementation: Consider refactoring your code to avoid extraction routines altogether.\n\n\n  Implementation: In PHP, call extract() with options such as EXTR_SKIP and EXTR_PREFIX_ALL;\n  call import_request_variables() with a prefix argument. Note that these capabilities\n  are not present in all PHP versions.'\nObserved_Examples: 'CVE-2006-7135: extract issue enables file inclusion\n\n\n  CVE-2006-7079: extract used for register_globals compatibility layer, enables path\n  traversal\n\n\n  CVE-2007-0649: extract() buried in include files makes post-disclosure analysis\n  confusing; original report had seemed incorrect.\n\n\n  CVE-2006-6661: extract() enables static code injection\n\n\n  CVE-2006-2828: import_request_variables() buried in include files makes post-disclosure\n  analysis confusing'\n",
  "ID: '622'\nName: Improper Validation of Function Hook Arguments\nDescription: The product adds hooks to user-accessible API functions, but it does\n  not properly validate the arguments. This could lead to resultant vulnerabilities.\nExtended_Description: Such hooks can be used in defensive software that runs with\n  privileges, such as anti-virus or firewall, which hooks kernel calls. When the arguments\n  are not validated, they could be used to bypass the protection scheme or attack\n  the product itself.\nPotential_Mitigations: 'Architecture and Design: Ensure that all arguments are verified,\n  as defined by the API you are protecting.\n\n\n  Architecture and Design: Drop privileges before invoking such functions, if possible.'\nObserved_Examples: 'CVE-2007-0708: DoS in firewall using standard Microsoft functions\n\n\n  CVE-2006-7160: DoS in firewall using standard Microsoft functions\n\n\n  CVE-2007-1376: function does not verify that its argument is the proper type, leading\n  to arbitrary memory write\n\n\n  CVE-2007-1220: invalid syscall arguments bypass code execution limits\n\n\n  CVE-2006-4541: DoS in IDS via NULL argument'\n",
  "ID: '623'\nName: Unsafe ActiveX Control Marked Safe For Scripting\nDescription: An ActiveX control is intended for restricted use, but it has been marked\n  as safe-for-scripting.\nExtended_Description: This might allow attackers to use dangerous functionality via\n  a web page that accesses the control, which can lead to different resultant vulnerabilities,\n  depending on the control's behavior.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: During development, do not mark it\n  as safe for scripting.\n\n\n  System Configuration: After distribution, you can set the kill bit for the control\n  so that it is not accessible from Internet Explorer.'\nObserved_Examples: 'CVE-2007-0617: control allows attackers to add malicious email\n  addresses to bypass spam limits\n\n\n  CVE-2007-0219: web browser uses certain COM objects as ActiveX\n\n\n  CVE-2006-6510: kiosk allows bypass to read files'\n",
  "ID: '624'\nName: Executable Regular Expression Error\nDescription: The product uses a regular expression that either (1) contains an executable\n  component with user-controlled inputs, or (2) allows a user to enable execution\n  by inserting pattern modifiers.\nExtended_Description: Case (2) is possible in the PHP preg_replace() function, and\n  possibly in other languages when a user-controlled input is inserted into a string\n  that is later parsed as a regular expression.\nApplicable_Platforms:\n  Language: PHP, Perl\nPotential_Mitigations: 'Implementation: The regular expression feature in some languages\n  allows inputs to be quoted or escaped before insertion, such as \\Q and \\E in Perl.'\nObserved_Examples: 'CVE-2006-2059: Executable regexp in PHP by inserting \"e\" modifier\n  into first argument to preg_replace\n\n\n  CVE-2005-3420: Executable regexp in PHP by inserting \"e\" modifier into first argument\n  to preg_replace\n\n\n  CVE-2006-2878: Complex curly syntax inserted into the replacement argument to PHP\n  preg_replace(), which uses the \"/e\" modifier\n\n\n  CVE-2006-2908: Function allows remote attackers to execute arbitrary PHP code via\n  the username field, which is used in a preg_replace function call with a /e (executable)\n  modifier.'\n",
  "ID: '625'\nName: Permissive Regular Expression\nDescription: The product uses a regular expression that does not sufficiently restrict\n  the set of allowed values.\nExtended_Description: 'This effectively causes the regexp to accept substrings that\n  match the pattern, which produces a partial comparison to the target. In some cases,\n  this can lead to other weaknesses. Common errors include:'\nApplicable_Platforms:\n  Language: Perl, PHP\nModes_Of_Introduction: 'Implementation: This problem is frequently found when the\n  regular expression is used in input validation or security features such as authentication.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: When applicable, ensure that the regular expression\n  marks beginning and ending string patterns, such as \"/^string$/\" for Perl.'\nObserved_Examples: 'CVE-2021-22204: Chain: regex in EXIF processor code does not correctly\n  determine where a string ends (CWE-625), enabling eval injection (CWE-95), as exploited\n  in the wild per CISA KEV.\n\n\n  CVE-2006-1895: \".*\" regexp leads to static code injection\n\n\n  CVE-2002-2175: insertion of username into regexp results in partial comparison,\n  causing wrong database entry to be updated when one username is a substring of another.\n\n\n  CVE-2006-4527: regexp intended to verify that all characters are legal, only checks\n  that at least one is legal, enabling file inclusion.\n\n\n  CVE-2005-1949: Regexp for IP address isn''t anchored at the end, allowing appending\n  of shell metacharacters.\n\n\n  CVE-2002-2109: Regexp isn''t \"anchored\" to the beginning or end, which allows spoofed\n  values that have trusted values as substrings.\n\n\n  CVE-2006-6511: regexp in .htaccess file allows access of files whose names contain\n  certain substrings\n\n\n  CVE-2006-6629: allow load of macro files whose names contain certain substrings.'\n",
  "ID: '626'\nName: Null Byte Interaction Error (Poison Null Byte)\nDescription: The product does not properly handle null bytes or NUL characters when\n  passing data between different representations or components.\nExtended_Description: 'A null byte (NUL character) can have different meanings across\n  representations or languages. For example, it is a string terminator in standard\n  C libraries, but Perl and PHP strings do not treat it as a terminator. When two\n  representations are crossed - such as when Perl or PHP invokes underlying C functionality\n  - this can produce an interaction error with unexpected results. Similar issues\n  have been reported for ASP. Other interpreters written in C might also be affected.\n\n  The poison null byte is frequently useful in path traversal attacks by terminating\n  hard-coded extensions that are added to a filename. It can play a role in regular\n  expression processing in PHP.'\nApplicable_Platforms:\n  Language: PHP, Perl, ASP.NET\nPotential_Mitigations: 'Implementation: Remove null bytes from all incoming strings.'\nObserved_Examples: 'CVE-2005-4155: NUL byte bypasses PHP regular expression check\n\n\n  CVE-2005-3153: inserting SQL after a NUL byte bypasses allowlist regexp, enabling\n  SQL injection'\n",
  "ID: '627'\nName: Dynamic Variable Evaluation\nDescription: In a language where the user can influence the name of a variable at\n  runtime, if the variable names are not controlled, an attacker can read or write\n  to arbitrary variables, or access arbitrary functions.\nExtended_Description: The resultant vulnerabilities depend on the behavior of the\n  application, both at the crossover point and in any control/data flow that is reachable\n  by the related variables or functions.\nApplicable_Platforms:\n  Language: PHP, Perl\nPotential_Mitigations: 'Implementation: Refactor the code to avoid dynamic variable\n  evaluation whenever possible.\n\n\n  Implementation: Use only allowlists of acceptable variable or function names.\n\n\n  Implementation: For function names, ensure that you are only calling functions that\n  accept the proper number of arguments, to avoid unexpected null arguments.'\nObserved_Examples: 'CVE-2009-0422: Chain: Dynamic variable evaluation allows resultant\n  remote file inclusion and path traversal.\n\n\n  CVE-2007-2431: Chain: dynamic variable evaluation in PHP program used to modify\n  critical, unexpected $_SERVER variable for resultant XSS.\n\n\n  CVE-2006-4904: Chain: dynamic variable evaluation in PHP program used to conduct\n  remote file inclusion.\n\n\n  CVE-2006-4019: Dynamic variable evaluation in mail program allows reading and modifying\n  attachments and preferences of other users.'\n",
  "ID: '628'\nName: Function Call with Incorrectly Specified Arguments\nDescription: The product calls a function, procedure, or routine with arguments that\n  are not correctly specified, leading to always-incorrect behavior and resultant\n  weaknesses.\nExtended_Description: 'There are multiple ways in which this weakness can be introduced,\n  including:'\nDetection_Methods: 'Other: Since these bugs typically introduce incorrect behavior\n  that is obvious to users, they are found quickly, unless they occur in rarely-tested\n  code paths. Managing the correct number of arguments can be made more difficult\n  in cases where format strings are used, or when variable numbers of arguments are\n  supported.'\nPotential_Mitigations: 'Build and Compilation: Once found, these issues are easy to\n  fix. Use code inspection tools and relevant compiler features to identify potential\n  violations. Pay special attention to code that is not likely to be exercised heavily\n  during QA.\n\n\n  Architecture and Design: Make sure your API''s are stable before you use them in\n  production code.'\nObserved_Examples: 'CVE-2006-7049: The method calls the functions with the wrong argument\n  order, which allows remote attackers to bypass intended access restrictions.'\n",
  "ID: '636'\nName: Not Failing Securely ('Failing Open')\nDescription: When the product encounters an error condition or failure, its design\n  requires it to fall back to a state that is less secure than other options that\n  are available, such as selecting the weakest encryption algorithm or using the most\n  permissive access control restrictions.\nExtended_Description: By entering a less secure state, the product inherits the weaknesses\n  associated with that state, making it easier to compromise. At the least, it causes\n  administrators to have a false sense of security. This weakness typically occurs\n  as a result of wanting to \"fail functional\" to minimize administration and support\n  costs, instead of \"failing safe.\"\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Subdivide and allocate resources\n  and components so that a failure in one part does not affect the entire product.'\nObserved_Examples: 'CVE-2007-5277: The failure of connection attempts in a web browser\n  resets DNS pin restrictions. An attacker can then bypass the same origin policy\n  by rebinding a domain name to a different IP address. This was an attempt to \"fail\n  functional.\"\n\n\n  CVE-2006-4407: Incorrect prioritization leads to the selection of a weaker cipher.\n  Although it is not known whether this issue occurred in implementation or design,\n  it is feasible that a poorly designed algorithm could be a factor.'\n",
  "ID: '637'\nName: Unnecessary Complexity in Protection Mechanism (Not Using 'Economy of Mechanism')\nDescription: The product uses a more complex mechanism than necessary, which could\n  lead to resultant weaknesses when the mechanism is not correctly understood, modeled,\n  configured, implemented, or used.\nExtended_Description: Security mechanisms should be as simple as possible. Complex\n  security mechanisms may engender partial implementations and compatibility problems,\n  with resulting mismatches in assumptions and implemented security. A corollary of\n  this principle is that data specifications should be as simple as possible, because\n  complex data specifications result in complex validation code. Complex tasks and\n  systems may also need to be guarded by complex security checks, so simple systems\n  should be preferred.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Avoid complex security mechanisms\n  when simpler ones would meet requirements. Avoid complex data models, and unnecessarily\n  complex operations. Adopt architectures that provide guarantees, simplify understanding\n  through elegance and abstraction, and that can be implemented similarly. Modularize,\n  isolate and do not trust complex code, and apply other secure programming principles\n  on these modules (e.g., least privilege) to mitigate vulnerabilities.'\nObserved_Examples: 'CVE-2007-6067: Support for complex regular expressions leads to\n  a resultant algorithmic complexity weakness (CWE-407).\n\n\n  CVE-2007-1552: Either a filename extension and a Content-Type header could be used\n  to infer the file type, but the developer only checks the Content-Type, enabling\n  unrestricted file upload (CWE-434).\n\n\n  CVE-2007-6479: In Apache environments, a \"filename.php.gif\" can be redirected to\n  the PHP interpreter instead of being sent as an image/gif directly to the user.\n  Not knowing this, the developer only checks the last extension of a submitted filename,\n  enabling arbitrary code execution.\n\n\n  CVE-2005-2148: The developer cleanses the $_REQUEST superglobal array, but PHP also\n  populates $_GET, allowing attackers to bypass the protection mechanism and conduct\n  SQL injection attacks against code that uses $_GET.'\n",
  "ID: '638'\nName: Not Using Complete Mediation\nDescription: The product does not perform access checks on a resource every time the\n  resource is accessed by an entity, which can create resultant weaknesses if that\n  entity's rights or privileges change over time.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Invalidate cached privileges, file\n  handles or descriptors, or other access credentials whenever identities, processes,\n  policies, roles, capabilities or permissions change. Perform complete authentication\n  checks before accepting, caching and reusing data, dynamic content and code (scripts).\n  Avoid caching access control decisions as much as possible.\n\n\n  Architecture and Design: Identify all possible code paths that might access sensitive\n  resources. If possible, create and use a single interface that performs the access\n  checks, and develop code standards that require use of this interface.'\nObserved_Examples: 'CVE-2007-0408: Server does not properly validate client certificates\n  when reusing cached connections.'\nRelated_Attack_Patterns: '104: '\n",
  "ID: '639'\nName: Authorization Bypass Through User-Controlled Key\nDescription: The system's authorization functionality does not prevent one user from\n  gaining access to another user's data or record by modifying the key value identifying\n  the data.\nExtended_Description: 'Retrieval of a user record occurs in the system based on some\n  key value that is under user control. The key would typically identify a user-related\n  record stored in the system and would be used to lookup that record for presentation\n  to the user. It is likely that an attacker would have to be an authenticated user\n  in the system. However, the authorization process would not properly check the data\n  access operation to ensure that the authenticated user performing the operation\n  has sufficient entitlements to perform the requested data access, hence bypassing\n  any other authorization checks present in the system.\n\n  For example, attackers can look at places where user specific data is retrieved\n  (e.g. search screens) and determine whether the key for the item being looked up\n  is controllable externally. The key may be a hidden field in the HTML form field,\n  might be passed as a URL parameter or as an unencrypted cookie variable, then in\n  each of these cases it will be possible to tamper with the key value.\n\n  One manifestation of this weakness is when a system uses sequential or otherwise\n  easily-guessable session IDs that would allow one user to easily switch to another\n  user''s session and read/modify their data.'\nAlternate_Terms: 'Insecure Direct Object Reference / IDOR: The \"Insecure Direct Object\n  Reference\" term, as described in the OWASP Top Ten, is broader than this CWE because\n  it also covers path traversal (CWE-22). Within the context of vulnerability theory,\n  there is a similarity between the OWASP concept and CWE-706: Use of Incorrectly-Resolved\n  Name or Reference.\n\n\n  Broken Object Level Authorization / BOLA: BOLA is used in the 2019 OWASP API Security\n  Top 10 and is said to be the same as IDOR.\n\n\n  Horizontal Authorization: \"Horizontal Authorization\" is used to describe situations\n  in which two users have the same privilege level, but must be prevented from accessing\n  each other''s resources. This is fairly common when using key-based access to resources\n  in a multi-user context.'\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: For each and every data access, ensure\n  that the user has sufficient privilege to access the record that is being requested.\n\n\n  Architecture and Design\n\n  Implementation: Make sure that the key that is used in the lookup of a specific\n  user''s record is not controllable externally by the user or that any tampering\n  can be detected.\n\n\n  Architecture and Design: Use encryption in order to make it more difficult to guess\n  other legitimate values of the key or associate a digital signature with the key\n  so that the server can verify that there has been no tampering.'\n",
  "ID: '64'\nName: Windows Shortcut Following (.LNK)\nDescription: The product, when opening a file or directory, does not sufficiently\n  handle when the file is a Windows shortcut (.LNK) whose target is outside of the\n  intended control sphere. This could allow an attacker to cause the product to operate\n  on unauthorized files.\nExtended_Description: The shortcut (file with the .lnk extension) can permit an attacker\n  to read/write a file that they originally did not have permissions to access.\nApplicable_Platforms:\n  Operating_System: Windows\nAlternate_Terms: \"Windows symbolic link following: \\n\\nsymlink: \"\nPotential_Mitigations: 'Architecture and Design: Follow the principle of least privilege\n  when assigning access rights to entities in a software system.\n\n  Denying access to a file can prevent an attacker from replacing that file with a\n  link to a sensitive file. Ensure good compartmentalization in the system to provide\n  protected areas that can be trusted.'\nObserved_Examples: 'CVE-2019-19793: network access control service executes program\n  with high privileges and allows symlink to invoke another executable or perform\n  DLL injection.\n\n\n  CVE-2000-0342: Mail client allows remote attackers to bypass the user warning for\n  executable attachments such as .exe, .com, and .bat by using a .lnk file that refers\n  to the attachment, aka \"Stealth Attachment.\"\n\n\n  CVE-2001-1042: FTP server allows remote attackers to read arbitrary files and directories\n  by uploading a .lnk (link) file that points to the target file.\n\n\n  CVE-2001-1043: FTP server allows remote attackers to read arbitrary files and directories\n  by uploading a .lnk (link) file that points to the target file.\n\n\n  CVE-2005-0587: Browser allows remote malicious web sites to overwrite arbitrary\n  files by tricking the user into downloading a .LNK (link) file twice, which overwrites\n  the file that was referenced in the first .LNK file.\n\n\n  CVE-2001-1386: \".LNK.\" - .LNK with trailing dot\n\n\n  CVE-2003-1233: Rootkits can bypass file access restrictions to Windows kernel directories\n  using NtCreateSymbolicLinkObject function to create symbolic link'\n",
  "ID: '640'\nName: Weak Password Recovery Mechanism for Forgotten Password\nDescription: The product contains a mechanism for users to recover or change their\n  passwords without knowing the original password, but the mechanism is weak.\nExtended_Description: 'It is common for an application to have a mechanism that provides\n  a means for a user to gain access to their account in the event they forget their\n  password. Very often the password recovery mechanism is weak, which has the effect\n  of making it more likely that it would be possible for a person other than the legitimate\n  system user to gain access to that user''s account. Weak password recovery schemes\n  completely undermine a strong password authentication scheme.\n\n  This weakness may be that the security question is too easy to guess or find an\n  answer to (e.g. because the question is too common, or the answers can be found\n  using social media). Or there might be an implementation weakness in the password\n  recovery mechanism code that may for instance trick the system into e-mailing the\n  new password to an e-mail account other than that of the user. There might be no\n  throttling done on the rate of password resets so that a legitimate user can be\n  denied service by an attacker if an attacker tries to recover their password in\n  a rapid succession. The system may send the original password to the user rather\n  than generating a new temporary password. In summary, password recovery functionality,\n  if not carefully designed and implemented can often become the system''s weakest\n  link that can be misused in a way that would allow an attacker to gain unauthorized\n  access to the system.'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Make sure that all input supplied\n  by the user to the password recovery mechanism is thoroughly filtered and validated.\n\n\n  Architecture and Design: Do not use standard weak security questions and use several\n  security questions.\n\n\n  Architecture and Design: Make sure that there is throttling on the number of incorrect\n  answers to a security question. Disable the password recovery functionality after\n  a certain (small) number of incorrect guesses.\n\n\n  Architecture and Design: Require that the user properly answers the security question\n  prior to resetting their password and sending the new password to the e-mail address\n  of record.\n\n\n  Architecture and Design: Never allow the user to control what e-mail address the\n  new password will be sent to in the password recovery mechanism.\n\n\n  Architecture and Design: Assign a new temporary password rather than revealing the\n  original password.'\nRelated_Attack_Patterns: '50: '\n",
  "ID: '641'\nName: Improper Restriction of Names for Files and Other Resources\nDescription: The product constructs the name of a file or other resource using input\n  from an upstream component, but it does not restrict or incorrectly restricts the\n  resulting name.\nExtended_Description: This may produce resultant weaknesses. For instance, if the\n  names of these resources contain scripting characters, it is possible that a script\n  may get executed in the client's browser if the application ever displays the name\n  of the resource on a dynamically generated web page. Alternately, if the resources\n  are consumed by some application parser, a specially crafted name can exploit some\n  vulnerability internal to the parser, potentially resulting in execution of arbitrary\n  code on the server machine. The problems will vary based on the context of usage\n  of such malformed resource names and whether vulnerabilities are present in or assumptions\n  are made by the targeted technology that would make code execution possible.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design: Do not allow users to control names\n  of resources used on the server side.\n\n\n  Architecture and Design: Perform allowlist input validation at entry points and\n  also before consuming the resources. Reject bad file names rather than trying to\n  cleanse them.\n\n\n  Architecture and Design: Make sure that technologies consuming the resources are\n  not vulnerable (e.g. buffer overflow, format string, etc.) in a way that would allow\n  code execution if the name of the resource is malformed.'\n",
  "ID: '642'\nName: External Control of Critical State Data\nDescription: The product stores security-critical state information about its users,\n  or the product itself, in a location that is accessible to unauthorized actors.\nExtended_Description: 'If an attacker can modify the state information without detection,\n  then it could be used to perform unauthorized actions or access unexpected resources,\n  since the application programmer does not expect that the state can be changed.\n\n  State information can be stored in various locations such as a cookie, in a hidden\n  web form field, input parameter or argument, an environment variable, a database\n  record, within a settings file, etc. All of these locations have the potential to\n  be modified by an attacker. When this state information is used to control security\n  or determine resource usage, then it may create a vulnerability. For example, an\n  application may perform authentication, then save the state in an \"authenticated=true\"\n  cookie. An attacker may simply create this cookie in order to bypass the authentication.'\nApplicable_Platforms:\n  Technology: Web Server\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Understand all the potential locations\n  that are accessible to attackers. For example, some programmers assume that cookies\n  and hidden form fields cannot be modified by an attacker, or they may not consider\n  that environment variables can be modified before a privileged program is invoked.\n\n\n  Architecture and Design: Store state information and sensitive data on the server\n  side only.\n\n  Ensure that the system definitively and unambiguously keeps track of its own state\n  and user state and has rules defined for legitimate state transitions. Do not allow\n  any application user to affect state directly in any way other than through legitimate\n  actions leading to state transitions.\n\n  If information must be stored on the client, do not do so without encryption and\n  integrity checking, or otherwise having a mechanism on the server side to catch\n  tampering. Use a message authentication code (MAC) algorithm, such as Hash Message\n  Authentication Code (HMAC) [REF-529]. Apply this against the state or sensitive\n  data that has to be exposed, which can guarantee the integrity of the data - i.e.,\n  that the data has not been modified. Ensure that a strong hash function is used\n  (CWE-328).\n\n\n  Architecture and Design: Store state information on the server side only. Ensure\n  that the system definitively and unambiguously keeps track of its own state and\n  user state and has rules defined for legitimate state transitions. Do not allow\n  any application user to affect state directly in any way other than through legitimate\n  actions leading to state transitions.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  With a stateless protocol such as HTTP, use some frameworks can maintain the state\n  for you.\n\n  Examples include ASP.NET View State and the OWASP ESAPI Session Management feature.\n\n  Be careful of language features that provide state support, since these might be\n  provided as a convenience to the programmer and may not be considering security.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Testing: Use dynamic tools and techniques that interact with the product using large\n  test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness\n  testing, and fault injection. The product''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.\n\n\n  Testing: Use tools and techniques that require manual (human) analysis, such as\n  penetration testing, threat modeling, and interactive tools that allow the tester\n  to record and modify an active session. These may be more effective than strictly\n  automated techniques. This is especially the case with weaknesses that are related\n  to design and business rules.'\nObserved_Examples: 'CVE-2005-2428: Mail client stores password hashes for unrelated\n  accounts in a hidden form field.\n\n\n  CVE-2008-0306: Privileged program trusts user-specified environment variable to\n  modify critical configuration settings.\n\n\n  CVE-1999-0073: Telnet daemon allows remote clients to specify critical environment\n  variables for the server, leading to code execution.\n\n\n  CVE-2007-4432: Untrusted search path vulnerability through modified LD_LIBRARY_PATH\n  environment variable.\n\n\n  CVE-2006-7191: Untrusted search path vulnerability through modified LD_LIBRARY_PATH\n  environment variable.\n\n\n  CVE-2008-5738: Calendar application allows bypass of authentication by setting a\n  certain cookie value to 1.\n\n\n  CVE-2008-5642: Setting of a language preference in a cookie enables path traversal\n  attack.\n\n\n  CVE-2008-5125: Application allows admin privileges by setting a cookie value to\n  \"admin.\"\n\n\n  CVE-2008-5065: Application allows admin privileges by setting a cookie value to\n  \"admin.\"\n\n\n  CVE-2008-4752: Application allows admin privileges by setting a cookie value to\n  \"admin.\"\n\n\n  CVE-2000-0102: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2000-0253: Shopping cart allows price modification via hidden form field.\n\n\n  CVE-2008-1319: Server allows client to specify the search path, which can be modified\n  to point to a program that the client has uploaded.'\nRelated_Attack_Patterns: \"21: \\n\\n31: \"\n",
  "ID: '643'\nName: Improper Neutralization of Data within XPath Expressions ('XPath Injection')\nDescription: The product uses external input to dynamically construct an XPath expression\n  used to retrieve data from an XML database, but it does not neutralize or incorrectly\n  neutralizes that input. This allows an attacker to control the structure of the\n  query.\nExtended_Description: The net effect is that the attacker will have control over the\n  information selected from the XML database and may use that ability to control application\n  flow, modify logic, retrieve unauthorized data, or bypass important checks (e.g.\n  authentication).\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use parameterized XPath queries (e.g. using\n  XQuery). This will help ensure separation between data plane and control plane.\n\n\n  Implementation: Properly validate user input. Reject data where appropriate, filter\n  where appropriate and escape where appropriate. Make sure input that will be used\n  in XPath queries is safe in that context.'\n",
  "ID: '644'\nName: Improper Neutralization of HTTP Headers for Scripting Syntax\nDescription: The product does not neutralize or incorrectly neutralizes web scripting\n  syntax in HTTP headers that can be used by web browser components that can process\n  raw headers, such as Flash.\nExtended_Description: 'An attacker may be able to conduct cross-site scripting and\n  other attacks against users who have these components enabled.\n\n  If a product does not neutralize user controlled data being placed in the header\n  of an HTTP response coming from the server, the header may contain a script that\n  will get executed in the client''s browser context, potentially resulting in a cross\n  site scripting vulnerability or possibly an HTTP response splitting attack. It is\n  important to carefully control data that is being placed both in HTTP response header\n  and in the HTTP response body to ensure that no scripting syntax is present, taking\n  various encodings into account.'\nApplicable_Platforms:\n  Technology: Web Based\nPotential_Mitigations: 'Architecture and Design: Perform output validation in order\n  to filter/escape/encode unsafe data that is being passed from the server in an HTTP\n  response header.\n\n\n  Architecture and Design: Disable script execution functionality in the clients''\n  browser.'\nObserved_Examples: 'CVE-2006-3918: Web server does not remove the Expect header from\n  an HTTP request when it is reflected back in an error message, allowing a Flash\n  SWF file to perform XSS attacks.'\n",
  "ID: '645'\nName: Overly Restrictive Account Lockout Mechanism\nDescription: The product contains an account lockout protection mechanism, but the\n  mechanism is too restrictive and can be triggered too easily, which allows attackers\n  to deny service to legitimate users by causing their accounts to be locked out.\nExtended_Description: Account lockout is a security feature often present in applications\n  as a countermeasure to the brute force attack on the password based authentication\n  mechanism of the system. After a certain number of failed login attempts, the users'\n  account may be disabled for a certain period of time or until it is unlocked by\n  an administrator. Other security events may also possibly trigger account lockout.\n  However, an attacker may use this very security feature to deny service to legitimate\n  system users. It is therefore important to ensure that the account lockout security\n  mechanism is not overly restrictive.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Implement more intelligent password\n  throttling mechanisms such as those which take IP address into account, in addition\n  to the login name.\n\n\n  Architecture and Design: Implement a lockout timeout that grows as the number of\n  incorrect login attempts goes up, eventually resulting in a complete lockout.\n\n\n  Architecture and Design: Consider alternatives to account lockout that would still\n  be effective against password brute force attacks, such as presenting the user machine\n  with a puzzle to solve (makes it do some computation).'\nRelated_Attack_Patterns: '2: '\n",
  "ID: '646'\nName: Reliance on File Name or Extension of Externally-Supplied File\nDescription: The product allows a file to be uploaded, but it relies on the file name\n  or extension of the file to determine the appropriate behaviors. This could be used\n  by attackers to cause the file to be misclassified and processed in a dangerous\n  fashion.\nExtended_Description: An application might use the file name or extension of a user-supplied\n  file to determine the proper course of action, such as selecting the correct process\n  to which control should be passed, deciding what data should be made available,\n  or what resources should be allocated. If the attacker can cause the code to misclassify\n  the supplied file, then the wrong action could occur. For example, an attacker could\n  supply a file that ends in a \".php.gif\" extension that appears to be a GIF image,\n  but would be processed as PHP code. In extreme cases, code execution is possible,\n  but the attacker could also cause exhaustion of resources, denial of service, exposure\n  of debug or system data (including application source code), or being bound to a\n  particular server side process. This weakness may be due to a vulnerability in any\n  of the technologies used by the web and application servers, due to misconfiguration,\n  or resultant from another flaw in the application itself.\nApplicable_Platforms:\n  Technology: Web Server\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Make decisions on the server side\n  based on file content and not on file name or extension.'\nRelated_Attack_Patterns: '209: '\n",
  "ID: '647'\nName: Use of Non-Canonical URL Paths for Authorization Decisions\nDescription: The product defines policy namespaces and makes authorization decisions\n  based on the assumption that a URL is canonical. This can allow a non-canonical\n  URL to bypass the authorization.\nExtended_Description: 'If an application defines policy namespaces and makes authorization\n  decisions based on the URL, but it does not require or convert to a canonical URL\n  before making the authorization decision, then it opens the application to attack.\n  For example, if the application only wants to allow access to http://www.example.com/mypage,\n  then the attacker might be able to bypass this restriction using equivalent URLs\n  such as:\n\n  Therefore it is important to specify access control policy that is based on the\n  path information in some canonical form with all alternate encodings rejected (which\n  can be accomplished by a default deny rule).'\nApplicable_Platforms:\n  Technology: Web Server\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Operation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Make access control policy based\n  on path information in canonical form. Use very restrictive regular expressions\n  to validate that the path is in the expected form.\n\n\n  Architecture and Design: Reject all alternate path encodings that are not in the\n  expected canonical form.'\n",
  "ID: '648'\nName: Incorrect Use of Privileged APIs\nDescription: The product does not conform to the API requirements for a function call\n  that requires extra privileges. This could allow attackers to gain privileges by\n  causing the function to be called incorrectly.\nExtended_Description: 'When a product contains certain functions that perform operations\n  requiring an elevated level of privilege, the caller of a privileged API must be\n  careful to:\n\n  If the caller of the API does not follow these requirements, then it may allow a\n  malicious user or process to elevate their privilege, hijack the process, or steal\n  sensitive data.\n\n  For instance, it is important to know if privileged APIs do not shed their privileges\n  before returning to the caller or if the privileged function might make certain\n  assumptions about the data, context or state information passed to it by the caller.\n  It is important to always know when and how privileged APIs can be called in order\n  to ensure that their elevated level of privilege cannot be exploited.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Implementation: Before calling privileged APIs, always ensure\n  that the assumptions made by the privileged code hold true prior to making the call.\n\n\n  Architecture and Design: Know architecture and implementation weaknesses of the\n  privileged APIs and make sure to account for these weaknesses before calling the\n  privileged APIs to ensure that they can be called safely.\n\n\n  Implementation: If privileged APIs make certain assumptions about data, context\n  or state validity that are passed by the caller, the calling code must ensure that\n  these assumptions have been validated prior to making the call.\n\n\n  Implementation: If privileged APIs do not shed their privilege prior to returning\n  to the calling code, then calling code needs to shed these privileges immediately\n  and safely right after the call to the privileged APIs. In particular, the calling\n  code needs to ensure that a privileged thread of execution will never be returned\n  to the user or made available to user-controlled processes.\n\n\n  Implementation: Only call privileged APIs from safe, consistent and expected state.\n\n\n  Implementation: Ensure that a failure or an error will not leave a system in a state\n  where privileges are not properly shed and privilege escalation is possible (i.e.\n  fail securely with regards to handling of privileges).'\nObserved_Examples: 'CVE-2003-0645: A Unix utility that displays online help files,\n  if installed setuid, could allow a local attacker to gain privileges when a particular\n  file-opening function is called.'\nRelated_Attack_Patterns: \"107: \\n\\n234: \"\n",
  "ID: '649'\nName: Reliance on Obfuscation or Encryption of Security-Relevant Inputs without Integrity\n  Checking\nDescription: The product uses obfuscation or encryption of inputs that should not\n  be mutable by an external actor, but the product does not use integrity checks to\n  detect if those inputs have been modified.\nExtended_Description: When an application relies on obfuscation or incorrectly applied\n  / weak encryption to protect client-controllable tokens or parameters, that may\n  have an effect on the user state, system state, or some decision made on the server.\n  Without protecting the tokens/parameters for integrity, the application is vulnerable\n  to an attack where an adversary traverses the space of possible values of the said\n  token/parameter in order to attempt to gain an advantage. The goal of the attacker\n  is to find another admissible value that will somehow elevate their privileges in\n  the system, disclose information or change the behavior of the system in some way\n  beneficial to the attacker. If the application does not protect these critical tokens/parameters\n  for integrity, it will not be able to determine that these values have been tampered\n  with. Measures that are used to protect data for confidentiality should not be relied\n  upon to provide the integrity service.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\nPotential_Mitigations: 'Architecture and Design: Protect important client controllable\n  tokens/parameters for integrity using PKI methods (i.e. digital signatures) or other\n  means, and checks for integrity on the server side.\n\n\n  Architecture and Design: Repeated requests from a particular user that include invalid\n  values of tokens/parameters (those that should not be changed manually by users)\n  should result in the user account lockout.\n\n\n  Architecture and Design: Client side tokens/parameters should not be such that it\n  would be easy/predictable to guess another valid state.\n\n\n  Architecture and Design: Obfuscation should not be relied upon. If encryption is\n  used, it needs to be properly applied (i.e. proven algorithm and implementation,\n  use padding, use random initialization vector, user proper encryption mode). Even\n  with proper encryption where the ciphertext does not leak information about the\n  plaintext or reveal its structure, compromising integrity is possible (although\n  less likely) without the provision of the integrity service.'\nObserved_Examples: 'CVE-2005-0039: An IPSec configuration does not perform integrity\n  checking of the IPSec packet as the result of either not configuring ESP properly\n  to support the integrity service or using AH improperly. In either case, the security\n  gateway receiving the IPSec packet would not validate the integrity of the packet\n  to ensure that it was not changed. Thus if the packets were intercepted the attacker\n  could undetectably change some of the bits in the packets. The meaningful bit flipping\n  was possible due to the known weaknesses in the CBC encryption mode. Since the attacker\n  knew the structure of the packet, they were able (in one variation of the attack)\n  to use bit flipping to change the destination IP of the packet to the destination\n  machine controlled by the attacker. And so the destination security gateway would\n  decrypt the packet and then forward the plaintext to the machine controlled by the\n  attacker. The attacker could then read the original message. For instance if VPN\n  was used with the vulnerable IPSec configuration the attacker could read the victim''s\n  e-mail. This vulnerability demonstrates the need to enforce the integrity service\n  properly when critical data could be modified by an attacker. This problem might\n  have also been mitigated by using an encryption mode that is not susceptible to\n  bit flipping attacks, but the preferred mechanism to address this problem still\n  remains message verification for integrity. While this attack focuses on the network\n  layer and requires an entity that controls part of the communication path such as\n  a router, the situation is not much different at the software level, where an attacker\n  can modify tokens/parameters used by the application.'\nRelated_Attack_Patterns: '463: '\n",
  "ID: '65'\nName: Windows Hard Link\nDescription: The product, when opening a file or directory, does not sufficiently\n  handle when the name is associated with a hard link to a target that is outside\n  of the intended control sphere. This could allow an attacker to cause the product\n  to operate on unauthorized files.\nExtended_Description: Failure for a system to check for hard links can result in vulnerability\n  to different types of attacks. For example, an attacker can escalate their privileges\n  if a file used by a privileged program is replaced with a hard link to a sensitive\n  file (e.g. AUTOEXEC.BAT). When the process opens the file, the attacker can assume\n  the privileges of that process, or prevent the program from accurately processing\n  data.\nApplicable_Platforms:\n  Operating_System: Windows\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Follow the principle of least privilege\n  when assigning access rights to entities in a software system.\n\n  Denying access to a file can prevent an attacker from replacing that file with a\n  link to a sensitive file. Ensure good compartmentalization in the system to provide\n  protected areas that can be trusted.'\nObserved_Examples: 'CVE-2002-0725: File system allows local attackers to hide file\n  usage activities via a hard link to the target file, which causes the link to be\n  recorded in the audit trail instead of the target file.\n\n\n  CVE-2003-0844: Web server plugin allows local users to overwrite arbitrary files\n  via a symlink attack on predictable temporary filenames.'\n",
  "ID: '650'\nName: Trusting HTTP Permission Methods on the Server Side\nDescription: The server contains a protection mechanism that assumes that any URI\n  that is accessed using HTTP GET will not cause a state change to the associated\n  resource. This might allow attackers to bypass intended access restrictions and\n  conduct resource modification and deletion attacks, since some applications allow\n  GET to modify state.\nExtended_Description: The HTTP GET method and some other methods are designed to retrieve\n  resources and not to alter the state of the application or resources on the server\n  side. Furthermore, the HTTP specification requires that GET requests (and other\n  requests) should not have side effects. Believing that it will be enough to prevent\n  unintended resource alterations, an application may disallow the HTTP requests to\n  perform DELETE, PUT and POST operations on the resource representation. However,\n  there is nothing in the HTTP protocol itself that actually prevents the HTTP GET\n  method from performing more than just query of the data. Developers can easily code\n  programs that accept a HTTP GET request that do in fact create, update or delete\n  data on the server. For instance, it is a common practice with REST based Web Services\n  to have HTTP GET requests modifying resources on the server side. However, whenever\n  that happens, the access control needs to be properly enforced in the application.\n  No assumptions should be made that only HTTP DELETE, PUT, POST, and other methods\n  have the power to alter the representation of the resource being accessed in the\n  request.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'System Configuration: Configure ACLs on the server side to\n  ensure that proper level of access control is defined for each accessible resource\n  representation.'\n",
  "ID: '651'\nName: Exposure of WSDL File Containing Sensitive Information\nDescription: The Web services architecture may require exposing a Web Service Definition\n  Language (WSDL) file that contains information on the publicly accessible services\n  and how callers of these services should interact with them (e.g. what parameters\n  they expect and what types they return).\nExtended_Description: 'An information exposure may occur if any of the following apply:'\nApplicable_Platforms:\n  Technology: Web Server\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Limit access to the WSDL file as\n  much as possible. If services are provided only to a limited number of entities,\n  it may be better to provide WSDL privately to each of these entities than to publish\n  WSDL publicly.\n\n\n  Architecture and Design: Make sure that WSDL does not describe methods that should\n  not be publicly accessible. Make sure to protect service methods that should not\n  be publicly accessible with access controls.\n\n\n  Architecture and Design: Do not use method names in WSDL that might help an adversary\n  guess names of private methods/resources used by the service.'\n",
  "ID: '652'\nName: Improper Neutralization of Data within XQuery Expressions ('XQuery Injection')\nDescription: The product uses external input to dynamically construct an XQuery expression\n  used to retrieve data from an XML database, but it does not neutralize or incorrectly\n  neutralizes that input. This allows an attacker to control the structure of the\n  query.\nExtended_Description: The net effect is that the attacker will have control over the\n  information selected from the XML database and may use that ability to control application\n  flow, modify logic, retrieve unauthorized data, or bypass important checks (e.g.\n  authentication).\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Implementation: Use parameterized queries. This will help\n  ensure separation between data plane and control plane.\n\n\n  Implementation: Properly validate user input. Reject data where appropriate, filter\n  where appropriate and escape where appropriate. Make sure input that will be used\n  in XQL queries is safe in that context.'\n",
  "ID: '653'\nName: Improper Isolation or Compartmentalization\nDescription: The product does not properly compartmentalize or isolate functionality,\n  processes, or resources that require different privilege levels, rights, or permissions.\nExtended_Description: When a weakness occurs in functionality that is accessible by\n  lower-privileged users, then without strong boundaries, an attack might extend the\n  scope of the damage to higher-privileged users.\nAlternate_Terms: 'Separation of Privilege: Some people and publications use the term\n  \"Separation of Privilege\" to describe this weakness, but this term has dual meanings\n  in current usage. This node conflicts with the original definition of \"Separation\n  of Privilege\" by Saltzer and Schroeder; that original definition is more closely\n  associated with CWE-654. Because there are multiple interpretations, use of the\n  \"Separation of Privilege\" term is discouraged.'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Break up privileges between different\n  modules, objects, or entities. Minimize the interfaces between modules and require\n  strong access control between them.'\nObserved_Examples: 'CVE-2019-6260: Baseboard Management Controller (BMC) device implements\n  Advanced High-performance Bus (AHB) bridges that do not require authentication for\n  arbitrary read and write access to the BMC''s physical address space from the host,\n  and possibly the network [REF-1138].'\n",
  "ID: '654'\nName: Reliance on a Single Factor in a Security Decision\nDescription: A protection mechanism relies exclusively, or to a large extent, on the\n  evaluation of a single condition or the integrity of a single object or entity in\n  order to make a decision about granting access to restricted resources or functionality.\nAlternate_Terms: 'Separation of Privilege: Some people and publications use the term\n  \"Separation of Privilege\" to describe this weakness, but this term has dual meanings\n  in current usage. While this entry is closely associated with the original definition\n  of \"Separation of Privilege\" by Saltzer and Schroeder, others use the same term\n  to describe poor compartmentalization (CWE-653). Because there are multiple interpretations,\n  use of the \"Separation of Privilege\" term is discouraged.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Architecture and Design: Use multiple simultaneous checks\n  before granting access to critical operations or granting critical privileges. A\n  weaker but helpful mitigation is to use several successive checks (multiple layers\n  of security).\n\n\n  Architecture and Design: Use redundant access rules on different choke points (e.g.,\n  firewalls).'\nRelated_Attack_Patterns: \"16: \\n\\n274: \\n\\n49: \\n\\n55: \\n\\n560: \\n\\n565: \\n\\n600:\\\n  \\ \\n\\n652: \\n\\n653: \\n\\n70: \"\n",
  "ID: '655'\nName: Insufficient Psychological Acceptability\nDescription: The product has a protection mechanism that is too difficult or inconvenient\n  to use, encouraging non-malicious users to disable or bypass the mechanism, whether\n  by accident or on purpose.\nPotential_Mitigations: 'Testing: Where possible, perform human factors and usability\n  studies to identify where your product''s security mechanisms are difficult to use,\n  and why.\n\n\n  Architecture and Design: Make the security mechanism as seamless as possible, while\n  also providing the user with sufficient details when a security decision produces\n  unexpected results.'\n",
  "ID: '656'\nName: Reliance on Security Through Obscurity\nDescription: The product uses a protection mechanism whose strength depends heavily\n  on its obscurity, such that knowledge of its algorithms or key data is sufficient\n  to defeat the mechanism.\nExtended_Description: This reliance on \"security through obscurity\" can produce resultant\n  weaknesses if an attacker is able to reverse engineer the inner workings of the\n  mechanism. Note that obscurity can be one small part of defense in depth, since\n  it can create more work for an attacker; however, it is a significant risk if used\n  as the primary means of protection.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design: Always consider whether knowledge\n  of your code or design is sufficient to break it. Reverse engineering is a highly\n  successful discipline, and financially feasible for motivated adversaries. Black-box\n  techniques are established for binary analysis of executables that use obfuscation,\n  runtime analysis of proprietary protocols, inferring file formats, and others.\n\n\n  Architecture and Design: When available, use publicly-vetted algorithms and procedures,\n  as these are more likely to undergo more extensive security analysis and testing.\n  This is especially the case with encryption and authentication.'\nObserved_Examples: 'CVE-2006-6588: Reliance on hidden form fields in a web application.\n  Many web application vulnerabilities exist because the developer did not consider\n  that \"hidden\" form fields can be processed using a modified client.\n\n\n  CVE-2006-7142: Hard-coded cryptographic key stored in executable program.\n\n\n  CVE-2005-4002: Hard-coded cryptographic key stored in executable program.\n\n\n  CVE-2006-4068: Hard-coded hashed values for username and password contained in client-side\n  script, allowing brute-force offline attacks.'\n",
  "ID: '657'\nName: Violation of Secure Design Principles\nDescription: The product violates well-established principles for secure design.\nExtended_Description: This can introduce resultant weaknesses or make it easier for\n  developers to introduce related weaknesses during implementation. Because code is\n  centered around design, it can be resource-intensive to fix design problems.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\n",
  "ID: '66'\nName: Improper Handling of File Names that Identify Virtual Resources\nDescription: The product does not handle or incorrectly handles a file name that identifies\n  a \"virtual\" resource that is not directly specified within the directory that is\n  associated with the file name, causing the product to perform file-based operations\n  on a resource that is not a file.\nExtended_Description: Virtual file names are represented like normal file names, but\n  they are effectively aliases for other resources that do not behave like normal\n  files. Depending on their functionality, they could be alternate entities. They\n  are not necessarily listed in directories.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\n",
  "ID: '662'\nName: Improper Synchronization\nDescription: The product utilizes multiple threads or processes to allow temporary\n  access to a shared resource that can only be exclusive to one process at a time,\n  but it does not properly synchronize these actions, which might cause simultaneous\n  accesses of this resource by multiple threads or processes.\nExtended_Description: Synchronization refers to a variety of behaviors and mechanisms\n  that allow two or more independently-operating processes or threads to ensure that\n  they operate on shared resources in predictable ways that do not interfere with\n  each other.  Some shared resource operations cannot be executed atomically; that\n  is, multiple steps must be guaranteed to execute sequentially, without any interference\n  by other processes.  Synchronization mechanisms vary widely, but they may include\n  locking, mutexes, and semaphores.  When a multi-step operation on a shared resource\n  cannot be guaranteed to execute independent of interference, then the resulting\n  behavior can be unpredictable. Improper synchronization could lead to data or memory\n  corruption, denial of service, etc.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Use industry standard APIs to synchronize\n  your code.'\nRelated_Attack_Patterns: \"25: \\n\\n26: \\n\\n27: \\n\\n29: \"\n",
  "ID: '663'\nName: Use of a Non-reentrant Function in a Concurrent Context\nDescription: The product calls a non-reentrant function in a concurrent context in\n  which a competing code sequence (e.g. thread or signal handler) may have an opportunity\n  to call the same function or otherwise influence its state.\nPotential_Mitigations: 'Implementation: Use reentrant functions if available.\n\n\n  Implementation: Add synchronization to your non-reentrant function.\n\n\n  Implementation: In Java, use the ReentrantLock Class.'\nObserved_Examples: 'CVE-2001-1349: unsafe calls to library functions from signal handler\n\n\n  CVE-2004-2259: SIGCHLD signal to FTP server can cause crash under heavy load while\n  executing non-reentrant functions like malloc/free.'\nRelated_Attack_Patterns: '29: '\n",
  "ID: '664'\nName: Improper Control of a Resource Through its Lifetime\nDescription: The product does not maintain or incorrectly maintains control over a\n  resource throughout its lifetime of creation, use, and release.\nExtended_Description: 'Resources often have explicit instructions on how to be created,\n  used and destroyed. When code does not follow these instructions, it can lead to\n  unexpected behaviors and potentially exploitable states.\n\n  Even without explicit instructions, various principles are expected to be adhered\n  to, such as \"Do not use an object until after its creation is complete,\" or \"do\n  not use an object after it has been slated for destruction.\"'\nPotential_Mitigations: 'Testing: Use Static analysis tools to check for unreleased\n  resources.'\nRelated_Attack_Patterns: \"196: \\n\\n21: \\n\\n60: \\n\\n61: \\n\\n62: \"\n",
  "ID: '665'\nName: Improper Initialization\nDescription: The product does not initialize or incorrectly initializes a resource,\n  which might leave the resource in an unexpected state when it is accessed or used.\nExtended_Description: This can have security implications when the associated resource\n  is expected to have certain properties or values, such as a variable that determines\n  whether a user has been authenticated or not.\nModes_Of_Introduction: 'Implementation: This weakness can occur in code paths that\n  are not well-tested, such as rare error conditions. This is because the use of uninitialized\n  data would be noticed as a bug during frequently-used functionality.\n\n\n  Operation: '\nDetection_Methods: 'Automated Dynamic Analysis: This weakness can be detected using\n  dynamic tools and techniques that interact with the software using large test suites\n  with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and\n  fault injection. The software''s operation may slow down, but it should not become\n  unstable, crash, or generate incorrect results.\n\n  Initialization problems may be detected with a stress-test by calling the software\n  simultaneously from a large number of threads or processes, and look for evidence\n  of any unexpected behavior. The software''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.\n\n\n  Manual Dynamic Analysis: Identify error conditions that are not likely to occur\n  during normal usage and trigger them. For example, run the program under low memory\n  conditions, run with insufficient privileges or permissions, interrupt a transaction\n  before it is completed, or disable connectivity to basic network services such as\n  DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled\n  exception or similar error that was discovered and handled by the application''s\n  environment, it may still indicate unexpected conditions that were not handled by\n  the application itself.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, in Java, if the programmer does not explicitly initialize a variable,\n  then the code could produce a compile-time error (if the variable is local) or automatically\n  initialize the variable to the default value for the variable''s type. In Perl,\n  if explicit initialization is not performed, then a default value of undef is assigned,\n  which is interpreted as 0, false, or an equivalent value depending on the context\n  in which the variable is accessed.\n\n\n  Architecture and Design: Identify all variables and data stores that receive information\n  from external sources, and apply input validation to make sure that they are only\n  initialized to expected values.\n\n\n  Implementation: Explicitly initialize all your variables and other data stores,\n  either during declaration or just before the first usage.\n\n\n  Implementation: Pay close attention to complex conditionals that affect initialization,\n  since some conditions might not perform the initialization.\n\n\n  Implementation: Avoid race conditions (CWE-362) during initialization routines.\n\n\n  Build and Compilation: Run or compile your product with settings that generate warnings\n  about uninitialized variables or data.\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.'\nObserved_Examples: 'CVE-2001-1471: chain: an invalid value prevents a library file\n  from being included, skipping initialization of key variables, leading to resultant\n  eval injection.\n\n\n  CVE-2008-3637: Improper error checking in protection mechanism produces an uninitialized\n  variable, allowing security bypass and code execution.\n\n\n  CVE-2008-4197: Use of uninitialized memory may allow code execution.\n\n\n  CVE-2008-2934: Free of an uninitialized pointer leads to crash and possible code\n  execution.\n\n\n  CVE-2007-3749: OS kernel does not reset a port when starting a setuid program, allowing\n  local users to access the port and gain privileges.\n\n\n  CVE-2008-0063: Product does not clear memory contents when generating an error message,\n  leading to information leak.\n\n\n  CVE-2008-0062: Lack of initialization triggers NULL pointer dereference or double-free.\n\n\n  CVE-2008-0081: Uninitialized variable leads to code execution in popular desktop\n  application.\n\n\n  CVE-2008-3688: chain: Uninitialized variable leads to infinite loop.\n\n\n  CVE-2008-3475: chain: Improper initialization leads to memory corruption.\n\n\n  CVE-2008-5021: Composite: race condition allows attacker to modify an object while\n  it is still being initialized, causing software to access uninitialized memory.\n\n\n  CVE-2005-1036: Chain: Bypass of access restrictions due to improper authorization\n  (CWE-862) of a user results from an improperly initialized (CWE-909) I/O permission\n  bitmap\n\n\n  CVE-2008-3597: chain: game server can access player data structures before initialization\n  has happened leading to NULL dereference\n\n\n  CVE-2009-2692: chain: uninitialized function pointers can be dereferenced allowing\n  code execution\n\n\n  CVE-2009-0949: chain: improper initialization of memory can lead to NULL dereference\n\n\n  CVE-2009-3620: chain: some unprivileged ioctls do not verify that a structure has\n  been initialized before invocation, leading to NULL dereference'\nRelated_Attack_Patterns: \"26: \\n\\n29: \"\n",
  "ID: '666'\nName: Operation on Resource in Wrong Phase of Lifetime\nDescription: The product performs an operation on a resource at the wrong phase of\n  the resource's lifecycle, which can lead to unexpected behaviors.\nExtended_Description: 'A resource''s lifecycle includes several phases: initialization,\n  use, and release. For each phase, it is important to follow the specifications outlined\n  for how to operate on the resource and to ensure that the resource is in the expected\n  phase. Otherwise, if a resource is in one phase but the operation is not valid for\n  that phase (i.e., an incorrect phase of the resource''s lifetime), then this can\n  produce resultant weaknesses. For example, using a resource before it has been fully\n  initialized could cause corruption or incorrect data to be used.'\nPotential_Mitigations: 'Architecture and Design: Follow the resource''s lifecycle\n  from creation to release.'\n",
  "ID: '667'\nName: Improper Locking\nDescription: The product does not properly acquire or release a lock on a resource,\n  leading to unexpected resource state changes and behaviors.\nExtended_Description: Locking is a type of synchronization behavior that ensures that\n  multiple independently-operating processes or threads do not interfere with each\n  other when accessing the same resource. All processes/threads are expected to follow\n  the same steps for locking. If these steps are not followed precisely - or if no\n  locking is done at all - then another process/thread could modify the shared resource\n  in a way that is not visible or predictable to the original process.  This can lead\n  to data or memory corruption, denial of service, etc.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use industry standard APIs to implement locking\n  mechanism.'\nObserved_Examples: 'CVE-2021-1782: Chain: improper locking (CWE-667) leads to race\n  condition (CWE-362), as exploited in the wild per CISA KEV.\n\n\n  CVE-2009-0935: Attacker provides invalid address to a memory-reading function, causing\n  a mutex to be unlocked twice\n\n\n  CVE-2010-4210: function in OS kernel unlocks a mutex that was not previously locked,\n  causing a panic or overwrite of arbitrary memory.\n\n\n  CVE-2008-4302: Chain: OS kernel does not properly handle a failure of a function\n  call (CWE-755), leading to an unlock of a resource that was not locked (CWE-832),\n  with resultant crash.\n\n\n  CVE-2009-1243: OS kernel performs an unlock in some incorrect circumstances, leading\n  to panic.\n\n\n  CVE-2009-2857: OS deadlock\n\n\n  CVE-2009-1961: OS deadlock involving 3 separate functions\n\n\n  CVE-2009-2699: deadlock in library\n\n\n  CVE-2009-4272: deadlock triggered by packets that force collisions in a routing\n  table\n\n\n  CVE-2002-1850: read/write deadlock between web server and script\n\n\n  CVE-2004-0174: web server deadlock involving multiple listening connections\n\n\n  CVE-2009-1388: multiple simultaneous calls to the same function trigger deadlock.\n\n\n  CVE-2006-5158: chain: other weakness leads to NULL pointer dereference (CWE-476)\n  or deadlock (CWE-833).\n\n\n  CVE-2006-4342: deadlock when an operation is performed on a resource while it is\n  being removed.\n\n\n  CVE-2006-2374: Deadlock in device driver triggered by using file handle of a related\n  device.\n\n\n  CVE-2006-2275: Deadlock when large number of small messages cannot be processed\n  quickly enough.\n\n\n  CVE-2005-3847: OS kernel has deadlock triggered by a signal during a core dump.\n\n\n  CVE-2005-3106: Race condition leads to deadlock.\n\n\n  CVE-2005-2456: Chain: array index error (CWE-129) leads to deadlock (CWE-833)\n\n\n  CVE-2001-0682: Program can not execute when attacker obtains a mutex.\n\n\n  CVE-2002-1914: Program can not execute when attacker obtains a lock on a critical\n  output file.\n\n\n  CVE-2002-1915: Program can not execute when attacker obtains a lock on a critical\n  output file.\n\n\n  CVE-2002-0051: Critical file can be opened with exclusive read access by user, preventing\n  application of security policy. Possibly related to improper permissions, large-window\n  race condition.\n\n\n  CVE-2000-0338: Chain: predictable file names used for locking, allowing attacker\n  to create the lock beforehand. Resultant from permissions and randomness.\n\n\n  CVE-2000-1198: Chain: Lock files with predictable names. Resultant from randomness.\n\n\n  CVE-2002-1869: Product does not check if it can write to a log file, allowing attackers\n  to avoid logging by accessing the file using an exclusive lock. Overlaps unchecked\n  error condition. This is not quite CWE-412, but close.'\nRelated_Attack_Patterns: \"25: \\n\\n26: \\n\\n27: \"\n",
  "ID: '668'\nName: Exposure of Resource to Wrong Sphere\nDescription: The product exposes a resource to the wrong control sphere, providing\n  unintended actors with inappropriate access to the resource.\nExtended_Description: 'Resources such as files and directories may be inadvertently\n  exposed through mechanisms such as insecure permissions, or when a program accidentally\n  operates on the wrong object. For example, a program may intend that private files\n  can only be provided to a specific user. This effectively defines a control sphere\n  that is intended to prevent attackers from accessing these private files. If the\n  file permissions are insecure, then parties other than the user will be able to\n  access those files.\n\n  A separate control sphere might effectively require that the user can only access\n  the private files, but not any other files on the system. If the program does not\n  ensure that the user is only requesting private files, then the user might be able\n  to access other files on the system.\n\n  In either case, the end result is that a resource has been exposed to the wrong\n  party.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\n",
  "ID: '669'\nName: Incorrect Resource Transfer Between Spheres\nDescription: The product does not properly transfer a resource/behavior to another\n  sphere, or improperly imports a resource/behavior from another sphere, in a manner\n  that provides unintended control over that resource.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\n",
  "ID: '67'\nName: Improper Handling of Windows Device Names\nDescription: The product constructs pathnames from user input, but it does not handle\n  or incorrectly handles a pathname containing a Windows device name such as AUX or\n  CON. This typically leads to denial of service or an information exposure when the\n  application attempts to process the pathname as a regular file.\nExtended_Description: Not properly handling virtual filenames (e.g. AUX, CON, PRN,\n  COM1, LPT1) can result in different types of vulnerabilities. In some cases an attacker\n  can request a device via injection of a virtual filename in a URL, which may cause\n  an error that leads to a denial of service or an error page that reveals sensitive\n  information. A product that allows device names to bypass filtering runs the risk\n  of an attacker injecting malicious code in a file with the name of a device.\nApplicable_Platforms:\n  Operating_System: Windows\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Implementation: Be familiar with the device names in the operating\n  system where your system is deployed. Check input for these device names.'\nObserved_Examples: 'CVE-2002-0106: Server allows remote attackers to cause a denial\n  of service via a series of requests to .JSP files that contain an MS-DOS device\n  name.\n\n\n  CVE-2002-0200: Server allows remote attackers to cause a denial of service via an\n  HTTP request for an MS-DOS device name.\n\n\n  CVE-2002-1052: Product allows remote attackers to use MS-DOS device names in HTTP\n  requests to cause a denial of service or obtain the physical path of the server.\n\n\n  CVE-2001-0493: Server allows remote attackers to cause a denial of service via a\n  URL that contains an MS-DOS device name.\n\n\n  CVE-2001-0558: Server allows a remote attacker to create a denial of service via\n  a URL request which includes a MS-DOS device name.\n\n\n  CVE-2000-0168: Microsoft Windows 9x operating systems allow an attacker to cause\n  a denial of service via a pathname that includes file device names, aka the \"DOS\n  Device in Path Name\" vulnerability.\n\n\n  CVE-2001-0492: Server allows remote attackers to determine the physical path of\n  the server via a URL containing MS-DOS device names.\n\n\n  CVE-2004-0552: Product does not properly handle files whose names contain reserved\n  MS-DOS device names, which can allow malicious code to bypass detection when it\n  is installed, copied, or executed.\n\n\n  CVE-2005-2195: Server allows remote attackers to cause a denial of service (application\n  crash) via a URL with a filename containing a .cgi extension and an MS-DOS device\n  name.'\n",
  "ID: '670'\nName: Always-Incorrect Control Flow Implementation\nDescription: The code contains a control flow path that does not reflect the algorithm\n  that the path is intended to implement, leading to incorrect behavior any time this\n  path is navigated.\nExtended_Description: This weakness captures cases in which a particular code segment\n  is always incorrect with respect to the algorithm that it is implementing. For example,\n  if a C programmer intends to include multiple statements in a single block but does\n  not include the enclosing braces (CWE-483), then the logic is always incorrect.\n  This issue is in contrast to most weaknesses in which the code usually behaves correctly,\n  except when it is externally manipulated in malicious ways.\nModes_Of_Introduction: 'Implementation: This issue typically appears in rarely-tested\n  code, since the \"always-incorrect\" nature will be detected as a bug during normal\n  usage.'\nObserved_Examples: 'CVE-2021-3011: virtual interrupt controller in a virtualization\n  product allows crash of host by writing a certain invalid value to a register, which\n  triggers a fatal error instead of returning an error code'\n",
  "ID: '671'\nName: Lack of Administrator Control over Security\nDescription: The product uses security features in a way that prevents the product's\n  administrator from tailoring security settings to reflect the environment in which\n  the product is being used. This introduces resultant weaknesses or prevents it from\n  operating at a level of security that is desired by the administrator.\nExtended_Description: If the product's administrator does not have the ability to\n  manage security-related decisions at all times, then protecting the product from\n  outside threats - including the product's developer - can become impossible. For\n  example, a hard-coded account name and password cannot be changed by the administrator,\n  thus exposing that product to attacks that the administrator can not prevent.\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n\n  Implementation: '\n",
  "ID: '672'\nName: Operation on a Resource after Expiration or Release\nDescription: The product uses, accesses, or otherwise operates on a resource after\n  that resource has been expired, released, or revoked.\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nObserved_Examples: 'CVE-2009-3547: chain: race condition might allow resource to be\n  released before operating on it, leading to NULL dereference'\n",
  "ID: '673'\nName: External Influence of Sphere Definition\nDescription: The product does not prevent the definition of control spheres from external\n  actors.\nExtended_Description: Typically, a product defines its control sphere within the code\n  itself, or through configuration by the product's administrator. In some cases,\n  an external party can change the definition of the control sphere. This is typically\n  a resultant weakness.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\n",
  "ID: '674'\nName: Uncontrolled Recursion\nDescription: The product does not properly control the amount of recursion that takes\n  place,  consuming excessive resources, such as allocated memory or the program stack.\nModes_Of_Introduction: 'Implementation: The uncontrolled recursion is often due to\n  an improper or missing conditional'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Ensure an end condition will be reached under\n  all logic conditions.  The end condition may include testing against the depth of\n  recursion and exiting with an error if the recursion goes too deep. The complexity\n  of the end condition contributes to the effectiveness of this action.\n\n\n  Implementation: Increase the stack size.'\nObserved_Examples: 'CVE-2007-1285: Deeply nested arrays trigger stack exhaustion.\n\n\n  CVE-2007-3409: Self-referencing pointers create infinite loop and resultant stack\n  exhaustion.\n\n\n  CVE-2016-10707: Javascript application accidentally changes input in a way that\n  prevents a recursive call from detecting an exit condition.\n\n\n  CVE-2016-3627: An attempt to recover a corrupted XML file infinite recursion protection\n  counter was not always incremented missing the exit condition.\n\n\n  CVE-2019-15118: USB-audio driver''s descriptor code parsing allows unlimited recursion\n  leading to stack exhaustion.'\nRelated_Attack_Patterns: \"230: \\n\\n231: \"\n",
  "ID: '675'\nName: Multiple Operations on Resource in Single-Operation Context\nDescription: The product performs the same operation on a resource two or more times,\n  when the operation should only be applied once.\n",
  "ID: '676'\nName: Use of Potentially Dangerous Function\nDescription: The product invokes a potentially dangerous function that could introduce\n  a vulnerability if it is used incorrectly, but the function can also be used safely.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Build and Compilation\n\n  Implementation: Identify a list of prohibited API functions and prohibit developers\n  from using these functions, providing safer alternatives. In some cases, automatic\n  code analysis tools or the compiler can be instructed to spot use of prohibited\n  functions, such as the \"banned.h\" include file from Microsoft''s SDL. [REF-554]\n  [REF-7]'\nObserved_Examples: 'CVE-2007-1470: Library has multiple buffer overflows using sprintf()\n  and strcpy()\n\n\n  CVE-2009-3849: Buffer overflow using strcat()\n\n\n  CVE-2006-2114: Buffer overflow using strcpy()\n\n\n  CVE-2006-0963: Buffer overflow using strcpy()\n\n\n  CVE-2011-0712: Vulnerable use of strcpy() changed to use safer strlcpy()\n\n\n  CVE-2008-5005: Buffer overflow using strcpy()'\n",
  "ID: '680'\nName: Integer Overflow to Buffer Overflow\nDescription: The product performs a calculation to determine how much memory to allocate,\n  but an integer overflow can occur that causes less memory to be allocated than expected,\n  leading to a buffer overflow.\nObserved_Examples: 'CVE-2017-1000121: chain: unchecked message size metadata allows\n  integer overflow (CWE-190) leading to buffer overflow (CWE-119).'\nRelated_Attack_Patterns: \"10: \\n\\n100: \\n\\n14: \\n\\n24: \\n\\n45: \\n\\n46: \\n\\n47: \\n\\n\\\n  67: \\n\\n8: \\n\\n9: \\n\\n92: \"\n",
  "ID: '681'\nName: Incorrect Conversion between Numeric Types\nDescription: When converting from one data type to another, such as long to integer,\n  data can be omitted or translated in a way that produces unexpected values. If the\n  resulting values are used in a sensitive context, then dangerous behaviors may occur.\nPotential_Mitigations: 'Implementation: Avoid making conversion between numeric types.\n  Always check for the allowed ranges.'\nObserved_Examples: 'CVE-2007-4268: Chain: integer signedness error (CWE-195) passes\n  signed comparison, leading to heap overflow (CWE-122)\n\n\n  CVE-2007-4988: Chain: signed short width value in image processor is sign extended\n  during conversion to unsigned int, which leads to integer overflow and heap-based\n  buffer overflow.\n\n\n  CVE-2009-0231: Integer truncation of length value leads to heap-based buffer overflow.\n\n\n  CVE-2008-3282: Size of a particular type changes for 64-bit platforms, leading to\n  an integer truncation in document processor causes incorrect index to be generated.'\n",
  "ID: '682'\nName: Incorrect Calculation\nDescription: The product performs a calculation that generates incorrect or unintended\n  results that are later used in security-critical decisions or resource management.\nExtended_Description: When product performs a security-critical calculation incorrectly,\n  it might lead to incorrect resource allocations, incorrect privilege assignments,\n  or failed comparisons among other things. Many of the direct results of an incorrect\n  calculation can lead to even larger problems such as failed protection mechanisms\n  or even arbitrary code execution.\nDetection_Methods: 'Manual Analysis: This weakness can be detected using tools and\n  techniques that require manual (human) analysis, such as penetration testing, threat\n  modeling, and interactive tools that allow the tester to record and modify an active\n  session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  allocation calculations. This can be useful for detecting overflow conditions (CWE-190)\n  or similar weaknesses that might have serious security impacts on the program.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.'\nPotential_Mitigations: 'Implementation: Understand your programming language''s underlying\n  representation and how it interacts with numeric calculation. Pay close attention\n  to byte size discrepancies, precision, signed/unsigned distinctions, truncation,\n  conversion and casting between types, \"not-a-number\" calculations, and how your\n  language handles numbers that are too large or too small for its underlying representation.\n\n\n  Implementation: Perform input validation on any numeric input by ensuring that it\n  is within the expected range. Enforce that the input meets both the minimum and\n  maximum requirements for the expected range.\n\n\n  Implementation: Use the appropriate type for the desired action. For example, in\n  C/C++, only use unsigned types for values that could never be negative, such as\n  height, width, or other numbers related to quantity.\n\n\n  Architecture and Design: Use languages, libraries, or frameworks that make it easier\n  to handle numbers without unexpected consequences.\n\n  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib\n  (C or C++).\n\n\n  Architecture and Design: Use languages, libraries, or frameworks that make it easier\n  to handle numbers without unexpected consequences.\n\n  Examples include safe integer handling packages such as SafeInt (C++) or IntegerLib\n  (C or C++).\n\n\n  Implementation: Examine compiler warnings closely and eliminate problems with potential\n  security implications, such as signed / unsigned mismatch in memory operations,\n  or use of uninitialized variables. Even if the weakness is rarely exploitable, a\n  single failure may lead to the compromise of the entire system.\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Testing: Use dynamic tools and techniques that interact with the product using large\n  test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness\n  testing, and fault injection. The product''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.'\nObserved_Examples: 'CVE-2020-0022: chain: mobile phone Bluetooth implementation does\n  not include offset when calculating packet length (CWE-682), leading to out-of-bounds\n  write (CWE-787)\n\n\n  CVE-2004-1363: substitution overflow: buffer overflow using environment variables\n  that are expanded after the length check is performed'\nRelated_Attack_Patterns: \"128: \\n\\n129: \"\n",
  "ID: '683'\nName: Function Call With Incorrect Order of Arguments\nDescription: The product calls a function, procedure, or routine, but the caller specifies\n  the arguments in an incorrect order, leading to resultant weaknesses.\nExtended_Description: While this weakness might be caught by the compiler in some\n  languages, it can occur more frequently in cases in which the called function accepts\n  variable numbers or types of arguments, such as format strings in C. It also can\n  occur in languages or environments that do not enforce strong typing.\nModes_Of_Introduction: 'Implementation: This problem typically occurs when the programmer\n  makes a typo, or copy and paste errors.'\nPotential_Mitigations: 'Implementation: Use the function, procedure, or routine as\n  specified.\n\n\n  Testing: Because this function call often produces incorrect behavior it will usually\n  be detected during testing or normal operation of the product. During testing exercise\n  all possible control paths will typically expose this weakness except in rare cases\n  when the incorrect function call accidentally produces the correct results or if\n  the provided argument type is very similar to the expected argument type.'\nObserved_Examples: 'CVE-2006-7049: Application calls functions with arguments in the\n  wrong order, allowing attacker to bypass intended access restrictions.'\n",
  "ID: '684'\nName: Incorrect Provision of Specified Functionality\nDescription: The code does not function according to its published specifications,\n  potentially leading to incorrect usage.\nExtended_Description: When providing functionality to an external party, it is important\n  that the product behaves in accordance with the details specified. When requirements\n  of nuances are not documented, the functionality may produce unintended behaviors\n  for the caller, possibly leading to an exploitable state.\nPotential_Mitigations: 'Implementation: Ensure that your code strictly conforms to\n  specifications.'\n",
  "ID: '685'\nName: Function Call With Incorrect Number of Arguments\nDescription: The product calls a function, procedure, or routine, but the caller specifies\n  too many arguments, or too few arguments, which may lead to undefined behavior and\n  resultant weaknesses.\nApplicable_Platforms:\n  Language: C, Perl\nModes_Of_Introduction: 'Implementation: This problem typically occurs when the programmer\n  makes a typo, or copy and paste errors.'\nDetection_Methods: 'Other: While this weakness might be caught by the compiler in\n  some languages, it can occur more frequently in cases in which the called function\n  accepts variable numbers of arguments, such as format strings in C. It also can\n  occur in languages or environments that do not require that functions always be\n  called with the correct number of arguments, such as Perl.'\nPotential_Mitigations: 'Testing: Because this function call often produces incorrect\n  behavior it will usually be detected during testing or normal operation of the product.\n  During testing exercise all possible control paths will typically expose this weakness\n  except in rare cases when the incorrect function call accidentally produces the\n  correct results or if the provided argument type is very similar to the expected\n  argument type.'\n",
  "ID: '686'\nName: Function Call With Incorrect Argument Type\nDescription: The product calls a function, procedure, or routine, but the caller specifies\n  an argument that is the wrong data type, which may lead to resultant weaknesses.\nExtended_Description: This weakness is most likely to occur in loosely typed languages,\n  or in strongly typed languages in which the types of variable arguments cannot be\n  enforced at compilation time, or where there is implicit casting.\nPotential_Mitigations: 'Testing: Because this function call often produces incorrect\n  behavior it will usually be detected during testing or normal operation of the product.\n  During testing exercise all possible control paths will typically expose this weakness\n  except in rare cases when the incorrect function call accidentally produces the\n  correct results or if the provided argument type is very similar to the expected\n  argument type.'\n",
  "ID: '687'\nName: Function Call With Incorrectly Specified Argument Value\nDescription: The product calls a function, procedure, or routine, but the caller specifies\n  an argument that contains the wrong value, which may lead to resultant weaknesses.\nDetection_Methods: 'Manual Static Analysis: This might require an understanding of\n  intended program behavior or design to determine whether the value is incorrect.'\n",
  "ID: '688'\nName: Function Call With Incorrect Variable or Reference as Argument\nDescription: The product calls a function, procedure, or routine, but the caller specifies\n  the wrong variable or reference as one of the arguments, which may lead to undefined\n  behavior and resultant weaknesses.\nApplicable_Platforms:\n  Language: C, Perl\nModes_Of_Introduction: 'Implementation: This problem typically occurs when the programmer\n  makes a typo, or copy and paste errors.'\nDetection_Methods: 'Other: While this weakness might be caught by the compiler in\n  some languages, it can occur more frequently in cases in which the called function\n  accepts variable numbers of arguments, such as format strings in C. It also can\n  occur in loosely typed languages or environments. This might require an understanding\n  of intended program behavior or design to determine whether the value is incorrect.'\nPotential_Mitigations: 'Testing: Because this function call often produces incorrect\n  behavior it will usually be detected during testing or normal operation of the product.\n  During testing exercise all possible control paths will typically expose this weakness\n  except in rare cases when the incorrect function call accidentally produces the\n  correct results or if the provided argument type is very similar to the expected\n  argument type.'\nObserved_Examples: 'CVE-2005-2548: Kernel code specifies the wrong variable in first\n  argument, leading to resultant NULL pointer dereference.'\n",
  "ID: '689'\nName: Permission Race Condition During Resource Copy\nDescription: The product, while copying or cloning a resource, does not set the resource's\n  permissions or access control until the copy is complete, leaving the resource exposed\n  to other spheres while the copy is taking place.\nApplicable_Platforms:\n  Language: C, Perl\nModes_Of_Introduction: 'Implementation: Common examples occur in file archive extraction,\n  in which the product begins the extraction with insecure default permissions, then\n  only sets the final permissions (as specified in the archive) once the copy is complete.\n  The larger the archive, the larger the timing window for the race condition.\n\n  This weakness has also occurred in some operating system utilities that perform\n  copies of deeply nested directories containing a large number of files.\n\n  This weakness can occur in any type of functionality that involves copying objects\n  or resources in a multi-user environment, including at the application level. For\n  example, a document management system might allow a user to copy a private document,\n  but if it does not set the new copy to be private as soon as the copy begins, then\n  other users might be able to view the document while the copy is still taking place.'\nObserved_Examples: 'CVE-2002-0760: Archive extractor decompresses files with world-readable\n  permissions, then later sets permissions to what the archive specified.\n\n\n  CVE-2005-2174: Product inserts a new object into database before setting the object''s\n  permissions, introducing a race condition.\n\n\n  CVE-2006-5214: Error file has weak permissions before a chmod is performed.\n\n\n  CVE-2005-2475: Archive permissions issue using hard link.\n\n\n  CVE-2003-0265: Database product creates files world-writable before initializing\n  the setuid bits, leading to modification of executables.'\nRelated_Attack_Patterns: \"26: \\n\\n27: \"\n",
  "ID: '69'\nName: Improper Handling of Windows ::DATA Alternate Data Stream\nDescription: The product does not properly prevent access to, or detect usage of,\n  alternate data streams (ADS).\nExtended_Description: An attacker can use an ADS to hide information about a file\n  (e.g. size, the name of the process) from a system or file browser tools such as\n  Windows Explorer and 'dir' at the command line utility. Alternately, the attacker\n  might be able to bypass intended access restrictions for the associated data fork.\nApplicable_Platforms:\n  Operating_System: Windows\nPotential_Mitigations: 'Testing: Software tools are capable of finding ADSs on your\n  system.\n\n\n  Implementation: Ensure that the source code correctly parses the filename to read\n  or write to the correct stream.'\nObserved_Examples: 'CVE-1999-0278: In IIS, remote attackers can obtain source code\n  for ASP files by appending \"::$DATA\" to the URL.\n\n\n  CVE-2000-0927: Product does not properly record file sizes if they are stored in\n  alternative data streams, which allows users to bypass quota restrictions.'\nRelated_Attack_Patterns: '168: '\n",
  "ID: '690'\nName: Unchecked Return Value to NULL Pointer Dereference\nDescription: The product does not check for an error after calling a function that\n  can return with a NULL pointer if the function fails, which leads to a resultant\n  NULL pointer dereference.\nExtended_Description: While unchecked return value weaknesses are not limited to returns\n  of NULL pointers (see the examples in CWE-252), functions often return NULL to indicate\n  an error status. When this error condition is not checked, a NULL pointer dereference\n  can occur.\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: 'Implementation: A typical occurrence of this weakness occurs\n  when an application includes user-controlled input to a malloc() call. The related\n  code might be correct with respect to preventing buffer overflows, but if a large\n  value is provided, the malloc() will fail due to insufficient memory. This problem\n  also frequently occurs when a parsing routine expects that certain elements will\n  always be present. If malformed input is provided, the parser might return NULL.\n  For example, strtok() can return NULL.'\nDetection_Methods: 'Black Box: This typically occurs in rarely-triggered error conditions,\n  reducing the chances of detection during black box testing.\n\n\n  White Box: Code analysis can require knowledge of API behaviors for library functions\n  that might return NULL, reducing the chances of detection when unknown libraries\n  are used.'\nObserved_Examples: 'CVE-2008-1052: Large Content-Length value leads to NULL pointer\n  dereference when malloc fails.\n\n\n  CVE-2006-6227: Large message length field leads to NULL pointer dereference when\n  malloc fails.\n\n\n  CVE-2006-2555: Parsing routine encounters NULL dereference when input is missing\n  a colon separator.\n\n\n  CVE-2003-1054: URI parsing API sets argument to NULL when a parsing failure occurs,\n  such as when the Referer header is missing a hostname, leading to NULL dereference.\n\n\n  CVE-2008-5183: chain: unchecked return value can lead to NULL dereference'\n",
  "ID: '691'\nName: Insufficient Control Flow Management\nDescription: The code does not sufficiently manage its control flow during execution,\n  creating conditions in which the control flow can be modified in unexpected ways.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nRelated_Attack_Patterns: '29: '\n",
  "ID: '692'\nName: Incomplete Denylist to Cross-Site Scripting\nDescription: The product uses a denylist-based protection mechanism to defend against\n  XSS attacks, but the denylist is incomplete, allowing XSS variants to succeed.\nExtended_Description: While XSS might seem simple to prevent, web browsers vary so\n  widely in how they parse web pages, that a denylist cannot keep track of all the\n  variations. The \"XSS Cheat Sheet\" [REF-714] contains a large number of attacks that\n  are intended to bypass incomplete denylists.\nObserved_Examples: 'CVE-2007-5727: Denylist only removes <SCRIPT> tag.\n\n\n  CVE-2006-3617: Denylist only removes <SCRIPT> tag.\n\n\n  CVE-2006-4308: Denylist only checks \"javascript:\" tag'\nRelated_Attack_Patterns: \"120: \\n\\n267: \\n\\n71: \\n\\n80: \\n\\n85: \"\n",
  "ID: '693'\nName: Protection Mechanism Failure\nDescription: The product does not use or incorrectly uses a protection mechanism that\n  provides sufficient defense against directed attacks against the product.\nExtended_Description: This weakness covers three distinct situations. A \"missing\"\n  protection mechanism occurs when the application does not define any mechanism against\n  a certain class of attack. An \"insufficient\" protection mechanism might provide\n  some defenses - for example, against the most common attacks - but it does not protect\n  against everything that is intended. Finally, an \"ignored\" mechanism occurs when\n  a mechanism is available and in active use within the product, but the developer\n  has not applied it in some code path.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nRelated_Attack_Patterns: \"1: \\n\\n107: \\n\\n127: \\n\\n17: \\n\\n20: \\n\\n22: \\n\\n237: \\n\\\n  \\n36: \\n\\n477: \\n\\n480: \\n\\n51: \\n\\n57: \\n\\n59: \\n\\n65: \\n\\n668: \\n\\n74: \\n\\n87: \"\n",
  "ID: '694'\nName: Use of Multiple Resources with Duplicate Identifier\nDescription: The product uses multiple resources that can have the same identifier,\n  in a context in which unique identifiers are required.\nExtended_Description: If the product assumes that each resource has a unique identifier,\n  the product could operate on the wrong resource if attackers can cause multiple\n  resources to be associated with the same identifier.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design: Where possible, use unique identifiers.\n  If non-unique identifiers are detected, then do not operate any resource with a\n  non-unique identifier and report the error appropriately.'\nObserved_Examples: 'CVE-2013-4787: chain: mobile OS verifies cryptographic signature\n  of file in an archive, but then installs a different file with the same name that\n  is also listed in the archive.'\n",
  "ID: '695'\nName: Use of Low-Level Functionality\nDescription: The product uses low-level functionality that is explicitly prohibited\n  by the framework or specification under which the product is supposed to operate.\nExtended_Description: The use of low-level functionality can violate the specification\n  in unexpected ways that effectively disable built-in protection mechanisms, introduce\n  exploitable inconsistencies, or otherwise expose the functionality to attack.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nRelated_Attack_Patterns: '36: '\n",
  "ID: '696'\nName: Incorrect Behavior Order\nDescription: The product performs multiple related behaviors, but the behaviors are\n  performed in the wrong order in ways which may produce resultant weaknesses.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nObserved_Examples: 'CVE-2019-9805: Chain: Creation of the packet client occurs before\n  initialization is complete (CWE-696) resulting in a read from uninitialized memory\n  (CWE-908), causing memory corruption.\n\n\n  CVE-2007-5191: file-system management programs call the setuid and setgid functions\n  in the wrong order and do not check the return values, allowing attackers to gain\n  unintended privileges\n\n\n  CVE-2007-1588: C++ web server program calls Process::setuid before calling Process::setgid,\n  preventing it from dropping privileges, potentially allowing CGI programs to be\n  called with higher privileges than intended'\nRelated_Attack_Patterns: '463: '\n",
  "ID: '697'\nName: Incorrect Comparison\nDescription: The product compares two entities in a security-relevant context, but\n  the comparison is incorrect, which may lead to resultant weaknesses.\nExtended_Description: 'This Pillar covers several possibilities:'\nObserved_Examples: 'CVE-2021-3116: Chain: Python-based HTTP Proxy server uses the\n  wrong boolean operators (CWE-480) causing an  incorrect comparison (CWE-697) that\n  identifies an authN failure if all three conditions are met instead of only one,\n  allowing bypass of the proxy authentication (CWE-1390)\n\n\n  CVE-2020-15811: Chain: Proxy uses a substring search instead of parsing the Transfer-Encoding\n  header (CWE-697), allowing request splitting (CWE-113) and cache poisoning\n\n\n  CVE-2016-10003: Proxy performs incorrect comparison of request headers, leading\n  to infoleak'\nRelated_Attack_Patterns: \"10: \\n\\n120: \\n\\n14: \\n\\n15: \\n\\n182: \\n\\n24: \\n\\n267: \\n\\\n  \\n3: \\n\\n41: \\n\\n43: \\n\\n44: \\n\\n45: \\n\\n46: \\n\\n47: \\n\\n52: \\n\\n53: \\n\\n6: \\n\\n\\\n  64: \\n\\n67: \\n\\n7: \\n\\n71: \\n\\n73: \\n\\n78: \\n\\n79: \\n\\n8: \\n\\n80: \\n\\n88: \\n\\n9:\\\n  \\ \\n\\n92: \"\n",
  "ID: '698'\nName: Execution After Redirect (EAR)\nDescription: The web application sends a redirect to another location, but instead\n  of exiting, it executes additional code.\nDetection_Methods: 'Black Box: This issue might not be detected if testing is performed\n  using a web browser, because the browser might obey the redirect and move the user\n  to a different page before the application has produced outputs that indicate something\n  is amiss.'\nObserved_Examples: 'CVE-2013-1402: Execution-after-redirect allows access to application\n  configuration details.\n\n\n  CVE-2009-1936: chain: library file sends a redirect if it is directly requested\n  but continues to execute, allowing remote file inclusion and path traversal.\n\n\n  CVE-2007-2713: Remote attackers can obtain access to administrator functionality\n  through EAR.\n\n\n  CVE-2007-4932: Remote attackers can obtain access to administrator functionality\n  through EAR.\n\n\n  CVE-2007-5578: Bypass of authentication step through EAR.\n\n\n  CVE-2007-2713: Chain: Execution after redirect triggers eval injection.\n\n\n  CVE-2007-6652: chain: execution after redirect allows non-administrator to perform\n  static code injection.'\n",
  "ID: '7'\nName: 'J2EE Misconfiguration: Missing Custom Error Page'\nDescription: The default error page of a web application should not display sensitive\n  information about the product.\nExtended_Description: 'A Web application must define a default error page for 4xx\n  errors (e.g. 404), 5xx (e.g. 500) errors and catch java.lang.Throwable exceptions\n  to prevent attackers from mining information from the application container''s built-in\n  error response.\n\n  When an attacker explores a web site looking for vulnerabilities, the amount of\n  information that the site provides is crucial to the eventual success or failure\n  of any attempted attacks.'\nApplicable_Platforms:\n  Language: Java\nPotential_Mitigations: 'Implementation: Handle exceptions appropriately in source\n  code.\n\n\n  Implementation, System Configuration: Always define appropriate error pages. The\n  application configuration should specify a default error page in order to guarantee\n  that the application will never leak error messages to an attacker. Handling standard\n  HTTP error codes is useful and user-friendly in addition to being a good security\n  practice, and a good configuration will also define a last-chance error handler\n  that catches any exception that could possibly be thrown by the application.\n\n\n  Implementation: Do not attempt to process an error or attempt to mask it.\n\n\n  Implementation: Verify return values are correct and do not supply sensitive information\n  about the system.'\n",
  "ID: '703'\nName: Improper Check or Handling of Exceptional Conditions\nDescription: The product does not properly anticipate or handle exceptional conditions\n  that rarely occur during normal operation of the product.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nDetection_Methods: 'Dynamic Analysis with Manual Results Interpretation: According\n  to SOAR, the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\n",
  "ID: '704'\nName: Incorrect Type Conversion or Cast\nDescription: The product does not correctly convert an object, resource, or structure\n  from one type to a different type.\nApplicable_Platforms:\n  Language: C, C++\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\n",
  "ID: '705'\nName: Incorrect Control Flow Scoping\nDescription: The product does not properly return control flow to the proper location\n  after it has completed a task or detected an unusual condition.\nObserved_Examples: 'CVE-2014-1266: chain: incorrect \"goto\" in Apple SSL product bypasses\n  certificate validation, allowing Adversary-in-the-Middle (AITM) attack (Apple \"goto\n  fail\" bug). CWE-705 (Incorrect Control Flow Scoping) -> CWE-561 (Dead Code) -> CWE-295\n  (Improper Certificate Validation) -> CWE-393 (Return of Wrong Status Code) -> CWE-300\n  (Channel Accessible by Non-Endpoint).'\n",
  "ID: '706'\nName: Use of Incorrectly-Resolved Name or Reference\nDescription: The product uses a name or reference to access a resource, but the name/reference\n  resolves to a resource that is outside of the intended control sphere.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nRelated_Attack_Patterns: \"159: \\n\\n177: \\n\\n48: \\n\\n641: \"\n",
  "ID: '707'\nName: Improper Neutralization\nDescription: The product does not ensure or incorrectly ensures that structured messages\n  or data are well-formed and that certain security properties are met before being\n  read from an upstream component or sent to a downstream component.\nExtended_Description: 'If a message is malformed, it may cause the message to be incorrectly\n  interpreted.\n\n  Neutralization is an abstract term for any technique that ensures that input (and\n  output) conforms with expectations and is \"safe.\"  This can be done by:\n\n  This weakness typically applies in cases where the product prepares a control message\n  that another process must act on, such as a command or query, and malicious input\n  that was intended as data, can enter the control plane instead. However, this weakness\n  also applies to more general cases where there are not always control implications.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nRelated_Attack_Patterns: \"250: \\n\\n276: \\n\\n277: \\n\\n278: \\n\\n279: \\n\\n3: \\n\\n43:\\\n  \\ \\n\\n468: \\n\\n52: \\n\\n53: \\n\\n64: \\n\\n7: \\n\\n78: \\n\\n79: \\n\\n83: \\n\\n84: \"\n",
  "ID: '708'\nName: Incorrect Ownership Assignment\nDescription: The product assigns an owner to a resource, but the owner is outside\n  of the intended control sphere.\nExtended_Description: This may allow the resource to be manipulated by actors outside\n  of the intended control sphere.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  \\nOperation: \"\nPotential_Mitigations: 'Policy: Periodically review the privileges and their owners.\n\n\n  Testing: Use automated tools to check for privilege settings.'\nObserved_Examples: 'CVE-2007-5101: File system sets wrong ownership and group when\n  creating a new file.\n\n\n  CVE-2007-4238: OS installs program with bin owner/group, allowing modification.\n\n\n  CVE-2007-1716: Manager does not properly restore ownership of a reusable resource\n  when a user logs out, allowing privilege escalation.\n\n\n  CVE-2005-3148: Backup software restores symbolic links with incorrect uid/gid.\n\n\n  CVE-2005-1064: Product changes the ownership of files that a symlink points to,\n  instead of the symlink itself.\n\n\n  CVE-2011-1551: Component assigns ownership of sensitive directory tree to a user\n  account, which can be leveraged to perform privileged operations.'\n",
  "ID: '71'\nName: 'DEPRECATED: Apple ''.DS_Store'''\nDescription: This entry has been deprecated as it represents a specific observed example\n  of a UNIX Hard Link weakness type rather than its own individual weakness type.\n  Please refer to CWE-62.\n",
  "ID: '710'\nName: Improper Adherence to Coding Standards\nDescription: The product does not follow certain coding rules for development, which\n  can lead to resultant weaknesses or increase the severity of the associated vulnerabilities.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Document and closely follow coding standards.\n\n\n  Testing, Implementation: Where possible, use automated tools to enforce the standards.'\n",
  "ID: '72'\nName: Improper Handling of Apple HFS+ Alternate Data Stream Path\nDescription: The product does not properly handle special paths that may identify\n  the data or resource fork of a file on the HFS+ file system.\nExtended_Description: If the product chooses actions to take based on the file name,\n  then if an attacker provides the data or resource fork, the product may take unexpected\n  actions. Further, if the product intends to restrict access to a file, then an attacker\n  might still be able to bypass intended access restrictions by requesting the data\n  or resource fork for that file.\nApplicable_Platforms:\n  Operating_System: macOS\nObserved_Examples: 'CVE-2004-1084: Server allows remote attackers to read files and\n  resource fork content via HTTP requests to certain special file names related to\n  multiple data streams in HFS+.'\n",
  "ID: '73'\nName: External Control of File Name or Path\nDescription: The product allows user input to control or influence paths or file names\n  that are used in filesystem operations.\nExtended_Description: 'This could allow an attacker to access or modify system files\n  or other files that are critical to the application.\n\n  Path manipulation errors occur when the following two conditions are met:\n\n  For example, the program may give the attacker the ability to overwrite the specified\n  file or run with a configuration controlled by the attacker.'\nApplicable_Platforms:\n  Operating_System: Unix, Windows, macOS\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: The external control or influence of\n  filenames can often be detected using automated static analysis that models data\n  flow within the product.\n\n  Automated static analysis might not be able to recognize when proper input validation\n  is being performed, leading to false positives - i.e., warnings that do not have\n  any security consequences or require any code changes.'\nPotential_Mitigations: 'Architecture and Design: When the set of filenames is limited\n  or known, create a mapping from a set of fixed input values (such as numeric IDs)\n  to the actual filenames, and reject all other inputs. For example, ID 1 could map\n  to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap\n  provide this capability.\n\n\n  Architecture and Design\n\n  Operation: Run your code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict all access to files within a particular directory.\n\n  Examples include the Unix chroot jail and AppArmor. In general, managed code may\n  provide some protection.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of your application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Implementation: Use a built-in path canonicalization function (such as realpath()\n  in C) that produces the canonical version of the pathname, which effectively removes\n  \"..\" sequences and symbolic links (CWE-23, CWE-59).\n\n\n  Installation, Operation: Use OS-level permissions and run as a low-privileged user\n  to limit the scope of any successful attack.\n\n\n  Operation, Implementation: If you are using PHP, configure your application so that\n  it does not use register_globals. During implementation, develop your application\n  so that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n\n\n  Testing: Use tools and techniques that require manual (human) analysis, such as\n  penetration testing, threat modeling, and interactive tools that allow the tester\n  to record and modify an active session. These may be more effective than strictly\n  automated techniques. This is especially the case with weaknesses that are related\n  to design and business rules.'\nObserved_Examples: 'CVE-2008-5748: Chain: external control of values for user''s desired\n  language and theme enables path traversal.\n\n\n  CVE-2008-5764: Chain: external control of user''s target language enables remote\n  file inclusion.'\nRelated_Attack_Patterns: \"13: \\n\\n267: \\n\\n64: \\n\\n72: \\n\\n76: \\n\\n78: \\n\\n79: \\n\\n\\\n  80: \"\n",
  "ID: '732'\nName: Incorrect Permission Assignment for Critical Resource\nDescription: The product specifies permissions for a security-critical resource in\n  a way that allows that resource to be read or modified by unintended actors.\nExtended_Description: When a resource is given a permission setting that provides\n  access to a wider range of actors than required, it could lead to the exposure of\n  sensitive information, or the modification of that resource by unintended parties.\n  This is especially dangerous when the resource is related to program configuration,\n  execution, or sensitive user data. For example, consider a misconfigured storage\n  account for the cloud that can be read or written by a public or anonymous user.\nApplicable_Platforms:\n  Technology: Cloud Computing\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\\n\\\n  The developer might make certain assumptions about the environment in which the\\\n  \\ product operates - e.g., that the software is running on a single-user system,\\\n  \\ or the software is only accessible to trusted administrators. When the software\\\n  \\ is running in a different environment, the permissions become a problem.\\n\\nInstallation:\\\n  \\ The developer may set loose permissions in order to minimize problems when the\\\n  \\ user first runs the program, then create documentation stating that permissions\\\n  \\ should be tightened. Since system administrators and users do not always read\\\n  \\ the documentation, this can result in insecure permissions being left unchanged.\\n\\\n  \\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis may be effective\n  in detecting permission problems for system resources such as files, directories,\n  shared memory, device interfaces, etc. Automated techniques may be able to detect\n  the use of library functions that modify permissions, then analyze function calls\n  for arguments that contain potentially insecure values.\n\n  However, since the software''s intended security policy might allow loose permissions\n  for certain operations (such as publishing a file on a web server), automated static\n  analysis may produce some false positives - i.e., warnings that do not have any\n  security consequences or require any code changes.\n\n  When custom permissions models are used - such as defining who can read messages\n  in a particular forum in a bulletin board system - these can be difficult to detect\n  using automated static analysis. It may be possible to define custom signatures\n  that identify any custom functions that implement the permission checks and assignments.\n\n\n  Automated Dynamic Analysis: Automated dynamic analysis may be effective in detecting\n  permission problems for system resources such as files, directories, shared memory,\n  device interfaces, etc.\n\n  However, since the software''s intended security policy might allow loose permissions\n  for certain operations (such as publishing a file on a web server), automated dynamic\n  analysis may produce some false positives - i.e., warnings that do not have any\n  security consequences or require any code changes.\n\n  When custom permissions models are used - such as defining who can read messages\n  in a particular forum in a bulletin board system - these can be difficult to detect\n  using automated dynamic analysis. It may be possible to define custom signatures\n  that identify any custom functions that implement the permission checks and assignments.\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Manual Static Analysis: Manual static analysis may be effective in detecting the\n  use of custom permissions models and functions. The code could then be examined\n  to identifying usage of the related functions. Then the human analyst could evaluate\n  permission assignments in the context of the intended security model of the software.\n\n\n  Manual Dynamic Analysis: Manual dynamic analysis may be effective in detecting the\n  use of custom permissions models and functions. The program could then be executed\n  with a focus on exercising code paths that are related to the custom permissions.\n  Then the human analyst could evaluate permission assignments in the context of the\n  intended security model of the software.\n\n\n  Fuzzing: Fuzzing is not effective in detecting this weakness.\n\n\n  Black Box: Use monitoring tools that examine the software''s process as it interacts\n  with the operating system and the network. This technique is useful in cases when\n  source code is unavailable, if the software was not developed by you, or if you\n  want to verify that the build phase did not introduce any new weaknesses. Examples\n  include debuggers that directly attach to the running process; system-call tracing\n  utilities such as truss (Solaris) and strace (Linux); system activity monitors such\n  as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows);\n  and sniffers and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and watch for library functions or system calls\n  on OS resources such as files, directories, and shared memory. Examine the arguments\n  to these calls to infer which permissions are being used.\n\n  Note that this technique is only useful for permissions issues related to system\n  resources. It is not likely to detect application-level business rules that are\n  related to permissions, such as if a user of a blog system marks a post as \"private,\"\n  but the blog system inadvertently marks it as \"public.\"\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Implementation: When using a critical resource such as a configuration\n  file, check to see if the resource has insecure permissions (such as being modifiable\n  by any regular user) [REF-62], and generate an error or even exit the software if\n  there is a possibility that the resource could have been modified by an unauthorized\n  party.\n\n\n  Architecture and Design: Divide the software into anonymous, normal, privileged,\n  and administrative areas. Reduce the attack surface by carefully defining distinct\n  user groups, privileges, and/or roles. Map these against data, functionality, and\n  the related resources. Then set the permissions accordingly. This will allow you\n  to maintain more fine-grained control over your resources. [REF-207]\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Implementation, Installation: During program startup, explicitly set the default\n  permissions or umask to the most restrictive setting possible. Also set the appropriate\n  permissions during program installation. This will prevent you from inheriting insecure\n  permissions from any user who installs or runs the program.\n\n\n  System Configuration: For all configuration files, executables, and libraries, make\n  sure that they are only readable and writable by the software''s administrator.\n\n\n  Documentation: Do not suggest insecure configuration changes in documentation, especially\n  if those configurations can extend to resources and other programs that are outside\n  the scope of the application.\n\n\n  Installation: Do not assume that a system administrator will manually change the\n  configuration to the settings that are recommended in the software''s manual.\n\n\n  Operation, System Configuration: Ensure that the software runs properly under the\n  United States Government Configuration Baseline (USGCB) [REF-199] or an equivalent\n  hardening configuration guide, which many organizations use to limit the attack\n  surface and potential risk of deployed software.\n\n\n  Implementation, System Configuration, Operation: When storing data in the cloud\n  (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider''s\n  controls to disable public access.'\nObserved_Examples: 'CVE-2022-29527: Go application for cloud management creates a\n  world-writable sudoers file that allows local attackers to inject sudo rules and\n  escalate privileges to root by winning a race condition.\n\n\n  CVE-2009-3482: Anti-virus product sets insecure \"Everyone: Full Control\" permissions\n  for files under the \"Program Files\" folder, allowing attackers to replace executables\n  with Trojan horses.\n\n\n  CVE-2009-3897: Product creates directories with 0777 permissions at installation,\n  allowing users to gain privileges and access a socket used for authentication.\n\n\n  CVE-2009-3489: Photo editor installs a service with an insecure security descriptor,\n  allowing users to stop or start the service, or execute commands as SYSTEM.\n\n\n  CVE-2020-15708: socket created with insecure permissions\n\n\n  CVE-2009-3289: Library function copies a file to a new target and uses the source\n  file''s permissions for the target, which is incorrect when the source file is a\n  symbolic link, which typically has 0777 permissions.\n\n\n  CVE-2009-0115: Device driver uses world-writable permissions for a socket file,\n  allowing attackers to inject arbitrary commands.\n\n\n  CVE-2009-1073: LDAP server stores a cleartext password in a world-readable file.\n\n\n  CVE-2009-0141: Terminal emulator creates TTY devices with world-writable permissions,\n  allowing an attacker to write to the terminals of other users.\n\n\n  CVE-2008-0662: VPN product stores user credentials in a registry key with \"Everyone:\n  Full Control\" permissions, allowing attackers to steal the credentials.\n\n\n  CVE-2008-0322: Driver installs its device interface with \"Everyone: Write\" permissions.\n\n\n  CVE-2009-3939: Driver installs a file with world-writable permissions.\n\n\n  CVE-2009-3611: Product changes permissions to 0777 before deleting a backup; the\n  permissions stay insecure for subsequent backups.\n\n\n  CVE-2007-6033: Product creates a share with \"Everyone: Full Control\" permissions,\n  allowing arbitrary program execution.\n\n\n  CVE-2007-5544: Product uses \"Everyone: Full Control\" permissions for memory-mapped\n  files (shared memory) in inter-process communication, allowing attackers to tamper\n  with a session.\n\n\n  CVE-2005-4868: Database product uses read/write permissions for everyone for its\n  shared memory, allowing theft of credentials.\n\n\n  CVE-2004-1714: Security product uses \"Everyone: Full Control\" permissions for its\n  configuration files.\n\n\n  CVE-2001-0006: \"Everyone: Full Control\" permissions assigned to a mutex allows users\n  to disable network connectivity.\n\n\n  CVE-2002-0969: Chain: database product contains buffer overflow that is only reachable\n  through a .ini configuration file - which has \"Everyone: Full Control\" permissions.'\nRelated_Attack_Patterns: \"1: \\n\\n122: \\n\\n127: \\n\\n17: \\n\\n180: \\n\\n206: \\n\\n234:\\\n  \\ \\n\\n60: \\n\\n61: \\n\\n62: \\n\\n642: \"\n",
  "ID: '733'\nName: Compiler Optimization Removal or Modification of Security-critical Code\nDescription: The developer builds a security-critical protection mechanism into the\n  software, but the compiler optimizes the program such that the mechanism is removed\n  or modified.\nApplicable_Platforms:\n  Language: C, C++, Compiled\nDetection_Methods: 'Black Box: This specific weakness is impossible to detect using\n  black box methods. While an analyst could examine memory to see that it has not\n  been scrubbed, an analysis of the executable would not be successful. This is because\n  the compiler has already removed the relevant code. Only the source code shows whether\n  the programmer intended to clear the memory or not, so this weakness is indistinguishable\n  from others.\n\n\n  White Box: This weakness is only detectable using white box methods (see black box\n  detection factor). Careful analysis is required to determine if the code is likely\n  to be removed by the compiler.'\nObserved_Examples: 'CVE-2008-1685: C compiler optimization, as allowed by specifications,\n  removes code that is used to perform checks to detect integer overflows.\n\n\n  CVE-2019-1010006: Chain: compiler optimization (CWE-733) removes or modifies code\n  used to detect integer overflow (CWE-190), allowing out-of-bounds write (CWE-787).'\nRelated_Attack_Patterns: \"10: \\n\\n24: \\n\\n46: \\n\\n8: \\n\\n9: \"\n",
  "ID: '74'\nName: Improper Neutralization of Special Elements in Output Used by a Downstream Component\n  ('Injection')\nDescription: The product constructs all or part of a command, data structure, or record\n  using externally-influenced input from an upstream component, but it does not neutralize\n  or incorrectly neutralizes special elements that could modify how it is parsed or\n  interpreted when it is sent to a downstream component.\nExtended_Description: Software or other automated logic has certain assumptions about\n  what constitutes data and control respectively. It is the lack of verification of\n  these assumptions for user-controlled input that leads to injection problems. Injection\n  problems encompass a wide variety of issues -- all mitigated in very different ways\n  and usually attempted in order to alter the control flow of the process. For this\n  reason, the most effective way to discuss these weaknesses is to note the distinct\n  features that classify them as injection weaknesses. The most important issue to\n  note is that all injection problems share one thing in common -- i.e., they allow\n  for the injection of control plane data into the user-controlled data plane. This\n  means that the execution of the process may be altered by sending code in through\n  legitimate data channels, using no other mechanism. While buffer overflows, and\n  many other flaws, involve the use of some further issue to gain execution, injection\n  problems need only for the data to be parsed.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Requirements: Programming languages and supporting technologies\n  might be chosen which are not subject to these issues.\n\n\n  Implementation: Utilize an appropriate mix of allowlist and denylist parsing to\n  filter control-plane syntax from all input.'\nObserved_Examples: 'CVE-2022-36069: Python-based dependency management tool avoids\n  OS command injection  when generating Git commands but allows  injection of optional\n  arguments with input beginning with a dash, potentially allowing for code execution.\n\n\n  CVE-1999-0067: Canonical example of OS command injection. CGI program does not neutralize\n  \"|\" metacharacter when invoking a phonebook program.\n\n\n  CVE-2022-1509: injection of sed script syntax (\"sed injection\")\n\n\n  CVE-2020-9054: Chain: improper input validation (CWE-20) in username parameter,\n  leading to OS command injection (CWE-78), as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-44228: Product does not neutralize ${xyz} style expressions, allowing remote\n  code execution. (log4shell vulnerability)'\nRelated_Attack_Patterns: \"10: \\n\\n101: \\n\\n105: \\n\\n108: \\n\\n120: \\n\\n13: \\n\\n135:\\\n  \\ \\n\\n14: \\n\\n24: \\n\\n250: \\n\\n267: \\n\\n273: \\n\\n28: \\n\\n3: \\n\\n34: \\n\\n42: \\n\\n\\\n  43: \\n\\n45: \\n\\n46: \\n\\n47: \\n\\n51: \\n\\n52: \\n\\n53: \\n\\n6: \\n\\n64: \\n\\n67: \\n\\n\\\n  7: \\n\\n71: \\n\\n72: \\n\\n76: \\n\\n78: \\n\\n79: \\n\\n8: \\n\\n80: \\n\\n83: \\n\\n84: \\n\\n9: \"\n",
  "ID: '749'\nName: Exposed Dangerous Method or Function\nDescription: The product provides an Applications Programming Interface (API) or similar\n  interface for interaction with external actors, but the interface includes a dangerous\n  method or function that is not properly restricted.\nExtended_Description: 'This weakness can lead to a wide variety of resultant weaknesses,\n  depending on the behavior of the exposed method. It can apply to any number of technologies\n  and approaches, such as ActiveX controls, Java functions, IOCTLs, and so on.\n\n  The exposure can occur in a few different ways:'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: If you must expose a method, make\n  sure to perform input validation on all arguments, limit access to authorized parties,\n  and protect against all possible vulnerabilities.\n\n\n  Architecture and Design\n\n  Implementation: Identify all exposed functionality. Explicitly list all functionality\n  that must be exposed to some user or set of users. Identify which functionality\n  may be:\n\n  Ensure that the implemented code follows these expectations. This includes setting\n  the appropriate access modifiers where applicable (public, private, protected, etc.)\n  or not marking ActiveX controls safe-for-scripting.'\nObserved_Examples: 'CVE-2007-6382: arbitrary Java code execution via exposed method\n\n\n  CVE-2007-1112: security tool ActiveX control allows download or upload of files'\nRelated_Attack_Patterns: '500: '\n",
  "ID: '75'\nName: Failure to Sanitize Special Elements into a Different Plane (Special Element\n  Injection)\nDescription: The product does not adequately filter user-controlled input for special\n  elements with control implications.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Requirements: Programming languages and supporting technologies\n  might be chosen which are not subject to these issues.\n\n\n  Implementation: Utilize an appropriate mix of allowlist and denylist parsing to\n  filter special element syntax from all input.'\nRelated_Attack_Patterns: \"81: \\n\\n93: \"\n",
  "ID: '754'\nName: Improper Check for Unusual or Exceptional Conditions\nDescription: The product does not check or incorrectly checks for unusual or exceptional\n  conditions that are not expected to occur frequently during day to day operation\n  of the product.\nExtended_Description: 'The programmer may assume that certain events or conditions\n  will never occur or do not need to be worried about, such as low memory conditions,\n  lack of access to resources due to restrictive permissions, or misbehaving clients\n  or components. However, attackers may intentionally trigger these unusual conditions,\n  thus violating the programmer''s assumptions, possibly introducing instability,\n  incorrect behavior, or a vulnerability.\n\n  Note that this entry is not exclusively about the use of exceptions and exception\n  handling, which are mechanisms for both checking and handling unusual or unexpected\n  conditions.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis may be useful\n  for detecting unusual conditions involving system resources or common programming\n  idioms, but not for violations of business rules.\n\n\n  Manual Dynamic Analysis: Identify error conditions that are not likely to occur\n  during normal usage and trigger them. For example, run the program under low memory\n  conditions, run with insufficient privileges or permissions, interrupt a transaction\n  before it is completed, or disable connectivity to basic network services such as\n  DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled\n  exception or similar error that was discovered and handled by the application''s\n  environment, it may still indicate unexpected conditions that were not handled by\n  the application itself.'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  Choose languages with features such as exception handling that force the programmer\n  to anticipate unusual conditions that may generate exceptions. Custom exceptions\n  may need to be developed to handle unusual business-logic conditions. Be careful\n  not to pass sensitive exceptions back to the user (CWE-209, CWE-248).\n\n\n  Implementation: Check the results of all functions that return a value and verify\n  that the value is expected.\n\n\n  Implementation: If using exception handling, catch and throw specific exceptions\n  instead of overly-general exceptions (CWE-396, CWE-397). Catch and handle exceptions\n  as locally as possible so that exceptions do not propagate too far up the call stack\n  (CWE-705). Avoid unchecked or uncaught exceptions where feasible (CWE-248).\n\n\n  Implementation: Ensure that error messages only contain minimal details that are\n  useful to the intended audience and no one else. The messages need to strike the\n  balance between being too cryptic (which can confuse users) or being too detailed\n  (which may reveal more than intended). The messages should not reveal the methods\n  that were used to determine the error. Attackers can use detailed information to\n  refine or optimize their original attack, thereby increasing their chances of success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.\n\n  Exposing additional information to a potential attacker in the context of an exceptional\n  condition can help the attacker determine what attack vectors are most likely to\n  succeed beyond DoS.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Architecture and Design\n\n  Implementation: If the program must fail, ensure that it fails gracefully (fails\n  closed). There may be a temptation to simply let the program fail poorly in cases\n  such as low memory conditions, but an attacker may be able to assert control before\n  the software has fully exited. Alternately, an uncontrolled failure could cause\n  cascading problems with other downstream components; for example, the program could\n  send a signal to a downstream process so the process immediately knows that a problem\n  has occurred and has a better chance of recovery.\n\n\n  Architecture and Design: Use system limits, which should help to prevent resource\n  exhaustion. However, the product should still handle low resource conditions since\n  they may still occur.'\nObserved_Examples: 'CVE-2007-3798: Unchecked return value leads to resultant integer\n  overflow and code execution.\n\n\n  CVE-2006-4447: Program does not check return value when invoking functions to drop\n  privileges, which could leave users with higher privileges than expected by forcing\n  those functions to fail.\n\n\n  CVE-2006-2916: Program does not check return value when invoking functions to drop\n  privileges, which could leave users with higher privileges than expected by forcing\n  those functions to fail.'\n",
  "ID: '755'\nName: Improper Handling of Exceptional Conditions\nDescription: The product does not handle or incorrectly handles an exceptional condition.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2021-3011: virtual interrupt controller in a virtualization\n  product allows crash of host by writing a certain invalid value to a register, which\n  triggers a fatal error instead of returning an error code\n\n\n  CVE-2008-4302: Chain: OS kernel does not properly handle a failure of a function\n  call (CWE-755), leading to an unlock of a resource that was not locked (CWE-832),\n  with resultant crash.'\n",
  "ID: '756'\nName: Missing Custom Error Page\nDescription: The product does not return custom error pages to the user, possibly\n  exposing sensitive information.\n",
  "ID: '757'\nName: Selection of Less-Secure Algorithm During Negotiation ('Algorithm Downgrade')\nDescription: A protocol or its implementation supports interaction between multiple\n  actors and allows those actors to negotiate which algorithm should be used as a\n  protection mechanism such as encryption or authentication, but it does not select\n  the strongest algorithm that is available to both parties.\nExtended_Description: When a security mechanism can be forced to downgrade to use\n  a less secure algorithm, this can make it easier for attackers to compromise the\n  product by exploiting weaker algorithm. The victim might not be aware that the less\n  secure algorithm is being used. For example, if an attacker can force a communications\n  channel to use cleartext instead of strongly-encrypted data, then the attacker could\n  read the channel by sniffing, instead of going through extra effort of trying to\n  decrypt the data using brute force techniques.\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2006-4302: Attacker can select an older version of the software\n  to exploit its vulnerabilities.\n\n\n  CVE-2006-4407: Improper prioritization of encryption ciphers during negotiation\n  leads to use of a weaker cipher.\n\n\n  CVE-2005-2969: chain: SSL/TLS implementation disables a verification step (CWE-325)\n  that enables a downgrade attack to a weaker protocol.\n\n\n  CVE-2001-1444: Telnet protocol implementation allows downgrade to weaker authentication\n  and encryption using an Adversary-in-the-Middle AITM attack.\n\n\n  CVE-2002-1646: SSH server implementation allows override of configuration setting\n  to use weaker authentication schemes. This may be a composite with CWE-642.'\nRelated_Attack_Patterns: \"220: \\n\\n606: \\n\\n620: \"\n",
  "ID: '758'\nName: Reliance on Undefined, Unspecified, or Implementation-Defined Behavior\nDescription: The product uses an API function, data structure, or other entity in\n  a way that relies on properties that are not always guaranteed to hold for that\n  entity.\nExtended_Description: This can lead to resultant weaknesses when the required properties\n  change, such as when the product is ported to a different platform or if an interaction\n  error (CWE-435) occurs.\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nObserved_Examples: 'CVE-2006-1902: Change in C compiler behavior causes resultant\n  buffer overflows in programs that depend on behaviors that were undefined in the\n  C standard.'\n",
  "ID: '759'\nName: Use of a One-Way Hash without a Salt\nDescription: The product uses a one-way cryptographic hash against an input that should\n  not be reversible, such as a password, but the product does not also use a salt\n  as part of the input.\nExtended_Description: 'This makes it easier for attackers to pre-compute the hash\n  value using dictionary attack techniques such as rainbow tables.\n\n  It should be noted that, despite common perceptions, the use of a good salt with\n  a hash does not sufficiently increase the effort for an attacker who is targeting\n  an individual password, or who has a large amount of computing resources available,\n  such as with cloud-based services or specialized, inexpensive hardware. Offline\n  password cracking can still be effective if the hash function is not expensive to\n  compute; many cryptographic functions are designed to be efficient and can be vulnerable\n  to attacks using massive computing resources, even if the hash is cryptographically\n  strong. The use of a salt only slightly increases the computing requirements for\n  an attacker compared to other strategies such as adaptive hash functions. See CWE-916\n  for more details.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use an adaptive hash function that\n  can be configured to change the amount of computational effort needed to compute\n  the hash, such as the number of iterations (\"stretching\") or the amount of memory\n  required. Some hash functions perform salting automatically. These functions can\n  significantly increase the overhead for a brute force attack compared to intentionally-fast\n  functions such as MD5. For example, rainbow table attacks can become infeasible\n  due to the high computing overhead. Finally, since computing power gets faster and\n  cheaper over time, the technique can be reconfigured to increase the workload without\n  forcing an entire replacement of the algorithm in use.\n\n  Some hash functions that have one or more of these desired properties include bcrypt\n  [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate\n  about which of these is the most effective, they are all stronger than using salts\n  with hash functions with very little computing overhead.\n\n  Note that using these functions can have an impact on performance, so they require\n  special consideration to avoid denial-of-service attacks. However, their configurability\n  provides finer control over how much CPU and memory is used, so it could be adjusted\n  to suit the environment''s needs.\n\n\n  Architecture and Design: If a technique that requires extra computational effort\n  can not be implemented, then for each password that is processed, generate a new\n  random salt using a strong random number generator with unpredictable seeds. Add\n  the salt to the plaintext password before hashing it. When storing the hash, also\n  store the salt. Do not use the same salt for every password.\n\n\n  Implementation\n\n  Architecture and Design: When using industry-approved techniques, use them correctly.\n  Don''t cut corners by skipping resource-intensive steps (CWE-325). These steps are\n  often essential for preventing common attacks.'\nObserved_Examples: 'CVE-2008-1526: Router does not use a salt with a hash, making\n  it easier to crack passwords.\n\n\n  CVE-2006-1058: Router does not use a salt with a hash, making it easier to crack\n  passwords.'\n",
  "ID: '76'\nName: Improper Neutralization of Equivalent Special Elements\nDescription: The product correctly neutralizes certain special elements, but it improperly\n  neutralizes equivalent special elements.\nExtended_Description: The product may have a fixed list of special characters it believes\n  is complete. However, there may be alternate encodings, or representations that\n  also have the same meaning. For example, the product may filter out a leading slash\n  (/) to prevent absolute path names, but does not account for a tilde (~) followed\n  by a user name, which on some *nix systems could be expanded to an absolute pathname.\n  Alternately, the product might filter a dangerous \"-e\" command-line switch when\n  calling an external program, but it might not account for \"--exec\" or other switches\n  that have the same semantics.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Requirements: Programming languages and supporting technologies\n  might be chosen which are not subject to these issues.\n\n\n  Implementation: Utilize an appropriate mix of allowlist and denylist parsing to\n  filter equivalent special element syntax from all input.'\n",
  "ID: '760'\nName: Use of a One-Way Hash with a Predictable Salt\nDescription: The product uses a one-way cryptographic hash against an input that should\n  not be reversible, such as a password, but the product uses a predictable salt as\n  part of the input.\nExtended_Description: 'This makes it easier for attackers to pre-compute the hash\n  value using dictionary attack techniques such as rainbow tables, effectively disabling\n  the protection that an unpredictable salt would provide.\n\n  It should be noted that, despite common perceptions, the use of a good salt with\n  a hash does not sufficiently increase the effort for an attacker who is targeting\n  an individual password, or who has a large amount of computing resources available,\n  such as with cloud-based services or specialized, inexpensive hardware. Offline\n  password cracking can still be effective if the hash function is not expensive to\n  compute; many cryptographic functions are designed to be efficient and can be vulnerable\n  to attacks using massive computing resources, even if the hash is cryptographically\n  strong. The use of a salt only slightly increases the computing requirements for\n  an attacker compared to other strategies such as adaptive hash functions. See CWE-916\n  for more details.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use an adaptive hash function that\n  can be configured to change the amount of computational effort needed to compute\n  the hash, such as the number of iterations (\"stretching\") or the amount of memory\n  required. Some hash functions perform salting automatically. These functions can\n  significantly increase the overhead for a brute force attack compared to intentionally-fast\n  functions such as MD5. For example, rainbow table attacks can become infeasible\n  due to the high computing overhead. Finally, since computing power gets faster and\n  cheaper over time, the technique can be reconfigured to increase the workload without\n  forcing an entire replacement of the algorithm in use.\n\n  Some hash functions that have one or more of these desired properties include bcrypt\n  [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate\n  about which of these is the most effective, they are all stronger than using salts\n  with hash functions with very little computing overhead.\n\n  Note that using these functions can have an impact on performance, so they require\n  special consideration to avoid denial-of-service attacks. However, their configurability\n  provides finer control over how much CPU and memory is used, so it could be adjusted\n  to suit the environment''s needs.\n\n\n  Implementation: If a technique that requires extra computational effort can not\n  be implemented, then for each password that is processed, generate a new random\n  salt using a strong random number generator with unpredictable seeds. Add the salt\n  to the plaintext password before hashing it. When storing the hash, also store the\n  salt. Do not use the same salt for every password.'\nObserved_Examples: 'CVE-2008-4905: Blogging software uses a hard-coded salt when calculating\n  a password hash.\n\n\n  CVE-2002-1657: Database server uses the username for a salt when encrypting passwords,\n  simplifying brute force attacks.\n\n\n  CVE-2001-0967: Server uses a constant salt when encrypting passwords, simplifying\n  brute force attacks.\n\n\n  CVE-2005-0408: chain: product generates predictable MD5 hashes using a constant\n  value combined with username, allowing authentication bypass.'\n",
  "ID: '761'\nName: Free of Pointer not at Start of Buffer\nDescription: The product calls free() on a pointer to a memory resource that was allocated\n  on the heap, but the pointer is not at the start of the buffer.\nExtended_Description: 'This can cause the product to crash, or in some cases, modify\n  critical program variables or execute code.\n\n  This weakness often occurs when the memory is allocated explicitly on the heap with\n  one of the malloc() family functions and free() is called, but pointer arithmetic\n  has caused the pointer to be in the interior or end of the buffer.'\nPotential_Mitigations: 'Implementation: When utilizing pointer arithmetic to traverse\n  a buffer, use a separate variable to track progress through memory and preserve\n  the originally allocated address for later freeing.\n\n\n  Implementation: When programming in C++, consider using smart pointers provided\n  by the boost library to help correctly and consistently manage memory.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, glibc in Linux provides protection against free of invalid pointers.\n\n\n  Architecture and Design: Use a language that provides abstractions for memory allocation\n  and deallocation.\n\n\n  Testing: Use a tool that dynamically detects memory management problems, such as\n  valgrind.'\nObserved_Examples: 'CVE-2019-11930: function \"internally calls ''calloc'' and returns\n  a pointer at an index... inside the allocated buffer. This led to freeing invalid\n  memory.\"'\n",
  "ID: '762'\nName: Mismatched Memory Management Routines\nDescription: The product attempts to return a memory resource to the system, but it\n  calls a release function that is not compatible with the function that was originally\n  used to allocate that resource.\nExtended_Description: 'This weakness can be generally described as mismatching memory\n  management routines, such as:\n\n  When the memory management functions are mismatched, the consequences may be as\n  severe as code execution, memory corruption, or program crash. Consequences and\n  ease of exploit will vary depending on the implementation of the routines and the\n  object being managed.'\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Implementation: Only call matching memory management functions.\n  Do not mix and match routines. For example, when you allocate a buffer with malloc(),\n  dispose of the original pointer with free().\n\n\n  Implementation: Choose a language or tool that provides automatic memory management,\n  or makes manual memory management less error-prone.\n\n  For example, glibc in Linux provides protection against free of invalid pointers.\n\n  When using Xcode to target OS X or iOS, enable automatic reference counting (ARC)\n  [REF-391].\n\n  To help correctly and consistently manage memory when programming in C++, consider\n  using a smart pointer class such as std::auto_ptr (defined by ISO/IEC ISO/IEC 14882:2003),\n  std::shared_ptr and std::unique_ptr (specified by an upcoming revision of the C++\n  standard, informally referred to as C++ 1x), or equivalent solutions such as Boost.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, glibc in Linux provides protection against free of invalid pointers.\n\n\n  Architecture and Design: Use a language that provides abstractions for memory allocation\n  and deallocation.\n\n\n  Testing: Use a tool that dynamically detects memory management problems, such as\n  valgrind.'\n",
  "ID: '763'\nName: Release of Invalid Pointer or Reference\nDescription: The product attempts to return a memory resource to the system, but it\n  calls the wrong release function or calls the appropriate release function incorrectly.\nExtended_Description: 'This weakness can take several forms, such as:'\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nPotential_Mitigations: 'Implementation: Only call matching memory management functions.\n  Do not mix and match routines. For example, when you allocate a buffer with malloc(),\n  dispose of the original pointer with free().\n\n\n  Implementation: When programming in C++, consider using smart pointers provided\n  by the boost library to help correctly and consistently manage memory.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, glibc in Linux provides protection against free of invalid pointers.\n\n\n  Architecture and Design: Use a language that provides abstractions for memory allocation\n  and deallocation.\n\n\n  Testing: Use a tool that dynamically detects memory management problems, such as\n  valgrind.'\n",
  "ID: '764'\nName: Multiple Locks of a Critical Resource\nDescription: The product locks a critical resource more times than intended, leading\n  to an unexpected state in the system.\nExtended_Description: When a product is operating in a concurrent environment and\n  repeatedly locks a critical resource, the consequences will vary based on the type\n  of lock, the lock's implementation, and the resource being protected. In some situations\n  such as with semaphores, the resources are pooled and extra locking calls will reduce\n  the size of the total available pool, possibly leading to degraded performance or\n  a denial of service. If this can be triggered by an attacker, it will be similar\n  to an unrestricted lock (CWE-412). In the context of a binary lock, it is likely\n  that any duplicate locking attempts will never succeed since the lock is already\n  held and progress may not be possible.\nPotential_Mitigations: 'Implementation: When locking and unlocking a resource, try\n  to be sure that all control paths through the code in which the resource is locked\n  one or more times correspond to exactly as many unlocks. If the software acquires\n  a lock and then determines it is not able to perform its intended behavior, be sure\n  to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s)\n  before trying again.'\n",
  "ID: '765'\nName: Multiple Unlocks of a Critical Resource\nDescription: The product unlocks a critical resource more times than intended, leading\n  to an unexpected state in the system.\nExtended_Description: When the product is operating in a concurrent environment and\n  repeatedly unlocks a critical resource, the consequences will vary based on the\n  type of lock, the lock's implementation, and the resource being protected. In some\n  situations such as with semaphores, the resources are pooled and extra calls to\n  unlock will increase the count for the number of available resources, likely resulting\n  in a crash or unpredictable behavior when the system nears capacity.\nPotential_Mitigations: 'Implementation: When locking and unlocking a resource, try\n  to be sure that all control paths through the code in which the resource is locked\n  one or more times correspond to exactly as many unlocks. If the product acquires\n  a lock and then determines it is not able to perform its intended behavior, be sure\n  to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s)\n  before trying again.'\nObserved_Examples: 'CVE-2009-0935: Attacker provides invalid address to a memory-reading\n  function, causing a mutex to be unlocked twice'\n",
  "ID: '766'\nName: Critical Data Element Declared Public\nDescription: The product declares a critical variable, field, or member to be public\n  when intended security policy requires it to be private.\nExtended_Description: This issue makes it more difficult to maintain the product,\n  which indirectly affects security by making it more difficult or time-consuming\n  to find and/or fix vulnerabilities.  It also might make it easier to introduce vulnerabilities.\nApplicable_Platforms:\n  Language: C++, C#, Java\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Data should be private, static, and final\n  whenever possible. This will assure that your code is protected by instantiating\n  early, preventing access, and preventing tampering.'\nObserved_Examples: 'CVE-2010-3860: variables declared public allows remote read of\n  system properties such as user name and home directory.'\n",
  "ID: '767'\nName: Access to Critical Private Variable via Public Method\nDescription: The product defines a public method that reads or modifies a private\n  variable.\nExtended_Description: If an attacker modifies the variable to contain unexpected values,\n  this could violate assumptions from other parts of the code. Additionally, if an\n  attacker can read the private variable, it may expose sensitive information or make\n  it easier to launch further attacks.\nApplicable_Platforms:\n  Language: C++, C#, Java\nPotential_Mitigations: 'Implementation: Use class accessor and mutator methods appropriately.\n  Perform validation when accepting data from a public method that is intended to\n  modify a critical private variable. Also be sure that appropriate access controls\n  are being applied when a public method interfaces with critical data.'\n",
  "ID: '768'\nName: Incorrect Short Circuit Evaluation\nDescription: The product contains a conditional statement with multiple logical expressions\n  in which one of the non-leading expressions may produce side effects. This may lead\n  to an unexpected state in the program after the execution of the conditional, because\n  short-circuiting logic may prevent the side effects from occurring.\nExtended_Description: 'Usage of short circuit evaluation, though well-defined in the\n  C standard, may alter control flow in a way that introduces logic errors that are\n  difficult to detect, possibly causing errors later during the product''s execution.\n  If an attacker can discover such an inconsistency, it may be exploitable to gain\n  arbitrary control over a system.\n\n  If the first condition of an \"or\" statement is assumed to be true under normal circumstances,\n  or if the first condition of an \"and\" statement is assumed to be false, then any\n  subsequent conditional may contain its own logic errors that are not detected during\n  code review or testing.\n\n  Finally, the usage of short circuit evaluation may decrease the maintainability\n  of the code.'\nPotential_Mitigations: 'Implementation: Minimizing the number of statements in a conditional\n  that produce side effects will help to prevent the likelihood of short circuit evaluation\n  to alter control flow in an unexpected way.'\n",
  "ID: '769'\nName: 'DEPRECATED: Uncontrolled File Descriptor Consumption'\nDescription: This entry has been deprecated because it was a duplicate of CWE-774.\n  All content has been transferred to CWE-774.\n",
  "ID: '77'\nName: Improper Neutralization of Special Elements used in a Command ('Command Injection')\nDescription: The product constructs all or part of a command using externally-influenced\n  input from an upstream component, but it does not neutralize or incorrectly neutralizes\n  special elements that could modify the intended command when it is sent to a downstream\n  component.\nExtended_Description: 'Command injection vulnerabilities typically occur when:\n\n  Many protocols and products have their own custom command language. While OS or\n  shell command strings are frequently discovered and targeted, developers may not\n  realize that these other command languages might also be vulnerable to attacks.\n\n  Command injection is a common problem with wrapper programs.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: If at all possible, use library calls\n  rather than external processes to recreate the desired functionality.\n\n\n  Implementation: If possible, ensure that all external commands called from the program\n  are statically created.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Operation: Run time: Run time policy enforcement may be used in an allowlist fashion\n  to prevent use of any non-sanctioned commands.\n\n\n  System Configuration: Assign permissions that prevent the user from accessing/opening\n  privileged files.'\nObserved_Examples: 'CVE-2022-36069: Python-based dependency management tool avoids\n  OS command injection  when generating Git commands but allows  injection of optional\n  arguments with input beginning with a dash, potentially allowing for code execution.\n\n\n  CVE-1999-0067: Canonical example of OS command injection. CGI program does not neutralize\n  \"|\" metacharacter when invoking a phonebook program.\n\n\n  CVE-2020-9054: Chain: improper input validation (CWE-20) in username parameter,\n  leading to OS command injection (CWE-78), as exploited in the wild per CISA KEV.\n\n\n  CVE-2022-1509: injection of sed script syntax (\"sed injection\")\n\n\n  CVE-2021-41282: injection of sed script syntax (\"sed injection\")\n\n\n  CVE-2019-13398: injection of sed script syntax (\"sed injection\")\n\n\n  CVE-2019-12921: image program allows injection of commands in \"Magick Vector Graphics\n  (MVG)\" language.\n\n\n  CVE-2020-11698: anti-spam product allows injection of SNMP commands into confiuration\n  file'\nRelated_Attack_Patterns: \"136: \\n\\n15: \\n\\n183: \\n\\n248: \\n\\n40: \\n\\n43: \\n\\n75: \\n\\\n  \\n76: \"\n",
  "ID: '770'\nName: Allocation of Resources Without Limits or Throttling\nDescription: The product allocates a reusable resource or group of resources on behalf\n  of an actor without imposing any restrictions on the size or number of resources\n  that can be allocated, in violation of the intended security policy for that actor.\nExtended_Description: Code frequently has to work with limited resources, so programmers\n  must be careful to ensure that resources are not consumed too quickly, or too easily.  Without\n  use of quotas, resource limits, or other protection mechanisms, it can be easy for\n  an attacker to consume many resources by rapidly making many requests, or causing\n  larger resources to be used than is needed. When too many resources are allocated,\n  or if a single resource is too large, then it can prevent the code from working\n  correctly, possibly leading to a denial of service.\nModes_Of_Introduction: \"Architecture and Design: OMISSION: This weakness is caused\\\n  \\ by missing a security tactic during the architecture and design phase.\\n\\nImplementation:\\\n  \\ \\n\\nOperation: \\n\\nSystem Configuration: \"\nDetection_Methods: 'Manual Static Analysis: Manual static analysis can be useful for\n  finding this weakness, but it might not achieve desired code coverage within limited\n  time constraints. If denial-of-service is not considered a significant risk, or\n  if there is strong emphasis on consequences such as code execution, then manual\n  analysis may not focus on this weakness at all.\n\n\n  Fuzzing: While fuzzing is typically geared toward finding low-level implementation\n  bugs, it can inadvertently find uncontrolled resource allocation problems. This\n  can occur when the fuzzer generates a large number of test cases but does not restart\n  the targeted product in between test cases. If an individual test case produces\n  a crash, but it does not do so reliably, then an inability to limit resource allocation\n  may be the cause.\n\n  When the allocation is directly affected by numeric inputs, then fuzzing may produce\n  indications of this weakness.\n\n\n  Automated Dynamic Analysis: Certain automated dynamic analysis techniques may be\n  effective in producing side effects of uncontrolled resource allocation problems,\n  especially with resources such as processes, memory, and connections. The technique\n  may involve generating a large number of requests to the product within a short\n  time frame. Manual analysis is likely required to interpret the results.\n\n\n  Automated Static Analysis: Specialized configuration or tuning may be required to\n  train automated tools to recognize this weakness.\n\n  Automated static analysis typically has limited utility in recognizing unlimited\n  allocation problems, except for the missing release of program-independent system\n  resources such as files, sockets, and processes, or unchecked arguments to memory.\n  For system resources, automated static analysis may be able to detect circumstances\n  in which resources are not released after they have expired, or if too much of a\n  resource is requested at once, as can occur with memory. Automated analysis of configuration\n  files may be able to detect settings that do not specify a maximum value.\n\n  Automated static analysis tools will not be appropriate for detecting exhaustion\n  of custom resources, such as an intended security policy in which a bulletin board\n  user is only allowed to make a limited number of posts per day.'\nPotential_Mitigations: 'Requirements: Clearly specify the minimum and maximum expectations\n  for capabilities, and dictate which behaviors are acceptable when resource allocation\n  reaches limits.\n\n\n  Architecture and Design: Limit the amount of resources that are accessible to unprivileged\n  users. Set per-user limits for resources. Allow the system administrator to define\n  these limits. Be careful to avoid CWE-410.\n\n\n  Architecture and Design: Design throttling mechanisms into the system architecture.\n  The best protection is to limit the amount of resources that an unauthorized user\n  can cause to be expended. A strong authentication and access control model will\n  help prevent such attacks from occurring in the first place, and it will help the\n  administrator to identify who is committing the abuse. The login application should\n  be protected against DoS attacks as much as possible. Limiting the database access,\n  perhaps by caching result sets, can help minimize the resources expended. To further\n  limit the potential for a DoS attack, consider tracking the rate of requests received\n  from users and blocking requests that exceed a defined rate threshold.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Architecture and Design: Mitigation of resource exhaustion attacks requires that\n  the target system either:\n\n  The first of these solutions is an issue in itself though, since it may allow attackers\n  to prevent the use of the system by a particular valid user. If the attacker impersonates\n  the valid user, they may be able to prevent the user from accessing the server in\n  question.\n\n  The second solution can be difficult to effectively institute -- and even when properly\n  done, it does not provide a full solution. It simply requires more resources on\n  the part of the attacker.\n\n\n  Architecture and Design: Ensure that protocols have specific limits of scale placed\n  on them.\n\n\n  Architecture and Design\n\n  Implementation: If the program must fail, ensure that it fails gracefully (fails\n  closed). There may be a temptation to simply let the program fail poorly in cases\n  such as low memory conditions, but an attacker may be able to assert control before\n  the software has fully exited. Alternately, an uncontrolled failure could cause\n  cascading problems with other downstream components; for example, the program could\n  send a signal to a downstream process so the process immediately knows that a problem\n  has occurred and has a better chance of recovery.\n\n  Ensure that all failures in resource allocation place the system into a safe posture.\n\n\n  Operation\n\n  Architecture and Design: Use resource-limiting settings provided by the operating\n  system or environment. For example, when managing system resources in POSIX, setrlimit()\n  can be used to set limits for certain types of resources, and getrlimit() can determine\n  how many resources are available. However, these functions are not available on\n  all operating systems.\n\n  When the current levels get close to the maximum that is defined for the application\n  (see CWE-770), then limit the allocation of further resources to privileged users;\n  alternately, begin releasing resources for less-privileged users. While this mitigation\n  may protect the system from attack, it will not necessarily stop attackers from\n  adversely impacting other users.\n\n  Ensure that the application performs the appropriate error checks and error handling\n  in case resources become unavailable (CWE-703).'\nObserved_Examples: 'CVE-2022-21668: Chain: Python library does not limit the resources\n  used to process images that specify a very large number of bands (CWE-1284), leading\n  to excessive memory consumption (CWE-789) or an integer overflow (CWE-190).\n\n\n  CVE-2009-4017: Language interpreter does not restrict the number of temporary files\n  being created when handling a MIME request with a large number of parts..\n\n\n  CVE-2009-2726: Driver does not use a maximum width when invoking sscanf style functions,\n  causing stack consumption.\n\n\n  CVE-2009-2540: Large integer value for a length property in an object causes a large\n  amount of memory allocation.\n\n\n  CVE-2009-2054: Product allows exhaustion of file descriptors when processing a large\n  number of TCP packets.\n\n\n  CVE-2008-5180: Communication product allows memory consumption with a large number\n  of SIP requests, which cause many sessions to be created.\n\n\n  CVE-2008-1700: Product allows attackers to cause a denial of service via a large\n  number of directives, each of which opens a separate window.\n\n\n  CVE-2005-4650: CMS does not restrict the number of searches that can occur simultaneously,\n  leading to resource exhaustion.\n\n\n  CVE-2020-15100: web application scanner attempts to read an excessively large file\n  created by a user, causing process termination\n\n\n  CVE-2020-7218: Go-based workload orchestrator does not limit resource usage with\n  unauthenticated connections, allowing a DoS by flooding the service'\nRelated_Attack_Patterns: \"125: \\n\\n130: \\n\\n147: \\n\\n197: \\n\\n229: \\n\\n230: \\n\\n231:\\\n  \\ \\n\\n469: \\n\\n482: \\n\\n486: \\n\\n487: \\n\\n488: \\n\\n489: \\n\\n490: \\n\\n491: \\n\\n493:\\\n  \\ \\n\\n494: \\n\\n495: \\n\\n496: \\n\\n528: \"\n",
  "ID: '771'\nName: Missing Reference to Active Allocated Resource\nDescription: The product does not properly maintain a reference to a resource that\n  has been allocated, which prevents the resource from being reclaimed.\nExtended_Description: This does not necessarily apply in languages or frameworks that\n  automatically perform garbage collection, since the removal of all references may\n  act as a signal that the resource is ready to be reclaimed.\nPotential_Mitigations: 'Operation\n\n  Architecture and Design: Use resource-limiting settings provided by the operating\n  system or environment. For example, when managing system resources in POSIX, setrlimit()\n  can be used to set limits for certain types of resources, and getrlimit() can determine\n  how many resources are available. However, these functions are not available on\n  all operating systems.\n\n  When the current levels get close to the maximum that is defined for the application\n  (see CWE-770), then limit the allocation of further resources to privileged users;\n  alternately, begin releasing resources for less-privileged users. While this mitigation\n  may protect the system from attack, it will not necessarily stop attackers from\n  adversely impacting other users.\n\n  Ensure that the application performs the appropriate error checks and error handling\n  in case resources become unavailable (CWE-703).'\n",
  "ID: '772'\nName: Missing Release of Resource after Effective Lifetime\nDescription: The product does not release a resource after its effective lifetime\n  has ended, i.e., after the resource is no longer needed.\nExtended_Description: When a resource is not released after use, it can allow attackers\n  to cause a denial of service by causing the allocation of resources without triggering\n  their release. Frequently-affected resources include memory, CPU, disk space, power\n  or battery, etc.\nApplicable_Platforms:\n  Technology: Mobile\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, languages such as Java, Ruby, and Lisp perform automatic garbage collection\n  that releases memory for objects that have been deallocated.\n\n\n  Implementation: It is good practice to be responsible for freeing all resources\n  you allocate and to be consistent with how and where you free resources in a function.\n  If you allocate resources that you intend to free upon completion of the function,\n  you must be sure to free the resources at all exit points for that function including\n  error conditions.\n\n\n  Operation\n\n  Architecture and Design: Use resource-limiting settings provided by the operating\n  system or environment. For example, when managing system resources in POSIX, setrlimit()\n  can be used to set limits for certain types of resources, and getrlimit() can determine\n  how many resources are available. However, these functions are not available on\n  all operating systems.\n\n  When the current levels get close to the maximum that is defined for the application\n  (see CWE-770), then limit the allocation of further resources to privileged users;\n  alternately, begin releasing resources for less-privileged users. While this mitigation\n  may protect the system from attack, it will not necessarily stop attackers from\n  adversely impacting other users.\n\n  Ensure that the application performs the appropriate error checks and error handling\n  in case resources become unavailable (CWE-703).'\nObserved_Examples: 'CVE-2007-0897: Chain: anti-virus product encounters a malformed\n  file but returns from a function without closing a file descriptor (CWE-775) leading\n  to file descriptor consumption (CWE-400) and failed scans.\n\n\n  CVE-2001-0830: Sockets not properly closed when attacker repeatedly connects and\n  disconnects from server.\n\n\n  CVE-1999-1127: Does not shut down named pipe connections if malformed data is sent.\n\n\n  CVE-2009-2858: Chain: memory leak (CWE-404) leads to resource exhaustion.\n\n\n  CVE-2009-2054: Product allows exhaustion of file descriptors when processing a large\n  number of TCP packets.\n\n\n  CVE-2008-2122: Port scan triggers CPU consumption with processes that attempt to\n  read data from closed sockets.\n\n\n  CVE-2007-4103: Product allows resource exhaustion via a large number of calls that\n  do not complete a 3-way handshake.\n\n\n  CVE-2002-1372: Return values of file/socket operations not checked, allowing resultant\n  consumption of file descriptors.'\nRelated_Attack_Patterns: '469: '\n",
  "ID: '773'\nName: Missing Reference to Active File Descriptor or Handle\nDescription: The product does not properly maintain references to a file descriptor\n  or handle, which prevents that file descriptor/handle from being reclaimed.\nExtended_Description: This can cause the product to consume all available file descriptors\n  or handles, which can prevent other processes from performing critical file processing\n  operations.\nPotential_Mitigations: 'Operation\n\n  Architecture and Design: Use resource-limiting settings provided by the operating\n  system or environment. For example, when managing system resources in POSIX, setrlimit()\n  can be used to set limits for certain types of resources, and getrlimit() can determine\n  how many resources are available. However, these functions are not available on\n  all operating systems.\n\n  When the current levels get close to the maximum that is defined for the application\n  (see CWE-770), then limit the allocation of further resources to privileged users;\n  alternately, begin releasing resources for less-privileged users. While this mitigation\n  may protect the system from attack, it will not necessarily stop attackers from\n  adversely impacting other users.\n\n  Ensure that the application performs the appropriate error checks and error handling\n  in case resources become unavailable (CWE-703).'\n",
  "ID: '774'\nName: Allocation of File Descriptors or Handles Without Limits or Throttling\nDescription: The product allocates file descriptors or handles on behalf of an actor\n  without imposing any restrictions on how many descriptors can be allocated, in violation\n  of the intended security policy for that actor.\nExtended_Description: This can cause the product to consume all available file descriptors\n  or handles, which can prevent other processes from performing critical file processing\n  operations.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Operation\n\n  Architecture and Design: Use resource-limiting settings provided by the operating\n  system or environment. For example, when managing system resources in POSIX, setrlimit()\n  can be used to set limits for certain types of resources, and getrlimit() can determine\n  how many resources are available. However, these functions are not available on\n  all operating systems.\n\n  When the current levels get close to the maximum that is defined for the application\n  (see CWE-770), then limit the allocation of further resources to privileged users;\n  alternately, begin releasing resources for less-privileged users. While this mitigation\n  may protect the system from attack, it will not necessarily stop attackers from\n  adversely impacting other users.\n\n  Ensure that the application performs the appropriate error checks and error handling\n  in case resources become unavailable (CWE-703).'\n",
  "ID: '775'\nName: Missing Release of File Descriptor or Handle after Effective Lifetime\nDescription: The product does not release a file descriptor or handle after its effective\n  lifetime has ended, i.e., after the file descriptor/handle is no longer needed.\nExtended_Description: When a file descriptor or handle is not released after use (typically\n  by explicitly closing it), attackers can cause a denial of service by consuming\n  all available file descriptors/handles, or otherwise preventing other system processes\n  from obtaining their own file descriptors/handles.\nPotential_Mitigations: 'Operation\n\n  Architecture and Design: Use resource-limiting settings provided by the operating\n  system or environment. For example, when managing system resources in POSIX, setrlimit()\n  can be used to set limits for certain types of resources, and getrlimit() can determine\n  how many resources are available. However, these functions are not available on\n  all operating systems.\n\n  When the current levels get close to the maximum that is defined for the application\n  (see CWE-770), then limit the allocation of further resources to privileged users;\n  alternately, begin releasing resources for less-privileged users. While this mitigation\n  may protect the system from attack, it will not necessarily stop attackers from\n  adversely impacting other users.\n\n  Ensure that the application performs the appropriate error checks and error handling\n  in case resources become unavailable (CWE-703).'\nObserved_Examples: 'CVE-2007-0897: Chain: anti-virus product encounters a malformed\n  file but returns from a function without closing a file descriptor (CWE-775) leading\n  to file descriptor consumption (CWE-400) and failed scans.'\n",
  "ID: '776'\nName: Improper Restriction of Recursive Entity References in DTDs ('XML Entity Expansion')\nDescription: The product uses XML documents and allows their structure to be defined\n  with a Document Type Definition (DTD), but it does not properly control the number\n  of recursive definitions of entities.\nExtended_Description: If the DTD contains a large number of nested or recursive entities,\n  this can lead to explosive growth of data when parsed, causing a denial of service.\nApplicable_Platforms:\n  Language: XML\nAlternate_Terms: \"XEE: XEE is the acronym commonly used for XML Entity Expansion.\\n\\\n  \\nBillion Laughs Attack: \\n\\nXML Bomb: While the \\\"XML Bomb\\\" term was used in the\\\n  \\ early years of knowledge of this issue, the XEE term seems to be more commonly\\\n  \\ used.\"\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Operation: If possible, prohibit the use of DTDs or use an\n  XML parser that limits the expansion of recursive DTD entities.\n\n\n  Implementation: Before parsing XML files with associated DTDs, scan for recursive\n  entity declarations and do not continue parsing potentially explosive content.'\nObserved_Examples: 'CVE-2008-3281: XEE in XML-parsing library.\n\n\n  CVE-2011-3288: XML bomb / XEE in enterprise communication product.\n\n\n  CVE-2011-1755: \"Billion laughs\" attack in XMPP server daemon.\n\n\n  CVE-2009-1955: XML bomb in web server module\n\n\n  CVE-2003-1564: Parsing library allows XML bomb'\nRelated_Attack_Patterns: '197: '\n",
  "ID: '777'\nName: Regular Expression without Anchors\nDescription: The product uses a regular expression to perform neutralization, but\n  the regular expression is not anchored and may allow malicious or malformed data\n  to slip through.\nExtended_Description: When performing tasks such as validating against a set of allowed\n  inputs (allowlist), data is examined and possibly modified to ensure that it is\n  well-formed and adheres to a list of safe values. If the regular expression is not\n  anchored, malicious or malformed data may be included before or after any string\n  matching the regular expression. The type of malicious data that is allowed will\n  depend on the context of the application and which anchors are omitted from the\n  regular expression.\nPotential_Mitigations: 'Implementation: Be sure to understand both what will be matched\n  and what will not be matched by a regular expression. Anchoring the ends of the\n  expression will allow the programmer to define an allowlist strictly limited to\n  what is matched by the text in the regular expression. If you are using a package\n  that only matches one line by default, ensure that you can match multi-line inputs\n  if necessary.'\nObserved_Examples: 'CVE-2022-30034: Chain: Web UI for a Python RPC framework does\n  not use regex anchors to validate user login emails (CWE-777), potentially allowing\n  bypass of OAuth (CWE-1390).'\n",
  "ID: '778'\nName: Insufficient Logging\nDescription: When a security-critical event occurs, the product either does not record\n  the event or omits important details about the event when logging it.\nExtended_Description: 'When security-critical events are not logged properly, such\n  as a failed login attempt, this can make malicious behavior more difficult to detect\n  and may hinder forensic analysis after an attack succeeds.\n\n  As organizations adopt cloud storage resources, these technologies often require\n  configuration changes to enable detailed logging information, since detailed logging\n  can incur additional costs. This could lead to telemetry gaps in critical audit\n  logs. For example, in Azure, the default value for logging is disabled.'\nApplicable_Platforms:\n  Technology: Cloud Computing\nModes_Of_Introduction: 'Operation: COMMISSION: This weakness refers to an incorrect\n  design related to an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Use a centralized logging mechanism\n  that supports multiple levels of detail.\n\n\n  Implementation: Ensure that all security-related successes and failures can be logged.\n  When storing data in the cloud (e.g., AWS S3 buckets, Azure blobs, Google Cloud\n  Storage, etc.), use the provider''s controls to enable and capture detailed logging\n  information.\n\n\n  Operation: Be sure to set the level of logging appropriately in a production environment.\n  Sufficient data should be logged to enable system administrators to detect attacks,\n  diagnose errors, and recover from attacks. At the same time, logging too much data\n  (CWE-779) can cause the same problems, including unexpected costs when using a cloud\n  environment.\n\n\n  Operation: To enable storage logging using Azure''s Portal, navigate to the name\n  of the Storage Account, locate Monitoring (CLASSIC) section, and select Diagnostic\n  settings (classic). For each of the various properties (blob, file, table, queue),\n  ensure the status is properly set for the desired logging data. If using PowerShell,\n  the Set-AzStorageServiceLoggingProperty command could be called using appropriate\n  -ServiceType, -LoggingOperations, and -RetentionDays arguments.'\nObserved_Examples: 'CVE-2008-4315: server does not log failed authentication attempts,\n  making it easier for attackers to perform brute force password guessing without\n  being detected\n\n\n  CVE-2008-1203: admin interface does not log failed authentication attempts, making\n  it easier for attackers to perform brute force password guessing without being detected\n\n\n  CVE-2007-3730: default configuration for POP server does not log source IP or username\n  for login attempts\n\n\n  CVE-2007-1225: proxy does not log requests without \"http://\" in the URL, allowing\n  web surfers to access restricted web content without detection\n\n\n  CVE-2003-1566: web server does not log requests for a non-standard request type'\n",
  "ID: '779'\nName: Logging of Excessive Data\nDescription: The product logs too much information, making log files hard to process\n  and possibly hindering recovery efforts or forensic analysis after an attack.\nExtended_Description: While logging is a good practice in general, and very high levels\n  of logging are appropriate for debugging stages of development, too much logging\n  in a production environment might hinder a system administrator's ability to detect\n  anomalous conditions. This can provide cover for an attacker while attempting to\n  penetrate a system, clutter the audit trail for forensic analysis, or make it more\n  difficult to debug problems in a production environment.\nModes_Of_Introduction: 'Operation: REALIZATION: This weakness is caused during implementation\n  of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Suppress large numbers of duplicate\n  log messages and replace them with periodic summaries. For example, syslog may include\n  an entry that states \"last message repeated X times\" when recording repeated events.\n\n\n  Architecture and Design: Support a maximum size for the log file that can be controlled\n  by the administrator. If the maximum size is reached, the admin should be notified.\n  Also, consider reducing functionality of the product. This may result in a denial-of-service\n  to legitimate product users, but it will prevent the product from adversely impacting\n  the entire system.\n\n\n  Implementation: Adjust configurations appropriately when the product is transitioned\n  from a debug state to production.'\nObserved_Examples: 'CVE-2007-0421: server records a large amount of data to the server\n  log when it receives malformed headers\n\n\n  CVE-2002-1154: chain: application does not restrict access to front-end for updates,\n  which allows attacker to fill the error log'\n",
  "ID: '78'\nName: Improper Neutralization of Special Elements used in an OS Command ('OS Command\n  Injection')\nDescription: The product constructs all or part of an OS command using externally-influenced\n  input from an upstream component, but it does not neutralize or incorrectly neutralizes\n  special elements that could modify the intended OS command when it is sent to a\n  downstream component.\nExtended_Description: 'This could allow attackers to execute unexpected, dangerous\n  commands directly on the operating system. This weakness can lead to a vulnerability\n  in environments in which the attacker does not have direct access to the operating\n  system, such as in web applications. Alternately, if the weakness occurs in a privileged\n  program, it could allow the attacker to specify commands that normally would not\n  be accessible, or to call alternate commands with privileges that the attacker does\n  not have. The problem is exacerbated if the compromised process does not follow\n  the principle of least privilege, because the attacker-controlled commands may run\n  with special system privileges that increases the amount of damage.\n\n  There are at least two subtypes of OS command injection:\n\n  From a weakness standpoint, these variants represent distinct programmer errors.\n  In the first variant, the programmer clearly intends that input from untrusted parties\n  will be part of the arguments in the command to be executed. In the second variant,\n  the programmer does not intend for the command to be accessible to any untrusted\n  party, but the programmer probably has not accounted for alternate ways in which\n  malicious attackers can provide input.'\nAlternate_Terms: \"Shell injection: \\n\\nShell metacharacters: \"\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis might not be able to recognize when proper input validation\n  is being performed, leading to false positives - i.e., warnings that do not have\n  any security consequences or require any code changes.\n\n  Automated static analysis might not be able to detect the usage of custom API functions\n  or third-party libraries that indirectly invoke OS commands, leading to false negatives\n  - especially if the API/library code is not available for analysis.\n\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the product using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The product''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n\n  Manual Static Analysis: Since this weakness does not typically appear frequently\n  within a single software package, manual white box techniques may be able to provide\n  sufficient code coverage and reduction of false positives if all potentially-vulnerable\n  operations can be assessed within limited time constraints.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: If at all possible, use library calls\n  rather than external processes to recreate the desired functionality.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Architecture and Design: For any data that will be used to generate a command to\n  be executed, keep as much of that data out of external control as possible. For\n  example, in web applications, this may require storing the data locally in the session''s\n  state instead of sending it out to the client in a hidden form field.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool,\n  library, or framework. These will help the programmer encode outputs in a manner\n  less prone to error.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n\n  Implementation: If the program to be executed allows arguments to be specified within\n  an input file or from standard input, then consider using that mode to pass arguments\n  instead of the command line.\n\n\n  Architecture and Design: If available, use structured mechanisms that automatically\n  enforce the separation between data and code. These mechanisms may be able to provide\n  the relevant quoting, encoding, and validation automatically, instead of relying\n  on the developer to provide this capability at every point where output is generated.\n\n  Some languages offer multiple functions that can be used to invoke commands. Where\n  possible, identify any function that invokes a command shell using a single string,\n  and replace it with a function that requires individual arguments. These functions\n  typically perform appropriate quoting and filtering of arguments. For example, in\n  C, the system() function accepts a string that contains the entire command to be\n  executed, whereas execl(), execve(), and others require an array of strings, one\n  for each argument. In Windows, CreateProcess() only accepts one command at a time.\n  In Perl, if system() is provided with an array of arguments, then it will quote\n  each of the arguments.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When constructing OS command strings, use stringent allowlists that limit the character\n  set based on the expected value of the parameter in the request. This will indirectly\n  limit the scope of an attack, but this technique is less important than proper output\n  encoding and escaping.\n\n  Note that proper output encoding, escaping, and quoting is the most effective solution\n  for preventing OS command injection, although input validation may provide some\n  defense-in-depth. This is because it effectively limits what will appear in output.\n  Input validation will not always prevent OS command injection, especially if you\n  are required to support free-form text fields that could contain arbitrary characters.\n  For example, when invoking a mail program, you might need to allow the subject field\n  to contain otherwise-dangerous inputs like \";\" and \">\" characters, which would need\n  to be escaped or otherwise handled. In this case, stripping the character might\n  reduce the risk of OS command injection, but it would produce incorrect behavior\n  because the subject field would not be recorded as the user intended. This might\n  seem to be a minor inconvenience, but it could be more important when the program\n  relies on well-structured subject lines in order to pass messages to other components.\n\n  Even if you make a mistake in your validation (such as forgetting one out of 100\n  input fields), appropriate encoding is still likely to protect you from injection-based\n  attacks. As long as it is not done in isolation, input validation is still a useful\n  technique, since it may significantly reduce your attack surface, allow you to detect\n  some attacks, and provide other security benefits that proper encoding does not\n  address.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\n  Operation: Run the code in an environment that performs automatic taint propagation\n  and prevents any command execution that uses tainted variables, such as Perl''s\n  \"-T\" switch. This will force the program to perform validation steps that remove\n  the taint, although you must be careful to correctly validate your inputs so that\n  you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n\n  Operation: Run the code in an environment that performs automatic taint propagation\n  and prevents any command execution that uses tainted variables, such as Perl''s\n  \"-T\" switch. This will force the program to perform validation steps that remove\n  the taint, although you must be careful to correctly validate your inputs so that\n  you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n\n  Implementation: Ensure that error messages only contain minimal details that are\n  useful to the intended audience and no one else. The messages need to strike the\n  balance between being too cryptic (which can confuse users) or being too detailed\n  (which may reveal more than intended). The messages should not reveal the methods\n  that were used to determine the error. Attackers can use detailed information to\n  refine or optimize their original attack, thereby increasing their chances of success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.\n\n  In the context of OS Command Injection, error information passed back to the user\n  might reveal whether an OS command is being executed and possibly which command\n  is being used.\n\n\n  Operation: Use runtime policy enforcement to create an allowlist of allowable commands,\n  then prevent use of any command that does not appear in the allowlist. Technologies\n  such as AppArmor are available to do this.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.'\nObserved_Examples: 'CVE-2020-10987: OS command injection in Wi-Fi router, as exploited\n  in the wild per CISA KEV.\n\n\n  CVE-2020-10221: Template functionality in network configuration management tool\n  allows OS command injection, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-9054: Chain: improper input validation (CWE-20) in username parameter,\n  leading to OS command injection (CWE-78), as exploited in the wild per CISA KEV.\n\n\n  CVE-1999-0067: Canonical example of OS command injection. CGI program does not neutralize\n  \"|\" metacharacter when invoking a phonebook program.\n\n\n  CVE-2001-1246: Language interpreter''s mail function accepts another argument that\n  is concatenated to a string used in a dangerous popen() call. Since there is no\n  neutralization of this argument, both OS Command Injection (CWE-78) and Argument\n  Injection (CWE-88) are possible.\n\n\n  CVE-2002-0061: Web server allows command execution using \"|\" (pipe) character.\n\n\n  CVE-2003-0041: FTP client does not filter \"|\" from filenames returned by the server,\n  allowing for OS command injection.\n\n\n  CVE-2008-2575: Shell metacharacters in a filename in a ZIP archive\n\n\n  CVE-2002-1898: Shell metacharacters in a telnet:// link are not properly handled\n  when the launching application processes the link.\n\n\n  CVE-2008-4304: OS command injection through environment variable.\n\n\n  CVE-2008-4796: OS command injection through https:// URLs\n\n\n  CVE-2007-3572: Chain: incomplete denylist for OS command injection\n\n\n  CVE-2012-1988: Product allows remote users to execute arbitrary commands by creating\n  a file whose pathname contains shell metacharacters.'\nRelated_Attack_Patterns: \"108: \\n\\n15: \\n\\n43: \\n\\n6: \\n\\n88: \"\n",
  "ID: '780'\nName: Use of RSA Algorithm without OAEP\nDescription: The product uses the RSA algorithm but does not incorporate Optimal Asymmetric\n  Encryption Padding (OAEP), which might weaken the encryption.\nExtended_Description: Padding schemes are often used with cryptographic algorithms\n  to make the plaintext less predictable and complicate attack efforts. The OAEP scheme\n  is often used with RSA to nullify the impact of predictable common text.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '781'\nName: Improper Address Validation in IOCTL with METHOD_NEITHER I/O Control Code\nDescription: The product defines an IOCTL that uses METHOD_NEITHER for I/O, but it\n  does not validate or incorrectly validates the addresses that are provided.\nExtended_Description: When an IOCTL uses the METHOD_NEITHER option for I/O control,\n  it is the responsibility of the IOCTL to validate the addresses that have been supplied\n  to it. If validation is missing or incorrect, attackers can supply arbitrary memory\n  addresses, leading to code execution or a denial of service.\nApplicable_Platforms:\n  Language: C, C++\n  Operating_System: Windows NT\nPotential_Mitigations: 'Implementation: If METHOD_NEITHER is required for the IOCTL,\n  then ensure that all user-space addresses are properly validated before they are\n  first accessed. The ProbeForRead and ProbeForWrite routines are available for this\n  task. Also properly protect and manage the user-supplied buffers, since the I/O\n  Manager does not do this when METHOD_NEITHER is being used. See References.\n\n\n  Architecture and Design: If possible, avoid using METHOD_NEITHER in the IOCTL and\n  select methods that effectively control the buffer size, such as METHOD_BUFFERED,\n  METHOD_IN_DIRECT, or METHOD_OUT_DIRECT.\n\n\n  Architecture and Design\n\n  Implementation: If the IOCTL is part of a driver that is only intended to be accessed\n  by trusted users, then use proper access control for the associated device or device\n  namespace. See References.'\nObserved_Examples: 'CVE-2006-2373: Driver for file-sharing and messaging protocol\n  allows attackers to execute arbitrary code.\n\n\n  CVE-2009-0686: Anti-virus product does not validate addresses, allowing attackers\n  to gain SYSTEM privileges.\n\n\n  CVE-2009-0824: DVD software allows attackers to cause a crash.\n\n\n  CVE-2008-5724: Personal firewall allows attackers to gain SYSTEM privileges.\n\n\n  CVE-2007-5756: chain: device driver for packet-capturing software allows access\n  to an unintended IOCTL with resultant array index error.'\n",
  "ID: '782'\nName: Exposed IOCTL with Insufficient Access Control\nDescription: The product implements an IOCTL with functionality that should be restricted,\n  but it does not properly enforce access control for the IOCTL.\nExtended_Description: 'When an IOCTL contains privileged functionality and is exposed\n  unnecessarily, attackers may be able to access this functionality by invoking the\n  IOCTL. Even if the functionality is benign, if the programmer has assumed that the\n  IOCTL would only be accessed by a trusted process, there may be little or no validation\n  of the incoming data, exposing weaknesses that would never be reachable if the attacker\n  cannot call the IOCTL directly.\n\n  The implementations of IOCTLs will differ between operating system types and versions,\n  so the methods of attack and prevention may vary widely.'\nApplicable_Platforms:\n  Language: C, C++\n  Operating_System: Unix, Windows\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design: In Windows environments, use proper\n  access control for the associated device or device namespace. See References.'\nObserved_Examples: 'CVE-2009-2208: Operating system does not enforce permissions on\n  an IOCTL that can be used to modify network settings.\n\n\n  CVE-2008-3831: Device driver does not restrict ioctl calls to its direct rendering\n  manager.\n\n\n  CVE-2008-3525: ioctl does not check for a required capability before processing\n  certain requests.\n\n\n  CVE-2008-0322: Chain: insecure device permissions allows access to an IOCTL, allowing\n  arbitrary memory to be overwritten.\n\n\n  CVE-2007-4277: Chain: anti-virus product uses weak permissions for a device, leading\n  to resultant buffer overflow in an exposed IOCTL.\n\n\n  CVE-2007-1400: Chain: sandbox allows opening of a TTY device, enabling shell commands\n  through an exposed ioctl.\n\n\n  CVE-2006-4926: Anti-virus product uses insecure security descriptor for a device\n  driver, allowing access to a privileged IOCTL.\n\n\n  CVE-1999-0728: Unauthorized user can disable keyboard or mouse by directly invoking\n  a privileged IOCTL.'\n",
  "ID: '783'\nName: Operator Precedence Logic Error\nDescription: The product uses an expression in which operator precedence causes incorrect\n  logic to be used.\nExtended_Description: While often just a bug, operator precedence logic errors can\n  have serious consequences if they are used in security-critical code, such as making\n  an authentication decision.\nApplicable_Platforms:\n  Language: C, C++\nModes_Of_Introduction: 'Implementation: Logic errors related to operator precedence\n  may cause problems even during normal operation, so they are probably discovered\n  quickly during the testing phase. If testing is incomplete or there is a strong\n  reliance on manual review of the code, then these errors may not be discovered before\n  the software is deployed.'\nPotential_Mitigations: 'Implementation: Regularly wrap sub-expressions in parentheses,\n  especially in security-critical code.'\nObserved_Examples: 'CVE-2008-2516: Authentication module allows authentication bypass\n  because it uses \"(x = call(args) == SUCCESS)\" instead of \"((x = call(args)) == SUCCESS)\".\n\n\n  CVE-2008-0599: Chain: Language interpreter calculates wrong buffer size (CWE-131)\n  by using \"size = ptr ? X : Y\" instead of \"size = (ptr ? X : Y)\" expression.\n\n\n  CVE-2001-1155: Chain: product does not properly check the result of a reverse DNS\n  lookup because of operator precedence (CWE-783), allowing bypass of DNS-based access\n  restrictions.'\n",
  "ID: '784'\nName: Reliance on Cookies without Validation and Integrity Checking in a Security\n  Decision\nDescription: The product uses a protection mechanism that relies on the existence\n  or values of a cookie, but it does not properly ensure that the cookie is valid\n  for the associated user.\nExtended_Description: Attackers can easily modify cookies, within the browser or by\n  implementing the client-side code outside of the browser. Attackers can bypass protection\n  mechanisms such as authorization and authentication by modifying the cookie to contain\n  an expected value.\nApplicable_Platforms:\n  Technology: Web Based\nPotential_Mitigations: 'Architecture and Design: Avoid using cookie data for a security-related\n  decision.\n\n\n  Implementation: Perform thorough input validation (i.e.: server side validation)\n  on the cookie data if you''re going to use it for a security related decision.\n\n\n  Architecture and Design: Add integrity checks to detect tampering.\n\n\n  Architecture and Design: Protect critical cookies from replay attacks, since cross-site\n  scripting or other attacks may allow attackers to steal a strongly-encrypted cookie\n  that also passes integrity checks. This mitigation applies to cookies that should\n  only be valid during a single transaction or session. By enforcing timeouts, you\n  may limit the scope of an attack. As part of your integrity check, use an unpredictable,\n  server-side value that is not exposed to the client.'\nObserved_Examples: 'CVE-2009-1549: Attacker can bypass authentication by setting a\n  cookie to a specific value.\n\n\n  CVE-2009-1619: Attacker can bypass authentication and gain admin privileges by setting\n  an \"admin\" cookie to 1.\n\n\n  CVE-2009-0864: Content management system allows admin privileges by setting a \"login\"\n  cookie to \"OK.\"\n\n\n  CVE-2008-5784: e-dating application allows admin privileges by setting the admin\n  cookie to 1.\n\n\n  CVE-2008-6291: Web-based email list manager allows attackers to gain admin privileges\n  by setting a login cookie to \"admin.\"'\n",
  "ID: '785'\nName: Use of Path Manipulation Function without Maximum-sized Buffer\nDescription: The product invokes a function for normalizing paths or file names, but\n  it provides an output buffer that is smaller than the maximum possible size, such\n  as PATH_MAX.\nExtended_Description: Passing an inadequately-sized output buffer to a path manipulation\n  function can result in a buffer overflow. Such functions include realpath(), readlink(),\n  PathAppend(), and others.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Implementation: Always specify output buffers large enough\n  to handle the maximum-size possible result from path manipulation functions.'\n",
  "ID: '786'\nName: Access of Memory Location Before Start of Buffer\nDescription: The product reads or writes to a buffer using an index or pointer that\n  references a memory location prior to the beginning of the buffer.\nExtended_Description: This typically occurs when a pointer or its index is decremented\n  to a position before the buffer, when pointer arithmetic results in a position before\n  the beginning of the valid memory location, or when a negative index is used.\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nObserved_Examples: 'CVE-2002-2227: Unchecked length of SSLv2 challenge value leads\n  to buffer underflow.\n\n\n  CVE-2007-4580: Buffer underflow from a small size value with a large buffer (length\n  parameter inconsistency, CWE-130)\n\n\n  CVE-2007-1584: Buffer underflow from an all-whitespace string, which causes a counter\n  to be decremented before the buffer while looking for a non-whitespace character.\n\n\n  CVE-2007-0886: Buffer underflow resultant from encoded data that triggers an integer\n  overflow.\n\n\n  CVE-2006-6171: Product sets an incorrect buffer size limit, leading to \"off-by-two\"\n  buffer underflow.\n\n\n  CVE-2006-4024: Negative value is used in a memcpy() operation, leading to buffer\n  underflow.\n\n\n  CVE-2004-2620: Buffer underflow due to mishandled special characters'\n",
  "ID: '787'\nName: Out-of-bounds Write\nDescription: The product writes data past the end, or before the beginning, of the\n  intended buffer.\nExtended_Description: Typically, this can result in corruption of data, a crash, or\n  code execution.  The product may modify an index or perform pointer arithmetic that\n  references a memory location that is outside of the boundaries of the buffer.  A\n  subsequent write operation then produces undefined or unexpected results.\nApplicable_Platforms:\n  Language: C, C++, Assembly\n  Technology: ICS/OT\nAlternate_Terms: 'Memory Corruption: Often used to describe the consequences of writing\n  to memory outside the bounds of a buffer, or to memory that is invalid, when the\n  root cause is something other than a sequential copy of excessive data from a fixed\n  starting location. This may include issues such as incorrect pointer arithmetic,\n  accessing invalid pointers due to incomplete initialization or memory release, etc.'\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis generally does not account for environmental considerations\n  when reporting out-of-bounds memory operations. This can make it difficult for users\n  to determine which warnings should be investigated first. For example, an analysis\n  tool might report buffer overflows that originate from command line arguments in\n  a program that is not expected to run with setuid or other special privileges.\n\n  Detection techniques for buffer-related errors are more mature than for most other\n  weakness types.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, many languages that perform their own memory management, such as Java\n  and Perl, are not subject to buffer overflows. Other languages, such as Ada and\n  C#, typically provide overflow protection, but the protection can be disabled by\n  the programmer.\n\n  Be wary that a language''s interface to native code may still be subject to overflows,\n  even if the language itself is theoretically safe.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57],\n  and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer\n  versions of overflow-prone string-handling functions.\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Implementation: Consider adhering to the following rules when allocating and managing\n  an application''s memory:\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Implementation: Replace unbounded copy functions with analogous functions that support\n  length arguments, such as strcpy with strncpy. Create these if they are not available.'\nObserved_Examples: 'CVE-2021-21220: Chain: insufficient input validation (CWE-20)\n  in browser allows heap corruption (CWE-787), as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-28664: GPU kernel driver allows memory corruption because a user can obtain\n  read/write access to read-only pages, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-17087: Chain: integer truncation (CWE-197) causes small buffer allocation\n  (CWE-131) leading to out-of-bounds write (CWE-787) in kernel pool, as exploited\n  in the wild per CISA KEV.\n\n\n  CVE-2020-1054: Out-of-bounds write in kernel-mode driver, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2020-0041: Escape from browser sandbox using out-of-bounds write due to incorrect\n  bounds check, as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-0968: Memory corruption in web browser scripting engine, as exploited in\n  the wild per CISA KEV.\n\n\n  CVE-2020-0022: chain: mobile phone Bluetooth implementation does not include offset\n  when calculating packet length (CWE-682), leading to out-of-bounds write (CWE-787)\n\n\n  CVE-2019-1010006: Chain: compiler optimization (CWE-733) removes or modifies code\n  used to detect integer overflow (CWE-190), allowing out-of-bounds write (CWE-787).\n\n\n  CVE-2009-1532: malformed inputs cause accesses of uninitialized or previously-deleted\n  objects, leading to memory corruption\n\n\n  CVE-2009-0269: chain: -1 value from a function call was intended to indicate an\n  error, but is used as an array index instead.\n\n\n  CVE-2002-2227: Unchecked length of SSLv2 challenge value leads to buffer underflow.\n\n\n  CVE-2007-4580: Buffer underflow from a small size value with a large buffer (length\n  parameter inconsistency, CWE-130)\n\n\n  CVE-2007-4268: Chain: integer signedness error (CWE-195) passes signed comparison,\n  leading to heap overflow (CWE-122)\n\n\n  CVE-2009-2550: Classic stack-based buffer overflow in media player using a long\n  entry in a playlist\n\n\n  CVE-2009-2403: Heap-based buffer overflow in media player using a long entry in\n  a playlist'\n",
  "ID: '788'\nName: Access of Memory Location After End of Buffer\nDescription: The product reads or writes to a buffer using an index or pointer that\n  references a memory location after the end of the buffer.\nExtended_Description: This typically occurs when a pointer or its index is incremented\n  to a position after the buffer; or when pointer arithmetic results in a position\n  after the buffer.\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nObserved_Examples: 'CVE-2009-2550: Classic stack-based buffer overflow in media player\n  using a long entry in a playlist\n\n\n  CVE-2009-2403: Heap-based buffer overflow in media player using a long entry in\n  a playlist\n\n\n  CVE-2009-0689: large precision value in a format string triggers overflow\n\n\n  CVE-2009-0558: attacker-controlled array index leads to code execution\n\n\n  CVE-2008-4113: OS kernel trusts userland-supplied length value, allowing reading\n  of sensitive information\n\n\n  CVE-2007-4268: Chain: integer signedness error (CWE-195) passes signed comparison,\n  leading to heap overflow (CWE-122)'\n",
  "ID: '789'\nName: Memory Allocation with Excessive Size Value\nDescription: The product allocates memory based on an untrusted, large size value,\n  but it does not ensure that the size is within expected limits, allowing arbitrary\n  amounts of memory to be allocated.\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: 'Stack Exhaustion: When a weakness allocates excessive memory on\n  the stack, it is often described as \"stack exhaustion,\" which is a technical impact\n  of the weakness. This technical impact is often encountered as a consequence of\n  CWE-789 and/or CWE-1325.'\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.\n\n\n  Automated Static Analysis: Automated static analysis, commonly referred to as Static\n  Application Security Testing (SAST), can find some instances of this weakness by\n  analyzing source code (or binary/compiled code) without having to execute it. Typically,\n  this is done by building a model of data flow and control flow, then searching for\n  potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\"\n  (destinations where the data interacts with external components, a lower layer such\n  as the OS, etc.)'\nPotential_Mitigations: 'Implementation\n\n  Architecture and Design: Perform adequate input validation against any value that\n  influences the amount of memory that is allocated. Define an appropriate strategy\n  for handling requests that exceed the limit, and consider supporting a configuration\n  option so that the administrator can extend the amount of memory to be used if necessary.\n\n\n  Operation: Run your program using system-provided resource limits for memory. This\n  might still cause the program to crash or exit, but the impact to the rest of the\n  system will be minimized.'\nObserved_Examples: 'CVE-2022-21668: Chain: Python library does not limit the resources\n  used to process images that specify a very large number of bands (CWE-1284), leading\n  to excessive memory consumption (CWE-789) or an integer overflow (CWE-190).\n\n\n  CVE-2010-3701: program uses ::alloca() for encoding messages, but large messages\n  trigger segfault\n\n\n  CVE-2008-1708: memory consumption and daemon exit by specifying a large value in\n  a length field\n\n\n  CVE-2008-0977: large value in a length field leads to memory consumption and crash\n  when no more memory is available\n\n\n  CVE-2006-3791: large key size in game program triggers crash when a resizing function\n  cannot allocate enough memory\n\n\n  CVE-2004-2589: large Content-Length HTTP header value triggers application crash\n  in instant messaging application due to failure in memory allocation'\n",
  "ID: '79'\nName: Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')\nDescription: The product does not neutralize or incorrectly neutralizes user-controllable\n  input before it is placed in output that is used as a web page that is served to\n  other users.\nExtended_Description: 'Cross-site scripting (XSS) vulnerabilities occur when:\n\n  There are three main kinds of XSS:\n\n  Once the malicious script is injected, the attacker can perform a variety of malicious\n  activities. The attacker could transfer private information, such as cookies that\n  may include session information, from the victim''s machine to the attacker. The\n  attacker could send malicious requests to a web site on behalf of the victim, which\n  could be especially dangerous to the site if the victim has administrator privileges\n  to manage that site. Phishing attacks could be used to emulate trusted web sites\n  and trick the victim into entering a password, allowing the attacker to compromise\n  the victim''s account on that web site. Finally, the script could exploit a vulnerability\n  in the web browser itself possibly taking over the victim''s machine, sometimes\n  referred to as \"drive-by hacking.\"\n\n  In many cases, the attack can be launched without the victim even being aware of\n  it. Even with careful users, attackers frequently use a variety of methods to encode\n  the malicious portion of the attack, such as URL encoding or Unicode, so the request\n  looks less suspicious.'\nApplicable_Platforms:\n  Technology: Web Based\nAlternate_Terms: 'XSS: A common abbreviation for Cross-Site Scripting.\n\n\n  HTML Injection: Used as a synonym of stored (Type 2) XSS.\n\n\n  CSS: In the early years after initial discovery of XSS, \"CSS\" was a commonly-used\n  acronym.  However, this would cause confusion with \"Cascading Style Sheets,\" so\n  usage of this acronym has declined significantly.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Use automated static analysis tools\n  that target this type of weakness. Many modern techniques use data flow analysis\n  to minimize the number of false positives. This is not a perfect solution, since\n  100% accuracy and coverage are not feasible, especially when multiple components\n  are involved.\n\n\n  Black Box: Use the XSS Cheat Sheet [REF-714] or automated test-generation tools\n  to help launch a wide variety of attacks against your web application. The Cheat\n  Sheet contains many subtle XSS variations that are specifically targeted against\n  weak XSS defenses.\n\n  With Stored XSS, the indirection caused by the data store can make it more difficult\n  to find the problem. The tester must first inject the XSS string into the data store,\n  then find the appropriate application functionality in which the XSS string is sent\n  to other users of the application. These are two distinct steps in which the activation\n  of the XSS can take place minutes, hours, or days after the XSS was originally injected\n  into the data store.'\nPotential_Mitigations: 'Architecture and Design: Use a vetted library or framework\n  that does not allow this weakness to occur or provides constructs that make this\n  weakness easier to avoid.\n\n  Examples of libraries and frameworks that make it easier to generate properly encoded\n  output include Microsoft''s Anti-XSS library, the OWASP ESAPI Encoding module, and\n  Apache Wicket.\n\n\n  Implementation\n\n  Architecture and Design: Understand the context in which your data will be used\n  and the encoding that will be expected. This is especially important when transmitting\n  data between different components, or when generating outputs that can contain multiple\n  encodings at the same time, such as web pages or multi-part mail messages. Study\n  all expected communication protocols and data representations to determine the required\n  encoding strategies.\n\n  For any data that will be output to another web page, especially any data that was\n  received from external inputs, use the appropriate encoding on all non-alphanumeric\n  characters.\n\n  Parts of the same output document may require different encodings, which will vary\n  depending on whether the output is in the:\n\n  etc. Note that HTML Entity Encoding is only appropriate for the HTML body.\n\n  Consult the XSS Prevention Cheat Sheet [REF-724] for more details on the types of\n  encoding and escaping that are needed.\n\n\n  Architecture and Design\n\n  Implementation: Understand all the potential areas where untrusted inputs can enter\n  your software: parameters or arguments, cookies, anything read from the network,\n  environment variables, reverse DNS lookups, query results, request headers, URL\n  components, e-mail, files, filenames, databases, and any external systems that provide\n  data to the application. Remember that such inputs may be obtained indirectly through\n  API calls.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Architecture and Design: If available, use structured mechanisms that automatically\n  enforce the separation between data and code. These mechanisms may be able to provide\n  the relevant quoting, encoding, and validation automatically, instead of relying\n  on the developer to provide this capability at every point where output is generated.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When dynamically constructing web pages, use stringent allowlists that limit the\n  character set based on the expected value of the parameter in the request. All input\n  should be validated and cleansed, not just parameters that the user is supposed\n  to specify, but all data in the request, including hidden fields, cookies, headers,\n  the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities\n  is to validate only fields that are expected to be redisplayed by the site. It is\n  common to see data from the request that is reflected by the application server\n  or the application that the development team did not anticipate. Also, a field that\n  is not currently reflected may be used by a future developer. Therefore, validating\n  ALL parts of the HTTP request is recommended.\n\n  Note that proper output encoding, escaping, and quoting is the most effective solution\n  for preventing XSS, although input validation may provide some defense-in-depth.\n  This is because it effectively limits what will appear in output. Input validation\n  will not always prevent XSS, especially if you are required to support free-form\n  text fields that could contain arbitrary characters. For example, in a chat application,\n  the heart emoticon (\"<3\") would likely pass the validation step, since it is commonly\n  used. However, it cannot be directly inserted into the web page because it contains\n  the \"<\" character, which would need to be escaped or otherwise handled. In this\n  case, stripping the \"<\" might reduce the risk of XSS, but it would produce incorrect\n  behavior because the emoticon would not be recorded. This might seem to be a minor\n  inconvenience, but it would be more important in a mathematical forum that wants\n  to represent inequalities.\n\n  Even if you make a mistake in your validation (such as forgetting one out of 100\n  input fields), appropriate encoding is still likely to protect you from injection-based\n  attacks. As long as it is not done in isolation, input validation is still a useful\n  technique, since it may significantly reduce your attack surface, allow you to detect\n  some attacks, and provide other security benefits that proper encoding does not\n  address.\n\n  Ensure that you perform input validation at well-defined interfaces within the application.\n  This will help protect the application even if a component is reused or moved elsewhere.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.'\nObserved_Examples: 'CVE-2021-25926: Python Library Manager did not sufficiently neutralize\n  a user-supplied search term, allowing reflected XSS.\n\n\n  CVE-2021-25963: Python-based e-commerce platform did not escape returned content\n  on error pages, allowing for reflected Cross-Site Scripting attacks.\n\n\n  CVE-2021-1879: Universal XSS in mobile operating system, as exploited in the wild\n  per CISA KEV.\n\n\n  CVE-2020-3580: Chain: improper input validation (CWE-20) in firewall product leads\n  to XSS (CWE-79), as exploited in the wild per CISA KEV.\n\n\n  CVE-2014-8958: Admin GUI allows XSS through cookie.\n\n\n  CVE-2017-9764: Web stats program allows XSS through crafted HTTP header.\n\n\n  CVE-2014-5198: Web log analysis product allows XSS through crafted HTTP Referer\n  header.\n\n\n  CVE-2008-5080: Chain: protection mechanism failure allows XSS\n\n\n  CVE-2006-4308: Chain: incomplete denylist (CWE-184) only checks \"javascript:\" tag,\n  allowing XSS (CWE-79) using other tags\n\n\n  CVE-2007-5727: Chain: incomplete denylist (CWE-184) only removes SCRIPT tags, enabling\n  XSS (CWE-79)\n\n\n  CVE-2008-5770: Reflected XSS using the PATH_INFO in a URL\n\n\n  CVE-2008-4730: Reflected XSS not properly handled when generating an error message\n\n\n  CVE-2008-5734: Reflected XSS sent through email message.\n\n\n  CVE-2008-0971: Stored XSS in a security product.\n\n\n  CVE-2008-5249: Stored XSS using a wiki page.\n\n\n  CVE-2006-3568: Stored XSS in a guestbook application.\n\n\n  CVE-2006-3211: Stored XSS in a guestbook application using a javascript: URI in\n  a bbcode img tag.\n\n\n  CVE-2006-3295: Chain: library file is not protected against a direct request (CWE-425),\n  leading to reflected XSS (CWE-79).'\nRelated_Attack_Patterns: \"209: \\n\\n588: \\n\\n591: \\n\\n592: \\n\\n63: \\n\\n85: \"\n",
  "ID: '790'\nName: Improper Filtering of Special Elements\nDescription: The product receives data from an upstream component, but does not filter\n  or incorrectly filters special elements before sending it to a downstream component.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '791'\nName: Incomplete Filtering of Special Elements\nDescription: The product receives data from an upstream component, but does not completely\n  filter special elements before sending it to a downstream component.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '792'\nName: Incomplete Filtering of One or More Instances of Special Elements\nDescription: The product receives data from an upstream component, but does not completely\n  filter one or more instances of special elements before sending it to a downstream\n  component.\nExtended_Description: 'Incomplete filtering of this nature involves either:'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '793'\nName: Only Filtering One Instance of a Special Element\nDescription: The product receives data from an upstream component, but only filters\n  a single instance of a special element before sending it to a downstream component.\nExtended_Description: Incomplete filtering of this nature may be location-dependent,\n  as in only the first or last element is filtered.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '794'\nName: Incomplete Filtering of Multiple Instances of Special Elements\nDescription: The product receives data from an upstream component, but does not filter\n  all instances of a special element before sending it to a downstream component.\nExtended_Description: 'Incomplete filtering of this nature may be applied to:'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '795'\nName: Only Filtering Special Elements at a Specified Location\nDescription: The product receives data from an upstream component, but only accounts\n  for special elements at a specified location, thereby missing remaining special\n  elements that may exist before sending it to a downstream component.\nExtended_Description: 'A filter might only account for instances of special elements\n  when they occur:\n\n  This may leave special elements in the data that did not match the filter position,\n  but still may be dangerous.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '796'\nName: Only Filtering Special Elements Relative to a Marker\nDescription: The product receives data from an upstream component, but only accounts\n  for special elements positioned relative to a marker (e.g. \"at the beginning/end\n  of a string; the second argument\"), thereby missing remaining special elements that\n  may exist before sending it to a downstream component.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '797'\nName: Only Filtering Special Elements at an Absolute Position\nDescription: The product receives data from an upstream component, but only accounts\n  for special elements at an absolute position (e.g. \"byte number 10\"), thereby missing\n  remaining special elements that may exist before sending it to a downstream component.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '798'\nName: Use of Hard-coded Credentials\nDescription: The product contains hard-coded credentials, such as a password or cryptographic\n  key, which it uses for its own inbound authentication, outbound communication to\n  external components, or encryption of internal data.\nExtended_Description: 'Hard-coded credentials typically create a significant hole\n  that allows an attacker to bypass the authentication that has been configured by\n  the product administrator. This hole might be difficult for the system administrator\n  to detect. Even if detected, it can be difficult to fix, so the administrator may\n  be forced into disabling the product entirely. There are two main variations:\n\n  In the Inbound variant, a default administration account is created, and a simple\n  password is hard-coded into the product and associated with that account. This hard-coded\n  password is the same for each installation of the product, and it usually cannot\n  be changed or disabled by system administrators without manually modifying the program,\n  or otherwise patching the product. If the password is ever discovered or published\n  (a common occurrence on the Internet), then anybody with knowledge of this password\n  can access the product. Finally, since all installations of the product will have\n  the same password, even across different organizations, this enables massive attacks\n  such as worms to take place.\n\n  The Outbound variant applies to front-end systems that authenticate with a back-end\n  service. The back-end service may require a fixed password which can be easily discovered.\n  The programmer may simply hard-code those back-end credentials into the front-end\n  product. Any user of that program may be able to extract the password. Client-side\n  systems with hard-coded passwords pose even more of a threat, since the extraction\n  of a password from a binary is usually very simple.'\nApplicable_Platforms:\n  Technology: Mobile, ICS/OT\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Black Box: Credential storage in configuration files is findable\n  using black box methods, but the use of hard-coded credentials for an incoming authentication\n  routine typically involves an account that is not visible outside of the code.\n\n\n  Automated Static Analysis: Automated white box techniques have been published for\n  detecting hard-coded credentials for incoming authentication, but there is some\n  expert disagreement regarding their effectiveness and applicability to a broad range\n  of methods.\n\n\n  Manual Static Analysis: This weakness may be detectable using manual code analysis.\n  Unless authentication is decentralized and applied throughout the product, there\n  can be sufficient time for the analyst to find incoming authentication routines\n  and examine the program logic looking for usage of hard-coded credentials. Configuration\n  files could also be analyzed.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules.\n\n\n  Manual Dynamic Analysis: For hard-coded credentials in incoming authentication:\n  use monitoring tools that examine the product''s process as it interacts with the\n  operating system and the network. This technique is useful in cases when source\n  code is unavailable, if the product was not developed by you, or if you want to\n  verify that the build phase did not introduce any new weaknesses. Examples include\n  debuggers that directly attach to the running process; system-call tracing utilities\n  such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon,\n  RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers\n  and protocol analyzers that monitor network traffic.\n\n  Attach the monitor to the process and perform a login. Using call trees or similar\n  artifacts from the output, examine the associated behaviors and see if any of them\n  appear to be comparing the input to a fixed string or value.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: For outbound authentication: store\n  passwords, keys, and other credentials outside of the code in a strongly-protected,\n  encrypted configuration file or database that is protected from access by all outsiders,\n  including other local users on the same system. Properly protect the key (CWE-320).\n  If you cannot use encryption to protect the file, then make sure that the permissions\n  are as restrictive as possible [REF-7].\n\n  In Windows environments, the Encrypted File System (EFS) may provide some protection.\n\n\n  Architecture and Design: For inbound authentication: Rather than hard-code a default\n  username and password, key, or other authentication credentials for first time logins,\n  utilize a \"first login\" mode that requires the user to enter a unique strong password\n  or key.\n\n\n  Architecture and Design: If the product must contain hard-coded credentials or they\n  cannot be removed, perform access control checks and limit which entities can access\n  the feature that requires the hard-coded credentials. For example, a feature might\n  only be enabled through the system console instead of through a network connection.\n\n\n  Architecture and Design: For inbound authentication using passwords: apply strong\n  one-way hashes to passwords and store those hashes in a configuration file or database\n  with appropriate access control. That way, theft of the file/database still requires\n  the attacker to try to crack the password. When handling an incoming password during\n  authentication, take the hash of the password and compare it to the saved hash.\n\n  Use randomly assigned salts for each separate hash that is generated. This increases\n  the amount of computation that an attacker needs to conduct a brute-force attack,\n  possibly limiting the effectiveness of the rainbow table method.\n\n\n  Architecture and Design: For front-end to back-end connections: Three solutions\n  are possible, although none are complete.'\nObserved_Examples: 'CVE-2022-29953: Condition Monitor firmware has a maintenance interface\n  with hard-coded credentials\n\n\n  CVE-2022-29960: Engineering Workstation uses hard-coded cryptographic keys that\n  could allow for unathorized filesystem access and privilege escalation\n\n\n  CVE-2022-29964: Distributed Control System (DCS) has hard-coded passwords for local\n  shell access\n\n\n  CVE-2022-30997: Programmable Logic Controller (PLC) has a maintenance service that\n  uses undocumented, hard-coded credentials\n\n\n  CVE-2022-30314: Firmware for a Safety Instrumented System (SIS) has hard-coded credentials\n  for access to boot configuration\n\n\n  CVE-2022-30271: Remote Terminal Unit (RTU) uses a hard-coded SSH private key that\n  is likely to be used in typical deployments\n\n\n  CVE-2021-37555: Telnet service for IoT feeder for dogs and cats has hard-coded password\n  [REF-1288]\n\n\n  CVE-2012-3503: Installation script has a hard-coded secret token value, allowing\n  attackers to bypass authentication\n\n\n  CVE-2010-2772: SCADA system uses a hard-coded password to protect back-end database\n  containing authorization information, exploited by Stuxnet worm\n\n\n  CVE-2010-2073: FTP server library uses hard-coded usernames and passwords for three\n  default accounts\n\n\n  CVE-2010-1573: Chain: Router firmware uses hard-coded username and password for\n  access to debug functionality, which can be used to execute arbitrary code\n\n\n  CVE-2008-2369: Server uses hard-coded authentication key\n\n\n  CVE-2008-0961: Backup product uses hard-coded username and password, allowing attackers\n  to bypass authentication via the RPC interface\n\n\n  CVE-2008-1160: Security appliance uses hard-coded password allowing attackers to\n  gain root access\n\n\n  CVE-2006-7142: Drive encryption product stores hard-coded cryptographic keys for\n  encrypted configuration files in executable programs\n\n\n  CVE-2005-3716: VoIP product uses hard-coded public credentials that cannot be changed,\n  which allows attackers to obtain sensitive information\n\n\n  CVE-2005-3803: VoIP product uses hard coded public and private SNMP community strings\n  that cannot be changed, which allows remote attackers to obtain sensitive information\n\n\n  CVE-2005-0496: Backup product contains hard-coded credentials that effectively serve\n  as a back door, which allows remote attackers to access the file system'\nRelated_Attack_Patterns: \"191: \\n\\n70: \"\n",
  "ID: '799'\nName: Improper Control of Interaction Frequency\nDescription: The product does not properly limit the number or frequency of interactions\n  that it has with an actor, such as the number of incoming requests.\nExtended_Description: This can allow the actor to perform actions more frequently\n  than expected. The actor could be a human or an automated process such as a virus\n  or bot. This could be used to cause a denial of service, compromise program logic\n  (such as limiting humans to a single vote), or other consequences. For example,\n  an authentication routine might not limit the number of times an attacker can guess\n  a password. Or, a web site might conduct a poll but only expect humans to vote a\n  maximum of once a day.\nAlternate_Terms: 'Insufficient anti-automation: The term \"insufficient anti-automation\"\n  focuses primarly on non-human actors such as viruses or bots, but the scope of this\n  CWE entry is broader.\n\n\n  Brute force: Vulnerabilities that can be targeted using brute force attacks are\n  often symptomatic of this weakness.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \\n\\nOperation: \"\nObserved_Examples: 'CVE-2002-1876: Mail server allows attackers to prevent other users\n  from accessing mail by sending large number of rapid requests.'\n",
  "ID: '8'\nName: 'J2EE Misconfiguration: Entity Bean Declared Remote'\nDescription: When an application exposes a remote interface for an entity bean, it\n  might also expose methods that get or set the bean's data. These methods could be\n  leveraged to read sensitive information, or to change data in ways that violate\n  the application's expectations, potentially leading to other vulnerabilities.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Implementation: Declare Java beans \"local\" when possible.\n  When a bean must be remotely accessible, make sure that sensitive information is\n  not exposed, and ensure that the application logic performs appropriate validation\n  of any data that might be modified by an attacker.'\n",
  "ID: '80'\nName: Improper Neutralization of Script-Related HTML Tags in a Web Page (Basic XSS)\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special characters such as \"<\", \">\", and \"&\"\n  that could be interpreted as web-scripting elements when they are sent to a downstream\n  component that processes web pages.\nExtended_Description: This may allow such characters to be treated as control characters,\n  which are executed client-side in the context of the user's session. Although this\n  can be classified as an injection problem, the more pertinent issue is the improper\n  conversion of such special characters to respective context-appropriate entities\n  before displaying them to the user.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Carefully check each input parameter against\n  a rigorous positive specification (allowlist) defining the specific characters and\n  format allowed. All input should be neutralized, not just parameters that the user\n  is supposed to specify, but all data in the request, including hidden fields, cookies,\n  headers, the URL itself, and so forth. A common mistake that leads to continuing\n  XSS vulnerabilities is to validate only fields that are expected to be redisplayed\n  by the site. We often encounter data from the request that is reflected by the application\n  server or the application that the development team did not anticipate. Also, a\n  field that is not currently reflected may be used by a future developer. Therefore,\n  validating ALL parts of the HTTP request is recommended.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2002-0938: XSS in parameter in a link.\n\n\n  CVE-2002-1495: XSS in web-based email product via attachment filenames.\n\n\n  CVE-2003-1136: HTML injection in posted message.\n\n\n  CVE-2004-2171: XSS not quoted in error page.'\nRelated_Attack_Patterns: \"18: \\n\\n193: \\n\\n32: \\n\\n86: \"\n",
  "ID: '804'\nName: Guessable CAPTCHA\nDescription: The product uses a CAPTCHA challenge, but the challenge can be guessed\n  or automatically recognized by a non-human actor.\nExtended_Description: 'An automated attacker could bypass the intended protection\n  of the CAPTCHA challenge and perform actions at a higher frequency than humanly\n  possible, such as launching spam attacks.\n\n  There can be several different causes of a guessable CAPTCHA:'\nApplicable_Platforms:\n  Technology: Web Server\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\n",
  "ID: '805'\nName: Buffer Access with Incorrect Length Value\nDescription: The product uses a sequential operation to read or write a buffer, but\n  it uses an incorrect length value that causes it to access memory that is outside\n  of the bounds of the buffer.\nExtended_Description: When the length value exceeds the size of the destination, a\n  buffer overflow could occur.\nApplicable_Platforms:\n  Language: C, C++, Assembly\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis generally does not account for environmental considerations\n  when reporting out-of-bounds memory operations. This can make it difficult for users\n  to determine which warnings should be investigated first. For example, an analysis\n  tool might report buffer overflows that originate from command line arguments in\n  a program that is not expected to run with setuid or other special privileges.\n\n  Detection techniques for buffer-related errors are more mature than for most other\n  weakness types.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the product using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The product''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n  Without visibility into the code, black box methods may not be able to sufficiently\n  distinguish this weakness from others, requiring manual methods to diagnose the\n  underlying problem.\n\n\n  Manual Analysis: Manual analysis can be useful for finding this weakness, but it\n  might not achieve desired code coverage within limited time constraints. This becomes\n  difficult for weaknesses that must be considered for all inputs, since the attack\n  surface can be too large.'\nPotential_Mitigations: 'Requirements: Use a language that does not allow this weakness\n  to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, many languages that perform their own memory management, such as Java\n  and Perl, are not subject to buffer overflows. Other languages, such as Ada and\n  C#, typically provide overflow protection, but the protection can be disabled by\n  the programmer.\n\n  Be wary that a language''s interface to native code may still be subject to overflows,\n  even if the language itself is theoretically safe.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  Examples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57],\n  and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer\n  versions of overflow-prone string-handling functions.\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Implementation: Consider adhering to the following rules when allocating and managing\n  an application''s memory:\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the product or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.'\nObserved_Examples: 'CVE-2011-1959: Chain: large length value causes buffer over-read\n  (CWE-126)\n\n\n  CVE-2011-1848: Use of packet length field to make a calculation, then copy into\n  a fixed-size buffer\n\n\n  CVE-2011-0105: Chain: retrieval of length value from an uninitialized memory location\n\n\n  CVE-2011-0606: Crafted length value in document reader leads to buffer overflow\n\n\n  CVE-2011-0651: SSL server overflow when the sum of multiple length fields exceeds\n  a given value\n\n\n  CVE-2010-4156: Language interpreter API function doesn''t validate length argument,\n  leading to information exposure'\nRelated_Attack_Patterns: \"100: \\n\\n256: \"\n",
  "ID: '806'\nName: Buffer Access Using Size of Source Buffer\nDescription: The product uses the size of a source buffer when reading from or writing\n  to a destination buffer, which may cause it to access memory that is outside of\n  the bounds of the buffer.\nExtended_Description: When the size of the destination is smaller than the size of\n  the source, a buffer overflow could occur.\nApplicable_Platforms:\n  Language: C, C++\nPotential_Mitigations: 'Architecture and Design: Use an abstraction library to abstract\n  away risky APIs. Examples include the Safe C String Library (SafeStr) by Viega,\n  and the Strsafe.h library from Microsoft. This is not a complete solution, since\n  many buffer overflows are not related to strings.\n\n\n  Operation\n\n  Build and Compilation: Use automatic buffer overflow detection mechanisms that are\n  offered by certain compilers or compiler extensions. Examples include: the Microsoft\n  Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and\n  ProPolice, which provide various mechanisms including canary-based detection and\n  range/index checking.\n\n  D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based\n  detection in detail.\n\n\n  Implementation: Programmers should adhere to the following rules when allocating\n  and managing their applications memory: Double check that your buffer is as large\n  as you specify. When using functions that accept a number of bytes to copy, such\n  as strncpy(), be aware that if the destination buffer size is equal to the source\n  buffer size, it may not NULL-terminate the string. Check buffer boundaries if calling\n  this function in a loop and make sure there is no danger of writing past the allocated\n  space. Truncate all input strings to a reasonable length before passing them to\n  the copy and concatenation functions\n\n\n  Operation\n\n  Build and Compilation: Run or compile the software using features or extensions\n  that randomly arrange the positions of a program''s executable and libraries in\n  memory. Because this makes the addresses unpredictable, it can prevent an attacker\n  from reliably jumping to exploitable code.\n\n  Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and\n  Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly\n  realigned if their default memory addresses conflict with other modules, in a process\n  known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using\n  randomly generated addresses. ASLR for libraries cannot be used in conjunction with\n  prelink since it would require relocating the libraries at run-time, defeating the\n  whole purpose of prelinking.\n\n  For more information on these techniques see D3-SAOR (Segment Address Offset Randomization)\n  from D3FEND [REF-1335].\n\n\n  Operation: Use a CPU and operating system that offers Data Execution Protection\n  (using hardware NX or XD bits) or the equivalent techniques that simulate this feature\n  in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction\n  executed is exclusively at a memory address that is part of the code segment.\n\n  For more information on these techniques see D3-PSEP (Process Segment Execution\n  Prevention) from D3FEND [REF-1336].\n\n\n  Build and Compilation\n\n  Operation: Most mitigating technologies at the compiler or OS level to date address\n  only a subset of buffer overflow problems and rarely provide complete protection\n  against even that subset. It is good practice to implement strategies to increase\n  the workload of an attacker, such as leaving the attacker to guess an unknown value\n  that changes every program execution.'\n",
  "ID: '807'\nName: Reliance on Untrusted Inputs in a Security Decision\nDescription: The product uses a protection mechanism that relies on the existence\n  or values of an input, but the input can be modified by an untrusted actor in a\n  way that bypasses the protection mechanism.\nExtended_Description: 'Developers may assume that inputs such as cookies, environment\n  variables, and hidden form fields cannot be modified. However, an attacker could\n  change these inputs using customized clients or other attacks. This change might\n  not be detected. When security decisions such as authentication and authorization\n  are made based on the values of these inputs, attackers can bypass the security\n  of the software.\n\n  Without sufficient encryption, integrity checking, or other mechanism, any input\n  that originates from an outsider cannot be trusted.'\nModes_Of_Introduction: 'Architecture and Design: COMMISSION: This weakness refers\n  to an incorrect design related to an architectural security tactic.\n\n\n  Implementation: '\nDetection_Methods: 'Manual Static Analysis: Since this weakness does not typically\n  appear frequently within a single software package, manual white box techniques\n  may be able to provide sufficient code coverage and reduction of false positives\n  if all potentially-vulnerable operations can be assessed within limited time constraints.\n\n  The effectiveness and speed of manual analysis will be reduced if the there is not\n  a centralized security mechanism, and the security logic is widely distributed throughout\n  the software.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Store state information and sensitive\n  data on the server side only.\n\n  Ensure that the system definitively and unambiguously keeps track of its own state\n  and user state and has rules defined for legitimate state transitions. Do not allow\n  any application user to affect state directly in any way other than through legitimate\n  actions leading to state transitions.\n\n  If information must be stored on the client, do not do so without encryption and\n  integrity checking, or otherwise having a mechanism on the server side to catch\n  tampering. Use a message authentication code (MAC) algorithm, such as Hash Message\n  Authentication Code (HMAC) [REF-529]. Apply this against the state or sensitive\n  data that has to be exposed, which can guarantee the integrity of the data - i.e.,\n  that the data has not been modified. Ensure that a strong hash function is used\n  (CWE-328).\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  With a stateless protocol such as HTTP, use a framework that maintains the state\n  for you.\n\n  Examples include ASP.NET View State [REF-756] and the OWASP ESAPI Session Management\n  feature [REF-45].\n\n  Be careful of language features that provide state support, since these might be\n  provided as a convenience to the programmer and may not be considering security.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n\n\n  Architecture and Design\n\n  Implementation: Understand all the potential areas where untrusted inputs can enter\n  your software: parameters or arguments, cookies, anything read from the network,\n  environment variables, reverse DNS lookups, query results, request headers, URL\n  components, e-mail, files, filenames, databases, and any external systems that provide\n  data to the application. Remember that such inputs may be obtained indirectly through\n  API calls.\n\n  Identify all inputs that are used for security decisions and determine if you can\n  modify the design so that you do not have to rely on submitted inputs at all. For\n  example, you may be able to keep critical information about the user''s session\n  on the server side instead of recording it within external data.'\nObserved_Examples: 'CVE-2009-1549: Attacker can bypass authentication by setting a\n  cookie to a specific value.\n\n\n  CVE-2009-1619: Attacker can bypass authentication and gain admin privileges by setting\n  an \"admin\" cookie to 1.\n\n\n  CVE-2009-0864: Content management system allows admin privileges by setting a \"login\"\n  cookie to \"OK.\"\n\n\n  CVE-2008-5784: e-dating application allows admin privileges by setting the admin\n  cookie to 1.\n\n\n  CVE-2008-6291: Web-based email list manager allows attackers to gain admin privileges\n  by setting a login cookie to \"admin.\"'\n",
  "ID: '81'\nName: Improper Neutralization of Script in an Error Message Web Page\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes special characters that could be interpreted\n  as web-scripting elements when they are sent to an error page.\nExtended_Description: 'Error pages may include customized 403 Forbidden or 404 Not\n  Found pages.\n\n  When an attacker can trigger an error that contains script syntax within the attacker''s\n  input, then cross-site scripting attacks may be possible.'\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nPotential_Mitigations: 'Implementation: Do not write user-controlled input to error\n  pages.\n\n\n  Implementation: Carefully check each input parameter against a rigorous positive\n  specification (allowlist) defining the specific characters and format allowed. All\n  input should be neutralized, not just parameters that the user is supposed to specify,\n  but all data in the request, including hidden fields, cookies, headers, the URL\n  itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities\n  is to validate only fields that are expected to be redisplayed by the site. We often\n  encounter data from the request that is reflected by the application server or the\n  application that the development team did not anticipate. Also, a field that is\n  not currently reflected may be used by a future developer. Therefore, validating\n  ALL parts of the HTTP request is recommended.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2002-0840: XSS in default error page from Host: header.\n\n\n  CVE-2002-1053: XSS in error message.\n\n\n  CVE-2002-1700: XSS in error page from targeted parameter.'\nRelated_Attack_Patterns: '198: '\n",
  "ID: '82'\nName: Improper Neutralization of Script in Attributes of IMG Tags in a Web Page\nDescription: The web application does not neutralize or incorrectly neutralizes scripting\n  elements within attributes of HTML IMG tags, such as the src attribute.\nExtended_Description: Attackers can embed XSS exploits into the values for IMG attributes\n  (e.g. SRC) that is streamed and then executed in a victim's browser. Note that when\n  the page is loaded into a user's browsers, the exploit will automatically execute.\nPotential_Mitigations: 'Implementation: Use and specify an output encoding that can\n  be handled by the downstream component that is reading the output. Common encodings\n  include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream\n  component may choose a different encoding, either by assuming a default encoding\n  or automatically inferring which encoding is being used, which can be erroneous.\n  When the encodings are inconsistent, the downstream component might treat some character\n  or byte sequences as special, even if they are not special in the original encoding.\n  Attackers might then be able to exploit this discrepancy and conduct injection attacks;\n  they even might be able to bypass protection mechanisms that assume the original\n  encoding is also being used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2006-3211: Stored XSS in a guestbook application using a javascript:\n  URI in a bbcode img tag.\n\n\n  CVE-2002-1649: javascript URI scheme in IMG tag.\n\n\n  CVE-2002-1803: javascript URI scheme in IMG tag.\n\n\n  CVE-2002-1804: javascript URI scheme in IMG tag.\n\n\n  CVE-2002-1805: javascript URI scheme in IMG tag.\n\n\n  CVE-2002-1806: javascript URI scheme in IMG tag.\n\n\n  CVE-2002-1807: javascript URI scheme in IMG tag.\n\n\n  CVE-2002-1808: javascript URI scheme in IMG tag.'\n",
  "ID: '820'\nName: Missing Synchronization\nDescription: The product utilizes a shared resource in a concurrent manner but does\n  not attempt to synchronize access to the resource.\nExtended_Description: If access to a shared resource is not synchronized, then the\n  resource may not be in a state that is expected by the product. This might lead\n  to unexpected or insecure behaviors, especially if an attacker can influence the\n  shared resource.\n",
  "ID: '821'\nName: Incorrect Synchronization\nDescription: The product utilizes a shared resource in a concurrent manner, but it\n  does not correctly synchronize access to the resource.\nExtended_Description: If access to a shared resource is not correctly synchronized,\n  then the resource may not be in a state that is expected by the product. This might\n  lead to unexpected or insecure behaviors, especially if an attacker can influence\n  the shared resource.\n",
  "ID: '822'\nName: Untrusted Pointer Dereference\nDescription: The product obtains a value from an untrusted source, converts this value\n  to a pointer, and dereferences the resulting pointer.\nExtended_Description: 'An attacker can supply a pointer for memory locations that\n  the product is not expecting. If the pointer is dereferenced for a write operation,\n  the attack might allow modification of critical state variables, cause a crash,\n  or execute code. If the dereferencing operation is for a read, then the attack might\n  allow reading of sensitive data, cause a crash, or set a variable to an unexpected\n  value (since the value will be read from an unexpected memory location).\n\n  There are several variants of this weakness, including but not necessarily limited\n  to:'\nObserved_Examples: 'CVE-2007-5655: message-passing framework interprets values in\n  packets as pointers, causing a crash.\n\n\n  CVE-2010-2299: labeled as a \"type confusion\" issue, also referred to as a \"stale\n  pointer.\" However, the bug ID says \"contents are simply interpreted as a pointer...\n  renderer ordinarily doesn''t supply this pointer directly\". The \"handle\" in the\n  untrusted area is replaced in one function, but not another - thus also, effectively,\n  exposure to wrong sphere (CWE-668).\n\n\n  CVE-2009-1719: Untrusted dereference using undocumented constructor.\n\n\n  CVE-2009-1250: An error code is incorrectly checked and interpreted as a pointer,\n  leading to a crash.\n\n\n  CVE-2009-0311: An untrusted value is obtained from a packet and directly called\n  as a function pointer, leading to code execution.\n\n\n  CVE-2010-1818: Undocumented attribute in multimedia software allows \"unmarshaling\"\n  of an untrusted pointer.\n\n\n  CVE-2010-3189: ActiveX control for security software accepts a parameter that is\n  assumed to be an initialized pointer.\n\n\n  CVE-2010-1253: Spreadsheet software treats certain record values that lead to \"user-controlled\n  pointer\" (might be untrusted offset, not untrusted pointer).'\nRelated_Attack_Patterns: '129: '\n",
  "ID: '823'\nName: Use of Out-of-range Pointer Offset\nDescription: The product performs pointer arithmetic on a valid pointer, but it uses\n  an offset that can point outside of the intended range of valid memory locations\n  for the resulting pointer.\nExtended_Description: 'While a pointer can contain a reference to any arbitrary memory\n  location, a program typically only intends to use the pointer to access limited\n  portions of memory, such as contiguous memory used to access an individual array.\n\n  Programs may use offsets in order to access fields or sub-elements stored within\n  structured data. The offset might be out-of-range if it comes from an untrusted\n  source, is the result of an incorrect calculation, or occurs because of another\n  error.\n\n  If an attacker can control or influence the offset so that it points outside of\n  the intended boundaries of the structure, then the attacker may be able to read\n  or write to memory locations that are used elsewhere in the product. As a result,\n  the attack might change the state of the product as accessed through program variables,\n  cause a crash or instable behavior, and possibly lead to code execution.'\nAlternate_Terms: 'Untrusted pointer offset: This term is narrower than the concept\n  of \"out-of-range\" offset, since the offset might be the result of a calculation\n  or other error that does not depend on any externally-supplied values.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2010-2160: Invalid offset in undocumented opcode leads to\n  memory corruption.\n\n\n  CVE-2010-1281: Multimedia player uses untrusted value from a file when using file-pointer\n  calculations.\n\n\n  CVE-2009-3129: Spreadsheet program processes a record with an invalid size field,\n  which is later used as an offset.\n\n\n  CVE-2009-2694: Instant messaging library does not validate an offset value specified\n  in a packet.\n\n\n  CVE-2009-2687: Language interpreter does not properly handle invalid offsets in\n  JPEG image, leading to out-of-bounds memory access and crash.\n\n\n  CVE-2009-0690: negative offset leads to out-of-bounds read\n\n\n  CVE-2008-4114: untrusted offset in kernel\n\n\n  CVE-2010-2873: \"blind trust\" of an offset value while writing heap memory allows\n  corruption of function pointer,leading to code execution\n\n\n  CVE-2010-2866: negative value (signed) causes pointer miscalculation\n\n\n  CVE-2010-2872: signed values cause incorrect pointer calculation\n\n\n  CVE-2007-5657: values used as pointer offsets\n\n\n  CVE-2010-2867: a return value from a function is sign-extended if the value is signed,\n  then used as an offset for pointer arithmetic\n\n\n  CVE-2009-1097: portions of a GIF image used as offsets, causing corruption of an\n  object pointer.\n\n\n  CVE-2008-1807: invalid numeric field leads to a free of arbitrary memory locations,\n  then code execution.\n\n\n  CVE-2007-2500: large number of elements leads to a free of an arbitrary address\n\n\n  CVE-2008-1686: array index issue (CWE-129) with negative offset, used to dereference\n  a function pointer\n\n\n  CVE-2010-2878: \"buffer seek\" value - basically an offset?'\nRelated_Attack_Patterns: '129: '\n",
  "ID: '824'\nName: Access of Uninitialized Pointer\nDescription: The product accesses or uses a pointer that has not been initialized.\nExtended_Description: 'If the pointer contains an uninitialized value, then the value\n  might not point to a valid memory location. This could cause the product to read\n  from or write to unexpected memory locations, leading to a denial of service. If\n  the uninitialized pointer is used as a function call, then arbitrary functions could\n  be invoked. If an attacker can influence the portion of uninitialized memory that\n  is contained in the pointer, this weakness could be leveraged to execute code or\n  perform other attacks.\n\n  Depending on memory layout, associated memory management behaviors, and product\n  operation, the attacker might be able to influence the contents of the uninitialized\n  pointer, thus gaining more fine-grained control of the memory location to be accessed.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2010-0211: chain: unchecked return value (CWE-252) leads to\n  free of invalid, uninitialized pointer (CWE-824).\n\n\n  CVE-2009-2768: Pointer in structure is not initialized, leading to NULL pointer\n  dereference (CWE-476) and system crash.\n\n\n  CVE-2009-1721: Free of an uninitialized pointer.\n\n\n  CVE-2009-1415: Improper handling of invalid signatures leads to free of invalid\n  pointer.\n\n\n  CVE-2009-0846: Invalid encoding triggers free of uninitialized pointer.\n\n\n  CVE-2009-0040: Crafted PNG image leads to free of uninitialized pointer.\n\n\n  CVE-2008-2934: Crafted GIF image leads to free of uninitialized pointer.\n\n\n  CVE-2007-4682: Access of uninitialized pointer might lead to code execution.\n\n\n  CVE-2007-4639: Step-based manipulation: invocation of debugging function before\n  the primary initialization function leads to access of an uninitialized pointer\n  and code execution.\n\n\n  CVE-2007-4000: Unchecked return values can lead to a write to an uninitialized pointer.\n\n\n  CVE-2007-2442: zero-length input leads to free of uninitialized pointer.\n\n\n  CVE-2007-1213: Crafted font leads to uninitialized function pointer.\n\n\n  CVE-2006-6143: Uninitialized function pointer in freed memory is invoked\n\n\n  CVE-2006-4175: LDAP server mishandles malformed BER queries, leading to free of\n  uninitialized memory\n\n\n  CVE-2006-0054: Firewall can crash with certain ICMP packets that trigger access\n  of an uninitialized pointer.\n\n\n  CVE-2003-1201: LDAP server does not initialize members of structs, which leads to\n  free of uninitialized pointer if an LDAP request fails.'\n",
  "ID: '825'\nName: Expired Pointer Dereference\nDescription: The product dereferences a pointer that contains a location for memory\n  that was previously valid, but is no longer valid.\nExtended_Description: When a product releases memory, but it maintains a pointer to\n  that memory, then the memory might be re-allocated at a later time. If the original\n  pointer is accessed to read or write data, then this could cause the product to\n  read or modify data that is in use by a different function or process. Depending\n  on how the newly-allocated memory is used, this could lead to a denial of service,\n  information exposure, or code execution.\nPotential_Mitigations: 'Architecture and Design: Choose a language that provides automatic\n  memory management.\n\n\n  Implementation: When freeing pointers, be sure to set them to NULL once they are\n  freed. However, the utilization of multiple or complex data structures may lower\n  the usefulness of this strategy.'\nObserved_Examples: 'CVE-2008-5013: access of expired memory address leads to arbitrary\n  code execution\n\n\n  CVE-2010-3257: stale pointer issue leads to denial of service and possibly other\n  consequences\n\n\n  CVE-2008-0062: Chain: a message having an unknown message type may cause a reference\n  to uninitialized memory resulting in a null pointer dereference (CWE-476) or dangling\n  pointer (CWE-825), possibly crashing the system or causing heap corruption.\n\n\n  CVE-2007-1211: read of value at an offset into a structure after the offset is no\n  longer valid'\n",
  "ID: '826'\nName: Premature Release of Resource During Expected Lifetime\nDescription: The product releases a resource that is still intended to be used by\n  itself or another actor.\nExtended_Description: 'This weakness focuses on errors in which the product should\n  not release a resource, but performs the release anyway. This is different than\n  a weakness in which the product releases a resource at the appropriate time, but\n  it maintains a reference to the resource, which it later accesses. For this weakness,\n  the resource should still be valid upon the subsequent access.\n\n  When a product releases a resource that is still being used, it is possible that\n  operations will still be taken on this resource, which may have been repurposed\n  in the meantime, leading to issues similar to CWE-825. Consequences may include\n  denial of service, information exposure, or code execution.'\nObserved_Examples: 'CVE-2009-3547: chain: race condition might allow resource to be\n  released before operating on it, leading to NULL dereference'\n",
  "ID: '827'\nName: Improper Control of Document Type Definition\nDescription: The product does not restrict a reference to a Document Type Definition\n  (DTD) to the intended control sphere. This might allow attackers to reference arbitrary\n  DTDs, possibly causing the product to expose files, consume excessive system resources,\n  or execute arbitrary http requests on behalf of the attacker.\nExtended_Description: 'As DTDs are processed, they might try to read or include files\n  on the machine performing the parsing. If an attacker is able to control the DTD,\n  then the attacker might be able to specify sensitive resources or requests or provide\n  malicious content.\n\n  For example, the SOAP specification prohibits SOAP messages from containing DTDs.'\nApplicable_Platforms:\n  Language: XML\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2010-2076: Product does not properly reject DTDs in SOAP messages,\n  which allows remote attackers to read arbitrary files, send HTTP requests to intranet\n  servers, or cause a denial of service.'\n",
  "ID: '828'\nName: Signal Handler with Functionality that is not Asynchronous-Safe\nDescription: The product defines a signal handler that contains code sequences that\n  are not asynchronous-safe, i.e., the functionality is not reentrant, or it can be\n  interrupted.\nExtended_Description: 'This can lead to an unexpected system state with a variety\n  of potential consequences depending on context, including denial of service and\n  code execution.\n\n  Signal handlers are typically intended to interrupt normal functionality of a program,\n  or even other signals, in order to notify the process of an event. When a signal\n  handler uses global or static variables, or invokes functions that ultimately depend\n  on such state or its associated metadata, then it could corrupt system state that\n  is being used by normal functionality. This could subject the program to race conditions\n  or other weaknesses that allow an attacker to cause the program state to be corrupted.\n  While denial of service is frequently the consequence, in some cases this weakness\n  could be leveraged for code execution.\n\n  There are several different scenarios that introduce this issue:\n\n  Note that in some environments or contexts, it might be possible for the signal\n  handler to be interrupted itself.\n\n  If both a signal handler and the normal behavior of the product have to operate\n  on the same set of state variables, and a signal is received in the middle of the\n  normal execution''s modifications of those variables, the variables may be in an\n  incorrect or corrupt state during signal handler execution, and possibly still incorrect\n  or corrupt upon return.'\nPotential_Mitigations: 'Implementation\n\n  Architecture and Design: Eliminate the usage of non-reentrant functionality inside\n  of signal handlers. This includes replacing all non-reentrant library calls with\n  reentrant calls.\n\n  Note: This will not always be possible and may require large portions of the product\n  to be rewritten or even redesigned. Sometimes reentrant-safe library alternatives\n  will not be available. Sometimes non-reentrant interaction between the state of\n  the system and the signal handler will be required by design.\n\n\n  Implementation: Where non-reentrant functionality must be leveraged within a signal\n  handler, be sure to block or mask signals appropriately. This includes blocking\n  other signals within the signal handler itself that may also leverage the functionality.\n  It also includes blocking all signals reliant upon the functionality when it is\n  being accessed or modified by the normal behaviors of the product.'\nObserved_Examples: 'CVE-2008-4109: Signal handler uses functions that ultimately call\n  the unsafe syslog/malloc/s*printf, leading to denial of service via multiple login\n  attempts\n\n\n  CVE-2006-5051: Chain: Signal handler contains too much functionality (CWE-828),\n  introducing a race condition (CWE-362) that leads to a double free (CWE-415).\n\n\n  CVE-2001-1349: unsafe calls to library functions from signal handler\n\n\n  CVE-2004-0794: SIGURG can be used to remotely interrupt signal handler; other variants\n  exist.\n\n\n  CVE-2004-2259: SIGCHLD signal to FTP server can cause crash under heavy load while\n  executing non-reentrant functions like malloc/free.\n\n\n  CVE-2002-1563: SIGCHLD not blocked in a daemon loop while counter is modified, causing\n  counter to get out of sync.'\n",
  "ID: '829'\nName: Inclusion of Functionality from Untrusted Control Sphere\nDescription: The product imports, requires, or includes executable functionality (such\n  as a library) from a source that is outside of the intended control sphere.\nExtended_Description: 'When including third-party functionality, such as a web widget,\n  library, or other source of functionality, the product must effectively trust that\n  functionality. Without sufficient protection mechanisms, the functionality could\n  be malicious in nature (either by coming from an untrusted source, being spoofed,\n  or being modified in transit from a trusted source). The functionality might also\n  contain its own weaknesses, or grant access to additional functionality and state\n  information that should be kept private to the base system, such as system state\n  information, sensitive application data, or the DOM of a web application.\n\n  This might lead to many different consequences depending on the included functionality,\n  but some examples include injection of malware, information exposure by granting\n  excessive privileges or permissions to the untrusted functionality, DOM-based XSS\n  vulnerabilities, stealing user''s cookies, or open redirect to malware (CWE-601).'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use a vetted library or framework\n  that does not allow this weakness to occur or provides constructs that make this\n  weakness easier to avoid.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n  For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\".\n  Features such as the ESAPI AccessReferenceMap [REF-45] provide this capability.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent allowlists that limit the character set\n  to be used. If feasible, only allow a single \".\" character in the filename to avoid\n  weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid\n  CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Architecture and Design\n\n  Operation: Store library, include, and utility files outside of the web document\n  root, if possible. Otherwise, store them in a separate directory and use the web\n  server''s access control capabilities to prevent attackers from directly requesting\n  them. One common practice is to define a fixed constant in each calling program,\n  then check for the existence of the constant in the library/include file; if the\n  constant does not exist, then the file was directly requested, and it can exit immediately.\n\n  This significantly reduces the chance of an attacker being able to bypass any protection\n  mechanisms that are in the base program but not in the include files. It will also\n  reduce the attack surface.\n\n\n  Architecture and Design\n\n  Implementation: Understand all the potential areas where untrusted inputs can enter\n  your software: parameters or arguments, cookies, anything read from the network,\n  environment variables, reverse DNS lookups, query results, request headers, URL\n  components, e-mail, files, filenames, databases, and any external systems that provide\n  data to the application. Remember that such inputs may be obtained indirectly through\n  API calls.\n\n  Many file inclusion problems occur because the programmer assumed that certain inputs\n  could not be modified, especially for cookies and URL components.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.'\nObserved_Examples: 'CVE-2010-2076: Product does not properly reject DTDs in SOAP messages,\n  which allows remote attackers to read arbitrary files, send HTTP requests to intranet\n  servers, or cause a denial of service.\n\n\n  CVE-2004-0285: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2004-0030: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2004-0068: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2005-2157: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2005-2162: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2005-2198: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2004-0128: Modification of assumed-immutable variable in configuration script\n  leads to file inclusion.\n\n\n  CVE-2005-1864: PHP file inclusion.\n\n\n  CVE-2005-1869: PHP file inclusion.\n\n\n  CVE-2005-1870: PHP file inclusion.\n\n\n  CVE-2005-2154: PHP local file inclusion.\n\n\n  CVE-2002-1704: PHP remote file include.\n\n\n  CVE-2002-1707: PHP remote file include.\n\n\n  CVE-2005-1964: PHP remote file include.\n\n\n  CVE-2005-1681: PHP remote file include.\n\n\n  CVE-2005-2086: PHP remote file include.\n\n\n  CVE-2004-0127: Directory traversal vulnerability in PHP include statement.\n\n\n  CVE-2005-1971: Directory traversal vulnerability in PHP include statement.\n\n\n  CVE-2005-3335: PHP file inclusion issue, both remote and local; local include uses\n  \"..\" and \"%00\" characters as a manipulation, but many remote file inclusion issues\n  probably have this vector.'\nRelated_Attack_Patterns: \"175: \\n\\n201: \\n\\n228: \\n\\n251: \\n\\n252: \\n\\n253: \\n\\n263:\\\n  \\ \\n\\n538: \\n\\n549: \\n\\n640: \\n\\n660: \\n\\n695: \\n\\n698: \"\n",
  "ID: '83'\nName: Improper Neutralization of Script in Attributes in a Web Page\nDescription: The product does not neutralize or incorrectly neutralizes \"javascript:\"\n  or other URIs from dangerous attributes within tags, such as onmouseover, onload,\n  onerror, or style.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Carefully check each input parameter against\n  a rigorous positive specification (allowlist) defining the specific characters and\n  format allowed. All input should be neutralized, not just parameters that the user\n  is supposed to specify, but all data in the request, including tag attributes, hidden\n  fields, cookies, headers, the URL itself, and so forth. A common mistake that leads\n  to continuing XSS vulnerabilities is to validate only fields that are expected to\n  be redisplayed by the site. We often encounter data from the request that is reflected\n  by the application server or the application that the development team did not anticipate.\n  Also, a field that is not currently reflected may be used by a future developer.\n  Therefore, validating ALL parts of the HTTP request is recommended.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2001-0520: Bypass filtering of SCRIPT tags using onload in\n  BODY, href in A, BUTTON, INPUT, and others.\n\n\n  CVE-2002-1493: guestbook XSS in STYLE or IMG SRC attributes.\n\n\n  CVE-2002-1965: Javascript in onerror attribute of IMG tag.\n\n\n  CVE-2002-1495: XSS in web-based email product via onmouseover event.\n\n\n  CVE-2002-1681: XSS via script in <P> tag.\n\n\n  CVE-2004-1935: Onload, onmouseover, and other events in an e-mail attachment.\n\n\n  CVE-2005-0945: Onmouseover and onload events in img, link, and mail tags.\n\n\n  CVE-2003-1136: Javascript in onmouseover attribute in e-mail address or URL.'\nRelated_Attack_Patterns: \"243: \\n\\n244: \\n\\n588: \"\n",
  "ID: '830'\nName: Inclusion of Web Functionality from an Untrusted Source\nDescription: The product includes web functionality (such as a web widget) from another\n  domain, which causes it to operate within the domain of the product, potentially\n  granting total access and control of the product to the untrusted source.\nExtended_Description: 'Including third party functionality in a web-based environment\n  is risky, especially if the source of the functionality is untrusted.\n\n  Even if the third party is a trusted source, the product may still be exposed to\n  attacks and malicious behavior if that trusted source is compromised, or if the\n  code is modified in transmission from the third party to the product.\n\n  This weakness is common in \"mashup\" development on the web, which may include source\n  functionality from other domains. For example, Javascript-based web widgets may\n  be inserted by using ''<SCRIPT SRC=\"http://other.domain.here\">'' tags, which causes\n  the code to run in the domain of the product, not the remote site from which the\n  widget was loaded. As a result, the included code has access to the local DOM, including\n  cookies and other data that the developer might not want the remote site to be able\n  to access.\n\n  Such dependencies may be desirable, or even required, but sometimes programmers\n  are not aware that a dependency exists.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\n",
  "ID: '831'\nName: Signal Handler Function Associated with Multiple Signals\nDescription: The product defines a function that is used as a handler for more than\n  one signal.\nExtended_Description: 'While sometimes intentional and safe, when the same function\n  is used to handle multiple signals, a race condition could occur if the function\n  uses any state outside of its local declaration, such as global variables or non-reentrant\n  functions, or has any side effects.\n\n  An attacker could send one signal that invokes the handler function; in many OSes,\n  this will typically prevent the same signal from invoking the handler again, at\n  least until the handler function has completed execution. However, the attacker\n  could then send a different signal that is associated with the same handler function.\n  This could interrupt the original handler function while it is still executing.\n  If there is shared state, then the state could be corrupted. This can lead to a\n  variety of potential consequences depending on context, including denial of service\n  and code execution.\n\n  Another rarely-explored possibility arises when the signal handler is only designed\n  to be executed once (if at all). By sending multiple signals, an attacker could\n  invoke the function more than once. This may generate extra, unintended side effects.\n  A race condition might not even be necessary; the attacker could send one signal,\n  wait until it is handled, then send the other signal.'\n",
  "ID: '832'\nName: Unlock of a Resource that is not Locked\nDescription: The product attempts to unlock a resource that is not locked.\nExtended_Description: Depending on the locking functionality, an unlock of a non-locked\n  resource might cause memory corruption or other modification to the resource (or\n  its associated metadata that is used for tracking locks).\nObserved_Examples: 'CVE-2010-4210: function in OS kernel unlocks a mutex that was\n  not previously locked, causing a panic or overwrite of arbitrary memory.\n\n\n  CVE-2008-4302: Chain: OS kernel does not properly handle a failure of a function\n  call (CWE-755), leading to an unlock of a resource that was not locked (CWE-832),\n  with resultant crash.\n\n\n  CVE-2009-1243: OS kernel performs an unlock in some incorrect circumstances, leading\n  to panic.'\n",
  "ID: '833'\nName: Deadlock\nDescription: The product contains multiple threads or executable segments that are\n  waiting for each other to release a necessary lock, resulting in deadlock.\nObserved_Examples: 'CVE-1999-1476: A bug in some Intel Pentium processors allow DoS\n  (hang) via an invalid \"CMPXCHG8B\" instruction, causing a deadlock\n\n\n  CVE-2009-2857: OS deadlock\n\n\n  CVE-2009-1961: OS deadlock involving 3 separate functions\n\n\n  CVE-2009-2699: deadlock in library\n\n\n  CVE-2009-4272: deadlock triggered by packets that force collisions in a routing\n  table\n\n\n  CVE-2002-1850: read/write deadlock between web server and script\n\n\n  CVE-2004-0174: web server deadlock involving multiple listening connections\n\n\n  CVE-2009-1388: multiple simultaneous calls to the same function trigger deadlock.\n\n\n  CVE-2006-5158: chain: other weakness leads to NULL pointer dereference (CWE-476)\n  or deadlock (CWE-833).\n\n\n  CVE-2006-4342: deadlock when an operation is performed on a resource while it is\n  being removed.\n\n\n  CVE-2006-2374: Deadlock in device driver triggered by using file handle of a related\n  device.\n\n\n  CVE-2006-2275: Deadlock when large number of small messages cannot be processed\n  quickly enough.\n\n\n  CVE-2005-3847: OS kernel has deadlock triggered by a signal during a core dump.\n\n\n  CVE-2005-3106: Race condition leads to deadlock.\n\n\n  CVE-2005-2456: Chain: array index error (CWE-129) leads to deadlock (CWE-833)'\nRelated_Attack_Patterns: '25: '\n",
  "ID: '834'\nName: Excessive Iteration\nDescription: The product performs an iteration or loop without sufficiently limiting\n  the number of times that the loop is executed.\nExtended_Description: If the iteration can be influenced by an attacker, this weakness\n  could allow attackers to consume excessive resources such as CPU or memory. In many\n  cases, a loop does not need to be infinite in order to cause enough resource consumption\n  to adversely affect the product or its host system; it depends on the amount of\n  resources consumed per iteration.\nDetection_Methods: 'Dynamic Analysis with Manual Results Interpretation: According\n  to SOAR, the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nObserved_Examples: \"CVE-2011-1027: Chain: off-by-one error leads to infinite loop\\\n  \\ using invalid hex-encoded characters.\\n\\nCVE-2006-6499: Chain: web browser crashes\\\n  \\ due to infinite loop - \\\"bad\\n\\t      looping logic [that relies on] floating\\\n  \\ point math [CWE-1339] to exit\\n\\t      the loop [CWE-835]\\\"\"\n",
  "ID: '835'\nName: Loop with Unreachable Exit Condition ('Infinite Loop')\nDescription: The product contains an iteration or loop with an exit condition that\n  cannot be reached, i.e., an infinite loop.\nExtended_Description: If the loop can be influenced by an attacker, this weakness\n  could allow attackers to consume excessive resources such as CPU or memory.\nObserved_Examples: \"CVE-2022-25304: A Python machine communication platform did not\\\n  \\ account for receiving a malformed packet with a null size, causing the receiving\\\n  \\ function to never update the message buffer and be caught in an infinite loop.\\n\\\n  \\nCVE-2011-1027: Chain: off-by-one error leads to infinite loop using invalid hex-encoded\\\n  \\ characters.\\n\\nCVE-2011-1142: Chain: self-referential values in recursive definitions\\\n  \\ lead to infinite loop.\\n\\nCVE-2011-1002: NULL UDP packet is never cleared from\\\n  \\ a queue, leading to infinite loop.\\n\\nCVE-2006-6499: Chain: web browser crashes\\\n  \\ due to infinite loop - \\\"bad\\n\\t      looping logic [that relies on] floating\\\n  \\ point math [CWE-1339] to exit\\n\\t      the loop [CWE-835]\\\"\\n\\nCVE-2010-4476:\\\n  \\ Floating point conversion routine cycles back and forth between two different\\\n  \\ values.\\n\\nCVE-2010-4645: Floating point conversion routine cycles back and forth\\\n  \\ between two different values.\\n\\nCVE-2010-2534: Chain: improperly clearing a pointer\\\n  \\ in a linked list leads to infinite loop.\\n\\nCVE-2013-1591: Chain: an integer overflow\\\n  \\ (CWE-190) in the image size calculation causes an infinite loop (CWE-835) which\\\n  \\ sequentially allocates buffers without limits (CWE-1325) until the stack is full.\\n\\\n  \\nCVE-2008-3688: Chain: A denial of service may be caused by an uninitialized variable\\\n  \\ (CWE-457) allowing an infinite loop (CWE-835) resulting from a connection to an\\\n  \\ unresponsive server.\"\n",
  "ID: '836'\nName: Use of Password Hash Instead of Password for Authentication\nDescription: The product records password hashes in a data store, receives a hash\n  of a password from a client, and compares the supplied hash to the hash obtained\n  from the data store.\nExtended_Description: 'Some authentication mechanisms rely on the client to generate\n  the hash for a password, possibly to reduce load on the server or avoid sending\n  the password across the network. However, when the client is used to generate the\n  hash, an attacker can bypass the authentication by obtaining a copy of the hash,\n  e.g. by using SQL injection to compromise a database of authentication credentials,\n  or by exploiting an information exposure. The attacker could then use a modified\n  client to replay the stolen hash without having knowledge of the original password.\n\n  As a result, the server-side comparison against a client-side hash does not provide\n  any more security than the use of passwords without hashing.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2009-1283: Product performs authentication with user-supplied\n  password hashes that can be obtained from a separate SQL injection vulnerability\n  (CVE-2009-1282).\n\n\n  CVE-2005-3435: Product allows attackers to bypass authentication by obtaining the\n  password hash for another user and specifying the hash in the pwd argument.'\nRelated_Attack_Patterns: \"644: \\n\\n652: \"\n",
  "ID: '837'\nName: Improper Enforcement of a Single, Unique Action\nDescription: The product requires that an actor should only be able to perform an\n  action once, or to have only one unique action, but the product does not enforce\n  or improperly enforces this restriction.\nExtended_Description: In various applications, a user is only expected to perform\n  a certain action once, such as voting, requesting a refund, or making a purchase.\n  When this restriction is not enforced, sometimes this can have security implications.\n  For example, in a voting application, an attacker could attempt to \"stuff the ballot\n  box\" by voting multiple times. If these votes are counted separately, then the attacker\n  could directly affect who wins the vote. This could have significant business impact\n  depending on the purpose of the product.\nObserved_Examples: 'CVE-2008-0294: Ticket-booking web application allows a user to\n  lock a seat more than once.\n\n\n  CVE-2005-4051: CMS allows people to rate downloads by voting more than once.\n\n\n  CVE-2002-216: Polling software allows people to vote more than once by setting a\n  cookie.\n\n\n  CVE-2003-1433: Chain: lack of validation of a challenge key in a game allows a player\n  to register multiple times and lock other players out of the game.\n\n\n  CVE-2002-1018: Library feature allows attackers to check out the same e-book multiple\n  times, preventing other users from accessing copies of the e-book.\n\n\n  CVE-2009-2346: Protocol implementation allows remote attackers to cause a denial\n  of service (call-number exhaustion) by initiating many message exchanges.'\n",
  "ID: '838'\nName: Inappropriate Encoding for Output Context\nDescription: The product uses or specifies an encoding when generating output to a\n  downstream component, but the specified encoding is not the same as the encoding\n  that is expected by the downstream component.\nExtended_Description: 'This weakness can cause the downstream component to use a decoding\n  method that produces different data than what the product intended to send. When\n  the wrong encoding is used - even if closely related - the downstream component\n  could decode the data incorrectly. This can have security consequences when the\n  provided boundaries between control and data are inadvertently broken, because the\n  resulting data could introduce control characters or special elements that were\n  not sent by the product. The resulting data could then be used to bypass protection\n  mechanisms such as input validation, and enable injection attacks.\n\n  While using output encoding is essential for ensuring that communications between\n  components are accurate, the use of the wrong encoding - even if closely related\n  - could cause the downstream component to misinterpret the output.\n\n  For example, HTML entity encoding is used for elements in the HTML body of a web\n  page. However, a programmer might use entity encoding when generating output for\n  that is used within an attribute of an HTML tag, which could contain functional\n  Javascript that is not affected by the HTML encoding.\n\n  While web applications have received the most attention for this problem, this weakness\n  could potentially apply to any type of product that uses a communications stream\n  that could support multiple encodings.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use context-aware encoding. That is, understand\n  which encoding is being used by the downstream component, and ensure that this encoding\n  is used. If an encoding can be specified, do so, instead of assuming that the default\n  encoding is the same as the default being assumed by the downstream component.\n\n\n  Architecture and Design: Where possible, use communications protocols or data formats\n  that provide strict boundaries between control and data. If this is not feasible,\n  ensure that the protocols or formats allow the communicating components to explicitly\n  state which encoding/decoding method is being used. Some template frameworks provide\n  built-in support.\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, consider using the ESAPI Encoding control [REF-45] or a similar tool,\n  library, or framework. These will help the programmer encode outputs in a manner\n  less prone to error.\n\n  Note that some template mechanisms provide built-in support for the appropriate\n  encoding.'\nObserved_Examples: 'CVE-2009-2814: Server does not properly handle requests that do\n  not contain UTF-8 data; browser assumes UTF-8, allowing XSS.'\nRelated_Attack_Patterns: '468: '\n",
  "ID: '839'\nName: Numeric Range Comparison Without Minimum Check\nDescription: The product checks a value to ensure that it is less than or equal to\n  a maximum, but it does not also verify that the value is greater than or equal to\n  the minimum.\nExtended_Description: 'Some products use signed integers or floats even when their\n  values are only expected to be positive or 0. An input validation check might assume\n  that the value is positive, and only check for the maximum value. If the value is\n  negative, but the code assumes that the value is positive, this can produce an error.\n  The error may have security consequences if the negative value is used for memory\n  allocation, array access, buffer access, etc. Ultimately, the error could lead to\n  a buffer overflow or other type of memory corruption.\n\n  The use of a negative number in a positive-only context could have security implications\n  for other types of resources. For example, a shopping cart might check that the\n  user is not requesting more than 10 items, but a request for -3 items could cause\n  the application to calculate a negative price and credit the attacker''s account.'\nApplicable_Platforms:\n  Language: C, C++\nAlternate_Terms: 'Signed comparison: The \"signed comparison\" term is often used to\n  describe when the product uses a signed variable and checks it to ensure that it\n  is less than a maximum value (typically a maximum buffer size), but does not verify\n  that it is greater than 0.'\nPotential_Mitigations: 'Implementation: If the number to be used is always expected\n  to be positive, change the variable type from signed to unsigned or size_t.\n\n\n  Implementation: If the number to be used could have a negative value based on the\n  specification (thus requiring a signed value), but the number should only be positive\n  to preserve code correctness, then include a check to ensure that the value is positive.'\nObserved_Examples: 'CVE-2010-1866: Chain: integer overflow causes a negative signed\n  value, which later bypasses a maximum-only check, leading to heap-based buffer overflow.\n\n\n  CVE-2009-1099: Chain: 16-bit counter can be interpreted as a negative value, compared\n  to a 32-bit maximum value, leading to buffer under-write.\n\n\n  CVE-2011-0521: Chain: kernel''s lack of a check for a negative value leads to memory\n  corruption.\n\n\n  CVE-2010-3704: Chain: parser uses atoi() but does not check for a negative value,\n  which can happen on some platforms, leading to buffer under-write.\n\n\n  CVE-2010-2530: Chain: Negative value stored in an int bypasses a size check and\n  causes allocation of large amounts of memory.\n\n\n  CVE-2009-3080: Chain: negative offset value to IOCTL bypasses check for maximum\n  index, then used as an array index for buffer under-read.\n\n\n  CVE-2008-6393: chain: file transfer client performs signed comparison, leading to\n  integer overflow and heap-based buffer overflow.\n\n\n  CVE-2008-4558: chain: negative ID in media player bypasses check for maximum index,\n  then used as an array index for buffer under-read.'\n",
  "ID: '84'\nName: Improper Neutralization of Encoded URI Schemes in a Web Page\nDescription: The web application improperly neutralizes user-controlled input for\n  executable script disguised with URI encodings.\nPotential_Mitigations: 'Implementation: Resolve all URIs to absolute or canonical\n  representations before processing.\n\n\n  Implementation: Carefully check each input parameter against a rigorous positive\n  specification (allowlist) defining the specific characters and format allowed. All\n  input should be neutralized, not just parameters that the user is supposed to specify,\n  but all data in the request, including tag attributes, hidden fields, cookies, headers,\n  the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities\n  is to validate only fields that are expected to be redisplayed by the site. We often\n  encounter data from the request that is reflected by the application server or the\n  application that the development team did not anticipate. Also, a field that is\n  not currently reflected may be used by a future developer. Therefore, validating\n  ALL parts of the HTTP request is recommended.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2005-0563: Cross-site scripting (XSS) vulnerability in Microsoft\n  Outlook Web Access (OWA) component in Exchange Server 5.5 allows remote attackers\n  to inject arbitrary web script or HTML via an email message with an encoded javascript:\n  URL (\"jav&#X41sc&#0010;ript:\") in an IMG tag.\n\n\n  CVE-2005-2276: Cross-site scripting (XSS) vulnerability in Novell Groupwise WebAccess\n  6.5 before July 11, 2005 allows remote attackers to inject arbitrary web script\n  or HTML via an e-mail message with an encoded javascript URI (e.g. \"j&#X41vascript\"\n  in an IMG tag).\n\n\n  CVE-2005-0692: Encoded script within BBcode IMG tag.\n\n\n  CVE-2002-0117: Encoded \"javascript\" in IMG tag.\n\n\n  CVE-2002-0118: Encoded \"javascript\" in IMG tag.'\n",
  "ID: '841'\nName: Improper Enforcement of Behavioral Workflow\nDescription: The product supports a session in which more than one behavior must be\n  performed by an actor, but it does not properly ensure that the actor performs the\n  behaviors in the required sequence.\nExtended_Description: 'By performing actions in an unexpected order, or by omitting\n  steps, an attacker could manipulate the business logic of the product or cause it\n  to enter an invalid state. In some cases, this can also expose resultant weaknesses.\n\n  For example, a file-sharing protocol might require that an actor perform separate\n  steps to provide a username, then a password, before being able to transfer files.\n  If the file-sharing server accepts a password command followed by a transfer command,\n  without any username being provided, the product might still perform the transfer.\n\n  Note that this is different than CWE-696, which focuses on when the product performs\n  actions in the wrong sequence; this entry is closely related, but it is focused\n  on ensuring that the actor performs actions in the correct sequence.\n\n  Workflow-related behaviors include:'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nObserved_Examples: 'CVE-2011-0348: Bypass of access/billing restrictions by sending\n  traffic to an unrestricted destination before sending to a restricted destination.\n\n\n  CVE-2007-3012: Attacker can access portions of a restricted page by canceling out\n  of a dialog.\n\n\n  CVE-2009-5056: Ticket-tracking system does not enforce a permission setting.\n\n\n  CVE-2004-2164: Shopping cart does not close a database connection when user restores\n  a previous order, leading to connection exhaustion.\n\n\n  CVE-2003-0777: Chain: product does not properly handle dropped connections, leading\n  to missing NULL terminator (CWE-170) and segmentation fault.\n\n\n  CVE-2005-3327: Chain: Authentication bypass by skipping the first startup step as\n  required by the protocol.\n\n\n  CVE-2004-0829: Chain: File server crashes when sent a \"find next\" request without\n  an initial \"find first.\"\n\n\n  CVE-2010-2620: FTP server allows remote attackers to bypass authentication by sending\n  (1) LIST, (2) RETR, (3) STOR, or other commands without performing the required\n  login steps first.\n\n\n  CVE-2005-3296: FTP server allows remote attackers to list arbitrary directories\n  as root by running the LIST command before logging in.'\n",
  "ID: '842'\nName: Placement of User into Incorrect Group\nDescription: The product or the administrator places a user into an incorrect group.\nExtended_Description: If the incorrect group has more access or privileges than the\n  intended group, the user might be able to bypass intended security policy to access\n  unexpected resources or perform unexpected actions. The access-control system might\n  not be able to detect malicious usage of this group membership.\nModes_Of_Introduction: \"Implementation: \\n\\nOperation: \"\nObserved_Examples: 'CVE-1999-1193: Operating system assigns user to privileged wheel\n  group, allowing the user to gain root privileges.\n\n\n  CVE-2010-3716: Chain: drafted web request allows the creation of users with arbitrary\n  group membership.\n\n\n  CVE-2008-5397: Chain: improper processing of configuration options causes users\n  to contain unintended group memberships.\n\n\n  CVE-2007-6644: CMS does not prevent remote administrators from promoting other users\n  to the administrator group, in violation of the intended security model.\n\n\n  CVE-2007-3260: Product assigns members to the root group, allowing escalation of\n  privileges.\n\n\n  CVE-2002-0080: Chain: daemon does not properly clear groups before dropping privileges.'\n",
  "ID: '843'\nName: Access of Resource Using Incompatible Type ('Type Confusion')\nDescription: The product allocates or initializes a resource such as a pointer, object,\n  or variable using one type, but it later accesses that resource using a type that\n  is incompatible with the original type.\nExtended_Description: 'When the product accesses the resource using an incompatible\n  type, this could trigger logical errors because the resource does not have expected\n  properties. In languages without memory safety, such as C and C++, type confusion\n  can lead to out-of-bounds memory access.\n\n  While this weakness is frequently associated with unions when parsing data with\n  many different embedded object types in C, it can be present in any application\n  that can interpret the same variable or memory location in multiple ways.\n\n  This weakness is not unique to C and C++. For example, errors in PHP applications\n  can be triggered by providing array parameters when scalars are expected, or vice\n  versa. Languages such as Perl, which perform automatic conversion of a variable\n  of one type when it is accessed as if it were another type, can also contain these\n  issues.'\nApplicable_Platforms:\n  Language: C, C++\nObserved_Examples: 'CVE-2010-4577: Type confusion in CSS sequence leads to out-of-bounds\n  read.\n\n\n  CVE-2011-0611: Size inconsistency allows code execution, first discovered when it\n  was actively exploited in-the-wild.\n\n\n  CVE-2010-0258: Improperly-parsed file containing records of different types leads\n  to code execution when a memory location is interpreted as a different object than\n  intended.'\n",
  "ID: '85'\nName: Doubled Character XSS Manipulations\nDescription: The web application does not filter user-controlled input for executable\n  script disguised using doubling of the involved characters.\nPotential_Mitigations: 'Implementation: Resolve all filtered input to absolute or\n  canonical representations before processing.\n\n\n  Implementation: Carefully check each input parameter against a rigorous positive\n  specification (allowlist) defining the specific characters and format allowed. All\n  input should be neutralized, not just parameters that the user is supposed to specify,\n  but all data in the request, including tag attributes, hidden fields, cookies, headers,\n  the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities\n  is to validate only fields that are expected to be redisplayed by the site. We often\n  encounter data from the request that is reflected by the application server or the\n  application that the development team did not anticipate. Also, a field that is\n  not currently reflected may be used by a future developer. Therefore, validating\n  ALL parts of the HTTP request is recommended.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2002-2086: XSS using \"<script\".\n\n\n  CVE-2000-0116: Encoded \"javascript\" in IMG tag.\n\n\n  CVE-2001-1157: Extra \"<\" in front of SCRIPT tag.'\nRelated_Attack_Patterns: '245: '\n",
  "ID: '86'\nName: Improper Neutralization of Invalid Characters in Identifiers in Web Pages\nDescription: The product does not neutralize or incorrectly neutralizes invalid characters\n  or byte sequences in the middle of tag names, URI schemes, and other identifiers.\nExtended_Description: Some web browsers may remove these sequences, resulting in output\n  that may have unintended control implications. For example, the product may attempt\n  to remove a \"javascript:\" URI scheme, but a \"java%00script:\" URI may bypass this\n  check and still be rendered as active javascript by some browsers, allowing XSS\n  or other attacks.\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Use and specify an output encoding that can\n  be handled by the downstream component that is reading the output. Common encodings\n  include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream\n  component may choose a different encoding, either by assuming a default encoding\n  or automatically inferring which encoding is being used, which can be erroneous.\n  When the encodings are inconsistent, the downstream component might treat some character\n  or byte sequences as special, even if they are not special in the original encoding.\n  Attackers might then be able to exploit this discrepancy and conduct injection attacks;\n  they even might be able to bypass protection mechanisms that assume the original\n  encoding is also being used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2004-0595: XSS filter doesn''t filter null characters before\n  looking for dangerous tags, which are ignored by web browsers. Multiple Interpretation\n  Error (MIE) and validate-before-cleanse.'\nRelated_Attack_Patterns: \"247: \\n\\n73: \\n\\n85: \"\n",
  "ID: '862'\nName: Missing Authorization\nDescription: The product does not perform an authorization check when an actor attempts\n  to access a resource or perform an action.\nExtended_Description: 'Assuming a user with a given identity, authorization is the\n  process of determining whether that user can access a given resource, based on the\n  user''s privileges and any permissions or other access-control specifications that\n  apply to the resource.\n\n  When access control checks are not applied, users are able to access data or perform\n  actions that they should not be allowed to perform. This can lead to a wide range\n  of problems, including information exposures, denial of service, and arbitrary code\n  execution.'\nApplicable_Platforms:\n  Technology: Web Server, Database Server\nAlternate_Terms: 'AuthZ: \"AuthZ\" is typically used as an abbreviation of \"authorization\"\n  within the web application security community. It is distinct from \"AuthN\" (or,\n  sometimes, \"AuthC\") which is an abbreviation of \"authentication.\" The use of \"Auth\"\n  as an abbreviation is discouraged, since it could be used for either authentication\n  or authorization.'\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.\n\n  Authorization weaknesses may arise when a single-user application is ported to a\n  multi-user environment.\n\n\n  Implementation: A developer may introduce authorization weaknesses because of a\n  lack of understanding about the underlying technologies. For example, a developer\n  may assume that attackers cannot modify certain inputs such as headers or cookies.\n\n\n  Operation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis is useful\n  for detecting commonly-used idioms for authorization. A tool may be able to analyze\n  related configuration files, such as .htaccess in Apache web servers, or detect\n  the usage of commonly-used authorization libraries.\n\n  Generally, automated static analysis tools have difficulty detecting custom authorization\n  schemes. In addition, the software''s design may include some functionality that\n  is accessible to any user and does not require an authorization check; an automated\n  technique that detects the absence of authorization may report false positives.\n\n\n  Automated Dynamic Analysis: Automated dynamic analysis may find many or all possible\n  interfaces that do not require authorization, but manual analysis is required to\n  determine if the lack of authorization violates business logic.\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  custom authorization mechanisms.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules. However,\n  manual efforts might not achieve desired code coverage within limited time constraints.\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Divide the product into anonymous,\n  normal, privileged, and administrative areas. Reduce the attack surface by carefully\n  mapping roles with data and functionality. Use role-based access control (RBAC)\n  [REF-229] to enforce the roles at the appropriate boundaries.\n\n  Note that this approach may not protect against horizontal authorization, i.e.,\n  it will not protect a user from attacking others with the same role.\n\n\n  Architecture and Design: Ensure that access control checks are performed related\n  to the business logic. These checks may be different than the access control checks\n  that are applied to more generic resources such as files, connections, processes,\n  memory, and database records. For example, a database may restrict access for medical\n  records to a specific database user, but each record might only be intended to be\n  accessible to the patient and the patient''s doctor [REF-7].\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, consider using authorization frameworks such as the JAAS Authorization\n  Framework [REF-233] and the OWASP ESAPI Access Control feature [REF-45].\n\n\n  Architecture and Design: For web applications, make sure that the access control\n  mechanism is enforced correctly at the server side on every page. Users should not\n  be able to access any unauthorized functionality or information by simply requesting\n  direct access to that page.\n\n  One way to do this is to ensure that all pages containing sensitive information\n  are not cached, and that all such pages restrict access to requests that are accompanied\n  by an active and authenticated session token associated with a user who has the\n  required permissions to access that page.\n\n\n  System Configuration, Installation: Use the access control capabilities of your\n  operating system and server environment and define your access control lists accordingly.\n  Use a \"default deny\" policy when defining these ACLs.'\nObserved_Examples: 'CVE-2022-24730: Go-based continuous deployment product does not\n  check that a user has certain privileges to update or create an app, allowing adversaries\n  to read sensitive repository information\n\n\n  CVE-2009-3168: Web application does not restrict access to admin scripts, allowing\n  authenticated users to reset administrative passwords.\n\n\n  CVE-2009-3597: Web application stores database file under the web root with insufficient\n  access control (CWE-219), allowing direct request.\n\n\n  CVE-2009-2282: Terminal server does not check authorization for guest access.\n\n\n  CVE-2008-5027: System monitoring software allows users to bypass authorization by\n  creating custom forms.\n\n\n  CVE-2009-3781: Content management system does not check access permissions for private\n  files, allowing others to view those files.\n\n\n  CVE-2008-6548: Product does not check the ACL of a page accessed using an \"include\"\n  directive, allowing attackers to read unauthorized files.\n\n\n  CVE-2009-2960: Web application does not restrict access to admin scripts, allowing\n  authenticated users to modify passwords of other users.\n\n\n  CVE-2009-3230: Database server does not use appropriate privileges for certain sensitive\n  operations.\n\n\n  CVE-2009-2213: Gateway uses default \"Allow\" configuration for its authorization\n  settings.\n\n\n  CVE-2009-0034: Chain: product does not properly interpret a configuration option\n  for a system group, allowing users to gain privileges.\n\n\n  CVE-2008-6123: Chain: SNMP product does not properly parse a configuration option\n  for which hosts are allowed to connect, allowing unauthorized IP addresses to connect.\n\n\n  CVE-2008-7109: Chain: reliance on client-side security (CWE-602) allows attackers\n  to bypass authorization using a custom client.\n\n\n  CVE-2008-3424: Chain: product does not properly handle wildcards in an authorization\n  policy list, allowing unintended access.\n\n\n  CVE-2005-1036: Chain: Bypass of access restrictions due to improper authorization\n  (CWE-862) of a user results from an improperly initialized (CWE-909) I/O permission\n  bitmap\n\n\n  CVE-2008-4577: ACL-based protection mechanism treats negative access rights as if\n  they are positive, allowing bypass of intended restrictions.\n\n\n  CVE-2007-2925: Default ACL list for a DNS server does not set certain ACLs, allowing\n  unauthorized DNS queries.\n\n\n  CVE-2006-6679: Product relies on the X-Forwarded-For HTTP header for authorization,\n  allowing unintended access by spoofing the header.\n\n\n  CVE-2005-3623: OS kernel does not check for a certain privilege before setting ACLs\n  for files.\n\n\n  CVE-2005-2801: Chain: file-system code performs an incorrect comparison (CWE-697),\n  preventing default ACLs from being properly applied.\n\n\n  CVE-2001-1155: Chain: product does not properly check the result of a reverse DNS\n  lookup because of operator precedence (CWE-783), allowing bypass of DNS-based access\n  restrictions.\n\n\n  CVE-2020-17533: Chain: unchecked return value (CWE-252) of some functions for policy\n  enforcement leads to authorization bypass (CWE-862)'\nRelated_Attack_Patterns: '665: '\n",
  "ID: '863'\nName: Incorrect Authorization\nDescription: The product performs an authorization check when an actor attempts to\n  access a resource or perform an action, but it does not correctly perform the check.\n  This allows attackers to bypass intended access restrictions.\nExtended_Description: 'Assuming a user with a given identity, authorization is the\n  process of determining whether that user can access a given resource, based on the\n  user''s privileges and any permissions or other access-control specifications that\n  apply to the resource.\n\n  When access control checks are incorrectly applied, users are able to access data\n  or perform actions that they should not be allowed to perform. This can lead to\n  a wide range of problems, including information exposures, denial of service, and\n  arbitrary code execution.'\nApplicable_Platforms:\n  Technology: Web Server, Database Server\nAlternate_Terms: 'AuthZ: \"AuthZ\" is typically used as an abbreviation of \"authorization\"\n  within the web application security community. It is distinct from \"AuthN\" (or,\n  sometimes, \"AuthC\") which is an abbreviation of \"authentication.\" The use of \"Auth\"\n  as an abbreviation is discouraged, since it could be used for either authentication\n  or authorization.'\nModes_Of_Introduction: 'Architecture and Design: Authorization weaknesses may arise\n  when a single-user application is ported to a multi-user environment.\n\n\n  Implementation: REALIZATION: This weakness is caused during implementation of an\n  architectural security tactic.\n\n  A developer may introduce authorization weaknesses because of a lack of understanding\n  about the underlying technologies. For example, a developer may assume that attackers\n  cannot modify certain inputs such as headers or cookies.\n\n\n  Operation: '\nDetection_Methods: 'Automated Static Analysis: Automated static analysis is useful\n  for detecting commonly-used idioms for authorization. A tool may be able to analyze\n  related configuration files, such as .htaccess in Apache web servers, or detect\n  the usage of commonly-used authorization libraries.\n\n  Generally, automated static analysis tools have difficulty detecting custom authorization\n  schemes. Even if they can be customized to recognize these schemes, they might not\n  be able to tell whether the scheme correctly performs the authorization in a way\n  that cannot be bypassed or subverted by an attacker.\n\n\n  Automated Dynamic Analysis: Automated dynamic analysis may not be able to find interfaces\n  that are protected by authorization checks, even if those checks contain weaknesses.\n\n\n  Manual Analysis: This weakness can be detected using tools and techniques that require\n  manual (human) analysis, such as penetration testing, threat modeling, and interactive\n  tools that allow the tester to record and modify an active session.\n\n  Specifically, manual static analysis is useful for evaluating the correctness of\n  custom authorization mechanisms.\n\n  These may be more effective than strictly automated techniques. This is especially\n  the case with weaknesses that are related to design and business rules. However,\n  manual efforts might not achieve desired code coverage within limited time constraints.\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Divide the product into anonymous,\n  normal, privileged, and administrative areas. Reduce the attack surface by carefully\n  mapping roles with data and functionality. Use role-based access control (RBAC)\n  [REF-229] to enforce the roles at the appropriate boundaries.\n\n  Note that this approach may not protect against horizontal authorization, i.e.,\n  it will not protect a user from attacking others with the same role.\n\n\n  Architecture and Design: Ensure that access control checks are performed related\n  to the business logic. These checks may be different than the access control checks\n  that are applied to more generic resources such as files, connections, processes,\n  memory, and database records. For example, a database may restrict access for medical\n  records to a specific database user, but each record might only be intended to be\n  accessible to the patient and the patient''s doctor [REF-7].\n\n\n  Architecture and Design: Use a vetted library or framework that does not allow this\n  weakness to occur or provides constructs that make this weakness easier to avoid.\n\n  For example, consider using authorization frameworks such as the JAAS Authorization\n  Framework [REF-233] and the OWASP ESAPI Access Control feature [REF-45].\n\n\n  Architecture and Design: For web applications, make sure that the access control\n  mechanism is enforced correctly at the server side on every page. Users should not\n  be able to access any unauthorized functionality or information by simply requesting\n  direct access to that page.\n\n  One way to do this is to ensure that all pages containing sensitive information\n  are not cached, and that all such pages restrict access to requests that are accompanied\n  by an active and authenticated session token associated with a user who has the\n  required permissions to access that page.\n\n\n  System Configuration, Installation: Use the access control capabilities of your\n  operating system and server environment and define your access control lists accordingly.\n  Use a \"default deny\" policy when defining these ACLs.'\nObserved_Examples: 'CVE-2021-39155: Chain: A microservice integration and management\n  platform compares the hostname in the HTTP Host header in a case-sensitive way (CWE-178,\n  CWE-1289), allowing bypass of the authorization policy (CWE-863) using a hostname\n  with mixed case or other variations.\n\n\n  CVE-2019-15900: Chain: sscanf() call is used to check if a username and group exists,\n  but the return value of sscanf() call is not checked (CWE-252), causing an uninitialized\n  variable to be checked (CWE-457), returning success to allow authorization bypass\n  for executing a privileged (CWE-863).\n\n\n  CVE-2009-2213: Gateway uses default \"Allow\" configuration for its authorization\n  settings.\n\n\n  CVE-2009-0034: Chain: product does not properly interpret a configuration option\n  for a system group, allowing users to gain privileges.\n\n\n  CVE-2008-6123: Chain: SNMP product does not properly parse a configuration option\n  for which hosts are allowed to connect, allowing unauthorized IP addresses to connect.\n\n\n  CVE-2008-7109: Chain: reliance on client-side security (CWE-602) allows attackers\n  to bypass authorization using a custom client.\n\n\n  CVE-2008-3424: Chain: product does not properly handle wildcards in an authorization\n  policy list, allowing unintended access.\n\n\n  CVE-2008-4577: ACL-based protection mechanism treats negative access rights as if\n  they are positive, allowing bypass of intended restrictions.\n\n\n  CVE-2006-6679: Product relies on the X-Forwarded-For HTTP header for authorization,\n  allowing unintended access by spoofing the header.\n\n\n  CVE-2005-2801: Chain: file-system code performs an incorrect comparison (CWE-697),\n  preventing default ACLs from being properly applied.\n\n\n  CVE-2001-1155: Chain: product does not properly check the result of a reverse DNS\n  lookup because of operator precedence (CWE-783), allowing bypass of DNS-based access\n  restrictions.'\n",
  "ID: '87'\nName: Improper Neutralization of Alternate XSS Syntax\nDescription: The product does not neutralize or incorrectly neutralizes user-controlled\n  input for alternate script syntax.\nPotential_Mitigations: 'Implementation: Resolve all input to absolute or canonical\n  representations before processing.\n\n\n  Implementation: Carefully check each input parameter against a rigorous positive\n  specification (allowlist) defining the specific characters and format allowed. All\n  input should be neutralized, not just parameters that the user is supposed to specify,\n  but all data in the request, including tag attributes, hidden fields, cookies, headers,\n  the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities\n  is to validate only fields that are expected to be redisplayed by the site. We often\n  encounter data from the request that is reflected by the application server or the\n  application that the development team did not anticipate. Also, a field that is\n  not currently reflected may be used by a future developer. Therefore, validating\n  ALL parts of the HTTP request is recommended.\n\n\n  Implementation: Use and specify an output encoding that can be handled by the downstream\n  component that is reading the output. Common encodings include ISO-8859-1, UTF-7,\n  and UTF-8. When an encoding is not specified, a downstream component may choose\n  a different encoding, either by assuming a default encoding or automatically inferring\n  which encoding is being used, which can be erroneous. When the encodings are inconsistent,\n  the downstream component might treat some character or byte sequences as special,\n  even if they are not special in the original encoding. Attackers might then be able\n  to exploit this discrepancy and conduct injection attacks; they even might be able\n  to bypass protection mechanisms that assume the original encoding is also being\n  used by the downstream component.\n\n  The problem of inconsistent output encodings often arises in web pages. If an encoding\n  is not specified in an HTTP header, web browsers often guess about which encoding\n  is being used. This can open up the browser to subtle XSS attacks.\n\n\n  Implementation: With Struts, write all data from form beans with the bean''s filter\n  attribute set to true.\n\n\n  Implementation: To help mitigate XSS attacks against the user''s session cookie,\n  set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature\n  (such as more recent versions of Internet Explorer and Firefox), this attribute\n  can prevent the user''s session cookie from being accessible to malicious client-side\n  scripts that use document.cookie. This is not a complete solution, since HttpOnly\n  is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful\n  browser technologies provide read access to HTTP headers, including the Set-Cookie\n  header in which the HttpOnly flag is set.'\nObserved_Examples: 'CVE-2002-0738: XSS using \"&={script}\".'\nRelated_Attack_Patterns: '199: '\n",
  "ID: '88'\nName: Improper Neutralization of Argument Delimiters in a Command ('Argument Injection')\nDescription: 'The product constructs a string for a command to be executed by a separate\n  component\n\n  in another control sphere, but it does not properly delimit the\n\n  intended arguments, options, or switches within that command string.'\nExtended_Description: When creating commands using interpolation into a string, developers\n  may assume that only the arguments/options that they specify will be processed.  This\n  assumption may be even stronger when the programmer has encoded the command in a\n  way that prevents separate commands from being provided maliciously, e.g. in the\n  case of shell metacharacters.  When constructing the command, the developer may\n  use whitespace or other delimiters that are required to separate arguments when\n  the command. However, if an attacker can provide an untrusted input that contains\n  argument-separating delimiters, then the resulting command will have more arguments\n  than intended by the developer.  The attacker may then be able to change the behavior\n  of the command.  Depending on the functionality supported by the extraneous arguments,\n  this may have security-relevant consequences.\nApplicable_Platforms:\n  Language: PHP\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Where possible, avoid building a single string\n  that contains the command and its arguments.  Some languages or frameworks have\n  functions that support specifying independent arguments, e.g. as an array, which\n  is used to automatically perform the appropriate quoting or escaping while building\n  the command.  For example, in PHP, escapeshellarg() can be used to escape a single\n  argument to system(), or exec() can be called with an array of arguments.  In C,\n  code can often be refactored from using system() - which accepts a single string\n  - to using exec(), which requires separate function arguments for each parameter.\n\n\n  Architecture and Design: Understand all the potential areas where untrusted inputs\n  can enter your product: parameters or arguments, cookies, anything read from the\n  network, environment variables, request headers as well as content, URL components,\n  e-mail, files, databases, and any external systems that provide data to the application.\n  Perform input validation at well-defined interfaces.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Directly convert your input type into the expected data type, such\n  as using a conversion function that translates a string into a number. After converting\n  to the expected data type, ensure that the input''s values fall within the expected\n  range of allowable values and that multi-field consistencies are maintained.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180, CWE-181). Make\n  sure that your application does not inadvertently decode the same input twice (CWE-174).\n  Such errors could be used to bypass allowlist schemes by introducing dangerous inputs\n  after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization\n  control.\n\n  Consider performing repeated canonicalization until your input does not change any\n  more. This will avoid double-decoding and similar scenarios, but it might inadvertently\n  modify inputs that are allowed to contain properly-encoded dangerous content.\n\n\n  Implementation: When exchanging data between components, ensure that both components\n  are using the same character encoding. Ensure that the proper encoding is applied\n  at each interface. Explicitly set the encoding you are using whenever the protocol\n  allows you to do so.\n\n\n  Implementation: When your application combines data from multiple sources, perform\n  the validation after the sources have been combined. The individual data elements\n  may pass the validation step but violate the intended restrictions after they have\n  been combined.\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Testing: Use dynamic tools and techniques that interact with the product using large\n  test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness\n  testing, and fault injection. The product''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.'\nObserved_Examples: 'CVE-2022-36069: Python-based dependency management tool avoids\n  OS command injection  when generating Git commands but allows  injection of optional\n  arguments with input beginning with a dash, potentially allowing for code execution.\n\n\n  CVE-1999-0113: Canonical Example - \"-froot\" argument is passed on to another program,\n  where the \"-f\" causes execution as user \"root\"\n\n\n  CVE-2001-0150: Web browser executes Telnet sessions using command line arguments\n  that are specified by the web site, which could allow remote attackers to execute\n  arbitrary commands.\n\n\n  CVE-2001-0667: Web browser allows remote attackers to execute commands by spawning\n  Telnet with a log file option on the command line and writing arbitrary code into\n  an executable file which is later executed.\n\n\n  CVE-2002-0985: Argument injection vulnerability in the mail function for PHP may\n  allow attackers to bypass safe mode restrictions and modify command line arguments\n  to the MTA (e.g. sendmail) possibly executing commands.\n\n\n  CVE-2003-0907: Help and Support center in windows does not properly validate HCP\n  URLs, which allows remote attackers to execute arbitrary code via quotation marks\n  in an \"hcp://\" URL.\n\n\n  CVE-2004-0121: Mail client does not sufficiently filter parameters of mailto: URLs\n  when using them as arguments to mail executable, which allows remote attackers to\n  execute arbitrary programs.\n\n\n  CVE-2004-0473: Web browser doesn''t filter \"-\" when invoking various commands, allowing\n  command-line switches to be specified.\n\n\n  CVE-2004-0480: Mail client allows remote attackers to execute arbitrary code via\n  a URI that uses a UNC network share pathname to provide an alternate configuration\n  file.\n\n\n  CVE-2004-0489: SSH URI handler for web browser allows remote attackers to execute\n  arbitrary code or conduct port forwarding via the a command line option.\n\n\n  CVE-2004-0411: Web browser doesn''t filter \"-\" when invoking various commands, allowing\n  command-line switches to be specified.\n\n\n  CVE-2005-4699: Argument injection vulnerability in TellMe 1.2 and earlier allows\n  remote attackers to modify command line arguments for the Whois program and obtain\n  sensitive information via \"--\" style options in the q_Host parameter.\n\n\n  CVE-2006-1865: Beagle before 0.2.5 can produce certain insecure command lines to\n  launch external helper applications while indexing, which allows attackers to execute\n  arbitrary commands. NOTE: it is not immediately clear whether this issue involves\n  argument injection, shell metacharacters, or other issues.\n\n\n  CVE-2006-2056: Argument injection vulnerability in Internet Explorer 6 for Windows\n  XP SP2 allows user-assisted remote attackers to modify command line arguments to\n  an invoked mail client via \" (double quote) characters in a mailto: scheme handler,\n  as demonstrated by launching Microsoft Outlook with an arbitrary filename as an\n  attachment. NOTE: it is not clear whether this issue is implementation-specific\n  or a problem in the Microsoft API.\n\n\n  CVE-2006-2057: Argument injection vulnerability in Mozilla Firefox 1.0.6 allows\n  user-assisted remote attackers to modify command line arguments to an invoked mail\n  client via \" (double quote) characters in a mailto: scheme handler, as demonstrated\n  by launching Microsoft Outlook with an arbitrary filename as an attachment. NOTE:\n  it is not clear whether this issue is implementation-specific or a problem in the\n  Microsoft API.\n\n\n  CVE-2006-2058: Argument injection vulnerability in Avant Browser 10.1 Build 17 allows\n  user-assisted remote attackers to modify command line arguments to an invoked mail\n  client via \" (double quote) characters in a mailto: scheme handler, as demonstrated\n  by launching Microsoft Outlook with an arbitrary filename as an attachment. NOTE:\n  it is not clear whether this issue is implementation-specific or a problem in the\n  Microsoft API.\n\n\n  CVE-2006-2312: Argument injection vulnerability in the URI handler in Skype 2.0.*.104\n  and 2.5.*.0 through 2.5.*.78 for Windows allows remote authorized attackers to download\n  arbitrary files via a URL that contains certain command-line switches.\n\n\n  CVE-2006-3015: Argument injection vulnerability in WinSCP 3.8.1 build 328 allows\n  remote attackers to upload or download arbitrary files via encoded spaces and double-quote\n  characters in a scp or sftp URI.\n\n\n  CVE-2006-4692: Argument injection vulnerability in the Windows Object Packager (packager.exe)\n  in Microsoft Windows XP SP1 and SP2 and Server 2003 SP1 and earlier allows remote\n  user-assisted attackers to execute arbitrary commands via a crafted file with a\n  \"/\" (slash) character in the filename of the Command Line property, followed by\n  a valid file extension, which causes the command before the slash to be executed,\n  aka \"Object Packager Dialogue Spoofing Vulnerability.\"\n\n\n  CVE-2006-6597: Argument injection vulnerability in HyperAccess 8.4 allows user-assisted\n  remote attackers to execute arbitrary vbscript and commands via the /r option in\n  a telnet:// URI, which is configured to use hawin32.exe.\n\n\n  CVE-2007-0882: Argument injection vulnerability in the telnet daemon (in.telnetd)\n  in Solaris 10 and 11 (SunOS 5.10 and 5.11) misinterprets certain client \"-f\" sequences\n  as valid requests for the login program to skip authentication, which allows remote\n  attackers to log into certain accounts, as demonstrated by the bin account.\n\n\n  CVE-2001-1246: Language interpreter''s mail function accepts another argument that\n  is concatenated to a string used in a dangerous popen() call. Since there is no\n  neutralization of this argument, both OS Command Injection (CWE-78) and Argument\n  Injection (CWE-88) are possible.\n\n\n  CVE-2019-13475: Argument injection allows execution of arbitrary commands by injecting\n  a \"-exec\" option, which is executed by the command.\n\n\n  CVE-2016-10033: Argument injection in mail-processing function allows writing unxpected\n  files and executing programs using tecnically-valid email addresses that insert\n  \"-o\" and \"-X\" switches.'\nRelated_Attack_Patterns: \"137: \\n\\n174: \\n\\n41: \\n\\n460: \\n\\n88: \"\n",
  "ID: '89'\nName: Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection')\nDescription: The product constructs all or part of an SQL command using externally-influenced\n  input from an upstream component, but it does not neutralize or incorrectly neutralizes\n  special elements that could modify the intended SQL command when it is sent to a\n  downstream component.\nExtended_Description: 'Without sufficient removal or quoting of SQL syntax in user-controllable\n  inputs, the generated SQL query can cause those inputs to be interpreted as SQL\n  instead of ordinary user data. This can be used to alter query logic to bypass security\n  checks, or to insert additional statements that modify the back-end database, possibly\n  including execution of system commands.\n\n  SQL injection has become a common issue with database-driven web sites. The flaw\n  is easily detected, and easily exploited, and as such, any site or product package\n  with even a minimal user base is likely to be subject to an attempted attack of\n  this kind. This flaw depends on the fact that SQL makes no real distinction between\n  the control and data planes.'\nApplicable_Platforms:\n  Technology: Database Server\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Implementation: This weakness typically appears in data-rich applications that save\n  user inputs in a database.'\nDetection_Methods: 'Automated Static Analysis: This weakness can often be detected\n  using automated static analysis tools. Many modern tools use data flow analysis\n  or constraint-based techniques to minimize the number of false positives.\n\n  Automated static analysis might not be able to recognize when proper input validation\n  is being performed, leading to false positives - i.e., warnings that do not have\n  any security consequences or do not require any code changes.\n\n  Automated static analysis might not be able to detect the usage of custom API functions\n  or third-party libraries that indirectly invoke SQL commands, leading to false negatives\n  - especially if the API/library code is not available for analysis.\n\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Automated Dynamic Analysis: This weakness can be detected using dynamic tools and\n  techniques that interact with the software using large test suites with many diverse\n  inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection.\n  The software''s operation may slow down, but it should not become unstable, crash,\n  or generate incorrect results.\n\n\n  Manual Analysis: Manual analysis can be useful for finding this weakness, but it\n  might not achieve desired code coverage within limited time constraints. This becomes\n  difficult for weaknesses that must be considered for all inputs, since the attack\n  surface can be too large.\n\n\n  Automated Static Analysis - Binary or Bytecode: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Automated Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Dynamic Analysis with Manual Results Interpretation: According to SOAR, the following\n  detection techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use a vetted library or framework\n  that does not allow this weakness to occur or provides constructs that make this\n  weakness easier to avoid.\n\n  For example, consider using persistence layers such as Hibernate or Enterprise Java\n  Beans, which can provide significant protection against SQL injection if used properly.\n\n\n  Architecture and Design: If available, use structured mechanisms that automatically\n  enforce the separation between data and code. These mechanisms may be able to provide\n  the relevant quoting, encoding, and validation automatically, instead of relying\n  on the developer to provide this capability at every point where output is generated.\n\n  Process SQL queries using prepared statements, parameterized queries, or stored\n  procedures. These features should accept parameters or variables and support strong\n  typing. Do not dynamically construct and execute query strings within these features\n  using \"exec\" or similar functionality, since this may re-introduce the possibility\n  of SQL injection. [REF-867]\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n  Specifically, follow the principle of least privilege when creating user accounts\n  to a SQL database. The database users should only have the minimum privileges necessary\n  to use their account. If the requirements of the system indicate that a user can\n  read and modify their own data, then limit their privileges so they cannot read/write\n  others'' data. Use the strictest permissions possible on all database objects, such\n  as execute-only for stored procedures.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Implementation: While it is risky to use dynamically-generated query strings, code,\n  or commands that mix control and data together, sometimes it may be unavoidable.\n  Properly quote arguments and escape any special characters within those arguments.\n  The most conservative approach is to escape or filter all characters that do not\n  pass an extremely strict allowlist (such as everything that is not alphanumeric\n  or white space). If some special characters are still needed, such as white space,\n  wrap each argument in quotes after the escaping/filtering step. Be careful of argument\n  injection (CWE-88).\n\n  Instead of building a new implementation, such features may be available in the\n  database or programming language. For example, the Oracle DBMS_ASSERT package can\n  check or enforce that parameters have certain properties that make them less vulnerable\n  to SQL injection. For MySQL, the mysql_real_escape_string() API function is available\n  in both C and PHP.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When constructing SQL query strings, use stringent allowlists that limit the character\n  set based on the expected value of the parameter in the request. This will indirectly\n  limit the scope of an attack, but this technique is less important than proper output\n  encoding and escaping.\n\n  Note that proper output encoding, escaping, and quoting is the most effective solution\n  for preventing SQL injection, although input validation may provide some defense-in-depth.\n  This is because it effectively limits what will appear in output. Input validation\n  will not always prevent SQL injection, especially if you are required to support\n  free-form text fields that could contain arbitrary characters. For example, the\n  name \"O''Reilly\" would likely pass the validation step, since it is a common last\n  name in the English language. However, it cannot be directly inserted into the database\n  because it contains the \"''\" apostrophe character, which would need to be escaped\n  or otherwise handled. In this case, stripping the apostrophe might reduce the risk\n  of SQL injection, but it would produce incorrect behavior because the wrong name\n  would be recorded.\n\n  When feasible, it may be safest to disallow meta-characters entirely, instead of\n  escaping them. This will provide some defense in depth. After the data is entered\n  into the database, later processes may neglect to escape meta-characters before\n  use, and you may not have control over those processes.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\n  Implementation: Ensure that error messages only contain minimal details that are\n  useful to the intended audience and no one else. The messages need to strike the\n  balance between being too cryptic (which can confuse users) or being too detailed\n  (which may reveal more than intended). The messages should not reveal the methods\n  that were used to determine the error. Attackers can use detailed information to\n  refine or optimize their original attack, thereby increasing their chances of success.\n\n  If errors must be captured in some detail, record them in log messages, but consider\n  what could occur if the log messages can be viewed by attackers. Highly sensitive\n  information such as passwords should never be saved to log files.\n\n  Avoid inconsistent messaging that might accidentally tip off an attacker about internal\n  state, such as whether a user account exists or not.\n\n  In the context of SQL Injection, error messages revealing the structure of a SQL\n  query can help attackers tailor successful attack strings.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.'\nObserved_Examples: 'CVE-2021-42258: SQL injection in time and billing software, as\n  exploited in the wild per CISA KEV.\n\n\n  CVE-2021-27101: SQL injection in file-transfer system via a crafted Host header,\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2020-12271: SQL injection in firewall product''s admin interface or user portal,\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2019-3792: An automation system written in Go contains an API that is vulnerable\n  to SQL injection allowing the attacker to read privileged data.\n\n\n  CVE-2004-0366: chain: SQL injection in library intended for database authentication\n  allows SQL injection and authentication bypass.\n\n\n  CVE-2008-2790: SQL injection through an ID that was supposed to be numeric.\n\n\n  CVE-2008-2223: SQL injection through an ID that was supposed to be numeric.\n\n\n  CVE-2007-6602: SQL injection via user name.\n\n\n  CVE-2008-5817: SQL injection via user name or password fields.\n\n\n  CVE-2003-0377: SQL injection in security product, using a crafted group name.\n\n\n  CVE-2008-2380: SQL injection in authentication library.\n\n\n  CVE-2017-11508: SQL injection in vulnerability management and reporting tool, using\n  a crafted password.'\nRelated_Attack_Patterns: \"108: \\n\\n109: \\n\\n110: \\n\\n470: \\n\\n66: \\n\\n7: \"\n",
  "ID: '9'\nName: 'J2EE Misconfiguration: Weak Access Permissions for EJB Methods'\nDescription: If elevated access rights are assigned to EJB methods, then an attacker\n  can take advantage of the permissions to exploit the product.\nExtended_Description: If the EJB deployment descriptor contains one or more method\n  permissions that grant access to the special ANYONE role, it indicates that access\n  control for the application has not been fully thought through or that the application\n  is structured in such a way that reasonable access control restrictions are impossible.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Architecture and Design\n\n  System Configuration: Follow the principle of least privilege when assigning access\n  rights to EJB methods. Permission to invoke EJB methods should not be granted to\n  the ANYONE role.'\n",
  "ID: '90'\nName: Improper Neutralization of Special Elements used in an LDAP Query ('LDAP Injection')\nDescription: The product constructs all or part of an LDAP query using externally-influenced\n  input from an upstream component, but it does not neutralize or incorrectly neutralizes\n  special elements that could modify the intended LDAP query when it is sent to a\n  downstream component.\nApplicable_Platforms:\n  Technology: Database Server\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nObserved_Examples: 'CVE-2021-41232: Chain: authentication routine in Go-based agile\n  development product does not escape user name (CWE-116), allowing LDAP injection\n  (CWE-90)\n\n\n  CVE-2005-2301: Server does not properly escape LDAP queries, which allows remote\n  attackers to cause a DoS and possibly conduct an LDAP injection attack.'\nRelated_Attack_Patterns: '136: '\n",
  "ID: '908'\nName: Use of Uninitialized Resource\nDescription: The product uses or accesses a resource that has not been initialized.\nExtended_Description: When a resource has not been properly initialized, the product\n  may behave unexpectedly. This may lead to a crash or invalid memory access, but\n  the consequences vary depending on the type of resource and how it is used within\n  the product.\nPotential_Mitigations: 'Implementation: Explicitly initialize the resource before\n  use. If this is performed through an API function or standard procedure, follow\n  all required steps.\n\n\n  Implementation: Pay close attention to complex conditionals that affect initialization,\n  since some branches might not perform the initialization.\n\n\n  Implementation: Avoid race conditions (CWE-362) during initialization routines.\n\n\n  Build and Compilation: Run or compile the product with settings that generate warnings\n  about uninitialized variables or data.'\nObserved_Examples: 'CVE-2019-9805: Chain: Creation of the packet client occurs before\n  initialization is complete (CWE-696) resulting in a read from uninitialized memory\n  (CWE-908), causing memory corruption.\n\n\n  CVE-2008-4197: Use of uninitialized memory may allow code execution.\n\n\n  CVE-2008-2934: Free of an uninitialized pointer leads to crash and possible code\n  execution.\n\n\n  CVE-2008-0063: Product does not clear memory contents when generating an error message,\n  leading to information leak.\n\n\n  CVE-2008-0062: Lack of initialization triggers NULL pointer dereference or double-free.\n\n\n  CVE-2008-0081: Uninitialized variable leads to code execution in popular desktop\n  application.\n\n\n  CVE-2008-3688: Chain: Uninitialized variable leads to infinite loop.\n\n\n  CVE-2008-3475: Chain: Improper initialization leads to memory corruption.\n\n\n  CVE-2005-1036: Chain: Bypass of access restrictions due to improper authorization\n  (CWE-862) of a user results from an improperly initialized (CWE-909) I/O permission\n  bitmap\n\n\n  CVE-2008-3597: Chain: game server can access player data structures before initialization\n  has happened leading to NULL dereference\n\n\n  CVE-2009-2692: Chain: uninitialized function pointers can be dereferenced allowing\n  code execution\n\n\n  CVE-2009-0949: Chain: improper initialization of memory can lead to NULL dereference\n\n\n  CVE-2009-3620: Chain: some unprivileged ioctls do not verify that a structure has\n  been initialized before invocation, leading to NULL dereference'\n",
  "ID: '909'\nName: Missing Initialization of Resource\nDescription: The product does not initialize a critical resource.\nExtended_Description: Many resources require initialization before they can be properly\n  used. If a resource is not initialized, it could contain unpredictable or expired\n  data, or it could be initialized to defaults that are invalid. This can have security\n  implications when the resource is expected to have certain properties or values.\nPotential_Mitigations: 'Implementation: Explicitly initialize the resource before\n  use. If this is performed through an API function or standard procedure, follow\n  all specified steps.\n\n\n  Implementation: Pay close attention to complex conditionals that affect initialization,\n  since some branches might not perform the initialization.\n\n\n  Implementation: Avoid race conditions (CWE-362) during initialization routines.\n\n\n  Build and Compilation: Run or compile your product with settings that generate warnings\n  about uninitialized variables or data.'\nObserved_Examples: 'CVE-2020-20739: A variable that has its value set in a conditional\n  statement is sometimes used when the conditional fails, sometimes causing data leakage\n\n\n  CVE-2005-1036: Chain: Bypass of access restrictions due to improper authorization\n  (CWE-862) of a user results from an improperly initialized (CWE-909) I/O permission\n  bitmap'\n",
  "ID: '91'\nName: XML Injection (aka Blind XPath Injection)\nDescription: The product does not properly neutralize special elements that are used\n  in XML, allowing attackers to modify the syntax, content, or commands of the XML\n  before it is processed by an end system.\nExtended_Description: Within XML, special elements could include reserved words or\n  characters such as \"<\", \">\", \"\"\", and \"&\", which could then be used to add new data\n  or modify XML syntax.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.'\nRelated_Attack_Patterns: \"250: \\n\\n83: \"\n",
  "ID: '910'\nName: Use of Expired File Descriptor\nDescription: The product uses or accesses a file descriptor after it has been closed.\nExtended_Description: After a file descriptor for a particular file or device has\n  been released, it can be reused. The code might not write to the original file,\n  since the reused file descriptor might reference a different file or device.\nApplicable_Platforms:\n  Language: C, C++\n",
  "ID: '911'\nName: Improper Update of Reference Count\nDescription: The product uses a reference count to manage a resource, but it does\n  not update or incorrectly updates the reference count.\nExtended_Description: Reference counts can be used when tracking how many objects\n  contain a reference to a particular resource, such as in memory management or garbage\n  collection. When the reference count reaches zero, the resource can be de-allocated\n  or reused because there are no more objects that use it. If the reference count\n  accidentally reaches zero, then the resource might be released too soon, even though\n  it is still in use. If all objects no longer use the resource, but the reference\n  count is not zero, then the resource might not ever be released.\nApplicable_Platforms:\n  Language: C, C++\nObserved_Examples: 'CVE-2002-0574: chain: reference count is not decremented, leading\n  to memory leak in OS by sending ICMP packets.\n\n\n  CVE-2004-0114: Reference count for shared memory not decremented when a function\n  fails, potentially allowing unprivileged users to read kernel memory.\n\n\n  CVE-2006-3741: chain: improper reference count tracking leads to file descriptor\n  consumption\n\n\n  CVE-2007-1383: chain: integer overflow in reference counter causes the same variable\n  to be destroyed twice.\n\n\n  CVE-2007-1700: Incorrect reference count calculation leads to improper object destruction\n  and code execution.\n\n\n  CVE-2008-2136: chain: incorrect update of reference count leads to memory leak.\n\n\n  CVE-2008-2785: chain/composite: use of incorrect data type for a reference counter\n  allows an overflow of the counter, leading to a free of memory that is still in\n  use.\n\n\n  CVE-2008-5410: Improper reference counting leads to failure of cryptographic operations.\n\n\n  CVE-2009-1709: chain: improper reference counting in a garbage collection routine\n  leads to use-after-free\n\n\n  CVE-2009-3553: chain: reference count not correctly maintained when client disconnects\n  during a large operation, leading to a use-after-free.\n\n\n  CVE-2009-3624: Reference count not always incremented, leading to crash or code\n  execution.\n\n\n  CVE-2010-0176: improper reference counting leads to expired pointer dereference.\n\n\n  CVE-2010-0623: OS kernel increments reference count twice but only decrements once,\n  leading to resource consumption and crash.\n\n\n  CVE-2010-2549: OS kernel driver allows code execution\n\n\n  CVE-2010-4593: improper reference counting leads to exhaustion of IP addresses\n\n\n  CVE-2011-0695: Race condition causes reference counter to be decremented prematurely,\n  leading to the destruction of still-active object and an invalid pointer dereference.\n\n\n  CVE-2012-4787: improper reference counting leads to use-after-free'\n",
  "ID: '912'\nName: Hidden Functionality\nDescription: The product contains functionality that is not documented, not part of\n  the specification, and not accessible through an interface or command sequence that\n  is obvious to the product's users or administrators.\nExtended_Description: Hidden functionality can take many forms, such as intentionally\n  malicious code, \"Easter Eggs\" that contain extraneous functionality such as games,\n  developer-friendly shortcuts that reduce maintenance or support costs such as hard-coded\n  accounts, etc. From a security perspective, even when the functionality is not intentionally\n  malicious or damaging, it can increase the product's attack surface and expose additional\n  weaknesses beyond what is already exposed by the intended functionality. Even if\n  it is not easily accessible, the hidden functionality could be useful for attacks\n  that modify the control flow of the application.\nApplicable_Platforms:\n  Technology: ICS/OT\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nPotential_Mitigations: 'Installation: Always verify the integrity of the product that\n  is being installed.\n\n\n  Testing: Conduct a code coverage analysis using live testing, then closely inspect\n  any code that is not covered.'\nRelated_Attack_Patterns: \"133: \\n\\n190: \"\n",
  "ID: '913'\nName: Improper Control of Dynamically-Managed Code Resources\nDescription: The product does not properly restrict reading from or writing to dynamically-managed\n  code resources such as variables, objects, classes, attributes, functions, or executable\n  instructions or statements.\nExtended_Description: Many languages offer powerful features that allow the programmer\n  to dynamically create or modify existing code, or resources used by code such as\n  variables and objects. While these features can offer significant flexibility and\n  reduce development time, they can be extremely dangerous if attackers can directly\n  influence these code resources in unexpected ways.\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Fuzzing: Fuzz testing (fuzzing) is a powerful technique for generating\n  large numbers of diverse inputs - either randomly or algorithmically - and dynamically\n  invoking the code with those inputs. Even with random inputs, it is often capable\n  of generating unexpected results such as crashes, memory corruption, or resource\n  consumption. Fuzzing effectively produces repeatable test cases that clearly indicate\n  bugs, which helps developers to diagnose the issues.'\nPotential_Mitigations: 'Implementation: For any externally-influenced input, check\n  the input against an allowlist of acceptable values.\n\n\n  Implementation\n\n  Architecture and Design: Refactor the code so that it does not need to be dynamically\n  managed.'\n",
  "ID: '914'\nName: Improper Control of Dynamically-Identified Variables\nDescription: The product does not properly restrict reading from or writing to dynamically-identified\n  variables.\nExtended_Description: Many languages offer powerful features that allow the programmer\n  to access arbitrary variables that are specified by an input string. While these\n  features can offer significant flexibility and reduce development time, they can\n  be extremely dangerous if attackers can modify unintended variables that have security\n  implications.\nPotential_Mitigations: 'Implementation: For any externally-influenced input, check\n  the input against an allowlist of internal program variables that are allowed to\n  be modified.\n\n\n  Implementation\n\n  Architecture and Design: Refactor the code so that internal program variables do\n  not need to be dynamically identified.'\nObserved_Examples: 'CVE-2006-7135: extract issue enables file inclusion\n\n\n  CVE-2006-7079: extract used for register_globals compatibility layer, enables path\n  traversal\n\n\n  CVE-2007-0649: extract() buried in include files makes post-disclosure analysis\n  confusing; original report had seemed incorrect.\n\n\n  CVE-2006-6661: extract() enables static code injection\n\n\n  CVE-2006-2828: import_request_variables() buried in include files makes post-disclosure\n  analysis confusing\n\n\n  CVE-2009-0422: Chain: Dynamic variable evaluation allows resultant remote file inclusion\n  and path traversal.\n\n\n  CVE-2007-2431: Chain: dynamic variable evaluation in PHP program used to modify\n  critical, unexpected $_SERVER variable for resultant XSS.\n\n\n  CVE-2006-4904: Chain: dynamic variable evaluation in PHP program used to conduct\n  remote file inclusion.\n\n\n  CVE-2006-4019: Dynamic variable evaluation in mail program allows reading and modifying\n  attachments and preferences of other users.'\n",
  "ID: '915'\nName: Improperly Controlled Modification of Dynamically-Determined Object Attributes\nDescription: The product receives input from an upstream component that specifies\n  multiple attributes, properties, or fields that are to be initialized or updated\n  in an object, but it does not properly control which attributes can be modified.\nExtended_Description: 'If the object contains attributes that were only intended for\n  internal use, then their unexpected modification could lead to a vulnerability.\n\n  This weakness is sometimes known by the language-specific mechanisms that make it\n  possible, such as mass assignment, autobinding, or object injection.'\nApplicable_Platforms:\n  Language: Ruby, ASP.NET, PHP, Python\nAlternate_Terms: 'Mass Assignment: \"Mass assignment\" is the name of a feature in Ruby\n  on Rails that allows simultaneous modification of multiple object attributes.\n\n\n  AutoBinding: The \"Autobinding\" term is used in frameworks such as Spring MVC and\n  ASP.NET MVC.\n\n\n  PHP Object Injection: Some PHP application researchers use this term for attacking\n  unsafe use of the unserialize() function, but it is also used for CWE-502.'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: If available, use features of the language\n  or framework that allow specification of allowlists of attributes or fields that\n  are allowed to be modified. If possible, prefer allowlists over denylists.\n\n  For applications written with Ruby on Rails, use the attr_accessible (allowlist)\n  or attr_protected (denylist) macros in each class that may be used in mass assignment.\n\n\n  Architecture and Design\n\n  Implementation: If available, use the signing/sealing features of the programming\n  language to assure that deserialized data has not been tainted. For example, a hash-based\n  message authentication code (HMAC) could be used to ensure that data has not been\n  modified.\n\n\n  Implementation: For any externally-influenced input, check the input against an\n  allowlist of internal object attributes or fields that are allowed to be modified.\n\n\n  Implementation\n\n  Architecture and Design: Refactor the code so that object attributes or fields do\n  not need to be dynamically identified, and only expose getter/setter functionality\n  for the intended attributes.'\nObserved_Examples: 'CVE-2012-2054: Mass assignment allows modification of arbitrary\n  attributes using modified URL.\n\n\n  CVE-2012-2055: Source version control product allows modification of trusted key\n  using mass assignment.\n\n\n  CVE-2008-7310: Attackers can bypass payment step in e-commerce product.\n\n\n  CVE-2013-1465: Use of PHP unserialize function on untrusted input allows attacker\n  to modify application configuration.\n\n\n  CVE-2012-3527: Use of PHP unserialize function on untrusted input in content management\n  system might allow code execution.\n\n\n  CVE-2012-0911: Use of PHP unserialize function on untrusted input in content management\n  system allows code execution using a crafted cookie value.\n\n\n  CVE-2012-0911: Content management system written in PHP allows unserialize of arbitrary\n  objects, possibly allowing code execution.\n\n\n  CVE-2011-4962: Content management system written in PHP allows code execution through\n  page comments.\n\n\n  CVE-2009-4137: Use of PHP unserialize function on cookie value allows remote code\n  execution or upload of arbitrary files.\n\n\n  CVE-2007-5741: Content management system written in Python interprets untrusted\n  data as pickles, allowing code execution.\n\n\n  CVE-2011-2520: Python script allows local users to execute code via pickled data.\n\n\n  CVE-2005-2875: Python script allows remote attackers to execute arbitrary code using\n  pickled objects.\n\n\n  CVE-2013-0277: Ruby on Rails allows deserialization of untrusted YAML to execute\n  arbitrary code.\n\n\n  CVE-2011-2894: Spring framework allows deserialization of objects from untrusted\n  sources to execute arbitrary code.\n\n\n  CVE-2012-1833: Grails allows binding of arbitrary parameters to modify arbitrary\n  object properties.\n\n\n  CVE-2010-3258: Incorrect deserialization in web browser allows escaping the sandbox.\n\n\n  CVE-2008-1013: Media library allows deserialization of objects by untrusted Java\n  applets, leading to arbitrary code execution.'\n",
  "ID: '916'\nName: Use of Password Hash With Insufficient Computational Effort\nDescription: The product generates a hash for a password, but it uses a scheme that\n  does not provide a sufficient level of computational effort that would make password\n  cracking attacks infeasible or expensive.\nExtended_Description: 'Many password storage mechanisms compute a hash and store the\n  hash, instead of storing the original password in plaintext. In this design, authentication\n  involves accepting an incoming password, computing its hash, and comparing it to\n  the stored hash.\n\n  Many hash algorithms are designed to execute quickly with minimal overhead, even\n  cryptographic hashes. However, this efficiency is a problem for password storage,\n  because it can reduce an attacker''s workload for brute-force password cracking.\n  If an attacker can obtain the hashes through some other method (such as SQL injection\n  on a database that stores hashes), then the attacker can store the hashes offline\n  and use various techniques to crack the passwords by computing hashes efficiently.\n  Without a built-in workload, modern attacks can compute large numbers of hashes,\n  or even exhaust the entire space of all possible passwords, within a very short\n  amount of time, using massively-parallel computing (such as cloud computing) and\n  GPU, ASIC, or FPGA hardware. In such a scenario, an efficient hash algorithm helps\n  the attacker.\n\n  There are several properties of a hash scheme that are relevant to its strength\n  against an offline, massively-parallel attack:\n\n  Note that the security requirements for the product may vary depending on the environment\n  and the value of the passwords. Different schemes might not provide all of these\n  properties, yet may still provide sufficient security for the environment. Conversely,\n  a solution might be very strong in preserving one property, which still being very\n  weak for an attack against another property, or it might not be able to significantly\n  reduce the efficiency of a massively-parallel attack.'\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis - Binary or Bytecode: According to SOAR,\n  the following detection techniques may be useful:\n\n\n  Manual Static Analysis - Binary or Bytecode: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Manual Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis - Source Code: According to SOAR, the following detection\n  techniques may be useful:\n\n\n  Automated Static Analysis: According to SOAR, the following detection techniques\n  may be useful:\n\n\n  Architecture or Design Review: According to SOAR, the following detection techniques\n  may be useful:'\nPotential_Mitigations: 'Architecture and Design: Use an adaptive hash function that\n  can be configured to change the amount of computational effort needed to compute\n  the hash, such as the number of iterations (\"stretching\") or the amount of memory\n  required. Some hash functions perform salting automatically. These functions can\n  significantly increase the overhead for a brute force attack compared to intentionally-fast\n  functions such as MD5. For example, rainbow table attacks can become infeasible\n  due to the high computing overhead. Finally, since computing power gets faster and\n  cheaper over time, the technique can be reconfigured to increase the workload without\n  forcing an entire replacement of the algorithm in use.\n\n  Some hash functions that have one or more of these desired properties include bcrypt\n  [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate\n  about which of these is the most effective, they are all stronger than using salts\n  with hash functions with very little computing overhead.\n\n  Note that using these functions can have an impact on performance, so they require\n  special consideration to avoid denial-of-service attacks. However, their configurability\n  provides finer control over how much CPU and memory is used, so it could be adjusted\n  to suit the environment''s needs.\n\n\n  Implementation\n\n  Architecture and Design: When using industry-approved techniques, use them correctly.\n  Don''t cut corners by skipping resource-intensive steps (CWE-325). These steps are\n  often essential for preventing common attacks.'\nObserved_Examples: 'CVE-2008-1526: Router does not use a salt with a hash, making\n  it easier to crack passwords.\n\n\n  CVE-2006-1058: Router does not use a salt with a hash, making it easier to crack\n  passwords.\n\n\n  CVE-2008-4905: Blogging software uses a hard-coded salt when calculating a password\n  hash.\n\n\n  CVE-2002-1657: Database server uses the username for a salt when encrypting passwords,\n  simplifying brute force attacks.\n\n\n  CVE-2001-0967: Server uses a constant salt when encrypting passwords, simplifying\n  brute force attacks.\n\n\n  CVE-2005-0408: chain: product generates predictable MD5 hashes using a constant\n  value combined with username, allowing authentication bypass.'\nRelated_Attack_Patterns: '55: '\n",
  "ID: '917'\nName: Improper Neutralization of Special Elements used in an Expression Language Statement\n  ('Expression Language Injection')\nDescription: The product constructs all or part of an expression language (EL) statement\n  in a framework such as a Java Server Page (JSP) using externally-influenced input\n  from an upstream component, but it does not neutralize or incorrectly neutralizes\n  special elements that could modify the intended EL statement before it is executed.\nExtended_Description: Frameworks such as Java Server Page (JSP) allow a developer\n  to insert executable expressions within otherwise-static content. When the developer\n  is not aware of the executable nature of these expressions and/or does not disable\n  them, then if an attacker can inject expressions, this could lead to code execution\n  or other unexpected behaviors.\nApplicable_Platforms:\n  Language: Java\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Avoid adding user-controlled data\n  into an expression interpreter when possible.\n\n\n  Implementation: If user-controlled data must be added to an expression interpreter,\n  one or more of the following should be performed:\n\n\n  System Configuration, Operation: The framework or tooling might allow the developer\n  to disable or deactivate the processing of EL expressions, such as setting the isELIgnored\n  attribute for a JSP page to \"true\".'\nObserved_Examples: 'CVE-2021-44228: Product does not neutralize ${xyz} style expressions,\n  allowing remote code execution. (log4shell vulnerability in log4j)'\n",
  "ID: '918'\nName: Server-Side Request Forgery (SSRF)\nDescription: The web server receives a URL or similar request from an upstream component\n  and retrieves the contents of this URL, but it does not sufficiently ensure that\n  the request is being sent to the expected destination.\nExtended_Description: By providing URLs to unexpected hosts or ports, attackers can\n  make it appear that the server is sending the request, possibly bypassing access\n  controls such as firewalls that prevent the attackers from accessing the URLs directly.\n  The server can be used as a proxy to conduct port scanning of hosts in internal\n  networks, use other URLs such as that can access documents on the system (using\n  file://), or use other protocols such as gopher:// or tftp://, which may provide\n  greater control over the contents of requests.\nApplicable_Platforms:\n  Technology: Web Server\nAlternate_Terms: 'XSPA: Cross Site Port Attack'\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2021-26855: Server Side Request Forgery (SSRF) in mail server,\n  as exploited in the wild per CISA KEV.\n\n\n  CVE-2021-21973: Server Side Request Forgery in cloud platform, as exploited in the\n  wild per CISA KEV.\n\n\n  CVE-2016-4029: Chain: incorrect validation of intended decimal-based IP address\n  format (CWE-1286) enables parsing of octal or hexadecimal formats (CWE-1389), allowing\n  bypass of an SSRF protection mechanism (CWE-918).\n\n\n  CVE-2002-1484: Web server allows attackers to request a URL from another server,\n  including other ports, which allows proxied scanning.\n\n\n  CVE-2004-2061: CGI script accepts and retrieves incoming URLs.\n\n\n  CVE-2010-1637: Web-based mail program allows internal network scanning using a modified\n  POP3 port number.\n\n\n  CVE-2009-0037: URL-downloading library automatically follows redirects to file://\n  and scp:// URLs'\nRelated_Attack_Patterns: '664: '\n",
  "ID: '92'\nName: 'DEPRECATED: Improper Sanitization of Custom Special Characters'\nDescription: This entry has been deprecated. It originally came from PLOVER, which\n  sometimes defined \"other\" and \"miscellaneous\" categories in order to satisfy exhaustiveness\n  requirements for taxonomies. Within the context of CWE, the use of a more abstract\n  entry is preferred in mapping situations. CWE-75 is a more appropriate mapping.\n",
  "ID: '920'\nName: Improper Restriction of Power Consumption\nDescription: The product operates in an environment in which power is a limited resource\n  that cannot be automatically replenished, but the product does not properly restrict\n  the amount of power that its operation consumes.\nExtended_Description: 'In environments such as embedded or mobile devices, power can\n  be a limited resource such as a battery, which cannot be automatically replenished\n  by the product itself, and the device might not always be directly attached to a\n  reliable power source. If the product uses too much power too quickly, then this\n  could cause the device (and subsequently, the product) to stop functioning until\n  power is restored, or increase the financial burden on the device owner because\n  of increased power costs.\n\n  Normal operation of an application will consume power. However, in some cases, an\n  attacker could cause the application to consume more power than intended, using\n  components such as:'\nApplicable_Platforms:\n  Technology: Mobile\n",
  "ID: '921'\nName: Storage of Sensitive Data in a Mechanism without Access Control\nDescription: The product stores sensitive information in a file system or device that\n  does not have built-in access control.\nExtended_Description: 'While many modern file systems or devices utilize some form\n  of access control in order to restrict access to data, not all storage mechanisms\n  have this capability. For example, memory cards, floppy disks, CDs, and USB devices\n  are typically made accessible to any user within the system. This can become a problem\n  when sensitive data is stored in these mechanisms in a multi-user environment, because\n  anybody on the system can read or write this data.\n\n  On Android devices, external storage is typically globally readable and writable\n  by other applications on the device. External storage may also be easily accessible\n  through the mobile device''s USB connection or physically accessible through the\n  device''s memory card port.'\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: 'Architecture and Design: OMISSION: This weakness is caused\n  by missing a security tactic during the architecture and design phase.'\n",
  "ID: '922'\nName: Insecure Storage of Sensitive Information\nDescription: The product stores sensitive information without properly limiting read\n  or write access by unauthorized actors.\nExtended_Description: If read access is not properly restricted, then attackers can\n  steal the sensitive information. If write access is not properly restricted, then\n  attackers can modify and possibly delete the data, causing incorrect results and\n  possibly a denial of service.\nModes_Of_Introduction: \"Architecture and Design: OMISSION: This weakness is caused\\\n  \\ by missing a security tactic during the architecture and design phase.\\n\\nImplementation:\\\n  \\ \\n\\nSystem Configuration: \"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\n",
  "ID: '923'\nName: Improper Restriction of Communication Channel to Intended Endpoints\nDescription: The product establishes a communication channel to (or from) an endpoint\n  for privileged or protected operations, but it does not properly ensure that it\n  is communicating with the correct endpoint.\nExtended_Description: 'Attackers might be able to spoof the intended endpoint from\n  a different system or process, thus gaining the same level of access as the intended\n  endpoint.\n\n  While this issue frequently involves authentication between network-based clients\n  and servers, other types of communication channels and endpoints can have this weakness.'\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nRelated_Attack_Patterns: \"161: \\n\\n481: \\n\\n501: \\n\\n697: \"\n",
  "ID: '924'\nName: Improper Enforcement of Message Integrity During Transmission in a Communication\n  Channel\nDescription: The product establishes a communication channel with an endpoint and\n  receives a message from that endpoint, but it does not sufficiently ensure that\n  the message was not modified during transmission.\nExtended_Description: Attackers might be able to modify the message and spoof the\n  endpoint by interfering with the data as it crosses the network or by redirecting\n  the connection to a system under their control.\nModes_Of_Introduction: 'Architecture and Design: REALIZATION: This weakness is caused\n  during implementation of an architectural security tactic.'\n",
  "ID: '925'\nName: Improper Verification of Intent by Broadcast Receiver\nDescription: The Android application uses a Broadcast Receiver that receives an Intent\n  but does not properly verify that the Intent came from an authorized source.\nExtended_Description: Certain types of Intents, identified by action string, can only\n  be broadcast by the operating system itself, not by third-party applications. However,\n  when an application registers to receive these implicit system intents, it is also\n  registered to receive any explicit intents. While a malicious application cannot\n  send an implicit system intent, it can send an explicit intent to the target application,\n  which may assume that any received intent is a valid implicit system intent and\n  not an explicit intent from another application. This may lead to unintended behavior.\nApplicable_Platforms:\n  Technology: Mobile\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Before acting on the Intent, check\n  the Intent Action to make sure it matches the expected System action.'\nRelated_Attack_Patterns: '499: '\n",
  "ID: '926'\nName: Improper Export of Android Application Components\nDescription: The Android application exports a component for use by other applications,\n  but does not properly restrict which applications can launch the component or access\n  the data it contains.\nExtended_Description: 'The attacks and consequences of improperly exporting a component\n  may depend on the exported component:'\nApplicable_Platforms:\n  Technology: Mobile\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Build and Compilation: If they do not need to be shared by\n  other applications, explicitly mark components with android:exported=\"false\" in\n  the application manifest.\n\n\n  Build and Compilation: If you only intend to use exported components between related\n  apps under your control, use android:protectionLevel=\"signature\" in the xml manifest\n  to restrict access to applications signed by you.\n\n\n  Build and Compilation\n\n  Architecture and Design: Limit Content Provider permissions (read/write) as appropriate.\n\n\n  Build and Compilation\n\n  Architecture and Design: Limit Content Provider permissions (read/write) as appropriate.'\n",
  "ID: '927'\nName: Use of Implicit Intent for Sensitive Communication\nDescription: The Android application uses an implicit intent for transmitting sensitive\n  data to other applications.\nExtended_Description: 'Since an implicit intent does not specify a particular application\n  to receive the data, any application can process the intent by using an Intent Filter\n  for that intent. This can allow untrusted applications to obtain sensitive data.\n  There are two variations on the standard broadcast intent, ordered and sticky.\n\n  Ordered broadcast intents are delivered to a series of registered receivers in order\n  of priority as declared by the Receivers. A malicious receiver can give itself a\n  high priority and cause a denial of service by stopping the broadcast from propagating\n  further down the chain. There is also the possibility of malicious data modification,\n  as a receiver may also alter the data within the Intent before passing it on to\n  the next receiver. The downstream components have no way of asserting that the data\n  has not been altered earlier in the chain.\n\n  Sticky broadcast intents remain accessible after the initial broadcast. An old sticky\n  intent will be broadcast again to any new receivers that register for it in the\n  future, greatly increasing the chances of information exposure over time. Also,\n  sticky broadcasts cannot be protected by permissions that may apply to other kinds\n  of intents.\n\n  In addition, any broadcast intent may include a URI that references data that the\n  receiving component does not normally have the privileges to access. The sender\n  of the intent can include special privileges that grant the receiver read or write\n  access to the specific URI included in the intent. A malicious receiver that intercepts\n  this intent will also gain those privileges and be able to read or write the resource\n  at the specified URI.'\nApplicable_Platforms:\n  Technology: Mobile\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: If the application only requires communication\n  with its own components, then the destination is always known, and an explicit intent\n  could be used.'\n",
  "ID: '93'\nName: Improper Neutralization of CRLF Sequences ('CRLF Injection')\nDescription: The product uses CRLF (carriage return line feeds) as a special element,\n  e.g. to separate lines or records, but it does not neutralize or incorrectly neutralizes\n  CRLF sequences from inputs.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Implementation: Avoid using CRLF as a special sequence.\n\n\n  Implementation: Appropriately filter or quote CRLF sequences in user-controlled\n  input.'\nObserved_Examples: 'CVE-2002-1771: CRLF injection enables spam proxy (add mail headers)\n  using email address or name.\n\n\n  CVE-2002-1783: CRLF injection in API function arguments modify headers for outgoing\n  requests.\n\n\n  CVE-2004-1513: Spoofed entries in web server log file via carriage returns\n\n\n  CVE-2006-4624: Chain: inject fake log entries with fake timestamps using CRLF injection\n\n\n  CVE-2005-1951: Chain: Application accepts CRLF in an object ID, allowing HTTP response\n  splitting.\n\n\n  CVE-2004-1687: Chain: HTTP response splitting via CRLF in parameter related to URL.'\nRelated_Attack_Patterns: \"15: \\n\\n81: \"\n",
  "ID: '939'\nName: Improper Authorization in Handler for Custom URL Scheme\nDescription: The product uses a handler for a custom URL scheme, but it does not properly\n  restrict which actors can invoke the handler using the scheme.\nExtended_Description: Mobile platforms and other architectures allow the use of custom\n  URL schemes to facilitate communication between applications. In the case of iOS,\n  this is the only method to do inter-application communication. The implementation\n  is at the developer's discretion which may open security flaws in the application.\n  An example could be potentially dangerous functionality such as modifying files\n  through a custom URL scheme.\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nPotential_Mitigations: 'Architecture and Design: Utilize a user prompt pop-up to authorize\n  potentially harmful actions such as those modifying data or dealing with sensitive\n  information.\n\n  When designing functionality of actions in the URL scheme, consider whether the\n  action should be accessible to all mobile applications, or if an allowlist of applications\n  to interface with is appropriate.'\nObserved_Examples: 'CVE-2013-5725: URL scheme has action replace which requires no\n  user prompt and allows remote attackers to perform undesired actions.\n\n\n  CVE-2013-5726: URL scheme has action follow and favorite which allows remote attackers\n  to force user to perform undesired actions.'\n",
  "ID: '94'\nName: Improper Control of Generation of Code ('Code Injection')\nDescription: The product constructs all or part of a code segment using externally-influenced\n  input from an upstream component, but it does not neutralize or incorrectly neutralizes\n  special elements that could modify the syntax or behavior of the intended code segment.\nExtended_Description: 'When a product allows a user''s input to contain code syntax,\n  it might be possible for an attacker to craft the code in such a way that it will\n  alter the intended control flow of the product. Such an alteration could lead to\n  arbitrary code execution.\n\n  Injection problems encompass a wide variety of issues -- all mitigated in very different\n  ways. For this reason, the most effective way to discuss these weaknesses is to\n  note the distinct features which classify them as injection weaknesses. The most\n  important issue to note is that all injection problems share one thing in common\n  -- i.e., they allow for the injection of control plane data into the user-controlled\n  data plane. This means that the execution of the process may be altered by sending\n  code in through legitimate data channels, using no other mechanism. While buffer\n  overflows, and many other flaws, involve the use of some further issue to gain execution,\n  injection problems need only for the data to be parsed. The most classic instantiations\n  of this category of weakness are SQL injection and format string vulnerabilities.'\nApplicable_Platforms:\n  Language: Interpreted\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Refactor your program so that you\n  do not have to dynamically generate code.\n\n\n  Architecture and Design: Run your code in a \"jail\" or similar sandbox environment\n  that enforces strict boundaries between the process and the operating system. This\n  may effectively restrict which code can be executed by your product.\n\n  Examples include the Unix chroot jail and AppArmor. In general, managed code may\n  provide some protection.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of your application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  To reduce the likelihood of code injection, use stringent allowlists that limit\n  which constructs are allowed. If you are dynamically constructing code that invokes\n  a function, then verifying that the input is alphanumeric might be insufficient.\n  An attacker might still be able to reference a dangerous function that you did not\n  intend to allow, such as system(), exec(), or exit().\n\n\n  Testing: Use automated static analysis tools that target this type of weakness.\n  Many modern techniques use data flow analysis to minimize the number of false positives.\n  This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n\n  Testing: Use dynamic tools and techniques that interact with the product using large\n  test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness\n  testing, and fault injection. The product''s operation may slow down, but it should\n  not become unstable, crash, or generate incorrect results.\n\n\n  Operation: Run the code in an environment that performs automatic taint propagation\n  and prevents any command execution that uses tainted variables, such as Perl''s\n  \"-T\" switch. This will force the program to perform validation steps that remove\n  the taint, although you must be careful to correctly validate your inputs so that\n  you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n\n  Operation: Run the code in an environment that performs automatic taint propagation\n  and prevents any command execution that uses tainted variables, such as Perl''s\n  \"-T\" switch. This will force the program to perform validation steps that remove\n  the taint, although you must be careful to correctly validate your inputs so that\n  you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).'\nObserved_Examples: 'CVE-2022-2054: Python compiler uses eval() to execute malicious\n  strings as Python code.\n\n\n  CVE-2021-22204: Chain: regex in EXIF processor code does not correctly determine\n  where a string ends (CWE-625), enabling eval injection (CWE-95), as exploited in\n  the wild per CISA KEV.\n\n\n  CVE-2020-8218: \"Code injection\" in VPN product, as exploited in the wild per CISA\n  KEV.\n\n\n  CVE-2008-5071: Eval injection in PHP program.\n\n\n  CVE-2002-1750: Eval injection in Perl program.\n\n\n  CVE-2008-5305: Eval injection in Perl program using an ID that should only contain\n  hyphens and numbers.\n\n\n  CVE-2002-1752: Direct code injection into Perl eval function.\n\n\n  CVE-2002-1753: Eval injection in Perl program.\n\n\n  CVE-2005-1527: Direct code injection into Perl eval function.\n\n\n  CVE-2005-2837: Direct code injection into Perl eval function.\n\n\n  CVE-2005-1921: MFV. code injection into PHP eval statement using nested constructs\n  that should not be nested.\n\n\n  CVE-2005-2498: MFV. code injection into PHP eval statement using nested constructs\n  that should not be nested.\n\n\n  CVE-2005-3302: Code injection into Python eval statement from a field in a formatted\n  file.\n\n\n  CVE-2007-1253: Eval injection in Python program.\n\n\n  CVE-2001-1471: chain: Resultant eval injection. An invalid value prevents initialization\n  of variables, which can be modified by attacker and later injected into PHP eval\n  statement.\n\n\n  CVE-2002-0495: Perl code directly injected into CGI library file from parameters\n  to another CGI program.\n\n\n  CVE-2005-1876: Direct PHP code injection into supporting template file.\n\n\n  CVE-2005-1894: Direct code injection into PHP script that can be accessed by attacker.\n\n\n  CVE-2003-0395: PHP code from User-Agent HTTP header directly inserted into log file\n  implemented as PHP script.'\nRelated_Attack_Patterns: \"242: \\n\\n35: \\n\\n77: \"\n",
  "ID: '940'\nName: Improper Verification of Source of a Communication Channel\nDescription: The product establishes a communication channel to handle an incoming\n  request that has been initiated by an actor, but it does not properly verify that\n  the request is coming from the expected origin.\nExtended_Description: When an attacker can successfully establish a communication\n  channel from an untrusted origin, the attacker may be able to gain privileges and\n  access unexpected functionality.\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nPotential_Mitigations: 'Architecture and Design: Use a mechanism that can validate\n  the identity of the source, such as a certificate, and validate the integrity of\n  data to ensure that it cannot be modified in transit using an Adversary-in-the-Middle\n  (AITM) attack.\n\n  When designing functionality of actions in the URL scheme, consider whether the\n  action should be accessible to all mobile applications, or if an allowlist of applications\n  to interface with is appropriate.'\nObserved_Examples: 'CVE-2000-1218: DNS server can accept DNS updates from hosts that\n  it did not query, leading to cache poisoning\n\n\n  CVE-2005-0877: DNS server can accept DNS updates from hosts that it did not query,\n  leading to cache poisoning\n\n\n  CVE-2001-1452: DNS server caches glue records received from non-delegated name servers'\nRelated_Attack_Patterns: \"500: \\n\\n594: \\n\\n595: \\n\\n596: \"\n",
  "ID: '941'\nName: Incorrectly Specified Destination in a Communication Channel\nDescription: The product creates a communication channel to initiate an outgoing request\n  to an actor, but it does not correctly specify the intended destination for that\n  actor.\nExtended_Description: 'Attackers at the destination may be able to spoof trusted servers\n  to steal data or cause a denial of service.\n\n  There are at least two distinct weaknesses that can cause the product to communicate\n  with an unintended destination:'\nApplicable_Platforms:\n  Technology: Mobile\nModes_Of_Introduction: \"Architecture and Design: \\n\\nImplementation: REALIZATION:\\\n  \\ This weakness is caused during implementation of an architectural security tactic.\"\nObserved_Examples: 'CVE-2013-5211: composite: NTP feature generates large responses\n  (high amplification factor) with spoofed UDP source addresses.\n\n\n  CVE-1999-0513: Classic \"Smurf\" attack, using spoofed ICMP packets to broadcast addresses.\n\n\n  CVE-1999-1379: DNS query with spoofed source address causes more traffic to be returned\n  to spoofed address than was sent by the attacker.'\n",
  "ID: '942'\nName: Permissive Cross-domain Policy with Untrusted Domains\nDescription: The product uses a cross-domain policy file that includes domains that\n  should not be trusted.\nExtended_Description: 'A cross-domain policy file (\"crossdomain.xml\" in Flash and\n  \"clientaccesspolicy.xml\" in Silverlight) defines a list of domains from which a\n  server is allowed to make cross-domain requests. When making a cross-domain request,\n  the Flash or Silverlight client will first look for the policy file on the target\n  server. If it is found, and the domain hosting the application is explicitly allowed\n  to make requests, the request is made.\n\n  Therefore, if a cross-domain policy file includes domains that should not be trusted,\n  such as when using wildcards, then the application could be attacked by these untrusted\n  domains.\n\n  An overly permissive policy file allows many of the same attacks seen in Cross-Site\n  Scripting (CWE-79). Once the user has executed a malicious Flash or Silverlight\n  application, they are vulnerable to a variety of attacks. The attacker could transfer\n  private information, such as cookies that may include session information, from\n  the victim''s machine to the attacker. The attacker could send malicious requests\n  to a web site on behalf of the victim, which could be especially dangerous to the\n  site if the victim has administrator privileges to manage that site.\n\n  In many cases, the attack can be launched without the victim even being aware of\n  it.'\nApplicable_Platforms:\n  Technology: Web Based\nModes_Of_Introduction: \"Implementation: \\n\\nArchitecture and Design: COMMISSION: This\\\n  \\ weakness refers to an incorrect design related to an architectural security tactic.\"\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design: Avoid using wildcards in the cross-domain\n  policy file. Any domain matching the wildcard expression will be implicitly trusted,\n  and can perform two-way interaction with the target server.\n\n\n  Architecture and Design\n\n  Operation: For Flash, modify crossdomain.xml to use meta-policy options such as\n  ''master-only'' or ''none'' to reduce the possibility of an attacker planting extraneous\n  cross-domain policy files on a server.\n\n\n  Architecture and Design\n\n  Operation: For Flash, modify crossdomain.xml to use meta-policy options such as\n  ''master-only'' or ''none'' to reduce the possibility of an attacker planting extraneous\n  cross-domain policy files on a server.'\nObserved_Examples: 'CVE-2012-2292: Product has a Silverlight cross-domain policy that\n  does not restrict access to another application, which allows remote attackers to\n  bypass the Same Origin Policy.\n\n\n  CVE-2014-2049: The default Flash Cross Domain policies in a product allows remote\n  attackers to access user files.\n\n\n  CVE-2007-6243: Chain: Adobe Flash Player does not sufficiently restrict the interpretation\n  and usage of cross-domain policy files, which makes it easier for remote attackers\n  to conduct cross-domain and cross-site scripting (XSS) attacks.\n\n\n  CVE-2008-4822: Chain: Adobe Flash Player and earlier does not properly interpret\n  policy files, which allows remote attackers to bypass a non-root domain policy.\n\n\n  CVE-2010-3636: Chain: Adobe Flash Player does not properly handle unspecified encodings\n  during the parsing of a cross-domain policy file, which allows remote web servers\n  to bypass intended access restrictions via unknown vectors.'\n",
  "ID: '943'\nName: Improper Neutralization of Special Elements in Data Query Logic\nDescription: The product generates a query intended to access or manipulate data in\n  a data store such as a database, but it does not neutralize or incorrectly neutralizes\n  special elements that can modify the intended logic of the query.\nExtended_Description: 'Depending on the capabilities of the query language, an attacker\n  could inject additional logic into the query to:\n\n  The ability to execute additional commands or change which entities are returned\n  has obvious risks. But when the product logic depends on the order or number of\n  entities, this can also lead to vulnerabilities. For example, if the query expects\n  to return only one entity that specifies an administrative user, but an attacker\n  can change which entities are returned, this could cause the logic to return information\n  for a regular user and incorrectly assume that the user has administrative privileges.\n\n  While this weakness is most commonly associated with SQL injection, there are many\n  other query languages that are also subject to injection attacks, including HTSQL,\n  LDAP, DQL, XQuery, Xpath, and \"NoSQL\" languages.'\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nObserved_Examples: 'CVE-2014-2503: Injection using Documentum Query Language (DQL)\n\n\n  CVE-2014-2508: Injection using Documentum Query Language (DQL)'\nRelated_Attack_Patterns: '676: '\n",
  "ID: '95'\nName: Improper Neutralization of Directives in Dynamically Evaluated Code ('Eval Injection')\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes code syntax before using the input in a dynamic\n  evaluation call (e.g. \"eval\").\nExtended_Description: This may allow an attacker to execute arbitrary code, or at\n  least modify what code can be executed.\nApplicable_Platforms:\n  Language: Java, JavaScript, Python, Perl, PHP, Ruby, Interpreted\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Implementation: This weakness is prevalent in handler/dispatch procedures that might\n  want to invoke a large number of functions, or set a large number of variables.'\nDetection_Methods: 'Automated Static Analysis: Automated static analysis, commonly\n  referred to as Static Application Security Testing (SAST), can find some instances\n  of this weakness by analyzing source code (or binary/compiled code) without having\n  to execute it. Typically, this is done by building a model of data flow and control\n  flow, then searching for potentially-vulnerable patterns that connect \"sources\"\n  (origins of input) with \"sinks\" (destinations where the data interacts with external\n  components, a lower layer such as the OS, etc.)'\nPotential_Mitigations: 'Architecture and Design\n\n  Implementation: If possible, refactor your code so that it does not need to use\n  eval() at all.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Inputs should be decoded and canonicalized to the application''s\n  current internal representation before being validated (CWE-180, CWE-181). Make\n  sure that your application does not inadvertently decode the same input twice (CWE-174).\n  Such errors could be used to bypass allowlist schemes by introducing dangerous inputs\n  after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization\n  control.\n\n  Consider performing repeated canonicalization until your input does not change any\n  more. This will avoid double-decoding and similar scenarios, but it might inadvertently\n  modify inputs that are allowed to contain properly-encoded dangerous content.'\nObserved_Examples: 'CVE-2022-2054: Python compiler uses eval() to execute malicious\n  strings as Python code.\n\n\n  CVE-2021-22204: Chain: regex in EXIF processor code does not correctly determine\n  where a string ends (CWE-625), enabling eval injection (CWE-95), as exploited in\n  the wild per CISA KEV.\n\n\n  CVE-2021-22205: Chain: backslash followed by a newline can bypass a validation step\n  (CWE-20), leading to eval injection (CWE-95), as exploited in the wild per CISA\n  KEV.\n\n\n  CVE-2008-5071: Eval injection in PHP program.\n\n\n  CVE-2002-1750: Eval injection in Perl program.\n\n\n  CVE-2008-5305: Eval injection in Perl program using an ID that should only contain\n  hyphens and numbers.\n\n\n  CVE-2002-1752: Direct code injection into Perl eval function.\n\n\n  CVE-2002-1753: Eval injection in Perl program.\n\n\n  CVE-2005-1527: Direct code injection into Perl eval function.\n\n\n  CVE-2005-2837: Direct code injection into Perl eval function.\n\n\n  CVE-2005-1921: MFV. code injection into PHP eval statement using nested constructs\n  that should not be nested.\n\n\n  CVE-2005-2498: MFV. code injection into PHP eval statement using nested constructs\n  that should not be nested.\n\n\n  CVE-2005-3302: Code injection into Python eval statement from a field in a formatted\n  file.\n\n\n  CVE-2007-1253: Eval injection in Python program.\n\n\n  CVE-2001-1471: chain: Resultant eval injection. An invalid value prevents initialization\n  of variables, which can be modified by attacker and later injected into PHP eval\n  statement.\n\n\n  CVE-2007-2713: Chain: Execution after redirect triggers eval injection.'\nRelated_Attack_Patterns: '35: '\n",
  "ID: '96'\nName: Improper Neutralization of Directives in Statically Saved Code ('Static Code\n  Injection')\nDescription: The product receives input from an upstream component, but it does not\n  neutralize or incorrectly neutralizes code syntax before inserting the input into\n  an executable resource, such as a library, configuration file, or template.\nApplicable_Platforms:\n  Language: PHP, Perl, Interpreted\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.\n\n\n  Implementation: This issue is frequently found in PHP applications that allow users\n  to set configuration variables that are stored within executable PHP files. Technically,\n  this could also be performed in some compiled code (e.g., by byte-patching an executable),\n  although it is highly unlikely.'\nPotential_Mitigations: 'Implementation: Assume all input is malicious. Use an \"accept\n  known good\" input validation strategy, i.e., use a list of acceptable inputs that\n  strictly conform to specifications. Reject any input that does not strictly conform\n  to specifications, or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n\n  Implementation: Perform proper output validation and escaping to neutralize all\n  code syntax from data written to code files.'\nObserved_Examples: 'CVE-2002-0495: Perl code directly injected into CGI library file\n  from parameters to another CGI program.\n\n\n  CVE-2005-1876: Direct PHP code injection into supporting template file.\n\n\n  CVE-2005-1894: Direct code injection into PHP script that can be accessed by attacker.\n\n\n  CVE-2003-0395: PHP code from User-Agent HTTP header directly inserted into log file\n  implemented as PHP script.\n\n\n  CVE-2007-6652: chain: execution after redirect allows non-administrator to perform\n  static code injection.'\nRelated_Attack_Patterns: \"35: \\n\\n73: \\n\\n77: \\n\\n81: \\n\\n85: \"\n",
  "ID: '97'\nName: Improper Neutralization of Server-Side Includes (SSI) Within a Web Page\nDescription: The product generates a web page, but does not neutralize or incorrectly\n  neutralizes user-controllable input that could be interpreted as a server-side include\n  (SSI) directive.\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nRelated_Attack_Patterns: \"101: \\n\\n35: \"\n",
  "ID: '98'\nName: Improper Control of Filename for Include/Require Statement in PHP Program ('PHP\n  Remote File Inclusion')\nDescription: The PHP application receives input from an upstream component, but it\n  does not restrict or incorrectly restricts the input before its usage in \"require,\"\n  \"include,\" or similar functions.\nExtended_Description: In certain versions and configurations of PHP, this can allow\n  an attacker to specify a URL to a remote location from which the product will obtain\n  the code to execute. In other cases in association with path traversal, the attacker\n  can specify a local file that may contain executable statements that can be parsed\n  by PHP.\nApplicable_Platforms:\n  Language: PHP\nAlternate_Terms: \"Remote file include: \\n\\nRFI: The Remote File Inclusion (RFI) acronym\\\n  \\ is often used by vulnerability researchers.\\n\\nLocal file inclusion: This term\\\n  \\ is frequently used in cases in which remote download is disabled, or when the\\\n  \\ first part of the filename is not under the attacker's control, which forces use\\\n  \\ of relative path traversal (CWE-23) attack techniques to access files that may\\\n  \\ contain previously-injected PHP code, such as web access logs.\"\nModes_Of_Introduction: 'Implementation: REALIZATION: This weakness is caused during\n  implementation of an architectural security tactic.'\nDetection_Methods: 'Manual Analysis: Manual white-box analysis can be very effective\n  for finding this issue, since there is typically a relatively small number of include\n  or require statements in each program.\n\n\n  Automated Static Analysis: The external control or influence of filenames can often\n  be detected using automated static analysis that models data flow within the product.\n\n  Automated static analysis might not be able to recognize when proper input validation\n  is being performed, leading to false positives - i.e., warnings that do not have\n  any security consequences or require any code changes. If the program uses a customized\n  input validation library, then some tools may allow the analyst to create custom\n  signatures to detect usage of those routines.'\nPotential_Mitigations: 'Architecture and Design: Use a vetted library or framework\n  that does not allow this weakness to occur or provides constructs that make this\n  weakness easier to avoid.\n\n\n  Architecture and Design: When the set of acceptable objects, such as filenames or\n  URLs, is limited or known, create a mapping from a set of fixed input values (such\n  as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n  For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\".\n  Features such as the ESAPI AccessReferenceMap [REF-185] provide this capability.\n\n\n  Architecture and Design: For any security checks that are performed on the client\n  side, ensure that these checks are duplicated on the server side, in order to avoid\n  CWE-602. Attackers can bypass the client-side checks by modifying values after the\n  checks have been performed, or by changing the client to remove the client-side\n  checks entirely. Then, these modified values would be submitted to the server.\n\n\n  Architecture and Design\n\n  Operation: Run the code in a \"jail\" or similar sandbox environment that enforces\n  strict boundaries between the process and the operating system. This may effectively\n  restrict which files can be accessed in a particular directory or which commands\n  can be executed by the software.\n\n  OS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general,\n  managed code may provide some protection. For example, java.io.FilePermission in\n  the Java SecurityManager allows the software to specify restrictions on file operations.\n\n  This may not be a feasible solution, and it only limits the impact to the operating\n  system; the rest of the application may still be subject to compromise.\n\n  Be careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n  Architecture and Design\n\n  Operation: Run your code using the lowest privileges that are required to accomplish\n  the necessary tasks [REF-76]. If possible, create isolated accounts with limited\n  privileges that are only used for a single task. That way, a successful attack will\n  not immediately give the attacker access to the rest of the software or its environment.\n  For example, database applications rarely need to run as the database administrator,\n  especially in day-to-day operations.\n\n\n  Implementation: Assume all input is malicious. Use an \"accept known good\" input\n  validation strategy, i.e., use a list of acceptable inputs that strictly conform\n  to specifications. Reject any input that does not strictly conform to specifications,\n  or transform it into something that does.\n\n  When performing input validation, consider all potentially relevant properties,\n  including length, type of input, the full range of acceptable values, missing or\n  extra inputs, syntax, consistency across related fields, and conformance to business\n  rules. As an example of business rule logic, \"boat\" may be syntactically valid because\n  it only contains alphanumeric characters, but it is not valid if the input is only\n  expected to contain colors such as \"red\" or \"blue.\"\n\n  Do not rely exclusively on looking for malicious or malformed inputs.  This is likely\n  to miss at least one undesirable input, especially if the code''s environment changes.\n  This can give attackers enough room to bypass the intended validation. However,\n  denylists can be useful for detecting potential attacks or determining which inputs\n  are so malformed that they should be rejected outright.\n\n  When validating filenames, use stringent lists that limit the character set to be\n  used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses\n  such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use\n  a list of allowable file extensions, which will help to avoid CWE-434.\n\n  Do not rely exclusively on a filtering mechanism that removes potentially dangerous\n  characters. This is equivalent to a denylist, which may be incomplete (CWE-184).\n  For example, filtering \"/\" is insufficient protection if the filesystem also supports\n  the use of \"\\\" as a directory separator. Another possible error could occur when\n  the filtering is applied in a way that still produces dangerous data (CWE-182).\n  For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential\n  fashion, two instances of \"../\" would be removed from the original string, but the\n  remaining characters would still form the \"../\" string.\n\n\n  Architecture and Design\n\n  Operation: Store library, include, and utility files outside of the web document\n  root, if possible. Otherwise, store them in a separate directory and use the web\n  server''s access control capabilities to prevent attackers from directly requesting\n  them. One common practice is to define a fixed constant in each calling program,\n  then check for the existence of the constant in the library/include file; if the\n  constant does not exist, then the file was directly requested, and it can exit immediately.\n\n  This significantly reduces the chance of an attacker being able to bypass any protection\n  mechanisms that are in the base program but not in the include files. It will also\n  reduce the attack surface.\n\n\n  Architecture and Design\n\n  Implementation: Understand all the potential areas where untrusted inputs can enter\n  your software: parameters or arguments, cookies, anything read from the network,\n  environment variables, reverse DNS lookups, query results, request headers, URL\n  components, e-mail, files, filenames, databases, and any external systems that provide\n  data to the application. Remember that such inputs may be obtained indirectly through\n  API calls.\n\n  Many file inclusion problems occur because the programmer assumed that certain inputs\n  could not be modified, especially for cookies and URL components.\n\n\n  Operation: Use an application firewall that can detect attacks against this weakness.\n  It can be beneficial in cases in which the code cannot be fixed (because it is controlled\n  by a third party), as an emergency prevention measure while more comprehensive software\n  assurance measures are applied, or to provide defense in depth.\n\n\n  Operation, Implementation: Develop and run your code in the most recent versions\n  of PHP available, preferably PHP 6 or later. Many of the highly risky features in\n  earlier PHP interpreters have been removed, restricted, or disabled by default.\n\n\n  Operation, Implementation: When using PHP, configure the application so that it\n  does not use register_globals. During implementation, develop the application so\n  that it does not rely on this feature, but be wary of implementing a register_globals\n  emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n\n  Often, programmers do not protect direct access to files intended only to be included\n  by core programs. These include files may assume that critical variables have already\n  been initialized by the calling program. As a result, the use of register_globals\n  combined with the ability to directly access the include file may allow attackers\n  to conduct file inclusion attacks. This remains an extremely common pattern as of\n  2009.\n\n\n  Operation: Set allow_url_fopen to false, which limits the ability to include files\n  from remote locations.'\nObserved_Examples: 'CVE-2004-0285: Modification of assumed-immutable configuration\n  variable in include file allows file inclusion via direct request.\n\n\n  CVE-2004-0030: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2004-0068: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2005-2157: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2005-2162: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2005-2198: Modification of assumed-immutable configuration variable in include\n  file allows file inclusion via direct request.\n\n\n  CVE-2004-0128: Modification of assumed-immutable variable in configuration script\n  leads to file inclusion.\n\n\n  CVE-2005-1864: PHP file inclusion.\n\n\n  CVE-2005-1869: PHP file inclusion.\n\n\n  CVE-2005-1870: PHP file inclusion.\n\n\n  CVE-2005-2154: PHP local file inclusion.\n\n\n  CVE-2002-1704: PHP remote file include.\n\n\n  CVE-2002-1707: PHP remote file include.\n\n\n  CVE-2005-1964: PHP remote file include.\n\n\n  CVE-2005-1681: PHP remote file include.\n\n\n  CVE-2005-2086: PHP remote file include.\n\n\n  CVE-2004-0127: Directory traversal vulnerability in PHP include statement.\n\n\n  CVE-2005-1971: Directory traversal vulnerability in PHP include statement.\n\n\n  CVE-2005-3335: PHP file inclusion issue, both remote and local; local include uses\n  \"..\" and \"%00\" characters as a manipulation, but many remote file inclusion issues\n  probably have this vector.\n\n\n  CVE-2009-1936: chain: library file sends a redirect if it is directly requested\n  but continues to execute, allowing remote file inclusion and path traversal.'\nRelated_Attack_Patterns: '193: '\n"
]